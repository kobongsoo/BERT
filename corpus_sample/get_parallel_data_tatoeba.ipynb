{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b592bf7-2bd2-4afa-b7dc-bf52447e3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 언어쌍으로 된 말뭉치 다운로드\n",
    "# => bert 모델을 사용하여 영어에서 다른언어 모델로 학습을 이전시키는 작업에 사용되는 corpus\n",
    "#https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/multilingual/get_parallel_data_tatoeba.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce8ff0d2-4f3a-4c54-86c7-d92add0777d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tatoeba (https://tatoeba.org/) is a collection of sentences and translation, mainly aiming for language learning.\n",
    "It is available for more than 300 languages.\n",
    "This script downloads the Tatoeba corpus and extracts the sentences & translations in the languages you like\n",
    "\"\"\"\n",
    "import os\n",
    "import sentence_transformers\n",
    "import tarfile\n",
    "import gzip\n",
    "\n",
    "# Note: Tatoeba uses 3 letter languages codes (ISO-639-2),\n",
    "# while other datasets like OPUS / TED2020 use 2 letter language codes (ISO-639-1)\n",
    "# For training of sentence transformers, which type of language code is used doesn't matter.\n",
    "# For language codes, see: https://en.wikipedia.org/wiki/List_of_ISO_639-2_codes\n",
    "source_languages = set(['eng'])\n",
    "#target_languages = set(['deu', 'ara', 'tur', 'spa', 'ita', 'fra'])\n",
    "target_languages = set(['kor'])\n",
    "\n",
    "num_dev_sentences = 1000     #Number of sentences that are used to create a development set\n",
    "\n",
    "\n",
    "tatoeba_folder = \"../korpora/tatoeba\"\n",
    "output_folder = \"parallel-sentences/\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sentences_file_bz2 = os.path.join(tatoeba_folder, 'sentences.tar.bz2')\n",
    "sentences_file = os.path.join(tatoeba_folder, 'sentences.csv')\n",
    "links_file_bz2 = os.path.join(tatoeba_folder, 'links.tar.bz2')\n",
    "links_file = os.path.join(tatoeba_folder, 'links.csv')\n",
    "\n",
    "download_url = \"https://downloads.tatoeba.org/exports/\"\n",
    "\n",
    "\n",
    "os.makedirs(tatoeba_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd159eb-087c-4d3b-9d7a-1888ea90d803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download https://downloads.tatoeba.org/exports/sentences.tar.bz2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4bbf0b4865c46dbae3d6123058c6fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/160M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download https://downloads.tatoeba.org/exports/links.tar.bz2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2244b991036747668ed12adad73d1165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/109M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract ../korpora/tatoeba/sentences.tar.bz2\n",
      "Extract ../korpora/tatoeba/links.tar.bz2\n",
      "Read sentences.csv file\n",
      "Read links.csv\n",
      "Write output files\n",
      "eng-kor has 5680 sentences\n",
      "---DONE---\n"
     ]
    }
   ],
   "source": [
    "#Download files if needed\n",
    "for filepath in [sentences_file_bz2, links_file_bz2]:\n",
    "    if not os.path.exists(filepath):\n",
    "        url = download_url+os.path.basename(filepath)\n",
    "        print(\"Download\", url)\n",
    "        sentence_transformers.util.http_get(url, filepath)\n",
    "\n",
    "#Extract files if needed\n",
    "if not os.path.exists(sentences_file):\n",
    "    print(\"Extract\", sentences_file_bz2)\n",
    "    tar = tarfile.open(sentences_file_bz2, \"r:bz2\")\n",
    "    tar.extract('sentences.csv', path=tatoeba_folder)\n",
    "    tar.close()\n",
    "\n",
    "if not os.path.exists(links_file):\n",
    "    print(\"Extract\", links_file_bz2)\n",
    "    tar = tarfile.open(links_file_bz2, \"r:bz2\")\n",
    "    tar.extract('links.csv', path=tatoeba_folder)\n",
    "    tar.close()\n",
    "\n",
    "\n",
    "#Read sentences\n",
    "sentences = {}\n",
    "all_langs = target_languages.union(source_languages)\n",
    "print(\"Read sentences.csv file\")\n",
    "with open(sentences_file, encoding='utf8') as fIn:\n",
    "    for line in fIn:\n",
    "        id, lang, sentence = line.strip().split('\\t')\n",
    "        if lang in all_langs:\n",
    "            sentences[id] = (lang, sentence)\n",
    "\n",
    "#Read links that map the translations between different languages\n",
    "print(\"Read links.csv\")\n",
    "translations = {src_lang: {trg_lang: {} for trg_lang in target_languages} for src_lang in source_languages}\n",
    "with open(links_file, encoding='utf8') as fIn:\n",
    "    for line in fIn:\n",
    "        src_id, target_id = line.strip().split()\n",
    "\n",
    "        if src_id in sentences and target_id in sentences:\n",
    "            src_lang, src_sent = sentences[src_id]\n",
    "            trg_lang, trg_sent = sentences[target_id]\n",
    "\n",
    "            if src_lang in source_languages and trg_lang in target_languages:\n",
    "                if src_sent not in translations[src_lang][trg_lang]:\n",
    "                    translations[src_lang][trg_lang][src_sent] = []\n",
    "                translations[src_lang][trg_lang][src_sent].append(trg_sent)\n",
    "\n",
    "#Write everything to the output folder\n",
    "print(\"Write output files\")\n",
    "for src_lang in source_languages:\n",
    "    for trg_lang in target_languages:\n",
    "        source_sentences = list(translations[src_lang][trg_lang])\n",
    "        train_sentences = source_sentences[num_dev_sentences:]\n",
    "        dev_sentences = source_sentences[0:num_dev_sentences]\n",
    "\n",
    "        print(\"{}-{} has {} sentences\".format(src_lang, trg_lang, len(source_sentences)))\n",
    "        if len(dev_sentences) > 0:\n",
    "            with gzip.open(os.path.join(output_folder, 'Tatoeba-{}-{}-dev.tsv.gz'.format(src_lang, trg_lang)), 'wt', encoding='utf8') as fOut:\n",
    "                for sent in dev_sentences:\n",
    "                    fOut.write(\"\\t\".join([sent]+translations[src_lang][trg_lang][sent]))\n",
    "                    fOut.write(\"\\n\")\n",
    "\n",
    "        if len(train_sentences) > 0:\n",
    "            with gzip.open(os.path.join(output_folder, 'Tatoeba-{}-{}-train.tsv.gz'.format(src_lang, trg_lang)), 'wt', encoding='utf8') as fOut:\n",
    "                for sent in train_sentences:\n",
    "                    fOut.write(\"\\t\".join([sent]+translations[src_lang][trg_lang][sent]))\n",
    "                    fOut.write(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"---DONE---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6302f9b-79b2-44c8-8162-be2d256f837c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
