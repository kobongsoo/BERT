{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a21884-9f61-42dd-a66e-27e44246cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================================================\n",
    "# AI_HUB(https://aihub.or.kr/) 에 '대규모 웹데이터 기반 한국어 말뭉치 데이터'(json파일) 중에서\n",
    "# ***라벨링된 파일를 파싱해서, 2줄짜리 txt 말뭉치 만드는 예제\n",
    "# => 대규모 웹데이터 기반 한국어 말뭉치 데이터 \n",
    "# : https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=624\n",
    "#\n",
    "# 1. 위 URL에서 대규모 웹데이터 기반 한국어 말뭉치 데이터  다운로드\n",
    "# 2. 압축 풀기 \n",
    "# => unzip abc.zip -d <경로> # 특정 디렉토리에 압축 해제\n",
    "# \n",
    "#==============================================================================================================\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from typing import Dict, List, Optional\n",
    "sys.path.append(\"..\")\n",
    "from myutils import getListOfFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d064c4c0-c2b5-4871-8d29-85740c4e3d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*file_count: 10, file_list:['../../data11/ai_hub/vl1/test/BWSC217000050253.json', '../../data11/ai_hub/vl1/test/BWHE217000028346.json', '../../data11/ai_hub/vl1/test/BWEC217000009721.json', '../../data11/ai_hub/vl1/test/BWED217000013574.json', '../../data11/ai_hub/vl1/test/BWAC217000002828.json']\n"
     ]
    }
   ],
   "source": [
    "# 폴더에 있는 파일 목록 얻기(*반드시 /로 끝나야함)\n",
    "inpdirectory = '../../data11/ai_hub/vl1/test/'\n",
    "files = getListOfFiles(inpdirectory)\n",
    "\n",
    "print('*file_count: {}, file_list:{}'.format(len(files), files[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37759ef7-3126-4add-811a-50527be36412",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_text_len = 10        # MIN_SETENCE_LEN 이하인 문장은 추가 안함\n",
    "max_text_len = 150       # MAX 문장 길이 이상인 경우에는 .으로 구분해서 나눔\n",
    "SEP_STRING = ';$;'           # 2문장 구분자 => 문장A+[SET_STR]+문장B\n",
    "SEP_TYPE = 2                 # 어떻게 한줄에 문장을 나눌지?(0=문단으로 나눔, 1=1줄로 나눔, 2=2줄로 나눔)\n",
    "remove_pattern_list = ['@(이메일)', '<저작권자', '전재-재배포', '전재 및 재배포 금지>','무단 전재 및 재배포 금지']    # 문장에 remove_list에 들어간 경우 추가 안함 \n",
    "\n",
    "# 출력 파일 열기 \n",
    "outfilepath = '../../data11/ai_hub/vl1/vl1-2줄-test.txt'\n",
    "f1 = open(outfilepath, 'wt', encoding='utf-8')\n",
    "        \n",
    "# SEP_TYPE 범위를 벗어나면 error 발생!\n",
    "if SEP_TYPE < 0 or SEP_TYPE > 2:\n",
    "    raise Exception(\"SEP_TYPE 에러 (범위:0~2)\")\n",
    "    \n",
    "#================================================================================    \n",
    "# 입력 문장 목록을 가지고 패턴 검사 및 긴 문장 .로 분할해서 문장 전처리하는 함수\n",
    "# - inputlist = 문장 list\n",
    "# - remove_pattern_list = 해당 패턴 있는 문장은 제거\n",
    "# - min_len = 문장 최소길이(해당길이보다 작은 문장은 제거)\n",
    "# - max_len = 해당 길이보다 긴 문장은 .(마침표) 문장을 분할함.\n",
    "#================================================================================ \n",
    "def check_sentectlist(inputlist: List,       \n",
    "                      remove_pattern_list: List, \n",
    "                      min_len: int=10, max_len: int=200):\n",
    "    \n",
    "    outlist = [] \n",
    "    for sentence in inputlist:\n",
    "        text = sentence['sentence']\n",
    "        tlen = len(text)\n",
    "        \n",
    "        if tlen > min_len:\n",
    "               \n",
    "            # remove 패턴인 경우에는 추가안함\n",
    "            isremove = 0\n",
    "            for pattern in remove_pattern_list:\n",
    "                result = text.find(pattern)\n",
    "                if result > 0:\n",
    "                    isremove = 1\n",
    "                    break\n",
    "                              \n",
    "            if isremove == 0:\n",
    "                # 긴 문장인 경우에는 . 기준으로 나눠서 문장 만듬\n",
    "                if tlen > max_len:\n",
    "                    for text1 in text.split('.'):\n",
    "                        if text1 != '' and len(text1) > min_len:\n",
    "                            outlist.append(text1)\n",
    "                else:\n",
    "                    outlist.append(text)\n",
    "    \n",
    "    return outlist\n",
    "\n",
    "#==================================================================================\n",
    "# 2문장을 -> 1문장으로 합치기 \n",
    "# - inputlist = 문장 list\n",
    "# - sepstr = 문장1과 2 사이에 구분자\n",
    "#==================================================================================\n",
    "def line2(inputlist: List, \n",
    "          sepstr):\n",
    "    \n",
    "    start = 0\n",
    "    outlist = []\n",
    "    inputlist_len = len(inputlist)\n",
    "    for idx in range(inputlist_len):\n",
    "        # 2문장을 'sepstr' 기준으로 해서 1나의 문장으로. 만듬\n",
    "        outlist.append(inputlist[start].strip() + sepstr + inputlist[start+1].strip())\n",
    "        start += 2\n",
    "                    \n",
    "        if start >= inputlist_len-1:\n",
    "            break  \n",
    "    \n",
    "    return outlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a197d61-98eb-4eb5-83da-f6a4a5e73228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07975a6031854947a206829f867e9ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "   \n",
    "# 해당 json 파일들을 불러옴\n",
    "for idx, file in enumerate(tqdm(files)):\n",
    "    if \".json\" not in file:  #.json 파일이 아니면 합치지 않음\n",
    "        continue\n",
    "        \n",
    "    # json 파일 로딩 => [named_entity] entry만 불러옴\n",
    "    json_data = json.load(open(file, \"r\", encoding=\"utf-8\"))['named_entity']\n",
    "\n",
    "    for entry in json_data:\n",
    "        \n",
    "        sentences = []\n",
    "        \n",
    "        # title sentnece 추가\n",
    "        title = entry['title']\n",
    "        outlist = check_sentectlist(title, remove_pattern_list, min_text_len, max_text_len)\n",
    "        for text in outlist:\n",
    "            sentences.append(text)\n",
    "\n",
    "        # content sentence 추가\n",
    "        content = entry['content']\n",
    "        outlist = check_sentectlist(content, remove_pattern_list, min_text_len, max_text_len)\n",
    "        for text in outlist:\n",
    "            sentences.append(text)\n",
    "        \n",
    "        \n",
    "        # 문장이 2개 이상인 경우에만 처리 \n",
    "        num_sentences = len(sentences)\n",
    "        if num_sentences >= 2:\n",
    "            \n",
    "            if SEP_TYPE == 1:# 1줄씩 출력\n",
    "                f1.write(\"\\n\".join(sentences))\n",
    "                \n",
    "            elif SEP_TYPE == 2: #2줄씩 출력\n",
    "                data = line2(sentences, SEP_STRING)\n",
    "                for data1 in data:\n",
    "                    f1.write(data1+'\\n')\n",
    "                    \n",
    "            elif SEP_TYPE == 0: # 문단단위로 출력\n",
    "                f1.write(SEP_STRING.join(sentences))             \n",
    "                f1.write('\\n')\n",
    "                                    \n",
    "# 출력파일 닫기\n",
    "f1.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3af0531-215f-43e4-a5ac-0f87c1448b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7127\n"
     ]
    }
   ],
   "source": [
    "# out 생성된 파일 읽어오기(한줄씩 읽어오기)\n",
    "with open(outfilepath, 'r', encoding='UTF8') as f:\n",
    "     lines = f.readlines()\n",
    "        \n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9221ecf1-36f5-48de-ada5-bc0e38131404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"청호나이스, '먹는물·씻는물 안심' 정수기로 프리미엄시장 공략;$;청호나이스가 2가지 정수 시스템을 이용해 먹는 물과 씻는 물 모두 (이름)는 하이브리드 얼음정수기 ‘도도’를 출시했다.\\n\", '먹는 물에는 자사의 가장 뛰어난 필터 기술을 적용하고 식재료를 닦는 물에도 직수 필터 기술을 적용해 정수기 본질을 지킨 프리미엄 제품이라는 주장이다..;$;청호나이스는 환경오염과 생활 건강에 대한 소비자들 관심이 늘어나는 만큼 프리미엄 전략을 유지하며 직수 방식이나 다른 보급형 정수기를 쓰고 있는 가정을 고객으로 적극 끌어들일 계획이다.\\n', '해외시장에도 활발히 나서 매년 국내외 제품 매출을 2배 수준으로 키운다는 포부다..;$;청호나이스는 9일 서울시 중구 소재 서울 웨스턴(이름)텔에서 하이브리드 얼음정수기 ‘도도’ 출시 발표회를 열었다..\\n', '(이름) 청호나이스 대표는 최근 정수기들은 디자인, 가격 경쟁력만 강조하고 있지만 도도는 좋은 물이라는 정수기 본질에 집중했다고 강조했다..;$;이 대표는 “최근 정수기는 얼마나 작고 예쁜지 또 얼마나 저렴하게 렌탈할 수 있는지 등 디자인, 가격 측면만 강조돼 안타깝다”며 “청호나이스는 정수기 본질이 뭔지 고민했고 이런 고민 속에 도도를 출시했다”고 말했다..\\n', '■ 목적따라 2가지 정수물 제공.;$;도도의 가장 큰 특징은 2가지 정수 시스템이다.\\n', '먹는 물과 쌀, 채소 등 식재료 세척에 쓰는 물을 함께 제공한다.;$;두 시스템 목적이 다른 만큼 적용 기술도 차이가 있다..\\n', '음용수는 청호나이스 주력 정수 방식인 ro 멤브레인 필터와 포스트 카본 필터(역삼투압 방식)를 거쳐 정수기 코크에서 나온다.;$;ro 멤브레인 필터는 0.0001미크론(μ) 기공 크기의 초정밀 분리막으로 미세 플라스틱뿐만 아니라 중금속, 박테리아, 유기화학물질, 불소, 질산성 질소 등 유해 이온성 물질까지 제거한다..\\n', '청호나이스는 최고 품질의 ro 멤브레인 필터를 확보하기 위해 미국 화학업체 다우 케미칼(dow chemical), 정수처리업체 칼콘(calgon) 필터 재료를 원자재로 하고 있다.;$;필터 생산은 청호나이스 자회사 마이크로필터와 mcm가 맡고 있다..\\n', '생활수는 정수 성능은 살짝 떨어지지만 미생물, 바이러스, 일부 중금속을 잡아주면서 물량도 풍부한 직수 방식이 적용됐다.;$;음용수와 공통 첫 단계엔 t-카본 필터를 거친 후 0.2μ 수준 나노 섬유로 제작된 나노 필터를 거쳐 싱크대 조리수 밸브로 나온다..\\n', '청호나이스는 ro 멤브레인 정수와 직수 방식 모두 품질검사를 거쳐 국가통합인증마크 kc마크를 획득해 안심하고 사용할 수 있다고 밝혔다..;$;목경수 청호나이스 상무는 “미국항공우주국(nasa)에서는 ro 멤브레인 필터를 활용해 우주비행사들의 땀 같은 배설물을 걸러 마시는 물을 만들 정도”라고 말했다.\\n']\n"
     ]
    }
   ],
   "source": [
    "print(lines[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6accb1-ac75-48ab-bec8-5e934006d27a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
