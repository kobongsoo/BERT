{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d2266a-06cc-41fc-8573-51fee4628282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:../../log/s-bert-sts_2022-07-01.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "#======================================================================================================\n",
    "# sentence-bert STS 데이터셋을 가지고, 훈련 및 평가 예시\n",
    "#\n",
    "# => 기존 (distil)bert 모델을 가지고, STS 훈련 및 평가 후, S-BERT로 만드는 예시임.\n",
    "\n",
    "#=> 필요에 따라 출력 dimension을 768보다 작게 줄이고 싶을때 dense 모델을 추가해서 줄일수 있음\n",
    "#=> reduce_out_dimension = True 로 하면, 출력 임베딩 dimension이 줄어들게 설정가능함\n",
    "\n",
    "# => sentence-transformers 패키지를 이용하여 구현 함.(*pip install -U sentence-transformers 설치 필요)\n",
    "#\n",
    "# 도큐먼트 : https://www.sbert.net/index.html\n",
    "# 소스참고 : https://github.com/BM-K/KoSentenceBERT-ETRI\n",
    "\n",
    "# pip install -U sentence-transformers\n",
    "#======================================================================================================\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "\n",
    "sys.path.append('..')\n",
    "from myutils import seed_everything, GPU_info, mlogging\n",
    "\n",
    "logger = mlogging(loggername=\"s-bert-sts\", logfilename=\"../../log/s-bert-sts\")\n",
    "device = GPU_info()\n",
    "seed_everything(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560f4d38-e45e-4c30-87c8-7a16a002a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../data11/model/distilbert/distilbert-base-multilingual-cased-nlp_corpus_morphs_vocab_add/2 were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# s-bert로 만들 원본 bert 경로\n",
    "model_path = \"../../data11/model/distilbert/distilbert-base-multilingual-cased-nlp_corpus_morphs_vocab_add/2\"\n",
    "\n",
    "# 원본 bert를 sentencebert로 만든후 만들어진 s-bert 저장 경로\n",
    "#smodel_path = 'output/training_nli_'+model_name.replace(\"/\", \"-\")+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "smodel_path = \"../../data11/model/sbert/sbert-distilbert-nlp_corpus_morphs_vocab_add_768\"\n",
    "\n",
    "# 평가시 cosine 유사도등 측정 결과값 파일 (similarity_evaluation_xxxx.xls) 저장될 경로\n",
    "output_path = smodel_path\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "train_file_type = 2 #0이면 korsts.tsv 파일, 1이면 klue-stst.json 파일, 2이면 korsts.tsv, klue-sts.json 둘다 \n",
    "\n",
    "train_file1 = '../../data11/korpora/korsts/tune_train.tsv'\n",
    "eval_file1 = '../../data11/korpora/korsts/tune_dev.tsv'\n",
    "    \n",
    "train_file2 = '../../data11/korpora/klue-sts/klue-sts-v1.1_train.json'\n",
    "eval_file2 = '../../data11/korpora/klue-sts/klue-sts-v1.1_dev.json'\n",
    "       \n",
    "test_file = '../../data11/korpora/korsts/tune_test.tsv'\n",
    "\n",
    "train_batch_size = 32\n",
    "num_epochs = 100\n",
    "\n",
    "#============================================================================\n",
    "# *출력 dimension을 줄일 경우에는 True로 하고, out_dimension에 줄일 값을 설정함\n",
    "reduce_out_dimension = False  # True이면 dimension을 줄임=>Dense 모델 추가됨\n",
    "out_dimension = 128\n",
    "#============================================================================\n",
    "\n",
    "# 모델과 tokenizer 를 불러옴\n",
    "# => **사전파일(vocab.txt, *.json) 와 model 경로(config.json, pytorch_model.bin)가 같은 경로에 있어야 함.\n",
    "word_embedding_model = models.Transformer(model_path, max_seq_length=128)\n",
    "\n",
    "# word embedding_model 출력 \n",
    "print(word_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30816f29-8579-4b62-ab99-3f6436035657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "# 2 bert 모델의 임베딩 풀링 정책을 설정(cls 이용, 워드임베딩 평균이용, 워드임베딩 max 이용)\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),  #모델이 dimension(768)\n",
    "                               pooling_mode_mean_tokens=True,  # 워드 임베딩 평균을 이용\n",
    "                               pooling_mode_cls_token=False,   # cls 를 이용\n",
    "                               pooling_mode_max_tokens=False)  # 워드 임베딩 값중 max 값을 이용\n",
    "# pooling model 출력 \n",
    "print(pooling_model)\n",
    "print(pooling_model.get_sentence_embedding_dimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5a82c1-c5a5-467e-b758-362c7056918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. dense 모델 추가(옵션)\n",
    "#=> 필요에 따라 출력 dimension을 768보다 작게 줄이고 싶을때 dense 모델을 추가해서 줄임.\n",
    "#=> https://www.sbert.net/docs/training/overview.html?highlight=dense 참조\n",
    "if reduce_out_dimension:\n",
    "    dense_model = models.Dense(in_features=pooling_model.get_sentence_embedding_dimension(), # 입력 dimension은 앞에 pooling모델 embedding dimension으로 지정\n",
    "                               out_features=out_dimension,  # 출력 dimension\n",
    "                               activation_function=nn.Tanh())  # activation function은 Tahn으로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6609d844-3e00-42f9-ae0f-c12102b0925e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# SBERT 모델 생성\n",
    "if reduce_out_dimension:\n",
    "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model])\n",
    "else:\n",
    "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4de9a825-5d52-425f-aa0b-7afd2ce336f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-01 15:44:31,817 - s-bert-sts - INFO - Read STS train dataset=>../../data11/korpora/korsts/tune_train.tsv\n",
      "2022-07-01 15:44:31,853 - s-bert-sts - INFO - Read STS train dataset=>../../data11/korpora/klue-sts/klue-sts-v1.1_train.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비행기가 이륙하고 있다., 비행기가 이륙하고 있다., 1.0\n",
      "한 남자가 큰 플루트를 연주하고 있다., 남자가 플루트를 연주하고 있다., 0.76\n",
      "한 남자가 피자에 치즈를 뿌려놓고 있다., 한 남자가 구운 피자에 치즈 조각을 뿌려놓고 있다., 0.76\n",
      "세 남자가 체스를 하고 있다., 두 남자가 체스를 하고 있다., 0.52\n",
      "한 남자가 첼로를 연주하고 있다., 자리에 앉은 남자가 첼로를 연주하고 있다., 0.85\n",
      "*train_samples_len:17417\n",
      "[<sentence_transformers.readers.InputExample.InputExample object at 0x7f534c3f86d0>, <sentence_transformers.readers.InputExample.InputExample object at 0x7f50bc2f8c10>, <sentence_transformers.readers.InputExample.InputExample object at 0x7f50bc2f8fd0>]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# korsts 훈련 데이터 불러오기\n",
    "# => [sentence1, sentence2], labels 식으로 만듬\n",
    "train_samples = []\n",
    "count = 0\n",
    "    \n",
    "if train_file_type == 0 or train_file_type == 2:\n",
    "    logger.info(f\"Read STS train dataset=>{train_file1}\")\n",
    "    with open(train_file1, \"rt\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            text_a, text_b, score = line.split('\\t')\n",
    "            score = score.strip()\n",
    "            score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "            \n",
    "            if count < 5:\n",
    "                print(f\"{text_a}, {text_b}, {score}\")\n",
    "                \n",
    "            train_samples.append(InputExample(texts= [text_a,text_b], label=score))\n",
    "            count += 1\n",
    "            \n",
    "# klue 훈련 데이터 불러오기\n",
    "if train_file_type == 1 or train_file_type == 2:  \n",
    "    logger.info(f\"Read STS train dataset=>{train_file2}\")\n",
    "    with open(train_file2, \"rt\", encoding=\"utf-8\") as f:\n",
    "        datas = json.load(f)\n",
    "        for data in datas:\n",
    "            text_a = data[\"sentence1\"]\n",
    "            text_b = data[\"sentence2\"]\n",
    "            score = data[\"labels\"][\"label\"]\n",
    "            score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "\n",
    "            if count < 5:\n",
    "                print(f\"{text_a}, {text_b}, {score}\")\n",
    "\n",
    "            train_samples.append(InputExample(texts= [text_a,text_b], label=score))\n",
    "            count += 1\n",
    "        \n",
    "print(f'*train_samples_len:{len(train_samples)}')\n",
    "print(train_samples[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "840a2b16-b2f5-4f97-a751-248c9a7bc1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋, 데이터 로더, 손실함수 정의\n",
    "train_dataset = SentencesDataset(train_samples, model=model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a5ab735-a87e-4ca9-a3d7-03f8949b392a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-01 15:44:58,205 - s-bert-sts - INFO - Read STS dev dataset=>../../data11/korpora/korsts/tune_dev.tsv\n",
      "2022-07-01 15:44:58,232 - s-bert-sts - INFO - Read STS dev dataset=>../../data11/korpora/klue-sts/klue-sts-v1.1_dev.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안전모를 가진 한 남자가 춤을 추고 있다., 안전모를 쓴 한 남자가 춤을 추고 있다., 1.0\n",
      "어린아이가 말을 타고 있다., 아이가 말을 타고 있다., 0.95\n",
      "한 남자가 뱀에게 쥐를 먹이고 있다., 남자가 뱀에게 쥐를 먹이고 있다., 1.0\n",
      "한 여성이 기타를 연주하고 있다., 한 남자가 기타를 치고 있다., 0.48\n",
      "한 여성이 플루트를 연주하고 있다., 남자가 플루트를 연주하고 있다., 0.55\n",
      "*dev_samples_len:2019\n",
      "[<sentence_transformers.readers.InputExample.InputExample object at 0x7f50bf01a490>, <sentence_transformers.readers.InputExample.InputExample object at 0x7f50bf01a760>, <sentence_transformers.readers.InputExample.InputExample object at 0x7f50bf01a520>]\n"
     ]
    }
   ],
   "source": [
    "#Read STSbenchmark dataset and use it as development set\n",
    "# 평가데이터 불러오기\n",
    "#korsts 파일로 두 문장간 유사도를 수치로(5.0이 만점=매우 유사) 측정함.\n",
    "dev_samples = []\n",
    "count = 0\n",
    "\n",
    "# korSTS.tsv 파일인 경우 \n",
    "if train_file_type == 0 or train_file_type == 2:\n",
    "    logger.info(f\"Read STS dev dataset=>{eval_file1}\")\n",
    "    with open(eval_file1, 'rt', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            text_a, text_b, score = line.split('\\t')\n",
    "            score = score.strip()\n",
    "            score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "            \n",
    "            if count < 5:\n",
    "                print(f\"{text_a}, {text_b}, {score}\")\n",
    "            \n",
    "            dev_samples.append(InputExample(texts= [text_a,text_b], label=score))\n",
    "            count += 1\n",
    "            \n",
    "#KLUE-STS.json 파일인 경우            \n",
    "if train_file_type == 1 or train_file_type == 2:\n",
    "    logger.info(f\"Read STS dev dataset=>{eval_file2}\")\n",
    "    with open(eval_file2, \"rt\", encoding=\"utf-8\") as f:\n",
    "        datas = json.load(f)\n",
    "        for data in datas:\n",
    "            text_a = data[\"sentence1\"]\n",
    "            text_b = data[\"sentence2\"]\n",
    "            score = data[\"labels\"][\"label\"]\n",
    "            score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "\n",
    "            if count < 5:\n",
    "                print(f\"{text_a}, {text_b}, {score}\")\n",
    "\n",
    "            dev_samples.append(InputExample(texts= [text_a,text_b], label=score))\n",
    "            count += 1\n",
    " \n",
    "print(f'*dev_samples_len:{len(dev_samples)}')\n",
    "print(dev_samples[0:3])\n",
    "\n",
    "# 2개의 bert 모델에서 구한 2개의 embedding 값들의 cosine 유사도를 구해서, 이를 실제 score와 비교해서 유사도 측정함\n",
    "dev_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, \n",
    "                                                                 batch_size=train_batch_size, \n",
    "                                                                 name='sts-dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea020cec-bd98-4385-a202-86c76adee505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#warmup_step은 10% 로 설정\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) \n",
    "\n",
    "# evaluation_steps은 20%로 설정\n",
    "evaluation_steps = int(len(train_dataset) * num_epochs / train_batch_size * 0.2)\n",
    "\n",
    "logger.info(f\"model:{model_path}, smodel:{smodel_path}\")\n",
    "logger.info(\"*batch_size: {}, epoch:{}, train_dataset:{}, Warmup-steps: {}, evaluation_step: {}\".format(train_batch_size, num_epochs, len(train_dataset), warmup_steps, evaluation_steps))\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=dev_evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=evaluation_steps,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=smodel_path\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ce8ee-8b39-4c09-9ce3-85ac036af96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "# => 훈련되어서 저장된 s-bert 모델을 불러와서 성능 평가 해봄\n",
    "##############################################################################\n",
    "import time\n",
    "\n",
    "test_samples = []\n",
    "with open(test_file, 'rt', encoding='utf-8') as fIn:\n",
    "    lines = fIn.readlines()\n",
    "    for line in lines:\n",
    "        s1, s2, score = line.split('\\t')\n",
    "        score = score.strip()\n",
    "        score = float(score) / 5.0\n",
    "        test_samples.append(InputExample(texts=[s1,s2], label=score))\n",
    "\n",
    "logger.info(\"\\n\")\n",
    "logger.info(\"======================TEST===================\")\n",
    "logger.info(\"\\n\\n\")\n",
    "logger.info(f\"model save path > {smodel_path}\")\n",
    "start = time.time()\n",
    "model = SentenceTransformer(smodel_path)\n",
    "\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, batch_size=train_batch_size, name='sts-test', show_progress_bar=True)\n",
    "result = test_evaluator(model, output_path=output_path)\n",
    "\n",
    "logger.info(f\"\\n\")\n",
    "logger.info(f\"model path: {smodel_path}\")\n",
    "logger.info(f'=== result: {result} ===')\n",
    "logger.info(f'=== 처리시간: {time.time() - start:.3f} 초 ===')\n",
    "logger.info(\"==============================================\")\n",
    "logger.info(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79dcfa5-7474-4e72-ba49-b77dbdb2ee5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
