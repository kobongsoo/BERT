{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52dd55f0-57f8-42f9-9baa-841ba49e739e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:../../../log/s-bert_2022-09-26.log\n",
      "False\n",
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "#=========================================================================================================\n",
    "# 말뭉치를 가지고, STS Siver dataset 생성하는 예시\n",
    "#\n",
    "# - 1단계: 유사문장들 구할 bi_encoder 모델 정의, 스코어를 기록할 cross_encoder 모델 정의\n",
    "# - 2단계: bi_encoder를 이용하여 입력 말뭉치에서 각 문장당 유사한 문장들 쌍을 구함\n",
    "# - 3단계: cros_encoder를 이용하여 유사문장들에 대해 각 유사도 스코어를 매김\n",
    "#=========================================================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import math\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "\n",
    "sys.path.append('../../')\n",
    "from myutils import seed_everything, GPU_info, mlogging\n",
    "\n",
    "logger = mlogging(loggername=\"s-bert\", logfilename=\"../../../log/s-bert\")\n",
    "device = GPU_info()\n",
    "seed_everything(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6e9c902-c822-42bf-aed2-d84dfb879b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라메터들 정의 (필요한 값들 정의)\n",
    "max_seq_len = 128\n",
    "top_k = 3             # 훈련데이터에서 몇개의 유사도 문장을 뽑아낼지 정하는 값\n",
    "train_batch_size = 32\n",
    "\n",
    "# STS siver_data 만들 말뭉치\n",
    "corpus_path = '../../../../korpora/moco_1_small.txt'\n",
    "\n",
    "# STS siver_data  출력 파일 경로\n",
    "silver_data_file = 'silver_data-moco-sentencebertV2.1.tsv'\n",
    "\n",
    "# bi_encoder 모델 경로 \n",
    "# => paraphrase-multilingual-mpnet-base-v2 를 이용\n",
    "# bi_encoder_path = \"../../../model/sbert/teacher/paraphrase-multilingual-mpnet-base-v2/\"\n",
    "bi_encoder_path = \"../../../../model/sbert/sbert-mdistilbertV2.1-distil-sts/\"\n",
    "\n",
    "# cross 모델 경로 \n",
    "ce_model_path = \"../../../../model/sbert/sbert-mdistilbertV2.1-distil-sts/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde53ce5-6a5a-490e-abb6-342a4271b441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#======================================================================================================\n",
    "# bi-encoder 정의\n",
    "# => 훈련 데이터들의 유사도 문장들를 구할 bi-encoder 모델 정의\n",
    "#======================================================================================================\n",
    "word_embedding_encoder = models.Transformer(bi_encoder_path, max_seq_length=max_seq_len)\n",
    "\n",
    "pooling_encoder = models.Pooling(word_embedding_encoder.get_word_embedding_dimension(),  #모델이 dimension(768)\n",
    "                               pooling_mode_mean_tokens=True,  # 워드 임베딩 평균을 이용\n",
    "                               pooling_mode_cls_token=False,   # cls 를 이용\n",
    "                               pooling_mode_max_tokens=False)  # 워드 임베딩 값중 max 값을 이용\n",
    "\n",
    "bi_encoder = SentenceTransformer(modules=[word_embedding_encoder, pooling_encoder])\n",
    "print(bi_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eca70c09-4abf-4ea6-b36a-13000c6595e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at ../../../../model/sbert/sbert-mdistilbertV2.1-distil-sts/ and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sentence_transformers.cross_encoder.CrossEncoder.CrossEncoder object at 0x0000028CD228E240>\n"
     ]
    }
   ],
   "source": [
    "#======================================================================================================\n",
    "# cross-encoder 모델 정의\n",
    "ce_model = CrossEncoder(ce_model_path, num_labels=1)\n",
    "#======================================================================================================\n",
    "print(ce_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3b10e9a-8b0d-4f90-934d-0e83dc0f12c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139f9baad20a437e8cdf9fd8d02bf2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi_encoder.encoder Start===>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b45cf266254d028aab7f19907a80e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi_encoder.encode End<===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0cb6ccdd8843338d5420ceaf702e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_encoder.predict start===>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ced682723b04e7799b0e3050516831b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_encoder.predict End<===\n",
      "9016\n",
      "[('필요 시 입력 데이터를 생성하는 외부시스템이 시스템에 접근할 수 있는 FTP 계정과 비밀번호 설정하며 다른 디렉토리에 접근을 막는다.', '외부시스템과 데이터를 주고 받기 위해 사용되는 디렉토리는 다음과 같다.'), ('필요 시 입력 데이터를 생성하는 외부시스템이 시스템에 접근할 수 있는 FTP 계정과 비밀번호 설정하며 다른 디렉토리에 접근을 막는다.', '특히 당사의 주력사업인 보안관제 및 보안컨설팅 사업의 경우 사업장 내 인력 투입 필요성으로 인한 물리적 요인 및 국가간 규제등 다양한 요인에 따라 해외 진출이 쉽지 않습니다.'), ('필요 시 입력 데이터를 생성하는 외부시스템이 시스템에 접근할 수 있는 FTP 계정과 비밀번호 설정하며 다른 디렉토리에 접근을 막는다.', '보안관제 및 보안컨설팅 사업의 경우 사업장 내 인력 투입 필요성으로 인한 물리적 요인 및 국가간규제 등 다양한 요인에 따라 해외 진출이 쉽지 않습니다.'), ('외부시스템과 데이터를 주고 받기 위해 사용되는 디렉토리는 다음과 같다.', '유닛플로우에 대한 외부 실행시 사용하는 실행파일.'), ('외부시스템과 데이터를 주고 받기 위해 사용되는 디렉토리는 다음과 같다.', '하위 디렉토리에 해당 런너 관련 파일들이 생성됩니다.')]\n",
      "[0.50276655 0.48992833 0.48731878 0.48315886 0.48548257]\n"
     ]
    }
   ],
   "source": [
    "# 문장들을 불러옴.\n",
    "sentneces = []\n",
    "with open(corpus_path, encoding=\"utf-8\") as f:\n",
    "    sentences = [line for line in tqdm(f.read().splitlines()) if (len(line) > 0 and not line.isspace())]\n",
    "\n",
    "print(f'bi_encoder.encoder Start===>')\n",
    "# 문장들의 embedding을 구함.(*오래걸림)\n",
    "embeddings = bi_encoder.encode(sentences, batch_size=train_batch_size, show_progress_bar=True, convert_to_tensor=True)\n",
    "print(f'bi_encoder.encode End<===')\n",
    "\n",
    "# 각 문장들에서 유사도가 높은 문장들을 쌍으로 묶음\n",
    "duplicates = set()\n",
    "silver_train_data = []\n",
    "\n",
    "for idx in tqdm(range(len(sentences)), unit=\"docs\"):\n",
    "    sentence_embedding = embeddings[idx]\n",
    "    cos_scores = util.pytorch_cos_sim(sentence_embedding, embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "    top_results = torch.topk(cos_scores, k=top_k+1)\n",
    "    \n",
    "    for score, iid in zip(top_results[0], top_results[1]):\n",
    "        if iid != idx and (iid, idx) not in duplicates:\n",
    "            silver_train_data.append((sentences[idx], sentences[iid]))\n",
    "            duplicates.add((idx, iid))\n",
    "\n",
    "# 신규 데이터 말뭉치에 대해 score를 추가함\n",
    "print(f'cross_encoder.predict start===>')\n",
    "silver_scores = ce_model.predict(silver_train_data, show_progress_bar=True)\n",
    "print(f'cross_encoder.predict End<===')\n",
    "\n",
    "print(f'siver_data_len: {len(silver_train_data)}')\n",
    "print(silver_train_data[0:5])\n",
    "print(silver_scores[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "783d4128-0389-4a69-97ee-5124e13c9c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc887fcd1b7549598520d22304629954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# silver_data 를 .tsv 파일로 저장 해둠.\n",
    "\n",
    "with open(silver_data_file, 'w', encoding='utf-8') as f:\n",
    "    for data, score in tqdm(zip(silver_train_data, silver_scores)):\n",
    "        f.write(data[0]+'\\t')\n",
    "        f.write(data[1]+'\\t')\n",
    "        f.write(str(score) + '\\n')  \n",
    "        #print(f\"({data[0]} : {data[1]}: {str(score)})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
