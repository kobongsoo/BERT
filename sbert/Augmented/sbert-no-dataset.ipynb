{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52dd55f0-57f8-42f9-9baa-841ba49e739e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:../../log/bwdataset_2022-04-25.log\n",
      "logfilepath:../../log/qnadataset_2022-04-25.log\n",
      "logfilepath:../../log/s-bert_2022-04-25.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "#=========================================================================================================\n",
    "#문장쌍 STS dataset 이 없는 경우 예시\n",
    "#\n",
    "# - 1단계: 기존 korsts, kluests 등 sts dataset을 가지고, Cross-Encoder로 BERT 훈련 시킴\n",
    "# - 2단계: 1단계에서 훈련시킨 BERT를 Cross-Encoder로 label이 없는 sts dataset에 대해 label을 지정함\n",
    "# - 3단계: label이 지정된 sts dataset에 대해 Bi-Encoder 훈련 시킴\n",
    "#=========================================================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import math\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "\n",
    "sys.path.append('../../')\n",
    "from myutils import seed_everything, GPU_info, mlogging\n",
    "\n",
    "logger = mlogging(loggername=\"s-bert\", logfilename=\"../../log/s-bert\")\n",
    "device = GPU_info()\n",
    "seed_everything(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9209e358-3b19-4ff1-9749-07f492958ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../../model/bert/bmc-fpt-bong_corpus_mecab-0424/batch:32-ep:4-lr:0.000030000-4m25d-8:27/ were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../../../model/bert/bmc-fpt-bong_corpus_mecab-0424/batch:32-ep:4-lr:0.000030000-4m25d-8:27/ and are newly initialized: ['bert.pooler.dense.weight', 'classifier.bias', 'bert.pooler.dense.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sentence_transformers.cross_encoder.CrossEncoder.CrossEncoder object at 0x7f20d83f1b20>\n"
     ]
    }
   ],
   "source": [
    "# 모델들 정의\n",
    "max_seq_len = 128\n",
    "train_batch_size = 32\n",
    "num_epochs = 10\n",
    "top_k = 3             # 훈련데이터에서 몇개의 유사도 문장을 뽑아낼지 정하는 값\n",
    "\n",
    "#======================================================================================================\n",
    "# cross-encoder 모델 정의\n",
    "ce_model_path = \"../../../model/bert/bmc-fpt-bong_corpus_mecab-0424/batch:32-ep:4-lr:0.000030000-4m25d-8:27/\"\n",
    "ce_model = CrossEncoder(ce_model_path, num_labels=1)\n",
    "#======================================================================================================\n",
    "print(ce_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7bf7173-b8fc-4385-8cc9-a78106654c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다., 숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다., 0.74\n",
      "위반행위 조사 등을 거부·방해·기피한 자는 500만원 이하 과태료 부과 대상이다., 시민들 스스로 자발적인 예방 노력을 한 것은 아산 뿐만이 아니었다., 0.0\n",
      "회사가 보낸 메일은 이 지메일이 아니라 다른 지메일 계정으로 전달해줘., 사람들이 주로 네이버 메일을 쓰는 이유를 알려줘, 0.06\n",
      "긴급 고용안정지원금은 지역고용대응 등 특별지원금, 지자체별 소상공인 지원사업, 취업성공패키지, 청년구직활동지원금, 긴급복지지원제도 지원금과는 중복 수급이 불가능하다., 고용보험이 1차 고용안전망이라면, 국민취업지원제도는 2차 고용안전망입니다., 0.12\n",
      "호스트의 답장이 늦으나, 개선될 것으로 보입니다., 호스트 응답이 늦었지만 개선될 것으로 보입니다., 0.9400000000000001\n",
      "무엇보다도 호스트분들이 너무 친절하셨습니다., 무엇보다도, 호스트들은 매우 친절했습니다., 0.9800000000000001\n",
      "주요 관광지 모두 걸어서 이동가능합니다., 위치는 피렌체 중심가까지 걸어서 이동 가능합니다., 0.27999999999999997\n",
      "학생들의 균형 있는 영어능력을 향상시킬 수 있는 학교 수업을 유도하기 위해 2018학년도 수능부터 도입된 영어 영역 절대평가는 올해도 유지한다., 영어 영역의 경우 학생들이 한글 해석본을 암기하는 문제를 해소하기 위해 2016학년도부터 적용했던 EBS 연계 방식을 올해도 유지한다., 0.26\n",
      "다만, 도로와 인접해서 거리의 소음이 들려요., 하지만, 길과 가깝기 때문에 거리의 소음을 들을 수 있습니다., 0.74\n",
      "형이 다시 캐나다 들어가야 하니 가족모임 일정은 바꾸지 마세요., 가족 모임 일정은 바꾸지 말도록 하십시오., 0.5\n",
      "[<sentence_transformers.readers.InputExample.InputExample object at 0x7f1e4817b7f0>, <sentence_transformers.readers.InputExample.InputExample object at 0x7f1dca16bc70>]\n",
      "[<sentence_transformers.readers.InputExample.InputExample object at 0x7f1e48cff250>, <sentence_transformers.readers.InputExample.InputExample object at 0x7f1e48cff460>]\n"
     ]
    }
   ],
   "source": [
    "#  1단계: 기존 korsts, kluests 등 sts dataset을 가지고, Cross-Encoder로 BERT 훈련 시킴\n",
    "# => 여기서는 kluests를 가지고 훈련시킴\n",
    "import json\n",
    "\n",
    "train_file = '../../../korpora/klue-sts/klue-sts-v1.1_train.json'\n",
    "eval_file = '../../../korpora/klue-sts/klue-sts-v1.1_dev.json'\n",
    "count = 0\n",
    "\n",
    "# 훈련 골드 데이터 불러옴\n",
    "train_gold_samples = []\n",
    "with open(train_file, \"rt\", encoding=\"utf-8\") as f:\n",
    "    datas = json.load(f)\n",
    "    for data in datas:\n",
    "        text_a = data[\"sentence1\"]\n",
    "        text_b = data[\"sentence2\"]\n",
    "        score = data[\"labels\"][\"label\"]\n",
    "        score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "\n",
    "        if count < 5:\n",
    "            print(f\"{text_a}, {text_b}, {score}\")\n",
    "\n",
    "        train_gold_samples.append(InputExample(texts= [text_a,text_b], label=score))\n",
    "        count += 1\n",
    "      \n",
    "# 평가 데이터 불러옴\n",
    "count = 0\n",
    "dev_samples = []\n",
    "with open(eval_file, 'rt', encoding='utf-8') as f:\n",
    "    datas = json.load(f)\n",
    "    for data in datas:\n",
    "        text_a = data[\"sentence1\"]\n",
    "        text_b = data[\"sentence2\"]\n",
    "        score = data[\"labels\"][\"label\"]\n",
    "        score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "\n",
    "        if count < 5:\n",
    "            print(f\"{text_a}, {text_b}, {score}\")\n",
    "\n",
    "        dev_samples.append(InputExample(texts= [text_a,text_b], label=score))\n",
    "        count += 1\n",
    "        \n",
    "# 훈련 골드 데이터로더, 평가 데이터 로더 생성\n",
    "train_dataloader = DataLoader(train_gold_samples, shuffle=True, batch_size=train_batch_size)\n",
    "evaluator = CECorrelationEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "print(train_gold_samples[0:2])\n",
    "print(dev_samples[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e134133a-d77d-4df1-9c18-50aeb7cf4a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 14:19:13,002 - s-bert - INFO - Warmup-steps: 365\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23aa8422fcac4d34b3451fe96ceda845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb77c1f69de4cfa94265a68b8fe6bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55884a71ec324eb2ae29c82ffb6969f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93927e4838b640fdae6955652a77cb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10baef680e144aa7bb21b8fff90e2610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667509ccca644e1b8adfb86210098670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae58296650d4101ac99c392704ba926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cf2eb3a0704b338760ea1f4cd5d93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ddc7bb843f4b4daab26ee871769c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdc0778687742daaafa096aa08af5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aeb6170854c4faeb965efda74cf19b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1단계: 적은 STS dataset(gold sts dataset) 에 대해 Cross-Encoder로 BERT 훈련 시킴\n",
    "\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "logger.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "ce_odel_save_path = 'output/crossencoder-sts-train-'+datetime.now().strftime(\"%Y-%m-%d-%H:%M\")\n",
    "\n",
    "# Train the model\n",
    "ce_model.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=ce_odel_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2098c542-119b-41b2-8d4f-196f44487bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c30094121e84d5da5c3b4f55c212cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce32581586e941649aa6b7ae5acaa03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9818 [00:00<?, ?docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29504\n",
      "[('제임스 얼 \"지미\" 카터 주니어는 민주당 출신 미국 39번째 대통령 이다.', '46세의 나이로 대통령이 된 그는 역대 미국 대통령 중에서 세 번째로 젊은 대통령이었다.'), ('제임스 얼 \"지미\" 카터 주니어는 민주당 출신 미국 39번째 대통령 이다.', '클린턴은 프랭클린 루스벨트 이후로 두번의 임기를 모두 채운 첫 번째 민주당 대통령이었다.'), ('제임스 얼 \"지미\" 카터 주니어는 민주당 출신 미국 39번째 대통령 이다.', '1993년 민주당 최연소 최고위원이 되었다.'), ('지미 카터는 조지아주 섬터 카운티 플레인스 마을에서 태어났다.', '그녀는 미국의 남부 조지아주 애틀랜타에서 태어났다.'), ('지미 카터는 조지아주 섬터 카운티 플레인스 마을에서 태어났다.', '제임스 얼 \"지미\" 카터 주니어는 민주당 출신 미국 39번째 대통령 이다.')]\n",
      "[0.26152834 0.30554742 0.04845052 0.49450356 0.35710645]\n"
     ]
    }
   ],
   "source": [
    "# 2단계: 1단계에서 훈련시킨 BERT를 Cross-Encoder로 label이 없는 sts dataset에 대해 label을 지정함\n",
    "# => 여기서는 sts dataset도 없고, 그냥 문장 말뭉치만 있는 경우를 가정함.\n",
    "\n",
    "#======================================================================================================\n",
    "# 훈련 데이터들의 유사도 문장들를 구할 bi-encoder 모델 정의\n",
    "# => paraphrase-multilingual-mpnet-base-v2 를 이용\n",
    "bi_encoder_path = \"../../../model/sbert/teacher/paraphrase-multilingual-mpnet-base-v2/\"\n",
    "\n",
    "word_embedding_encoder = models.Transformer(bi_encoder_path, max_seq_length=max_seq_len)\n",
    "\n",
    "pooling_encoder = models.Pooling(word_embedding_encoder.get_word_embedding_dimension(),  #모델이 dimension(768)\n",
    "                               pooling_mode_mean_tokens=True,  # 워드 임베딩 평균을 이용\n",
    "                               pooling_mode_cls_token=False,   # cls 를 이용\n",
    "                               pooling_mode_max_tokens=False)  # 워드 임베딩 값중 max 값을 이용\n",
    "\n",
    "bi_encoder = SentenceTransformer(modules=[word_embedding_encoder, pooling_encoder])\n",
    "#======================================================================================================\n",
    "\n",
    "# 문장들을 불러옴.\n",
    "corpus_path = '../../../korpora/kowiki_20190620/wiki_20190620_small.txt'\n",
    "sentneces = []\n",
    "with open(corpus_path, encoding=\"utf-8\") as f:\n",
    "    sentences = [line for line in tqdm(f.read().splitlines()) if (len(line) > 0 and not line.isspace())]\n",
    "    \n",
    "# 문장들의 embedding을 구함.\n",
    "embeddings = bi_encoder.encode(sentences, batch_size=train_batch_size, convert_to_tensor=True)\n",
    "\n",
    "# 각 문장들에서 유사도가 높은 문장들을 쌍으로 묶음\n",
    "duplicates = set()\n",
    "silver_train_data = []\n",
    "\n",
    "for idx in tqdm(range(len(sentences)), unit=\"docs\"):\n",
    "    sentence_embedding = embeddings[idx]\n",
    "    cos_scores = util.pytorch_cos_sim(sentence_embedding, embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "    top_results = torch.topk(cos_scores, k=top_k+1)\n",
    "    \n",
    "    for score, iid in zip(top_results[0], top_results[1]):\n",
    "        if iid != idx and (iid, idx) not in duplicates:\n",
    "            silver_train_data.append((sentences[idx], sentences[iid]))\n",
    "            duplicates.add((idx, iid))\n",
    "\n",
    "# 신규 데이터 말뭉치에 대해 score를 추가함\n",
    "cs_new_model = CrossEncoder(ce_odel_save_path)\n",
    "silver_scores = cs_new_model.predict(silver_train_data)\n",
    "\n",
    "print(len(silver_train_data))\n",
    "print(silver_train_data[0:5])\n",
    "print(silver_scores[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3833dfca-8d56-4c9f-a28b-fe1d5225d584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f7d3951472499a98b5cb2b89bce281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# silver_data 를 .tsv 파일로 저장 해둠.\n",
    "silver_data_file = 'output/silver_data-'+datetime.now().strftime(\"%Y-%m-%d-%H:%M\")+'.tsv'\n",
    "with open(silver_data_file, 'w', encoding='utf-8') as f:\n",
    "    for data, score in tqdm(zip(silver_train_data, silver_scores)):\n",
    "        f.write(data[0]+'\\t')\n",
    "        f.write(data[1]+'\\t')\n",
    "        f.write(str(score) + '\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fa37885-35bd-40aa-bd58-c4fda2cf3e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../../model/bert/bmc-fpt-bong_corpus_mecab-0424/batch:32-ep:4-lr:0.000030000-4m25d-8:27/ were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ../../../model/bert/bmc-fpt-bong_corpus_mecab-0424/batch:32-ep:4-lr:0.000030000-4m25d-8:27/ and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f343316ea74de5b9586422ea5d9bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b83b962e1d14f89ad7b7faf366ba8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7182846c394c6d9c17cc8f5ac4e001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cbd87e6dcb440ca5580a10acba6e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3c337dd00a46ad81ef3ff1f9738d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b86c54bb314bb8b6bed85745c58edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7092a44b0f4237b35bf05e063c5844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b343cba22fe64db1b7bafb9c36c6b960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f9277a0ba94168ace6f6c2a864f464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46eb6edcb844ca0a3b02d7ddfc11f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7f0711416545ecaa128a0708c71bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3단계: gold sts dataset + silver sts dataset 을 훈련 데이터로 하여 Bi-Encoder 훈련 시킴\n",
    "\n",
    "#======================================================================================================\n",
    "# bi-encoder 모델 정의\n",
    "\n",
    "# word_embedding 모델은 앞에서 할 cross-encoder 모델 경로로 지정함 \n",
    "word_embedding_model = models.Transformer(ce_model_path, max_seq_length=max_seq_len)\n",
    "\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),  #모델이 dimension(768)\n",
    "                               pooling_mode_mean_tokens=True,  # 워드 임베딩 평균을 이용\n",
    "                               pooling_mode_cls_token=False,   # cls 를 이용\n",
    "                               pooling_mode_max_tokens=False)  # 워드 임베딩 값중 max 값을 이용\n",
    "\n",
    "bi_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "#======================================================================================================\n",
    "\n",
    "train_silver_samples = list(InputExample(texts=[data[0], data[1]], label=score) for \\\n",
    "    data, score in zip(silver_train_data, silver_scores))\n",
    "\n",
    "train_dataset = SentencesDataset(train_gold_samples + train_silver_samples, bi_model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=bi_model)\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "# Configure the training.\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "#logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "model_save_path = 'output/sbert-sts-train-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "# Train the bi-encoder model\n",
    "bi_model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4ef6cf-8983-43a9-b85c-2fab8e6a3f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
