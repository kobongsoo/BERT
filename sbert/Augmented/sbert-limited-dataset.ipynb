{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52dd55f0-57f8-42f9-9baa-841ba49e739e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:../../log/bwdataset_2022-04-25.log\n",
      "logfilepath:../../log/qnadataset_2022-04-25.log\n",
      "logfilepath:../../log/s-bert_2022-04-25.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "#=========================================================================================================\n",
    "#문장쌍 STS dataset 이 적은 경우(label이 적은 경우) 예시\n",
    "#\n",
    "# -1단계: 적은 STS dataset(gold sts dataset) 에 대해 Cross-Encoder로 BERT 훈련 시킴\n",
    "# -2.1단계: 기존 잘 훈련된 S-BERT(예: distiluse-base-multilingual-cased-v2)를 이용해, gold sts 문장들에 대해 유사도 측정해서, \n",
    "#           한 문장에 대해 K수만큼 유사한 문장들을 조합하여 문장 쌍을 만듬\n",
    "# -2.2단계: 1E단계에서 훈련된 BERT 로 2.1단계에서 만든 문장쌍들에 대해 점수를 매김->이를 silver sts dataset이라고 함\n",
    "# -3단계: gold sts dataset + silver sts dataset 을 훈련 데이터로 하여 Bi-Encoder 훈련 시킴\n",
    "#=========================================================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import math\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "\n",
    "sys.path.append('../../')\n",
    "from myutils import seed_everything, GPU_info, mlogging\n",
    "\n",
    "logger = mlogging(loggername=\"s-bert\", logfilename=\"../../log/s-bert\")\n",
    "device = GPU_info()\n",
    "seed_everything(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9209e358-3b19-4ff1-9749-07f492958ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../../model/bert/bmc-fpt-bong_corpus_mecab-0424/batch:32-ep:4-lr:0.000030000-4m25d-8:27/ were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../../../model/bert/bmc-fpt-bong_corpus_mecab-0424/batch:32-ep:4-lr:0.000030000-4m25d-8:27/ and are newly initialized: ['classifier.weight', 'bert.pooler.dense.weight', 'classifier.bias', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sentence_transformers.cross_encoder.CrossEncoder.CrossEncoder object at 0x7fa7827cb400>\n",
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델들 정의\n",
    "max_seq_len = 128\n",
    "train_batch_size = 32\n",
    "num_epochs = 10\n",
    "top_k = 3             # 훈련데이터에서 몇개의 유사도 문장을 뽑아낼지 정하는 값\n",
    "\n",
    "#======================================================================================================\n",
    "# cross-encoder 모델 정의\n",
    "ce_model_path = \"../../../model/bert/bmc-fpt-bong_corpus_mecab-0424/batch:32-ep:4-lr:0.000030000-4m25d-8:27/\"\n",
    "ce_model = CrossEncoder(ce_model_path, num_labels=1)\n",
    "#======================================================================================================\n",
    "\n",
    "#======================================================================================================\n",
    "# 훈련 데이터들의 유사도 문장들를 구할 bi-encoder 모델 정의\n",
    "# => distiluse-base-multilingual-cased-v2 를 이용\n",
    "bi_encoder_path = \"../../../model/sbert/teacher/distiluse-base-multilingual-cased-v2/\"\n",
    "\n",
    "word_embedding_encoder = models.Transformer(bi_encoder_path, max_seq_length=max_seq_len)\n",
    "\n",
    "pooling_encoder = models.Pooling(word_embedding_encoder.get_word_embedding_dimension(),  #모델이 dimension(768)\n",
    "                               pooling_mode_mean_tokens=True,  # 워드 임베딩 평균을 이용\n",
    "                               pooling_mode_cls_token=False,   # cls 를 이용\n",
    "                               pooling_mode_max_tokens=False)  # 워드 임베딩 값중 max 값을 이용\n",
    "\n",
    "bi_encoder = SentenceTransformer(modules=[word_embedding_encoder, pooling_encoder])\n",
    "#======================================================================================================\n",
    "\n",
    "print(ce_model)\n",
    "print(bi_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7bf7173-b8fc-4385-8cc9-a78106654c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비행기가 이륙하고 있다., 비행기가 이륙하고 있다., 1.0\n",
      "한 남자가 큰 플루트를 연주하고 있다., 남자가 플루트를 연주하고 있다., 0.76\n",
      "한 남자가 피자에 치즈를 뿌려놓고 있다., 한 남자가 구운 피자에 치즈 조각을 뿌려놓고 있다., 0.76\n",
      "세 남자가 체스를 하고 있다., 두 남자가 체스를 하고 있다., 0.52\n",
      "한 남자가 첼로를 연주하고 있다., 자리에 앉은 남자가 첼로를 연주하고 있다., 0.85\n",
      "안전모를 가진 한 남자가 춤을 추고 있다., 안전모를 쓴 한 남자가 춤을 추고 있다., 1.0\n",
      "어린아이가 말을 타고 있다., 아이가 말을 타고 있다., 0.95\n",
      "한 남자가 뱀에게 쥐를 먹이고 있다., 남자가 뱀에게 쥐를 먹이고 있다., 1.0\n",
      "한 여성이 기타를 연주하고 있다., 한 남자가 기타를 치고 있다., 0.48\n",
      "한 여성이 플루트를 연주하고 있다., 남자가 플루트를 연주하고 있다., 0.55\n",
      "[<sentence_transformers.readers.InputExample.InputExample object at 0x7faa084f1850>, <sentence_transformers.readers.InputExample.InputExample object at 0x7faa084dce20>]\n",
      "[<sentence_transformers.readers.InputExample.InputExample object at 0x7fa77bb91220>, <sentence_transformers.readers.InputExample.InputExample object at 0x7fa77bb913a0>]\n"
     ]
    }
   ],
   "source": [
    "# 1단계: 적은 STS dataset(gold sts dataset) 에 대해 Cross-Encoder로 BERT 훈련 시킴\n",
    "# => 여기서는 5,000개만 있는 korsts/tune_train.tsv 말뭉치를 가지고 함.\n",
    "\n",
    "train_file = '../../../korpora/korsts/tune_train.tsv'\n",
    "eval_file = '../../../korpora/korsts/tune_dev.tsv'\n",
    "count = 0\n",
    "\n",
    "# 훈련 골드 데이터 불러옴\n",
    "train_gold_samples = []\n",
    "with open(train_file, \"rt\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        text_a, text_b, score = line.split('\\t')\n",
    "        score = score.strip()\n",
    "        score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "            \n",
    "        if count < 5:\n",
    "            print(f\"{text_a}, {text_b}, {score}\")\n",
    "                \n",
    "        train_gold_samples.append(InputExample(texts= [text_a,text_a], label=score))\n",
    "        count += 1\n",
    "      \n",
    "# 평가 데이터 불러옴\n",
    "count = 0\n",
    "dev_samples = []\n",
    "with open(eval_file, 'rt', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        text_a, text_b, score = line.split('\\t')\n",
    "        score = score.strip()\n",
    "        score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "            \n",
    "        if count < 5:\n",
    "            print(f\"{text_a}, {text_b}, {score}\")\n",
    "            \n",
    "        dev_samples.append(InputExample(texts= [text_a,text_b], label=score))\n",
    "        count += 1\n",
    "        \n",
    "# 훈련 골드 데이터로더, 평가 데이터 로더 생성\n",
    "train_dataloader = DataLoader(train_gold_samples, shuffle=True, batch_size=train_batch_size)\n",
    "evaluator = CECorrelationEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "print(train_gold_samples[0:2])\n",
    "print(dev_samples[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e134133a-d77d-4df1-9c18-50aeb7cf4a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 11:33:27,950 - s-bert - INFO - Warmup-steps: 180\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac7c55ffcd542d6b3cbbd5887c8d20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e142c0b8ed06421aac01e91291e7d56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffb17e9c4494716a178dacbd7681243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17dcb7888e1459eb78703ac38fd1a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376daa8857514c1b9eb4d3869bf68552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca94425d1684cbcab1a12b49cf44cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a1e5cbc2714188b447d8da507d2894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8dde9a675145a1bdf2b03d0d092377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805509f55df74e2382a188c8a7c7c6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5da032dd8334513a318bdcd7e696a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5273c6c0d2f4d28ba9627bfc5159fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1단계: 적은 STS dataset(gold sts dataset) 에 대해 Cross-Encoder로 BERT 훈련 시킴\n",
    "\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "logger.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "ce_odel_save_path = 'output/crossencoder-sts-train-'+datetime.now().strftime(\"%Y-%m-%d-%H:%M\")\n",
    "\n",
    "# Train the model\n",
    "ce_model.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=ce_odel_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2098c542-119b-41b2-8d4f-196f44487bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384\n",
      "['나토 : 아프가니스탄 저항 세력으로부터 구조된 4명의 구호 요원', '인도 조건은 이탈리아 당국이 기소할 충분한 증거를 제공할 수 있는 서류 위조에 대한 단일 혐의에 대해서만 튀니지인이 기소될 수 있도록 규정하고 있다.', '원숭이가 나무에 매달려 있다.', '러시아와 나토 회원국들은 올 가을 유럽 조약(cfe )에서 재래식 세력에 대한 회의를 개최할 것이다.', '그러나 합동 정보 위원회는 관여하지 않았다는 것은 분명하다.']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993f74fcc78d43fbb0b189e2a5f6a83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5384 [00:00<?, ?docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26920\n",
      "[('나토 : 아프가니스탄 저항 세력으로부터 구조된 4명의 구호 요원', '나토 : 아프가니스탄에서 사망한 2명의 국제군'), ('나토 : 아프가니스탄 저항 세력으로부터 구조된 4명의 구호 요원', '아프가니스탄에서 4명의 나토군이 사망했다.'), ('나토 : 아프가니스탄 저항 세력으로부터 구조된 4명의 구호 요원', '나토 : 아프가니스탄 남부에서 5명의 미국인이 사망'), ('나토 : 아프가니스탄 저항 세력으로부터 구조된 4명의 구호 요원', '4명의 민간인, 3명의 나토 병사가 아프가니스탄에서 사망했다'), ('나토 : 아프가니스탄 저항 세력으로부터 구조된 4명의 구호 요원', '아프가니스탄에서 살해된 나토 병사 한 명')]\n",
      "[0.4914771  0.6120426  0.40192905 0.61064124 0.60000867]\n"
     ]
    }
   ],
   "source": [
    "# -2.1단계: 기존 잘 훈련된 S-BERT(예: distiluse-base-multilingual-cased-v2)를 이용해, gold sts 문장들에 대해 유사도 측정해서, \n",
    "#           한 문장에 대해 K수만큼 유사한 문장들을 조합하여 문장 쌍을 만듬\n",
    "# ** 굳이 gold sts 문장에셔 siver sts 를 생성하지 않고, 다른 말뭉치에서 생성해도 될듯 싶음.\n",
    "\n",
    "silver_train_data = []\n",
    "sentences = set()\n",
    "for sample in train_gold_samples:\n",
    "    sentences.update(sample.texts)\n",
    "   \n",
    "sentences = list(sentences)\n",
    "print(len(sentences))\n",
    "print(sentences[0:5])\n",
    "\n",
    "sent2idx = {sentence: idx for idx, sentence in enumerate(sentences)}\n",
    "duplicates = set((sent2idx[data.texts[0]], sent2idx[data.texts[1]]) for data in train_gold_samples)\n",
    "\n",
    "embeddings = bi_encoder.encode(sentences, batch_size=train_batch_size, convert_to_tensor=True)\n",
    "\n",
    "for idx in tqdm(range(len(sentences)), unit=\"docs\"):\n",
    "    sentence_embedding = embeddings[idx]\n",
    "    cos_scores = util.pytorch_cos_sim(sentence_embedding, embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "    top_results = torch.topk(cos_scores, k=top_k+1)\n",
    "    \n",
    "    for score, iid in zip(top_results[0], top_results[1]):\n",
    "        if iid != idx and (iid, idx) not in duplicates:\n",
    "            silver_train_data.append((sentences[idx], sentences[iid]))\n",
    "            duplicates.add((idx, iid))\n",
    "            \n",
    "# -2.2단계: 1E단계에서 훈련된 BERT 로 2.1단계에서 만든 문장쌍들에 대해 점수를 매김->이를 silver sts dataset이라고 함\n",
    "cs_new_model = CrossEncoder(ce_odel_save_path)\n",
    "silver_scores = cs_new_model.predict(silver_train_data)\n",
    "    \n",
    "print(len(silver_train_data))\n",
    "print(silver_train_data[0:5])\n",
    "print(silver_scores[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3833dfca-8d56-4c9f-a28b-fe1d5225d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# silver_data 를 .tsv 파일로 저장 해둠.\n",
    "silver_data_file = 'output/silver_data-'+datetime.now().strftime(\"%Y-%m-%d-%H:%M\")+'.tsv'\n",
    "with open(silver_data_file, 'w', encoding='utf-8') as f:\n",
    "    for data, score in tqdm(zip(silver_train_data, silver_scores)):\n",
    "        f.write(data[0]+'\\t')\n",
    "        f.write(data[1]+'\\t')\n",
    "        f.write(str(score) + '\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fa37885-35bd-40aa-bd58-c4fda2cf3e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../../model/bert/bmc-fpt-bong_corpus_mecab-0424/batch:32-ep:4-lr:0.000030000-4m25d-8:27/ were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ../../../model/bert/bmc-fpt-bong_corpus_mecab-0424/batch:32-ep:4-lr:0.000030000-4m25d-8:27/ and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7f92ce41e3454bb817d66f33c957d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f183f03318745959fc754f83656f3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb220df3c2ab4dfe9c8642bfa5babea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d073eb64f4f4b128c5be3f9c81dfc19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897bf7c673314f47b43dfd670bf7b145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a0ee04aa11451399f58a1ffda27c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94807dba26245b49c6f1027a2413a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcabfc6bcb314459a4bcf5515720b42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2d32bf96cd4140a8f64172969e5e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319ecbaa5e964e41abaf1e6bcdc7782d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5593c63f3bae42148adb98071d2b9756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3단계: gold sts dataset + silver sts dataset 을 훈련 데이터로 하여 Bi-Encoder 훈련 시킴\n",
    "\n",
    "#======================================================================================================\n",
    "# bi-encoder 모델 정의\n",
    "\n",
    "# word_embedding 모델은 앞에서 할 cross-encoder 모델 경로로 지정함 \n",
    "word_embedding_model = models.Transformer(ce_model_path, max_seq_length=max_seq_len)\n",
    "\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),  #모델이 dimension(768)\n",
    "                               pooling_mode_mean_tokens=True,  # 워드 임베딩 평균을 이용\n",
    "                               pooling_mode_cls_token=False,   # cls 를 이용\n",
    "                               pooling_mode_max_tokens=False)  # 워드 임베딩 값중 max 값을 이용\n",
    "\n",
    "bi_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "#======================================================================================================\n",
    "\n",
    "train_silver_samples = list(InputExample(texts=[data[0], data[1]], label=score) for \\\n",
    "    data, score in zip(silver_train_data, silver_scores))\n",
    "\n",
    "train_dataset = SentencesDataset(train_gold_samples + train_silver_samples, bi_model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=bi_model)\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "# Configure the training.\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "#logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "model_save_path = 'output/sbert-sts-train-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "# Train the bi-encoder model\n",
    "bi_model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4ef6cf-8983-43a9-b85c-2fab8e6a3f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
