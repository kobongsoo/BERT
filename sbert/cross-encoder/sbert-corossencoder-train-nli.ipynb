{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1cc833-f6a3-4eb9-9ec4-3de894616963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================================================================\n",
    "# sentence-bert(sbert)에 CrossEncoder 방식 NLI 훈련 예시임\n",
    "# => cross-encocoder 방식은 2개의 문장(문장1, 문장2)을 입력했을때 output으로 유사도(0~1값)을 출력해줌\n",
    "#\n",
    "# => 참고 : https://www.sbert.net/examples/training/cross-encoder/README.html\n",
    "#         https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/cross-encoder/training_stsbenchmark.py  \n",
    "#========================================================================================================================\n",
    "import torch \n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from os import sys\n",
    "from datetime import datetime\n",
    "sys.path.append('../../')\n",
    "from myutils import seed_everything, GPU_info, mlogging\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CESoftmaxAccuracyEvaluator\n",
    "from sentence_transformers import InputExample\n",
    "\n",
    "device = GPU_info()\n",
    "logger =  mlogging(loggername=\"sbertcross\", logfilename=\"../../../log/sbert-crossencocer-train-sts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db2e32-28e6-4676-a6c8-6810f8e95bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '../../../data11/korpora/kornli/snli_1.0_train.ko.tsv'\n",
    "eval_file = '../../../data11/korpora/kornli/xnli.dev.ko-1.tsv'\n",
    "\n",
    "train_batch_size = 64\n",
    "num_epochs = 3\n",
    "lr = 3e-5 # default=2e-5 \n",
    "eps = 1e-8 #lr이 0으로 나뉘어져 계산이 엉키는 것을 방지하기 위해 epsilion\n",
    "seed = 111 \n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea5472-12aa-4ca5-953b-58976805ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 불러오기\n",
    "# => [sentence1, sentence2], labels 식으로 만듬\n",
    "logger.info(\"Read kornli train/dev dataset\")\n",
    "\n",
    "label2int = {\"contradiction\": 0, \"entailment\": 1, \"neutral\": 2}\n",
    "train_samples = []\n",
    "\n",
    "with open(train_file, \"rt\", encoding=\"utf-8\") as fIn:\n",
    "    lines = fIn.readlines()\n",
    "    for line in lines:\n",
    "        s1, s2, label = line.split('\\t')\n",
    "        label = label2int[label.strip()]\n",
    "        train_samples.append(InputExample(texts=[s1, s2], label=label))\n",
    "  \n",
    "# 평가 데이터 불러오기\n",
    "dev_samples = []\n",
    "with open(eval_file, \"rt\", encoding=\"utf-8\") as fIn:\n",
    "    lines = fIn.readlines()\n",
    "    for line in lines:\n",
    "        s1, s2, label = line.split('\\t')\n",
    "        label = label2int[label.strip()]\n",
    "        dev_samples.append(InputExample(texts=[s1, s2], label=label))\n",
    " \n",
    "print(f'*train_len:{len(train_samples)}')\n",
    "print(train_samples[0:3])\n",
    "print(f'*dev_len:{len(dev_samples)}')            \n",
    "print(dev_samples[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214bc8a7-1b93-45c5-a47e-07c145be3194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We wrap train_samples, which is a list ot InputExample, in a pytorch DataLoader\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "#During training, we use CESoftmaxAccuracyEvaluator to measure the accuracy on the dev set.\n",
    "evaluator = CESoftmaxAccuracyEvaluator.from_input_examples(dev_samples, name='xnli.dev.ko.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c35036-9caa-42ed-b352-42f63b7bd0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기 \n",
    "model_path = \"bongsoo/albert-small-kor-v1\"\n",
    "model_save_path = '../../../data11/model/moco/cross/albert-small-kor-cross-nli' # +datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "model = CrossEncoder(model_path, num_labels=len(label2int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ebf68-7b50-49a2-9e19-e31dfe9473b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련시작\n",
    "# => model_save_path에 모델과, 평가 CESoftmaxAccuracyEvaluator-dev_results.csv 파일 생성됨\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "# evaluation_steps은 20%로 설정\n",
    "evaluation_steps = warmup_steps * 2\n",
    "\n",
    "logger.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=evaluation_steps,\n",
    "          warmup_steps=warmup_steps,\n",
    "          optimizer_params= {'lr': lr, 'eps': eps, 'correct_bias': False},\n",
    "          save_best_model=True, # **기본 = True : eval 가장 best 모델을 output_Path에 저장함\n",
    "          output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e447064-ba36-4bbd-b9bb-f6e33cc4e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "# => 훈련되어서 저장된 s-bert 모델을 불러와서 성능 평가 해봄\n",
    "##############################################################################\n",
    "import time \n",
    "\n",
    "#model_save_path = \"bongsoo/albert-small-kor-v1\"\n",
    "model_save_path = \"../../../data11/model/moco/cross/albert-small-kor-cross-nli\"\n",
    "\n",
    "test_file = '../../../data11/korpora/kornli/xnli.test.ko-1.tsv'\n",
    "\n",
    "# 테스트 데이터 불러옴 \n",
    "label2int = {\"contradiction\": 0, \"entailment\": 1, \"neutral\": 2}\n",
    "test_samples = []\n",
    "with open(test_file, 'rt', encoding='utf-8') as fIn:\n",
    "    lines = fIn.readlines()\n",
    "    for line in lines:\n",
    "        s1, s2, label = line.split('\\t')\n",
    "        label = label2int[label.strip()]\n",
    "        test_samples.append(InputExample(texts=[s1, s2], label=label))\n",
    "\n",
    "start = time.time()       \n",
    "model = CrossEncoder(model_save_path, num_labels=len(label2int))\n",
    "\n",
    "evaluator = CESoftmaxAccuracyEvaluator.from_input_examples(test_samples, name='xnli.test.ko.tsv')\n",
    "result = evaluator(model)\n",
    "\n",
    "logger.info(f\"\\n\")\n",
    "logger.info(f\"model path: {model_save_path}\")\n",
    "logger.info(f'=== result: {result} ===')\n",
    "logger.info(f'=== 처리시간: {time.time() - start:.3f} 초 ===')\n",
    "logger.info(\"==============================================\")\n",
    "logger.info(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d668d2-2eb1-4682-afb2-205a1b3198f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
