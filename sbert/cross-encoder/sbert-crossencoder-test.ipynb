{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c1aad-6bfa-410c-8787-dd229660cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================================================================\n",
    "# sentence-bert(sbert)에 CrossEncoder 방식 테스트 예시임\n",
    "# => cross-encocoder 방식은 2개의 문장(문장1, 문장2)을 입력했을때 output으로 유사도(0~1값)을 출력해줌\n",
    "#\n",
    "# => 입력 모델은 bert모델, distibert, roberta 등 됨(NLI, STS 학습된 모델이 성능이 좋음)\n",
    "#    **단 NLI, STS 학습된 bert 모델인 경우에는 bertmodel로 만들어야 함.\n",
    "#     왜냐하면 NLI는 classifiation 모델이므로, 출력값(참, 거짓, 중립)이 3개이므로, 출력은 임베딩값 출력되는 모델로 변환시켜야함\n",
    "#\n",
    "# => 참고 : https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/cross-encoder/cross-encoder_usage.py\n",
    "#========================================================================================================================\n",
    "import torch \n",
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from os import sys\n",
    "sys.path.append('../../')\n",
    "from myutils import seed_everything, GPU_info, mlogging\n",
    "import time\n",
    "\n",
    "seed_everything(111)\n",
    "device = GPU_info()\n",
    "logger =  mlogging(loggername=\"sbertcross\", logfilename=\"../../../log/sbert-crossencocer-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f52db-f06e-4958-ad75-93dc9e1d4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer, DistilBertModel, DistilBertTokenizer, AlbertModel, AlbertTokenizer\n",
    "\n",
    "# CrossEncoder 모델 로딩\n",
    "# => NLI 학습된 bert 모델인 경우에는 bertmodel로 만들어야 함(왜냐하면 NLI는 classifiation 모델이므로, 출력값이 3개로 됨)\n",
    "#model_path = \"../../../model/bert/bmc-fpt-wiki_20190620_mecab_false_0311-nouns-0327\"\n",
    " \n",
    "nlimodel = False\n",
    "#model_path = \"../../../model/classification/bmc-fpt-wiki_20190620_mecab_false_0311-nouns-0327-ft-nli-0328/bertmodel\"\n",
    "#model_path = \"../../../model/distilbert/distilbert-0331-TS-nli-0.1-10/bertmodel\"\n",
    "model_path = \"../../../data11/model/moco/cross/albert-small-kor-cross-nli\"\n",
    "\n",
    "if nlimodel:\n",
    "    # NLI 학습된 bert 모델인 경우에는 bertmodel로 만들어야 함\n",
    "    # **왜냐하면 NLI는 classifiation 모델이므로, 출력값(참, 거짓, 중립)이 3개이므로, 출력은 임베딩값 출력되는 모델로 변환시켜야함\n",
    "    #tokenizer = BertTokenizer.from_pretrained(model_path, do_lower_case=False)\n",
    "    #bertmodel = BertModel.from_pretrained(model_path)\n",
    "    tokenizer = AlbertTokenizer.from_pretrained(model_path, do_lower_case=True, keep_accent=False)\n",
    "    bertmodel = AlbertModel.from_pretrained(model_path)\n",
    "    OUTPATH = model_path + \"/bertmodel\"\n",
    "    os.makedirs(OUTPATH, exist_ok=True)\n",
    "    bertmodel.save_pretrained(OUTPATH)\n",
    "    tokenizer.save_pretrained(OUTPATH)\n",
    "    \n",
    "    model = CrossEncoder(OUTPATH)        # CrossEncoder NLI -> BERT 모델로 변환된 모델 로딩\n",
    "else:    \n",
    "    model = CrossEncoder(model_path)     # CrossEncoder 모델 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb6810-926e-4206-8963-238f7a817c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['서울은 대한민국에 수도이며, 정치 경제 중심지이다',\n",
    "          '내년 경제 성장은 4%대 성장을 이룰거라 예상된다',\n",
    "          '프랑스 파리는 전세계 관광객들이 매년 찾는 관광도시이다',\n",
    "          '올해에는 대통령 선거와 지방선거가 동시에 열린다',\n",
    "          '오늘 날씨는 비가 내리고 매우 춥다',\n",
    "          '손홍민이 영국 프리미어 축구 경기에서 11번째 골을 넣었다',\n",
    "          '건조한 날씨에 산불을 조심해야 한다',\n",
    "          '윈도우11 OS에 검색 기능을 강화 하였다',\n",
    "          '한국은행은 올해 하반기 금리를 동결했다',\n",
    "          'Going on a trip',\n",
    "          'it is raining',\n",
    "          'stock market opened',\n",
    "          'There is a voting for the class president election',\n",
    "          '오늘은 흐리고, 바람이 세다',\n",
    "          '대한민국',\n",
    "          '대한민국의 보수정당',\n",
    "          '대한민국 육군사관학교',\n",
    "          '대한민국의_소방',\n",
    "          '제주도',\n",
    "          '서울',\n",
    "         ]\n",
    "          \n",
    "query = '대한민국'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a889c4de-49ea-436b-bc1e-537578de2a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query와 corpus들을 묶어서 입력 문장 만듬\n",
    "sentence_combinations = [[query, corpus_sentence] for corpus_sentence in corpus]\n",
    "print(sentence_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72959a20-bc84-490f-a50a-fd75cdbf0f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측하여 스코어들을 구함\n",
    "logger.info(f\"============================================================\")\n",
    "logger.info(f'model : {model_path}')\n",
    "start = time.time()\n",
    "\n",
    "scores = model.predict(sentence_combinations)\n",
    "\n",
    "logger.info(f'*처리시간:{time.time()-start}\\n')\n",
    "\n",
    "# 내림 차순으로 정렬\n",
    "dec_scores = reversed(np.argsort(scores))\n",
    "\n",
    "# 출력\n",
    "logger.info(f\"query : {query}\")\n",
    "for idx in dec_scores:\n",
    "    print(idx)\n",
    "    logger.info(\"{:.2f}\\t{}\".format(scores[idx], corpus[idx]))\n",
    "logger.info(f\"============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579875b3-4e53-4740-a88f-446cf83bfec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
