{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad5e3edf-a94e-472d-a7b3-5f8c414b1923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:bwdataset_2022-03-14.log\n",
      "logfilepath:s-bert-ts_2022-03-14.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "#======================================================================================================\n",
    "# sentence-bert 를 tearch-student 관계 모델로 구성하여, 영어 sbert 학습을 학국어 모델에 증류학습시키는 예시\n",
    "# -> 선생님모델은  영어 bert가 되고, 학생모델은 학국어 포함된다국어 bert로 설정\n",
    "# -> 영어 bert가 다국어 bert를 가리키는 방식으로 학습됨\n",
    "#\n",
    "# => sentence-transformers 패키지를 이용하여 구현 함.(*pip install -U sentence-transformers 설치 필요)\n",
    "#\n",
    "# 도큐먼트 : https://towardsdatascience.com/a-complete-guide-to-transfer-learning-from-english-to-other-languages-using-sentence-embeddings-8c427f8804a9\n",
    "#\n",
    "# pip install -U sentence-transformers\n",
    "#======================================================================================================\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "\n",
    "sys.path.append('..')\n",
    "from myutils import seed_everything, GPU_info, mlogging\n",
    "\n",
    "logger = mlogging(loggername=\"s-bert-ts\", logfilname=\"s-bert-ts\")\n",
    "device = GPU_info()\n",
    "seed_everything(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5bfcf70-f795-46e8-8833-6e43b1408b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load teacher model\n"
     ]
    }
   ],
   "source": [
    "# 선생님 모델 설정\n",
    "\n",
    "print(\"Load teacher model\")\n",
    "teacher_model_name = 'bert-base-nli-stsb-mean-tokens'\n",
    "teacher_model = SentenceTransformer(teacher_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8b428c-7028-44e7-a986-acec80f86359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load student model\n",
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================================================\n",
    "# 학생 모델 설정\n",
    "# => * 학생모델이 이미 sentencebert일지라도, 아래처럼 sbert모델 아닌 것처럼 word_embedding_model, pooling_model 을 각각\n",
    "#    만들어서 처리하는것이 테스트 시 효율의 좋음\n",
    "#\n",
    "# [학생 모델 생성 방법]\n",
    "# 1) word_embedding 모델 생성\n",
    "# 2) pooling 모델 생성 : pooling 정책을 설정함 : CLS, 평균, MAX 정책중 택1(*평균 정책이 효율의 가장 좋다고 함)\n",
    "# 3) 1) + 2) 모델을 연결시켜서 하나의 sbert 모델 만듬\n",
    "#==========================================================================================================\n",
    "student_model_name = \"../model/distilbert/distilbert-fpt-wiki_20190620-mecab-model-0313-s-distilbert-nli-0314\"\n",
    "\n",
    "print(\"Load student model\")\n",
    "\n",
    "\n",
    "# === *sbert 모델 아닌 경우 =====\n",
    "# word embedding 모델 설정(기존 다국어 모델 불러옴)\n",
    "word_embedding_model = models.Transformer(student_model_name)\n",
    "\n",
    "# pooling 정책 설정(mean 평균 정책으로 지정)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "\n",
    "# 학생 SBERT 생성\n",
    "# -> word_embedding model 과 pooling_model를 연결시켜줌\n",
    "student_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "\n",
    "# === *sbert 모델 인 경우 =====\n",
    "# 기존 s-model 로딩 함\n",
    "#student_model = SentenceTransformer(student_model_name)\n",
    "\n",
    "print(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf8f7e8b-e46e-410a-b991-bcee2848b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 평가 데이터 불러오고, 손실함수(MSELoss) 설정함(*학생모델에 설정함)\n",
    "# 원본 소스코드 : \n",
    "# https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/datasets/ParallelSentencesDataset.py\n",
    "\n",
    "from sentence_transformers.datasets import ParallelSentencesDataset\n",
    "\n",
    "max_seq_length = 128\n",
    "train_batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "###### Load train sets ######    \n",
    "train_file = '../korpora/pair/Tatoeba-eng-kor/Tatoeba-eng-kor-train.tsv'\n",
    "\n",
    "train_reader = ParallelSentencesDataset(student_model=student_model, teacher_model=teacher_model)\n",
    "train_reader.load_data(train_file)\n",
    "train_dataloader = DataLoader(train_reader, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.MSELoss(model=student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fbcac7e-cc7d-496f-b16c-f3c80fca6345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9690\n",
      "('Go away!', {'저리 가!', 'Go away!'})\n"
     ]
    }
   ],
   "source": [
    "print(len(train_reader))\n",
    "train_reader.__getitem__(0)\n",
    "print(train_reader.next_entry(0)) # (source, {traget}) 첫번째 문장을 출력해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b56c40a-a560-4302-876c-272894ef2aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "###### Load dev sets ######\n",
    "# 평가 데이터 불러와서 유사도 측정 평가자 설정함\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentencesDataset, losses,readers\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator,MSEEvaluator, SequentialEvaluator\n",
    "\n",
    "evaluators = []\n",
    "dev_samples = []\n",
    "\n",
    "eval_file = '../korpora/pair/Tatoeba-eng-kor/Tatoeba-eng-kor-dev-1.tsv'\n",
    "with open(eval_file, 'rt', encoding='utf-8') as fIn:\n",
    "    lines = fIn.readlines()\n",
    "    for line in lines:\n",
    "        s1, s2, score = line.split('\\t')\n",
    "        if s1[0] == \"\" or s1[1] == \"\":\n",
    "            continue\n",
    "        score = score.strip()\n",
    "        score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "        dev_samples.append(InputExample(texts= [s1,s2], label=score))\n",
    "\n",
    "# 영어 문장, 한국어 문장 유사도 측정을 위한 평가자(Evaluator) 설정\n",
    "evaluator_sts = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, \n",
    "                                                                 batch_size=train_batch_size, \n",
    "                                                                 name='dev')\n",
    "# evaluators에 추가함(*아래 테스트 데이터 evaluators도 추가함)\n",
    "evaluators.append(evaluator_sts)\n",
    "print(len(evaluators))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55961955-a3c4-4224-95ae-a42c4a44d706",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Load test sets ######\n",
    "# 테스트 데이터 불러와서 MSE 평가자 설정함\n",
    "src_sentences = []\n",
    "trg_sentences = []\n",
    "\n",
    "test_file = '../korpora/pair/Tatoeba-eng-kor/Tatoeba-eng-kor-test.tsv'\n",
    "\n",
    "# 참고소스: https://texasvaluesaction.org/Foysal87/Bangla-sentence-embedding-transformer/blob/master/Bangla_transformer.py\n",
    "with open(test_file, 'rt', encoding='utf-8') as fIn:\n",
    "    for line in fIn:\n",
    "        splits = line.strip().split('\\t')\n",
    "        if len(splits) != 2:\n",
    "            continue\n",
    "\n",
    "        if splits[0] != \"\" and splits[1] != \"\":\n",
    "            src_sentences.append(splits[0])\n",
    "            trg_sentences.append(splits[1])\n",
    "        \n",
    "test_mse = MSEEvaluator(src_sentences, trg_sentences, teacher_model=teacher_model, name='test')\n",
    "evaluators.append(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cfddc50-571a-4fc8-aa9c-4a1bce2b79c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 15:15:32,112 - s-bert-ts - INFO - ----------------------------------------------------------------------\n",
      "2022-03-14 15:15:32,117 - s-bert-ts - INFO - *Warmup-steps:606, ephocs:20, train_data_len:9690, train_batch_size: 32\n",
      "2022-03-14 15:15:32,119 - s-bert-ts - INFO - *teacher_model: bert-base-nli-stsb-mean-tokens\n",
      "2022-03-14 15:15:32,120 - s-bert-ts - INFO - *student_model_name: ../model/distilbert/distilbert-fpt-wiki_20190620-mecab-model-0313-s-distilbert-nli-0314\n",
      "2022-03-14 15:15:32,122 - s-bert-ts - INFO - ----------------------------------------------------------------------\n",
      "2022-03-14 15:15:32,124 - s-bert-ts - INFO - *train_file: ../korpora/pair/Tatoeba-eng-kor/Tatoeba-eng-kor-train.tsv\n",
      "2022-03-14 15:15:32,125 - s-bert-ts - INFO - *eval_file: ../korpora/pair/Tatoeba-eng-kor/Tatoeba-eng-kor-dev-1.tsv\n",
      "2022-03-14 15:15:32,127 - s-bert-ts - INFO - *test_file: ../korpora/pair/Tatoeba-eng-kor/Tatoeba-eng-kor-test.tsv\n",
      "2022-03-14 15:15:32,128 - s-bert-ts - INFO - ----------------------------------------------------------------------\n",
      "2022-03-14 15:15:32,130 - s-bert-ts - INFO - *out_path: output/sbert-ts-model2022-03-14\n",
      "2022-03-14 15:15:32,144 - s-bert-ts - INFO - ----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80b4715403d40649b66287e67989b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7995660440d4ff9972225b7e33c0649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/MOCOMSYS/anaconda3/envs/bong/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:537: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180487213/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  labels = torch.tensor(labels).to(self._target_device)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5b747079724afe90da12262c07b444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a14e5efe91e41a5aa018a9d9c4bf1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4bbc7015207490cad8acaccff739743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712e86238d6c41e09d3a11f5a6018d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1bf882f29014b00a6fc42782747798b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2ec22eb16a4b7c9e2ffa7013308292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3020dc141316493abf45d346c91631c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b57439c35ff46e8a811c6648ec33254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf12b51ff944bbc98094a31c2622ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caf424265cf4f69a967aceca2d3e44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07eda3b4dfe4fca91a64ec064176b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb4f1c16b3b4a71848ebcf204f25b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560bdfc1e5c64910a88cd015c090ced2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4072630db4084041bc3c1ab4424e4dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570ca2dd277c48a49f95973c15a3e4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635e4f43b7064d38bcde5f78b963b75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8349a09df7574bb897372055b8c11120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5f2f4d143b40ef959f8d0d48cb62b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833b9b2dddc94c2587d67b18ab3aa934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 15:29:07,391 - s-bert-ts - INFO - === 처리시간: 815.245 초 ===\n",
      "2022-03-14 15:29:07,399 - s-bert-ts - INFO - \n",
      "\n"
     ]
    }
   ],
   "source": [
    "###### Train model ######\n",
    "# 훈련 시작\n",
    "# 훈련을 시작하면, output_path/eval/ 폴더에 mse 테스트, similarity 테스트 csv 파일에 기록됨\n",
    "# (mse_evaluation_test_results.csv , similarity_evaluation_dev_results.csv)\n",
    "import time\n",
    "\n",
    "#10% of train data for warm-up\n",
    "warmup_steps = math.ceil(len(train_reader) * num_epochs / train_batch_size * 0.1) \n",
    "evaluation_steps = warmup_steps\n",
    "output_path = \"output/sbert-ts-model\" + datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "logger.info(f\"----------------------------------------------------------------------\")\n",
    "logger.info(\"*Warmup-steps:{}, ephocs:{}, train_data_len:{}, train_batch_size: {}\".format(warmup_steps, num_epochs, len(train_reader), train_batch_size))\n",
    "logger.info(\"*teacher_model: {}\".format(teacher_model_name))\n",
    "logger.info(\"*student_model_name: {}\".format(student_model_name))\n",
    "logger.info(f\"----------------------------------------------------------------------\")\n",
    "logger.info(\"*train_file: {}\".format(train_file))\n",
    "logger.info(\"*eval_file: {}\".format(eval_file))\n",
    "logger.info(\"*test_file: {}\".format(test_file))\n",
    "logger.info(f\"----------------------------------------------------------------------\")\n",
    "logger.info(\"*out_path: {}\".format(output_path))\n",
    "logger.info(f\"----------------------------------------------------------------------\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "student_model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=SequentialEvaluator(evaluators, main_score_function=lambda scores: scores[-1]),\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=evaluation_steps,\n",
    "          warmup_steps=warmup_steps,   # 옵티마이저 2e-5까지 처음 1000 번은 아주작게 스탭을 옮김\n",
    "          scheduler='warmupconstant',\n",
    "          output_path=output_path,\n",
    "          save_best_model=True,\n",
    "          optimizer_params= {'lr': 2e-5, 'eps': 1e-6, 'correct_bias': False}\n",
    "          )\n",
    "\n",
    "logger.info(f'=== 처리시간: {time.time() - start:.3f} 초 ===')\n",
    "logger.info(f\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
