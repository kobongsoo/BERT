{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c768bf-96d5-45cb-81f0-177738d2efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================================\n",
    "# sbert 모델을 각 4가지 평가 데이터셋으로 하나씩 지정해서 평가하는 예시임\n",
    "# => 평가 데이터 셋 : Korsts, Kluests, gluests, stsb_multi_mt \n",
    "# => 각 개별적 eval 출력 하는 예시는 sbert-test2.ipynb 참조\n",
    "#=> ** skt/kobert-base-V1  테스트시에는  tokenizer_config.json 에 tokenizer_class:\"XLNetTokenizer\" 인지 확인해야 함\n",
    "#==============================================================================================\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.evaluation import SimilarityFunction\n",
    "\n",
    "sys.path.append('..')\n",
    "from myutils import seed_everything, GPU_info, mlogging\n",
    "\n",
    "logger = mlogging(loggername=\"s-bert-test\", logfilename=\"../../log/s-bert-test\")\n",
    "device = GPU_info()\n",
    "seed_everything(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af081cd9-c333-4d95-9168-f8e31d718d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 평가 설정 parameter 들 ########################################\n",
    "\n",
    "# 평가할 bert 모델 혹은 sbert모델 경로\n",
    "#=> ** skt/kobert-base-V1  테스트시에는  tokenizer_config.json 에 tokenizer_class:\"XLNetTokenizer\" 인지 확인해야 함\n",
    "bisSKKobertModel = 0  # skt/kobert-base-V1 허깅페이스 모델 사용시에는 1로 해줌\n",
    "model_path = \"../../data11/model/sbert/bert-base-multilingual-cased-sts-glue/\" #distilbert-base-multilingual-cased-sts\n",
    "#model_path = \"kpfbert-sts\"\n",
    "\n",
    "\n",
    "# 유사도 측정방식(COSINE, EUCLIDEAN, MANHATTAN, DOT_PRODUCT 중 선택 , 모두 spearman 방식임)\n",
    "# => None 이면 아래 값들중 MAX 값 추력함\n",
    "#main_similarity = None\n",
    "main_similarity = SimilarityFunction.COSINE\n",
    "#main_similarity = SimilarityFunction.EUCLIDEAN\n",
    "#main_similarity = SimilarityFunction.MANHATTAN\n",
    "#main_similarity = SimilarityFunction.DOT_PRODUCT\n",
    "\n",
    "# 평가시 cosine 유사도등 측정 결과값 파일 (similarity_evaluation_xxxx.xls) 저장될 경로\n",
    "output_path = 'eval'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "csvfilename = 'V3.1.1'   # 유사도 저장할 파일명 (eval/similarity_evaluation_{csffilename}.csv 형식으로 저장)\n",
    "\n",
    "# 평가 sts 형태의 말뭉치 파일들\n",
    "use_korsts = 0     #  korsts 파일\n",
    "use_kluests = 0    # kluests_v1.1 파일\n",
    "use_glue_sts = 1   # true이면 영문 glue_sts 데이터셋 추가하여 평기 시킴\n",
    "use_en_sts = 0     # true이면 영문 stsb_multi_mt데이터셋 추가하여 평가시킴.\n",
    "\n",
    "# * 모델에 상관없이 영어는 소문자로 입력하겠다는 뜻(glue는 소문자로만 비교하는게 더 적확함), 한국어는 True도 상관없음\n",
    "do_lower_case = False\n",
    "'''\n",
    "if use_glue_sts == 1 or use_en_sts == 1:\n",
    "    do_lower_case = True \n",
    "else:\n",
    "    do_lower_case = False\n",
    "'''    \n",
    "# korsts tsv 파일 경로\n",
    "korsts_file = '../../data11/korpora/korsts/tune_test.tsv'\n",
    "\n",
    "# kluests json 파일 경로\n",
    "kluests_file = '../../data11/korpora/klue-sts/klue-sts-v1.1_dev.json'\n",
    "\n",
    "# glue test tsv 파일경로\n",
    "glue_test_file = '../../data11/korpora/gluestsb/gluestsb-test.tsv'\n",
    "\n",
    "eval_batch_size = 64 # 배치파일사이즈 = 크면 eval 시간이 단축됨.단 gpu 메모리 올라감.\n",
    "max_seq_length = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7514e55a-82af-4e5b-852c-c1d9e2e06073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "test_samples = []\n",
    "\n",
    "\n",
    "# /korsts/tune_test.tsv 파일을 불러옴\n",
    "if use_korsts == True:\n",
    "    with open(korsts_file, 'rt', encoding='utf-8') as fIn1:\n",
    "        lines = fIn1.readlines()\n",
    "        for line in lines:\n",
    "            s1, s2, score = line.split('\\t')\n",
    "            score = score.strip()\n",
    "            score = float(score) / 5.0\n",
    "            test_samples.append(InputExample(texts=[s1,s2], label=score))\n",
    "\n",
    "\n",
    "# /klue-sts/klue-sts-v1.1_dev.json 파일을 불러옴\n",
    "if use_kluests == True:\n",
    "    import json\n",
    "\n",
    "    with open(kluests_file, \"r\", encoding='utf-8') as fIn2:\n",
    "        data = json.load(fIn2)\n",
    "        for el in data:\n",
    "            s1 = el[\"sentence1\"]\n",
    "            s2 = el[\"sentence2\"]\n",
    "            score = el[\"labels\"]['label']\n",
    "            test_samples.append(InputExample(texts=[s1,s2], label=score))\n",
    "        \n",
    "# 영문 stsb_multi_mt test 버전 파일 로딩함\n",
    "if use_en_sts == True:\n",
    "    en_sts_dataset = load_dataset(\"stsb_multi_mt\", name=\"en\", split=\"test\")\n",
    "    for data in en_sts_dataset:\n",
    "        text_a = data[\"sentence1\"]\n",
    "        text_b = data[\"sentence2\"]\n",
    "        score = data[\"similarity_score\"]\n",
    "        score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "        test_samples.append(InputExample(texts= [text_a,text_b], label=score))\n",
    "        \n",
    "if use_glue_sts == True: \n",
    "    \n",
    "    #glue stsb valildation 데이터셋 불러옴(subset : \"stsb\" = 1,500)\n",
    "    glue_stsb_dataset = load_dataset(\"glue\",\"stsb\", split=\"validation\")\n",
    "    for data in glue_stsb_dataset:\n",
    "        text_a = data[\"sentence1\"]\n",
    "        text_b = data[\"sentence2\"]\n",
    "        score = data[\"label\"]\n",
    "        score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "        test_samples.append(InputExample(texts= [text_a,text_b], label=score))\n",
    "    '''\n",
    "    # glue-test는 허깅페이스 데이터셋에는 labe(score)가 -1로 등록되어 있어서, 실제 glue 사이트에서 org파일을 받아서 불러옴\n",
    "    # => 해당 sts-test.tsv 파일에서 몇가지 주석달린 문장들은 제거함(약 300개)\n",
    "    with open(glue_test_file, 'rt', encoding='utf-8') as fIn1:\n",
    "        lines = fIn1.readlines()\n",
    "        for idx, line in enumerate(lines):\n",
    "            if idx == 0:\n",
    "                continue\n",
    "            _, _, _, _, score, text_a, text_b = line.split('\\t')\n",
    "            score = score.strip()\n",
    "            score = float(score) / 5.0\n",
    "            test_samples.append(InputExample(texts= [text_a,text_b], label=score))\n",
    "    '''\n",
    "\n",
    "print(test_samples[0:3])\n",
    "print(f'*test_samples_len: {len(test_samples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b90080-0e93-423f-9cee-7a2f297aff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델과 tokenizer 를 불러옴\n",
    "# => **사전파일(vocab.txt, *.json) 와 model 경로(config.json, pytorch_model.bin)가 같은 경로에 있어야 함.\n",
    "word_embedding_model = models.Transformer(model_path, max_seq_length=max_seq_length, do_lower_case=do_lower_case)\n",
    "\n",
    "#========================================================================================================\n",
    "# skt/kobert 모델은 tokenizer을 XLNET Tokenizer 이므로, 자체 KoBERTTOkenizer 를 불러와서 사용해야 함.\n",
    "# => 설치 : !pip install 'git+https://github.com/SKTBrain/KOBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n",
    "# => 출처 : https://velog.io/@m0oon0/KoBERT-%EC%82%AC%EC%9A%A9%EB%B2%95\n",
    "if bisSKKobertModel == 1:\n",
    "    from kobert_tokenizer import KoBERTTokenizer\n",
    "    word_embedding_model.tokenizer = KoBERTTokenizer.from_pretrained(model_path)\n",
    "#========================================================================================================\n",
    "\n",
    "# embedding 길이를 재조정 필요할때 auto_model.resize_token_embeddings 해줌\n",
    "print(f'token_len:{len(word_embedding_model.tokenizer)}')\n",
    "#word_embedding_model.auto_model.resize_token_embeddings(len(word_embedding_model.tokenizer))\n",
    "\n",
    "# 2 bert 모델의 임베딩 풀링 정책을 설정(cls 이용, 워드임베딩 평균이용, 워드임베딩 max 이용)\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),  #모델이 dimension(768)\n",
    "                               pooling_mode_mean_tokens=True,  # 워드 임베딩 평균을 이용\n",
    "                               pooling_mode_cls_token=False,   # cls 를 이용\n",
    "                               pooling_mode_max_tokens=False)  # 워드 임베딩 값중 max 값을 이용\n",
    "\n",
    "logger.info(\"\\n\")\n",
    "logger.info(\"======================TEST===================\")\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "print(model)\n",
    "\n",
    "#model = SentenceTransformer(smodel_path, device='cpu')\n",
    "#model = SentenceTransformer(smodel_path, cache_folder=output_path)\n",
    "#model.to(device)\n",
    "logger.info(f'{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae6702-ced5-4d65-9093-2b14b8d26a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"*main_similarity: {main_similarity}\")\n",
    "logger.info(f\"*model path: {model_path}\")\n",
    "\n",
    "if use_korsts == True:\n",
    "    logger.info(f\"*korsts file({korsts_file})\")\n",
    "\n",
    "if use_kluests == True:\n",
    "    logger.info(f\"*klue file({kluests_file})\")\n",
    "    \n",
    "if use_en_sts == True:\n",
    "    logger.info(f\"*stsb_multi_mt\")\n",
    "  \n",
    "if use_glue_sts == True:\n",
    "    logger.info(f\"*glue(stsb)\")\n",
    "    \n",
    "start = time.time()\n",
    "\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, main_similarity=main_similarity, batch_size=eval_batch_size, name=csvfilename, show_progress_bar=True)\n",
    "result = test_evaluator(model, output_path=output_path)\n",
    "logger.info(f\"\\n\")\n",
    "        \n",
    "logger.info(f'=== result: {result} ===')\n",
    "logger.info(f'=== 처리시간: {time.time() - start:.3f} 초 ===')\n",
    "logger.info(\"=====================================================\")\n",
    "logger.info(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda05ca6-1270-47ed-836e-3cae20ea88e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
