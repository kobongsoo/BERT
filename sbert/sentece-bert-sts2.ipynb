{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2266a-06cc-41fc-8573-51fee4628282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================================================================================\n",
    "# ai_hub '대규모 웹데이터 기반 한국어 말뭉치 데이터' 데이터셋을 가지고, STS 훈련 및 평가 예시\n",
    "#\n",
    "# => ai_hub '대규모 웹데이터 기반 한국어 말뭉치 데이터'  데이터 셋을 가지고 검색모델 처럼 context와 title를 데이터셋 쌍으로 묶고, STS 훈련시킴. 이때 label은 max(1)이 되도록 훈련.\n",
    "\n",
    "#=> 필요에 따라 출력 dimension을 768보다 작게 줄이고 싶을때 dense 모델을 추가해서 줄일수 있음\n",
    "#=> reduce_out_dimension = True 로 하면, 출력 임베딩 dimension이 줄어들게 설정가능함\n",
    "\n",
    "# => sentence-transformers 패키지를 이용하여 구현 함.(*pip install -U sentence-transformers 설치 필요)\n",
    "#\n",
    "# **learning rate는 기본이 2e-5임\n",
    "#\n",
    "# 도큐먼트 : https://www.sbert.net/index.html\n",
    "# 소스참고 : https://github.com/BM-K/KoSentenceBERT-ETRI\n",
    "#\n",
    "# pip install -U sentence-transformers\n",
    "#\n",
    "# # ** skt/kobert-base-V1  sbert 만들고 나서는 tokenizer_config.json 에 tokenizer_class:\"KoBERTTokenizer\" 를 tokenizer_class:\"XLNetTokenizer\" 로 변경해야함.\n",
    "#==========================================================================================================\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import SimilarityFunction, EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "\n",
    "sys.path.append('..')\n",
    "from myutils import seed_everything, GPU_info, mlogging, getListOfFiles\n",
    "\n",
    "logger = mlogging(loggername=\"s-bert-sts\", logfilename=\"../../log/s-bert-sts\")\n",
    "device = GPU_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f4d38-e45e-4c30-87c8-7a16a002a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import BertTokenizer, BertTokenizerFast\n",
    "\n",
    "# ** skt/kobert-base-V1  sbert 만들고 나서는 tokenizer_config.json 에 tokenizer_class:\"KoBERTTokenizer\" 를 tokenizer_class:\"XLNetTokenizer\" 로 변경해야함.\n",
    "bisSKKobertModel = 0  # skt/kobert-base-V1 허깅페이스 모델 사용시에는 1로 해줌\n",
    "# s-bert로 만들 원본 bert 경로\n",
    "#model_path = '../../data11/model/moco/albert-small-distil/albert-small-kor-sbert-v1.1-nli/'#\"skt/kobert-base-v1\"\n",
    "model_path = \"bongsoo/klue-sbert-v1\"\n",
    "\n",
    "# 원본 bert를 sentencebert로 만든후 만들어진 s-bert 저장 경로\n",
    "# => **해당 경로\\eval 폴더에 similarity_evaluation_sts-dev_result.csv 파일로 각 epoch 마다 평가된 결과가 기록된다.\n",
    "#smodel_path = 'output/training_nli_'+model_name.replace(\"/\", \"-\")+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "#smodel_path = '../../data11/model/bert/mbertV3.0-aihub-NSPMLM-checkout/checkpoint-4129542-sts-b128-lower-bias'#'../../data11/model/sbert/mdistilbertV3.1-sts-b32-lower'\n",
    "smodel_path = '../../data11/model/moco/klue-aihub/klue-sbert-v1-aihub'\n",
    "#======================================================================================================\n",
    "train_batch_size = 64  # base 이상 모델은=128, small 모델은=32 로 하는게 좋음\n",
    "eval_batch_size = 64\n",
    "num_epochs = 10      # 10 정도 해도 최상의 모델을 찾을수 있음 (*sbert는 eval이 최상인 모델이 out모델로 저장됨)\n",
    "max_seq_length = 256\n",
    "lr = 1e-4            # default=2e-5\n",
    "eps = 1e-6           #lr이 0으로 나뉘어져 계산이 엉키는 것을 방지하기 위해 epsilion\n",
    "seed=111\n",
    "\n",
    "# 임베딩 벡터 폴링 모드 선택 (*아래값중 문자열로 입력함, 기본=mean)\n",
    "# mean=단어 평균, max=최대값, cls=문장, \n",
    "#['mean', 'max', 'cls', 'weightedmean', 'lasttoken']\n",
    "pooling_mode = 'mean'\n",
    "\n",
    "do_lower_case_param = True # true = 대.소문자 구분없이 모두 소문자로 변환(*한국어는 True해도 상관없음)\n",
    "\n",
    "# sentence_transformers 2.2.2 부터는 'correct_bias' 인자가 없어졌음. => correct_bias : False 하면 sts 성능이 떨어짐(*원인 모름)\n",
    "use_correct_bias = 0\n",
    "\n",
    "if use_correct_bias == 0:\n",
    "    opt_params = {'lr': lr, 'eps': eps}  # defalut\n",
    "else:\n",
    "    opt_params = {'lr': lr, 'eps': eps, 'correct_bias': False}\n",
    "    print(f'**correct_bias:False')\n",
    "    \n",
    "# 평가 유사도 측정방식(COSINE, EUCLIDEAN, MANHATTAN, DOT_PRODUCT 중 선택 , 모두 spearman 방식임)\n",
    "# => None 이면 아래 값들중 MAX 값 추력함\n",
    "#main_similarity = None\n",
    "main_similarity = SimilarityFunction.COSINE\n",
    "#main_similarity = SimilarityFunction.EUCLIDEAN\n",
    "#main_similarity = SimilarityFunction.MANHATTAN\n",
    "#main_similarity = SimilarityFunction.DOT_PRODUCT\n",
    "\n",
    "#=======================================================================================================\n",
    "# title과 context를 쌍으로 하고, score는 무조건 1.0으로 해서 sts 훈련 시킴\n",
    "CORPORA_TRAIN_FOLDER = '../../data11/ai_hub/ts1/사회일반/' # ai_hub 훈련 말뭉치 .json 파일들이 있는 폴더 경로\n",
    "\n",
    "eval_korsts_file = '../../data11/korpora/korsts/tune_dev.tsv'              # KorSTS 평가 파일들\n",
    "eval_kluests_file = '../../data11/korpora/klue-sts/klue-sts-v1.1_dev.json' # KlueSTS 평가 파일들\n",
    "\n",
    "#============================================================================\n",
    "# *출력 dimension을 줄일 경우에는 True로 하고, out_dimension에 줄일 값을 설정함\n",
    "reduce_out_dimension = False  # True이면 dimension을 줄임=>Dense 모델 추가됨\n",
    "out_dimension = 128\n",
    "#============================================================================\n",
    "\n",
    "seed_everything(seed)\n",
    "\n",
    "#==========================================================================================================\n",
    "# 모델 설정\n",
    "# => * 훈련시킬 모델이 이미 sentencebert일지라도, 아래처럼 SentenceTransformer(model_path) 이용하지 않고, \n",
    "# word_embedding_model, pooling_model 을 각각 만들어서 처리하는것이 테스트 시 효율의 좋음\n",
    "#\n",
    "# [모델 생성 방법]\n",
    "# 1) word_embedding 모델 생성\n",
    "# 2) pooling 모델 생성 : pooling 정책을 설정함 : CLS, 평균, MAX 정책중 택1(*평균 정책이 효율의 가장 좋다고 함)\n",
    "# 3) 1) + 2) 모델을 연결시켜서 하나의 sbert 모델 만듬\n",
    "#==========================================================================================================\n",
    "\n",
    "# 모델과 tokenizer 를 불러옴\n",
    "# => **사전파일(vocab.txt, *.json) 와 model 경로(config.json, pytorch_model.bin)가 같은 경로에 있어야 함.\n",
    "#========================================================================================================\n",
    "# **tokenier가 모델과 다른 경우에는 tokenizer_path 를 모델과 같은 임이 tokenizer로 설정함.\n",
    "# => 모델과 동일한 tokenizer를 로딩한 후, 밑에서 다시 word_embedding_model.tokenizer를 다시 설정함.\n",
    "# => 이렇게 하는 이유는 Transformer 함수 내부에서 AutoTokenizer 를 호출시 모델과 동일한 tokenizer를 자동으로 호출하므로 에러 발생해서 \n",
    "# 꽁수로 모델과 동일한 tokenizer 로딩후, 아래에서 다시 설정하는 것임\n",
    "tokenizer_path = model_path #'bongsoo/albert-small-kor-v1' # model_Path\n",
    "#========================================================================================================\n",
    "word_embedding_model = models.Transformer(model_path, max_seq_length=max_seq_length, do_lower_case=do_lower_case_param, tokenizer_name_or_path=tokenizer_path)\n",
    "\n",
    "#========================================================================================================\n",
    "# **tokenier가 모델과 다른 경우에는 word_embedding_model.tokenizer 다시 설정함.\n",
    "# => 예: 모델은 albert 인데, tokenizer는 berttokenizer 인 경우(원래는 AlbertTokenizer 이어야 함)\n",
    "#word_embedding_model.tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
    "#========================================================================================================\n",
    "\n",
    "#========================================================================================================\n",
    "# skt/kobert 모델은 tokenizer을 XLNET Tokenizer 이므로, 자체 KoBERTTOkenizer 를 불러와서 사용해야 함.\n",
    "# => 설치 : !pip install 'git+https://github.com/SKTBrain/KOBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n",
    "# => 출처 : https://velog.io/@m0oon0/KoBERT-%EC%82%AC%EC%9A%A9%EB%B2%95\n",
    "if bisSKKobertModel == 1:\n",
    "    from kobert_tokenizer import KoBERTTokenizer\n",
    "    word_embedding_model.tokenizer = KoBERTTokenizer.from_pretrained(model_path)\n",
    "    print(f'load koBertTokenizer:{word_embedding_model.tokenizer}')\n",
    "#========================================================================================================\n",
    "\n",
    "# embedding 길이를 재조정 필요할때 auto_model.resize_token_embeddings 해줌\n",
    "print(f'token_len:{len(word_embedding_model.tokenizer)}')\n",
    "word_embedding_model.auto_model.resize_token_embeddings(len(word_embedding_model.tokenizer))\n",
    "\n",
    "# word embedding_model 출력 \n",
    "print(word_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30816f29-8579-4b62-ab99-3f6436035657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 bert 모델의 임베딩 풀링 정책을 설정(cls 이용, 워드임베딩 평균이용, 워드임베딩 max 이용)\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),  #모델이 dimension(768)\n",
    "                               pooling_mode=pooling_mode)  \n",
    "# pooling model 출력 \n",
    "print(pooling_model)\n",
    "print(pooling_model.get_sentence_embedding_dimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5a82c1-c5a5-467e-b758-362c7056918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. dense 모델 추가(옵션)\n",
    "#=> 필요에 따라 출력 dimension을 768보다 작게 줄이고 싶을때 dense 모델을 추가해서 줄임.\n",
    "#=> https://www.sbert.net/docs/training/overview.html?highlight=dense 참조\n",
    "if reduce_out_dimension:\n",
    "    dense_model = models.Dense(in_features=pooling_model.get_sentence_embedding_dimension(), # 입력 dimension은 앞에 pooling모델 embedding dimension으로 지정\n",
    "                               out_features=out_dimension,  # 출력 dimension\n",
    "                               activation_function=nn.Tanh())  # activation function은 Tahn으로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6609d844-3e00-42f9-ae0f-c12102b0925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SBERT 모델 생성\n",
    "if reduce_out_dimension:\n",
    "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model])\n",
    "else:\n",
    "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de9a825-5d52-425f-aa0b-7afd2ce336f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "train_samples = []\n",
    "\n",
    "# json 파일들이 있는 폴더에 .json 파일 이름들을 얻기\n",
    "# =>CORPORA_FOLDER: .JSON파일들이 있는 폴더\n",
    "files = getListOfFiles(CORPORA_TRAIN_FOLDER)\n",
    "assert len(files) > 0 # files가 0이면 assert 발생\n",
    "print('*file_count: {}, file_list:{}\\n'.format(len(files), files[0:5]))\n",
    "\n",
    "count = 0\n",
    "for idx, file in enumerate(tqdm(files)):\n",
    "    if \".json\" not in file:  #.json 파일이 아니면 합치지 않음\n",
    "        continue\n",
    "    \n",
    "    # json 파일 로딩 => [SJML][text] entry만 불러옴\n",
    "    json_data = json.load(open(file, \"r\", encoding=\"utf-8\"))['SJML']['text']\n",
    "    for data in json_data:\n",
    "        title = data['title']\n",
    "        paragraphs = data['content']\n",
    "        score = 1.0\n",
    "        \n",
    "        if count < 3:\n",
    "            print(f\"{title}, {paragraphs}, {score}\")\n",
    "        train_samples.append(InputExample(texts= [title, paragraphs], label=score))\n",
    "        count += 1\n",
    "    \n",
    "logger.info(f'------------------------------------------------------------------------')        \n",
    "logger.info(f'*train_samples_len:{len(train_samples)}')\n",
    "print(train_samples[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a2b16-b2f5-4f97-a751-248c9a7bc1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋, 데이터 로더, 손실함수 정의\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd6642-8234-45a4-9b95-e66e805f1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Read STSbenchmark dataset and use it as development set\n",
    "# 평가데이터 불러오기\n",
    "#korsts 파일로 두 문장간 유사도를 수치로(5.0이 만점=매우 유사) 측정함.\n",
    "dev_samples = []\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "# KorSTS 평가 데이터 셋 설정(.tsv 파일)\n",
    "####################################################################################################\n",
    "count = 0\n",
    "logger.info(f\"Read STS dev dataset=>{eval_korsts_file}\")\n",
    "with open(eval_korsts_file, 'rt', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        text_a, text_b, score = line.split('\\t')\n",
    "        score = score.strip()\n",
    "        score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "            \n",
    "        if count < 5:\n",
    "            print(f\"{text_a}, {text_b}, {score}\")\n",
    "            \n",
    "        dev_samples.append(InputExample(texts= [text_a,text_b], label=score))\n",
    "        count += 1\n",
    "logger.info(f'*{eval_korsts_file} len: {count}')\n",
    "####################################################################################################  \n",
    "\n",
    "####################################################################################################\n",
    "# KlueSTS 평가 데이터 셋 설정(.json 파일)\n",
    "# => 아래처럼 load_dataset으로 불러와서 사용할수도 있음.\n",
    "# datas = load_dataset(\"klue\", \"sts\", split=\"test\")\n",
    "# for data in datas:\n",
    "#        text_a = data[\"sentence1\"]\n",
    "#        text_b = data[\"sentence2\"]\n",
    "#        score = data[\"labels\"][\"label\"]\n",
    "#        score = float(score) / 5.0  \n",
    "####################################################################################################           \n",
    "count = 0\n",
    "logger.info(f\"Read STS dev dataset=>{eval_kluests_file}\")\n",
    "with open(eval_kluests_file, \"rt\", encoding=\"utf-8\") as f:\n",
    "    datas = json.load(f)\n",
    "    for data in datas:\n",
    "        text_a = data[\"sentence1\"]\n",
    "        text_b = data[\"sentence2\"]\n",
    "        score = data[\"labels\"][\"label\"]\n",
    "        score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "\n",
    "        if count < 5:\n",
    "            print(f\"{text_a}, {text_b}, {score}\")\n",
    "\n",
    "        dev_samples.append(InputExample(texts= [text_a,text_b], label=score))\n",
    "        count += 1\n",
    "logger.info(f'*{eval_kluests_file} len: {count}')\n",
    "####################################################################################################  \n",
    "    \n",
    "\n",
    "logger.info(f'------------------------------------------------------------------------')        \n",
    "logger.info(f'*dev_samples_len:{len(dev_samples)}')\n",
    "print(dev_samples[0:3])\n",
    "\n",
    "# 2개의 bert 모델에서 구한 2개의 embedding 값들의 cosine 유사도를 구해서, 이를 실제 score와 비교해서 유사도 측정함\n",
    "dev_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, \n",
    "                                                                 main_similarity=main_similarity,\n",
    "                                                                 batch_size=eval_batch_size, \n",
    "                                                                 name='sts-dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea020cec-bd98-4385-a202-86c76adee505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#warmup_step은 10% 로 설정\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) \n",
    "#warmup_steps = 0 # kcbert-config 참조함 \n",
    "\n",
    "# evaluation_steps은 10%로 설정\n",
    "evaluation_steps = int(len(train_dataset) * num_epochs / train_batch_size * 0.1)\n",
    "\n",
    "logger.info(f\"*IN-model:{model_path}\")\n",
    "logger.info(f\"*OUT-model:{smodel_path}\")\n",
    "logger.info(\"*seed:{}, train_batch:{}, eval_batch:{}, epoch:{}, lr:{}, eps:{}, max_seq_length:{}, train_dataset:{}, Warmup-steps: {}, evaluation_step: {}\".format(seed, train_batch_size, eval_batch_size, num_epochs, lr, eps, max_seq_length, len(train_dataset), warmup_steps, evaluation_steps))\n",
    "logger.info(f\"*do_lower_case:{do_lower_case_param}, use_correct_bias:{use_correct_bias}\")\n",
    "\n",
    "# Train the model\n",
    "# => **learning rate는 기본이 2e-5임\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=dev_evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=evaluation_steps,\n",
    "          warmup_steps=warmup_steps,\n",
    "          optimizer_params= opt_params, \n",
    "          save_best_model=True, # **기본 = True : eval 가장 best 모델을 output_Path에 저장함\n",
    "          output_path=smodel_path\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ce8ee-8b39-4c09-9ce3-85ac036af96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "# => 훈련되어서 저장된 s-bert 모델을 불러와서 성능 평가 해봄\n",
    "##############################################################################\n",
    "import time\n",
    "from sentence_transformers.evaluation import SimilarityFunction\n",
    "\n",
    "# 테스트 파일=KorSTS 테스트파일 경로 지정\n",
    "test_file = '../../data11/korpora/korsts/tune_test.tsv'\n",
    "\n",
    "# 평가시 cosine 유사도등 측정 결과값 파일 (similarity_evaluation_xxxx.xls) 저장될 경로\n",
    "output_path = '../../log'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "test_samples = []\n",
    "with open(test_file, 'rt', encoding='utf-8') as fIn:\n",
    "    lines = fIn.readlines()\n",
    "    for line in lines:\n",
    "        s1, s2, score = line.split('\\t')\n",
    "        score = score.strip()\n",
    "        score = float(score) / 5.0\n",
    "        test_samples.append(InputExample(texts=[s1,s2], label=score))\n",
    "\n",
    "logger.info(\"\\n\")\n",
    "logger.info(\"======================TEST===================\")\n",
    "logger.info(\"\\n\\n\")\n",
    "logger.info(f\"model save path > {smodel_path}\")\n",
    "start = time.time()\n",
    "model = SentenceTransformer(smodel_path)\n",
    "\n",
    "# 유사도 측정방식(COSINE, EUCLIDEAN, MANHATTAN, DOT_PRODUCT 중 선택 , 모두 spearman 방식임)\n",
    "# => None 이면 아래 값들중 MAX 값 추력함\n",
    "#main_similarity = None\n",
    "main_similarity = SimilarityFunction.COSINE\n",
    "#main_similarity = SimilarityFunction.EUCLIDEAN\n",
    "#main_similarity = SimilarityFunction.MANHATTAN\n",
    "#main_similarity = SimilarityFunction.DOT_PRODUCT\n",
    "\n",
    "logger.info(f\"main_similarity: {main_similarity}\")\n",
    "\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, main_similarity=main_similarity, batch_size=eval_batch_size, name='sts-test', show_progress_bar=True)\n",
    "result = test_evaluator(model, output_path=output_path)\n",
    "\n",
    "logger.info(f\"\\n\")\n",
    "logger.info(f\"model path: {smodel_path}\")\n",
    "logger.info(f'=== result: {result} ===')\n",
    "logger.info(f'=== 처리시간: {time.time() - start:.3f} 초 ===')\n",
    "logger.info(\"==============================================\")\n",
    "logger.info(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79dcfa5-7474-4e72-ba49-b77dbdb2ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 model 저장\n",
    "#output_path = \"../../data11/model/sbert/sbert-mdistilbertV3.1-last\"\n",
    "#model.save(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
