{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad5e3edf-a94e-472d-a7b3-5f8c414b1923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:s-bert-ts_2022-06-16.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "#======================================================================================================\n",
    "# sentence-bert 를 tearch-student 관계 모델로 구성하여, 영어 sbert 학습을 학국어 모델에 증류학습시키는 예시\n",
    "# -> 선생님모델은  영어 bert가 되고, 학생모델은 학국어 포함된다국어 bert로 설정\n",
    "# -> 영어 bert가 다국어 bert를 가리키는 방식으로 학습됨\n",
    "#\n",
    "# => sentence-transformers 패키지를 이용하여 구현 함.(*pip install -U sentence-transformers 설치 필요)\n",
    "#\n",
    "# => 여기서는 교사모델을 distiluse-base-multilingual-cased-v2 로, 학생모델은 distilbert-base-multilingual 로 하여 학습시캄.\n",
    "# => distiluse-base-multilingual-cased-v2 는 Teacher: mUSE; Student: distilbert-base-multilingual 로 학습시킨 s-bert 모델임\n",
    "#     (https://www.sbert.net/docs/pretrained_models.html 참조)\n",
    "#\n",
    "# => ** 중요한 것은 교사와 학생모델간 word_embedding dimension은 서로 일치해야 함.(일치하지않으면 훈련시 아래와 같은 에러 발생함)\n",
    "#     에러 : The size of tensor a (768) must match the size of tensor b (384) at non-singleton dimension 1\n",
    "#\n",
    "# [참고 소스] \n",
    "# https://towardsdatascience.com/a-complete-guide-to-transfer-learning-from-english-to-other-languages-using-sentence-embeddings-8c427f8804a9\n",
    "# https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/multilingual/make_multilingual_sys.py\n",
    "#\n",
    "# pip install -U sentence-transformers\n",
    "#======================================================================================================\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "\n",
    "sys.path.append('..')\n",
    "from myutils import seed_everything, GPU_info, mlogging\n",
    "\n",
    "logger = mlogging(loggername=\"s-bert-ts\", logfilename=\"s-bert-ts\")\n",
    "device = GPU_info()\n",
    "seed_everything(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5bfcf70-f795-46e8-8833-6e43b1408b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load teacher model\n",
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 선생님 모델 설정\n",
    "print(\"Load teacher model\")\n",
    "\n",
    "#teacher_model_name = 'bert-base-nli-stsb-mean-tokens'\n",
    "#teacher_model_name = \"../../data11/model/sbert/teacher/distiluse-base-multilingual-cased-v2-not-Dense\"\n",
    "teacher_model_name = \"../../data11/model/sbert/teacher/paraphrase-multilingual-mpnet-base-v2\"\n",
    "\n",
    "teacher_model = SentenceTransformer(teacher_model_name)\n",
    "print(teacher_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8b428c-7028-44e7-a986-acec80f86359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load student model\n",
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: AlbertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================================================\n",
    "# 학생 모델 설정\n",
    "# => * 학생모델이 이미 sentencebert일지라도, 아래처럼 sbert모델 아닌 것처럼 word_embedding_model, pooling_model 을 각각\n",
    "#    만들어서 처리하는것이 테스트 시 효율의 좋음\n",
    "#\n",
    "# [학생 모델 생성 방법]\n",
    "# 1) word_embedding 모델 생성\n",
    "# 2) pooling 모델 생성 : pooling 정책을 설정함 : CLS, 평균, MAX 정책중 택1(*평균 정책이 효율의 가장 좋다고 함)\n",
    "# 3) 1) + 2) 모델을 연결시켜서 하나의 sbert 모델 만듬\n",
    "#==========================================================================================================\n",
    "student_model_name = \"../../data11/model/albert/albert-ts-2022-06-16\"\n",
    "\n",
    "print(\"Load student model\")\n",
    "\n",
    "\n",
    "# === *sbert 모델 아닌 경우 =====\n",
    "# word embedding 모델 설정(기존 다국어 모델 불러옴)\n",
    "word_embedding_model = models.Transformer(student_model_name)\n",
    "\n",
    "# pooling 정책 설정(mean 평균 정책으로 지정)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "\n",
    "# 학생 SBERT 생성\n",
    "# -> word_embedding model 과 pooling_model를 연결시켜줌\n",
    "student_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "\n",
    "# === *sbert 모델 인 경우 =====\n",
    "# 기존 s-model 로딩 함\n",
    "#student_model = SentenceTransformer(student_model_name)\n",
    "\n",
    "print(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf8f7e8b-e46e-410a-b991-bcee2848b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 평가 데이터 불러오고, 손실함수(MSELoss) 설정함(*학생모델에 설정함)\n",
    "# 원본 소스코드 : \n",
    "# https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/datasets/ParallelSentencesDataset.py\n",
    "\n",
    "from sentence_transformers.datasets import ParallelSentencesDataset\n",
    "\n",
    "max_seq_length = 128\n",
    "train_batch_size = 32\n",
    "num_epochs = 40\n",
    "\n",
    "###### Load train sets ######    \n",
    "#train_file = '../korpora/pair/Tatoeba-eng-kor/Tatoeba-eng-kor-train.tsv'\n",
    "train_file = '../../data11/korpora/pair/TED2020-en-ko/TED2020-en-ko-train.tsv'\n",
    "\n",
    "train_reader = ParallelSentencesDataset(student_model=student_model, teacher_model=teacher_model)\n",
    "train_reader.load_data(train_file)\n",
    "train_dataloader = DataLoader(train_reader, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.MSELoss(model=student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fbcac7e-cc7d-496f-b16c-f3c80fca6345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589814\n",
      "('There are many differences among the arts, but there are also universal, cross-cultural aesthetic pleasures and values.', {'There are many differences among the arts, but there are also universal, cross-cultural aesthetic pleasures and values.', '예술들엔 많은 차이점이 있지만, 보편적이고 문화를 뛰어넘는 미적 기쁨과 가치가 있죠.'})\n"
     ]
    }
   ],
   "source": [
    "print(len(train_reader))\n",
    "train_reader.__getitem__(0)\n",
    "print(train_reader.next_entry(0)) # (source, {traget}) 첫번째 문장을 출력해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b56c40a-a560-4302-876c-272894ef2aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###### Load dev sets ######\n",
    "# 평가 데이터 불러와서 유사도 측정 평가자 설정함\n",
    "#=>stst 파일 있는 경우에만 지정해줌.\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentencesDataset, losses,readers\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator,MSEEvaluator, SequentialEvaluator\n",
    "\n",
    "evaluators = []\n",
    "dev_samples = []\n",
    "\n",
    "eval_file = '../../data11/korpora/korsts/tune_test.tsv'\n",
    "with open(eval_file, 'rt', encoding='utf-8') as fIn:\n",
    "    lines = fIn.readlines()\n",
    "    for line in lines:\n",
    "        s1, s2, score = line.split('\\t')\n",
    "        if s1[0] == \"\" or s1[1] == \"\":\n",
    "            continue\n",
    "        score = score.strip()\n",
    "        score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "        dev_samples.append(InputExample(texts= [s1,s2], label=score))\n",
    "\n",
    "# 영어 문장, 한국어 문장 유사도 측정을 위한 평가자(Evaluator) 설정\n",
    "evaluator_sts = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, \n",
    "                                                                 batch_size=train_batch_size, \n",
    "                                                                 name='dev')\n",
    "# evaluators에 추가함(*아래 테스트 데이터 evaluators도 추가함)\n",
    "evaluators.append(evaluator_sts)\n",
    "print(len(dev_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55961955-a3c4-4224-95ae-a42c4a44d706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "###### Load test sets ######\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentencesDataset, losses,readers\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator,MSEEvaluator, SequentialEvaluator, TranslationEvaluator\n",
    "evaluators = []\n",
    "# 테스트 데이터 불러와서 MSE 평가자 설정함\n",
    "src_sentences = []\n",
    "trg_sentences = []\n",
    "\n",
    "#test_file = '../korpora/pair/Tatoeba-eng-kor/Tatoeba-eng-kor-test.tsv'\n",
    "test_file = '../../data11/korpora/pair/TED2020-en-ko/TED2020-en-ko-dev.tsv'\n",
    "\n",
    "# 참고소스: https://texasvaluesaction.org/Foysal87/Bangla-sentence-embedding-transformer/blob/master/Bangla_transformer.py\n",
    "with open(test_file, 'rt', encoding='utf-8') as fIn:\n",
    "    for line in fIn:\n",
    "        splits = line.strip().split('\\t')\n",
    "        if len(splits) != 2:\n",
    "            continue\n",
    "\n",
    "        if splits[0] != \"\" and splits[1] != \"\":\n",
    "            src_sentences.append(splits[0])\n",
    "            trg_sentences.append(splits[1])\n",
    "        \n",
    "test_mse = MSEEvaluator(src_sentences, trg_sentences, teacher_model=teacher_model, name='test')\n",
    "evaluators.append(test_mse)\n",
    "\n",
    "# TranslationEvaluator computes the embeddings for all parallel sentences. \n",
    "# It then check if the embedding of source[i] is the closest to target[i] out of all available target sentences\n",
    "test_acc = TranslationEvaluator(src_sentences, trg_sentences, batch_size=train_batch_size)\n",
    "evaluators.append(test_acc)\n",
    "print(len(src_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfddc50-571a-4fc8-aa9c-4a1bce2b79c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 17:24:00,713 - s-bert-ts - INFO - ----------------------------------------------------------------------\n",
      "2022-06-16 17:24:00,716 - s-bert-ts - INFO - *Warmup-steps:73727, checkpoint_save_steps:147454, ephocs:40, train_data_len:589814, train_batch_size: 32\n",
      "2022-06-16 17:24:00,717 - s-bert-ts - INFO - *teacher_model: ../../data11/model/sbert/teacher/paraphrase-multilingual-mpnet-base-v2\n",
      "2022-06-16 17:24:00,718 - s-bert-ts - INFO - *student_model_name: ../../data11/model/albert/albert-ts-2022-06-16\n",
      "2022-06-16 17:24:00,720 - s-bert-ts - INFO - ----------------------------------------------------------------------\n",
      "2022-06-16 17:24:00,721 - s-bert-ts - INFO - *train_file: ../../data11/korpora/pair/TED2020-en-ko/TED2020-en-ko-train.tsv\n",
      "2022-06-16 17:24:00,722 - s-bert-ts - INFO - *test_file: ../../data11/korpora/pair/TED2020-en-ko/TED2020-en-ko-dev.tsv\n",
      "2022-06-16 17:24:00,723 - s-bert-ts - INFO - ----------------------------------------------------------------------\n",
      "2022-06-16 17:24:00,724 - s-bert-ts - INFO - *out_path: ../../data11/model/albert/albert-ts-2022-06-16-1\n",
      "2022-06-16 17:24:00,725 - s-bert-ts - INFO - *check_path: ../../data11/model/albert/checkpoint-2022-06-16\n",
      "2022-06-16 17:24:00,726 - s-bert-ts - INFO - ----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876c1e1ab2df424a8c5456bb7bbeb74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361185a4b980488fb26a6c5c68f696fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/MOCOMSYS/anaconda3/envs/bong/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:537: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180487213/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  labels = torch.tensor(labels).to(self._target_device)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8406247b3aad43a58918d7ab51c1ae9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb80bdb05f241d5af374d37718c6190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e3f0c2470b493083187e0088765ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1129bcb231784e5abb54deb235cf5de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d5769c9084486d8dd559fd1f696b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd975956bb7f47c5a0d6545be409d7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b974d5b790d4699a587face25863773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edda0b39f4ad431586b886c58d6b6477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf3d34a3dfb487d99b67ed776f9199f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5273e41bd4455aa82d0d09e285048c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c217626c3ee04c8a88b93ca364c65c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05760d2ba01a409096ee40b99dfe4190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949738660c3846efaee1f4b62ce91f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6003b3f48348ffa09cbcb093801c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec82ea6ebf944048dcf98873bb17db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2e09b79d2a4280a067a480d76c4d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cd1ca7237d4dd491e6226bb6080b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e02767c2ca4948a3e778a187ce6d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69582652b6504255b7326949be6131cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9276bdadf646dca6d9fbd2441489ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/18432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Train model ######\n",
    "# 훈련 시작\n",
    "# 훈련을 시작하면, output_path/eval/ 폴더에 mse 테스트, similarity 테스트 csv 파일에 기록됨\n",
    "# (mse_evaluation_test_results.csv , similarity_evaluation_dev_results.csv)\n",
    "import time\n",
    "\n",
    "#10% of train data for warm-up\n",
    "warmup_steps = math.ceil(len(train_reader) * num_epochs / train_batch_size * 0.1) \n",
    "evaluation_steps = warmup_steps\n",
    "checkpoint_save_steps = warmup_steps * 2\n",
    "\n",
    "output_path = \"../../data11/model/albert/albert-ts-\" + datetime.now().strftime(\"%Y-%m-%d\") + \"-1\"\n",
    "check_path = \"../../data11/model/albert/checkpoint-\" + datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "logger.info(f\"----------------------------------------------------------------------\")\n",
    "logger.info(\"*Warmup-steps:{}, checkpoint_save_steps:{}, ephocs:{}, train_data_len:{}, train_batch_size: {}\".format(warmup_steps, checkpoint_save_steps, num_epochs, len(train_reader), train_batch_size))\n",
    "logger.info(\"*teacher_model: {}\".format(teacher_model_name))\n",
    "logger.info(\"*student_model_name: {}\".format(student_model_name))\n",
    "logger.info(f\"----------------------------------------------------------------------\")\n",
    "logger.info(\"*train_file: {}\".format(train_file))\n",
    "#logger.info(\"*eval_file: {}\".format(eval_file))\n",
    "logger.info(\"*test_file: {}\".format(test_file))\n",
    "logger.info(f\"----------------------------------------------------------------------\")\n",
    "logger.info(\"*out_path: {}\".format(output_path))\n",
    "logger.info(\"*check_path: {}\".format(check_path))\n",
    "logger.info(f\"----------------------------------------------------------------------\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "student_model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=SequentialEvaluator(evaluators, main_score_function=lambda scores: scores[-1]),\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=evaluation_steps,\n",
    "          warmup_steps=warmup_steps,   # 옵티마이저 2e-5까지 처음 1000 번은 아주작게 스탭을 옮김\n",
    "          scheduler='warmupconstant',\n",
    "          output_path=output_path,\n",
    "          save_best_model=True,\n",
    "          optimizer_params= {'lr': 3e-5, 'eps': 1e-6, 'correct_bias': False},\n",
    "          checkpoint_path=check_path,\n",
    "          checkpoint_save_steps=checkpoint_save_steps,\n",
    "          checkpoint_save_total_limit=5 \n",
    "          )\n",
    "\n",
    "logger.info(f'=== 처리시간: {time.time() - start:.3f} 초 ===')\n",
    "logger.info(f\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61b8a8-3cb8-41ac-bac7-ec1592e14c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 model 저장\n",
    "output_path = \"../../data11/model/albert/albert-ts-last-\" + datetime.now().strftime(\"%Y-%m-%d\")\n",
    "student_model.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00fbf25-f922-4f67-b486-1460db8f137a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
