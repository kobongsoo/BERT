{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9bfffa-9708-49ce-815c-2c95531244af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/MOCOMSYS/anaconda3/envs/bong/lib/python3.9/site-packages/huggingface_hub/snapshot_download.py:6: FutureWarning: snapshot_download.py has been made private and will no longer be available from version 0.11. Please use `from huggingface_hub import snapshot_download` to import the only public function in this module. Other members of the file may be changed without a deprecation notice.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:../../log/s-bert_2022-10-13.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "#======================================================================================================\n",
    "# by kobongsoo, \n",
    "# ============= HISTORY =============================================\n",
    "# make by: 2022-04-13\n",
    "# updata: 2022-09-27\n",
    "# => KlueNLI 데이터 셋 추가\n",
    "# => 데이터 셋은 KorNLI(550,152) 가 KlueNLI(24,998)보다 20배정도 크지만, \n",
    "# Klue 데이터 셋이 실제 모델 훈련에는 더 좋다고 함.\n",
    "# ======================================================================\n",
    "#\n",
    "# sentence-bert NLI 훈련 및 평가 예시\n",
    "# => 기존 (distil)bert 모델을 가지고, NLI로 훈련 및 평가 후, S-BERT로 만드는 예시임.\n",
    "#\n",
    "#=> 필요에 따라 출력 dimension을 768보다 작게 줄이고 싶을때 dense 모델을 추가해서 줄일수 있음\n",
    "#=> reduce_out_dimension = True 로 하면, 출력 임베딩 dimension이 줄어들게 설정가능함\n",
    "#\n",
    "# => sentence-transformers 패키지를 이용하여 구현 함.(*pip install -U sentence-transformers 설치 필요)\n",
    "#\n",
    "# 도큐먼트 : https://www.sbert.net/index.html\n",
    "# 소스참고 : https://github.com/BM-K/KoSentenceBERT-ETRI\n",
    "\n",
    "# pip install -U sentence-transformers\n",
    "#======================================================================================================\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "\n",
    "sys.path.append('..')\n",
    "from myutils import seed_everything, GPU_info, mlogging\n",
    "\n",
    "logger = mlogging(loggername=\"s-bert\", logfilename=\"../../log/s-bert\")\n",
    "device = GPU_info()\n",
    "seed_everything(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad0402a-9791-4e56-804d-97e664179203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n"
     ]
    }
   ],
   "source": [
    "# s-bert로 만들 원본 bert 경로\n",
    "model_path = \"../../data11/model/sbert/sbert-mdistilbertV3.1.1-disitl-ns-1\"\n",
    "\n",
    "# 원본 bert를 sentencebert로 만든후 만들어진 s-bert 저장 경로\n",
    "# => **해당 경로\\eval 폴더에 similarity_evaluation_sts-dev_result.csv 파일로 각 epoch 마다 평가된 결과가 기록된다.\n",
    "#smodel_path = 'output/training_nli_'+model_name.replace(\"/\", \"-\")+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "smodel_path = \"../../data11/model/sbert/sbert-mdistilbertV3.1.1-disitl-ns-1.5\"\n",
    "\n",
    "use_kor = True   #kornli 훈련하는 경우 == True\n",
    "use_klue = True  #kluenli 훈련하는 경우 == True\n",
    "\n",
    "# KorNLI, KorSTS 파일 경로\n",
    "train_kornli_file = '../../data11/korpora/kornli/snli_1.0_train.ko.tsv'\n",
    "eval_korsts_file = '../../data11/korpora/korsts/tune_dev.tsv'\n",
    "\n",
    "# KLUENIL, KlueSTS 파일 경로\n",
    "train_kluenli_file = '../../data11/korpora/klue-nli/klue-nli-v1.1_train.json'\n",
    "eval_kluests_file = '../../data11/korpora/klue-sts/klue-sts-v1.1_dev.json'\n",
    "\n",
    "train_batch_size = 256\n",
    "num_epochs = 8          # 8 정도면 최상의 값 찾을수 있음\n",
    "max_seq_length = 128\n",
    "lr = 3e-5  # default=2e-5\n",
    "eps = 1e-6\n",
    "# * True=모델에 상관없이 영어는 소문자로 입력하겠다는 뜻(glue는 소문자로만 비교하는게 더 적확함), 한국어는 True도 상관없음\n",
    "#do_lower_case = True \n",
    "do_lower_case = False  \n",
    "#============================================================================\n",
    "# *출력 dimension을 줄일 경우에는 True로 하고, out_dimension에 줄일 값을 설정함\n",
    "reduce_out_dimension = False  # True이면 dimension을 줄임=>Dense 모델 추가됨\n",
    "out_dimension = 128\n",
    "#============================================================================\n",
    "\n",
    "# 모델과 tokenizer 를 불러옴\n",
    "# => **사전파일(vocab.txt, *.json) 와 model 경로(config.json, pytorch_model.bin)가 같은 경로에 있어야 함.\n",
    "word_embedding_model = models.Transformer(model_path, max_seq_length=max_seq_length, do_lower_case=do_lower_case)\n",
    "\n",
    "# word embedding_model 출력 \n",
    "print(word_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93d62b1e-7da7-4f63-b969-44c0f3812aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "# 2 bert 모델의 임베딩 풀링 정책을 설정(cls 이용, 워드임베딩 평균이용, 워드임베딩 max 이용)\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),  #모델이 dimension(768)\n",
    "                               pooling_mode_mean_tokens=True,  # 워드 임베딩 평균을 이용\n",
    "                               pooling_mode_cls_token=False,   # cls 를 이용\n",
    "                               pooling_mode_max_tokens=False)  # 워드 임베딩 값중 max 값을 이용\n",
    "# pooling model 출력 \n",
    "print(pooling_model)\n",
    "print(pooling_model.get_sentence_embedding_dimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "344136f0-7274-4a54-91f6-528e3662480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. dense 모델 추가(옵션)\n",
    "#=> 필요에 따라 출력 dimension을 768보다 작게 줄이고 싶을때 dense 모델을 추가해서 줄임.\n",
    "#=> https://www.sbert.net/docs/training/overview.html?highlight=dense 참조\n",
    "if reduce_out_dimension:\n",
    "    dense_model = models.Dense(in_features=pooling_model.get_sentence_embedding_dimension(), # 입력 dimension은 앞에 pooling모델 embedding dimension으로 지정\n",
    "                               out_features=out_dimension,  # 출력 dimension\n",
    "                               activation_function=nn.Tanh())  # activation function은 Tahn으로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff4b4be6-0fcc-46ab-9542-3bf81abed98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# SBERT 모델 생성\n",
    "if reduce_out_dimension:\n",
    "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model])\n",
    "else:\n",
    "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf6deb2a-3609-4358-b665-ca971a55841e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 12:32:57,698 - s-bert - INFO - Read NLI train dataset:../../data11/korpora/kornli/snli_1.0_train.ko.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말을 탄 사람이 고장난 비행기 위로 뛰어오른다., 한 사람이 경쟁을 위해 말을 훈련시키고 있다., 1\n",
      "말을 탄 사람이 고장난 비행기 위로 뛰어오른다., 한 사람이 식당에서 오믈렛을 주문하고 있다., 2\n",
      "말을 탄 사람이 고장난 비행기 위로 뛰어오른다., 사람은 야외에서 말을 타고 있다., 0\n",
      "카메라에 웃고 손을 흔드는 아이들, 그들은 부모님을 보고 웃고 있다, 1\n",
      "카메라에 웃고 손을 흔드는 아이들, 아이들이 있다, 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 12:33:00,380 - s-bert - INFO - *kornli len: 550152\n",
      "2022-10-13 12:33:00,382 - s-bert - INFO - Read NLI train dataset:../../data11/korpora/klue-nli/klue-nli-v1.1_train.json\n",
      "2022-10-13 12:33:00,559 - s-bert - INFO - *kluenli len: 24998\n",
      "2022-10-13 12:33:00,561 - s-bert - INFO - *train_samples_len:575150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "힛걸 진심 최고다 그 어떤 히어로보다 멋지다, 힛걸 진심 최고로 멋지다., 0\n",
      "100분간 잘껄 그래도 소닉붐땜에 2점준다, 100분간 잤다., 2\n",
      "100분간 잘껄 그래도 소닉붐땜에 2점준다, 소닉붐이 정말 멋있었다., 1\n",
      "100분간 잘껄 그래도 소닉붐땜에 2점준다, 100분간 자는게 더 나았을 것 같다., 1\n",
      "101빌딩 근처에 나름 즐길거리가 많습니다., 101빌딩 근처에서 즐길거리 찾기는 어렵습니다., 2\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 불러오기\n",
    "# => [sentence1, sentence2], labels 식으로 만듬\n",
    "label2int = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "train_samples = []\n",
    "\n",
    "####################################################################################################\n",
    "# KorNLI 훈련 데이터 셋 설정(.tsv 파일)\n",
    "####################################################################################################\n",
    "if use_kor == True:\n",
    "    count = 0\n",
    "    logger.info(f\"Read NLI train dataset:{train_kornli_file}\")\n",
    "\n",
    "    with open(train_kornli_file, \"rt\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            s1, s2, label = line.split('\\t')\n",
    "            label = label2int[label.strip()]\n",
    "            if count < 5:\n",
    "                print(f\"{s1}, {s2}, {label}\")\n",
    "            \n",
    "            train_samples.append(InputExample(texts=[s1, s2], label=label))\n",
    "            count += 1\n",
    "        \n",
    "    logger.info(f'*kornli len: {count}')\n",
    "####################################################################################################\n",
    "\n",
    "####################################################################################################\n",
    "# KlueNLI 훈련 데이터 셋 설정(.json 파일)\n",
    "# => 아래처럼 load_dataset으로 불러와서 사용할수도 있음.\n",
    "# datas = load_dataset(\"klue\", \"nli\", split=\"train\")\n",
    "# for data in datas:\n",
    "#        s1 = data[\"sentence1\"]\n",
    "#        s2 = data[\"sentence2\"]\n",
    "#        label = data[\"label\"][\"label\"]\n",
    "###################################################################################################    \n",
    "# kluenli 훈련인 경우 \n",
    "if use_klue == True:\n",
    "    count = 0\n",
    "    import json\n",
    "    logger.info(f\"Read NLI train dataset:{train_kluenli_file}\")\n",
    "\n",
    "    with open(train_kluenli_file, \"rt\", encoding=\"utf-8\") as f:\n",
    "        datas = json.load(f)\n",
    "        for data in datas:\n",
    "            #print(data)\n",
    "            s1 = data[\"premise\"].strip()\n",
    "            s2 = data[\"hypothesis\"].strip()\n",
    "            label = label2int[data[\"gold_label\"].strip()]\n",
    "            if count < 5:\n",
    "                print(f\"{s1}, {s2}, {label}\")\n",
    "\n",
    "            train_samples.append(InputExample(texts=[s1, s2], label=label))\n",
    "            count += 1\n",
    "            \n",
    "    logger.info(f'*kluenli len: {count}')\n",
    "        \n",
    "logger.info(f'*train_samples_len:{len(train_samples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80277681-2a65-4096-b601-c1e6763a98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋, 데이터 로더, 손실함수 정의\n",
    "train_dataset = SentencesDataset(train_samples, model=model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "# train_loss 정의 \n",
    "# => 기본은 MSELoss 인데, NLI 훈련시에는 MultilpleNegativesRankingLoss(MNR Loss)가 좋다고 함.\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "#train_loss = losses.SoftmaxLoss(model=model, \n",
    "#                                sentence_embedding_dimension=model.get_sentence_embedding_dimension(), \n",
    "#                                num_labels=len(label2int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c1829e-edb9-4bb7-b150-d478c8c854c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 12:33:00,578 - s-bert - INFO - Read STS dev dataset=>../../data11/korpora/korsts/tune_dev.tsv\n",
      "2022-10-13 12:33:00,615 - s-bert - INFO - Read STS dev dataset=>../../data11/korpora/klue-sts/klue-sts-v1.1_dev.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안전모를 가진 한 남자가 춤을 추고 있다., 안전모를 쓴 한 남자가 춤을 추고 있다., 1.0\n",
      "어린아이가 말을 타고 있다., 아이가 말을 타고 있다., 0.95\n",
      "한 남자가 뱀에게 쥐를 먹이고 있다., 남자가 뱀에게 쥐를 먹이고 있다., 1.0\n",
      "한 여성이 기타를 연주하고 있다., 한 남자가 기타를 치고 있다., 0.48\n",
      "한 여성이 플루트를 연주하고 있다., 남자가 플루트를 연주하고 있다., 0.55\n",
      "무엇보다도 호스트분들이 너무 친절하셨습니다., 무엇보다도, 호스트들은 매우 친절했습니다., 0.9800000000000001\n",
      "주요 관광지 모두 걸어서 이동가능합니다., 위치는 피렌체 중심가까지 걸어서 이동 가능합니다., 0.27999999999999997\n",
      "학생들의 균형 있는 영어능력을 향상시킬 수 있는 학교 수업을 유도하기 위해 2018학년도 수능부터 도입된 영어 영역 절대평가는 올해도 유지한다., 영어 영역의 경우 학생들이 한글 해석본을 암기하는 문제를 해소하기 위해 2016학년도부터 적용했던 EBS 연계 방식을 올해도 유지한다., 0.26\n",
      "다만, 도로와 인접해서 거리의 소음이 들려요., 하지만, 길과 가깝기 때문에 거리의 소음을 들을 수 있습니다., 0.74\n",
      "형이 다시 캐나다 들어가야 하니 가족모임 일정은 바꾸지 마세요., 가족 모임 일정은 바꾸지 말도록 하십시오., 0.5\n"
     ]
    }
   ],
   "source": [
    "#Read STSbenchmark dataset and use it as development set\n",
    "# 평가데이터 불러오기\n",
    "#korsts 파일로 두 문장간 유사도를 수치로(5.0이 만점=매우 유사) 측정함.\n",
    "dev_samples = []\n",
    "\n",
    "####################################################################################################\n",
    "# KorSTS 평가 데이터 셋 설정(.tsv 파일)\n",
    "####################################################################################################\n",
    "if use_kor == True:\n",
    "    count = 0\n",
    "    logger.info(f\"Read STS dev dataset=>{eval_korsts_file}\")\n",
    "    with open(eval_korsts_file, 'rt', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            text_a, text_b, score = line.split('\\t')\n",
    "            score = score.strip()\n",
    "            score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "            \n",
    "            if count < 5:\n",
    "                print(f\"{text_a}, {text_b}, {score}\")\n",
    "            \n",
    "            dev_samples.append(InputExample(texts= [text_a,text_b], label=score))\n",
    "            count += 1\n",
    "####################################################################################################  \n",
    "\n",
    "####################################################################################################\n",
    "# KlueSTS 평가 데이터 셋 설정(.json 파일)\n",
    "# => 아래처럼 load_dataset으로 불러와서 사용할수도 있음.\n",
    "# datas = load_dataset(\"klue\", \"sts\", split=\"test\")\n",
    "# for data in datas:\n",
    "#        text_a = data[\"sentence1\"]\n",
    "#        text_b = data[\"sentence2\"]\n",
    "#        score = data[\"labels\"][\"label\"]\n",
    "#        score = float(score) / 5.0  \n",
    "####################################################################################################           \n",
    "if use_klue == True:\n",
    "    count = 0\n",
    "    logger.info(f\"Read STS dev dataset=>{eval_kluests_file}\")\n",
    "    with open(eval_kluests_file, \"rt\", encoding=\"utf-8\") as f:\n",
    "        datas = json.load(f)\n",
    "        for data in datas:\n",
    "            text_a = data[\"sentence1\"]\n",
    "            text_b = data[\"sentence2\"]\n",
    "            score = data[\"labels\"][\"label\"]\n",
    "            score = float(score) / 5.0  #5로 나눠서 0~1 사이가 되도록 함\n",
    "\n",
    "            if count < 5:\n",
    "                print(f\"{text_a}, {text_b}, {score}\")\n",
    "\n",
    "            dev_samples.append(InputExample(texts= [text_a,text_b], label=score))\n",
    "            count += 1\n",
    "####################################################################################################  \n",
    "\n",
    "    \n",
    "# 2개의 bert 모델에서 구한 2개의 embedding 값들의 cosine 유사도를 구해서, 이를 실제 score와 비교해서 유사도 측정함\n",
    "dev_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, \n",
    "                                                                 batch_size=train_batch_size, \n",
    "                                                                 name='sts-dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eaf5a2e-df6a-424b-90fc-1b55ed09d32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 12:33:00,636 - s-bert - INFO - model:../../data11/model/sbert/sbert-mdistilbertV3.1.1-disitl-ns-1, smodel:../../data11/model/sbert/sbert-mdistilbertV3.1.1-disitl-ns-1.5\n",
      "2022-10-13 12:33:00,638 - s-bert - INFO - *batch_size: 256, epoch:8, train_dataset:575150, Warmup-steps: 1798, evaluation_step: 3594\n",
      "/MOCOMSYS/anaconda3/envs/bong/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939c09ab21ef41af8148651b9b62181c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de6cde56805486da81f9a0d43ec4de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf79551dbb264ba0ba947bedc1c1a467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19d8e6da7bc43b18d776da4d89396e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfa85e504294bf0a0d34c901c287b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdbe7b74ac704f97806a200f274de8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59aaae709e64c6f88b2384346e6b11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1343b7159246b5a8d0a7e1c65cf99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47cf38abf6043c89f247bf10fab9a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "# evaluation_steps은 20%로 설정\n",
    "evaluation_steps = int(len(train_dataset) * num_epochs / train_batch_size * 0.2)\n",
    "logger.info(f\"model:{model_path}, smodel:{smodel_path}\")\n",
    "logger.info(\"*batch_size: {}, epoch:{}, train_dataset:{}, Warmup-steps: {}, evaluation_step: {}\".format(train_batch_size, num_epochs, len(train_dataset), warmup_steps, evaluation_steps))\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=dev_evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=evaluation_steps,\n",
    "          warmup_steps=warmup_steps,\n",
    "          optimizer_params= {'lr': lr, 'eps': eps, 'correct_bias': False},\n",
    "          save_best_model=True, # **기본 = True : eval 가장 best 모델을 output_Path에 저장함\n",
    "          output_path=smodel_path\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47bb6494-f8ee-4e73-97cf-e27f8936c0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 13:57:56,729 - s-bert - INFO - \n",
      "\n",
      "2022-10-13 13:57:56,732 - s-bert - INFO - ======================TEST===================\n",
      "2022-10-13 13:57:56,732 - s-bert - INFO - \n",
      "\n",
      "\n",
      "2022-10-13 13:57:56,733 - s-bert - INFO - model save path > ../../data11/model/sbert/sbert-mdistilbertV3.1.1-disitl-ns-1.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bc5fa38f794de3b45321eb42b1a946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4824877132345259634893794ed4b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 13:57:59,538 - s-bert - INFO - 처리시간 > 2.8043\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "# => 훈련되어서 저장된 s-bert 모델을 불러와서 성능 평가 해봄\n",
    "##############################################################################\n",
    "import time\n",
    "\n",
    "# 훈련완료후 테스트해볼 파일 경로(*Kluests_test 파일은 없어서, korsts test 파일 이용)\n",
    "test_sts = '../../data11/korpora/korsts/tune_test.tsv'\n",
    "test_batch_size = 32\n",
    "\n",
    "# 테스트시 cosine 유사도등 측정 결과값 파일 (similarity_evaluation_xxxx.xls) 저장될 경로\n",
    "test_output_path = \"./output\"\n",
    "os.makedirs(test_output_path, exist_ok=True)\n",
    "\n",
    "test_samples = []\n",
    "with open(test_sts, 'rt', encoding='utf-8') as fIn:\n",
    "    lines = fIn.readlines()\n",
    "    for line in lines:\n",
    "        s1, s2, score = line.split('\\t')\n",
    "        score = score.strip()\n",
    "        score = float(score) / 5.0\n",
    "        test_samples.append(InputExample(texts=[s1,s2], label=score))\n",
    "\n",
    "logger.info(\"\\n\")\n",
    "logger.info(\"======================TEST===================\")\n",
    "logger.info(\"\\n\\n\")\n",
    "logger.info(f\"model save path > {smodel_path}\")\n",
    "start = time.time()\n",
    "model = SentenceTransformer(smodel_path)\n",
    "\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, batch_size=test_batch_size, name='sts-test', show_progress_bar=True)\n",
    "test_evaluator(model, output_path=test_output_path)\n",
    "logger.info(f\"처리시간 > {time.time() - start:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "529dd225-d60f-426b-960a-8bb7df22f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 model 저장\n",
    "#test_output_path = \"../../data11/model/sbert/test\"\n",
    "#model.save(test_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a105b-3163-427d-b289-e29483594e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
