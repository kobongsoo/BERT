{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d00b4d-9974-4123-bf7b-64de0f9feed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "# 입력 폴더에 말뭉치들을 regular express 처리하는 예제\n",
    "################################################################################################\n",
    "\n",
    "import os\n",
    "\n",
    "# 입력 폴더 말뭉치 파일명들을 리스트로 얻어옴\n",
    "in_folder_path = '../../../korpora/moco/txt'\n",
    "file_list = os.listdir(in_folder_path)\n",
    "print(file_list)\n",
    "\n",
    "# 출력 폴더 지정. 없으면 폴더 생성\n",
    "out_folder_path = '../../../korpora/moco/re-txt'\n",
    "os.makedirs(out_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049b7429-fce6-4268-a221-fb4131a5f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# regular express를 이용한 말뭉치 정재하기\n",
    "#\n",
    "#############################################################################\n",
    "# 정규화할 인자들\n",
    "alphabetP=True            # False=알바벳 제거\n",
    "numberP=True             # False=숫자제거\n",
    "punctuationP=False       # False=특수문자 (, . ? !) 제거\n",
    "symbolP=False            # False=괄호((), [], {}, ], ')등 제거\n",
    "\n",
    "# 4번이상 반복되는 단어 중복 제거 (remove_repeat_wordP=2 : 2번만 호출)\n",
    "# => 예: 안녕안녕안녕안녕 => 안녕안녕, 안녕 안녕 안녕 안녕 => 그대로(*띄어쓰기한 단어는 중복제거 안됨)\n",
    "remove_repeat_wordP=2     \n",
    "\n",
    "# 4번이상 반복되는 문자 중복 제거 (nremove_repeat_charP=2 : 2번만 호출)\n",
    "# => 예: aaaaa => aa, aaa aaa aaa aaa => 그대로(*띄어쓰기한 문자는 중복제거 안됨)\n",
    "remove_repeat_charP=2\n",
    "\n",
    "# 정규화할 입력 text가 있는 폴더\n",
    "#in_txt_path = '../../../korpora/kowiki/kowiki-202206-nlp-corpus.txt'\n",
    "#in_txt_path = '../../../korpora/moco/test-60.txt'\n",
    "\n",
    "# 출력 text\n",
    "#out_txt_path = '../../../korpora/kowiki/re-kowiki-202206-nlp-corpus.txt'\n",
    "\n",
    "# 삭제할 최대 길이 문장\n",
    "remove_min_len = 30 # 20이면 20보다 작은문장은 제거함\n",
    "\n",
    "remove_max_len = 600 # 1000자 보다 큰 문장은 제거함\n",
    "\n",
    "print_count = 100000 # 10000번째마다 문장 출력해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26396d-627d-487b-8732-44aa16668a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reqular 함수들 정의 \n",
    "import re\n",
    "\n",
    "doublespace_pattern = re.compile('\\s+')\n",
    "repeatchars_pattern = re.compile('(\\w)\\\\1{3,}')\n",
    "number_pattern = re.compile('[0-9]')\n",
    "punctuation_pattern = re.compile('[,\\.\\?\\!]')\n",
    "symbol_pattern = re.compile('[()\\[\\]\\{\\}`]')\n",
    "hangle_pattern = re.compile('[ㄱ-ㅎㅏ-ㅣ가-힣]')\n",
    "alphabet_pattern = re.compile('[a-zA-Z]')\n",
    "\n",
    "hangle_filter = re.compile('[^ㄱ-ㅎㅏ-ㅣ가-힣]')\n",
    "hangle_number_filter = re.compile('[^ㄱ-ㅎㅏ-ㅣ가-힣0-9]')\n",
    "text_filter = re.compile('[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9,\\.\\?\\!\\\"\\'-()\\[\\]\\{\\}]')\n",
    "\n",
    "##========================================================================\n",
    "# 4번이상 반복되는 단어 중복 제거 (num_repeat=2 : 2번만 호출)\n",
    "# => 예: 안녕안녕안녕안녕 => 안녕안녕, 안녕 안녕 안녕 안녕 => 그대로(*띄어쓰기한 단어는 중복제거 안됨)\n",
    "repeatchars_patterns = [\n",
    "    re.compile('(\\w\\w\\w\\w)\\\\1{3,}'),\n",
    "    re.compile('(\\w\\w\\w)\\\\1{3,}'),\n",
    "    re.compile('(\\w\\w)\\\\1{3,}'),\n",
    "    re.compile('(\\w)\\\\1{3,}')\n",
    "]\n",
    "\n",
    "def normalizetoken(sentence, num_repeat=2):\n",
    "    tokens = sentence.split()\n",
    "    return ' '.join(_normalize_korean_token(token, num_repeat) for token in tokens)\n",
    "\n",
    "def _normalize_korean_token(token, num_repeat=2):\n",
    "    #print(token)\n",
    "    #token = _normalize_emoji(token)\n",
    "    token = _remove_repeat(token, num_repeat)\n",
    "    return token\n",
    "\n",
    "def _remove_repeat(token, num_repeat=2):\n",
    "    if num_repeat > 0:\n",
    "        for pattern in repeatchars_patterns:\n",
    "            #print(pattern)\n",
    "            token = pattern.sub('\\\\1' * num_repeat, token)\n",
    "    return token\n",
    "##========================================================================\n",
    "\n",
    "\n",
    "def normalize(sentence, \n",
    "              alphabet=False, \n",
    "              number=False,\n",
    "              punctuation=False, \n",
    "              symbol=False, \n",
    "              remove_repeat_word=0, \n",
    "              remove_repeat_char=0):\n",
    "\n",
    "    sentence = text_filter.sub(' ', sentence)\n",
    "    \n",
    "    if not alphabet:\n",
    "        sentence = alphabet_pattern.sub(' ', sentence)\n",
    "    if not number:\n",
    "        sentence = number_pattern.sub(' ', sentence)\n",
    "    if not punctuation:\n",
    "        sentence = punctuation_pattern.sub(' ', sentence)\n",
    "    if not symbol:\n",
    "        sentence = symbol_pattern.sub(' ', sentence)\n",
    "    if remove_repeat_char > 0:\n",
    "        sentence = repeatchars_pattern.sub('\\\\1' * remove_repeat_char, sentence)\n",
    "        \n",
    "    if remove_repeat_word > 0:\n",
    "        sentence = normalizetoken(sentence, num_repeat=remove_repeat_word)\n",
    "        \n",
    "    return doublespace_pattern.sub(' ', sentence).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba3e377-e63e-41b6-b72e-e724a17e30ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## yield 를 이용하여 generator 함수 정의    \n",
    "def get_generator_corpus(data, max_len: int=100000):\n",
    "    \n",
    "    #dataset = data\n",
    "    dataset = list(set(data)) # ****중복 문장 제거(*순서 유지 안함)\n",
    "    \n",
    "    for start_idx in range(0, len(dataset), max_len):\n",
    "        samples = dataset[start_idx : start_idx + max_len]\n",
    "        yield samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccffa2c-71e7-4b6c-8dec-19c5dcb2a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for filename in file_list:\n",
    "    in_txt_path = in_folder_path+'/'+filename  # 입력 말뭉치 파일 풀경로 \n",
    "    out_txt_path = out_folder_path+'/'+filename# 출력 파일 풀경로 \n",
    "    \n",
    "    # 1.분석할 text 읽어오기(한줄씩 읽어오기)\n",
    "    with open(in_txt_path, 'r', encoding='utf8') as f:\n",
    "        #lines = f.read()\n",
    "        lines = f.readlines()\n",
    "        #print(lines)\n",
    "\n",
    "    training_corpus = get_generator_corpus(lines)\n",
    "\n",
    "    result=[]\n",
    "    count = 0\n",
    "    for lines in training_corpus:\n",
    "        for line in tqdm(lines):\n",
    "\n",
    "            #print(line)\n",
    "            # false=제거함.\n",
    "            clearline = normalize(line, \n",
    "                                  alphabet=alphabetP, number=numberP, punctuation=punctuationP, symbol=symbolP, \n",
    "                                  remove_repeat_word=remove_repeat_wordP, remove_repeat_char=remove_repeat_charP)\n",
    "\n",
    "            clearline1=clearline.strip()\n",
    "            count += 1\n",
    "            if count % print_count == 0:  # print_count 째마다 출력해봄\n",
    "                print(f'[{count}]{clearline1}')\n",
    "\n",
    "            #if clearline1 not in result: # ****순서유지 중복 제거(*순서유지하는 경우 시간 오래걸림)\n",
    "\n",
    "            # remove_min_len 보가 크고, remove_max_len 보다 작은 경우에만 저장\n",
    "            clearline1_len = len(clearline1)\n",
    "            if clearline1_len > remove_min_len and clearline1_len < remove_max_len: # 20자 이상인 경우에만 출력\n",
    "                #print(clearline1)\n",
    "                result.append(clearline1)\n",
    "\n",
    "    # 중복 문장 제거(*순서 유지 안함)\n",
    "    #result = list(set(clearlinelist))\n",
    "\n",
    "    #print('\\r\\n===[out]====')\n",
    "    print(f'*len:{len(result)}')\n",
    "    #count = 0\n",
    "    #for line1 in result:\n",
    "    #    print(line1)\n",
    "    #    count += 1\n",
    "    #    if count > 10:\n",
    "    #        break\n",
    "            \n",
    "   # 리스트를 파일로 저장\n",
    "    with open(out_txt_path, 'w', encoding='utf8') as f:\n",
    "        f.write('\\n'.join(result)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ffff97-fd22-4853-bb0b-af38bfaa2a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moco (1).txt', 'moco (10).txt', 'moco (100).txt', 'moco (101).txt', 'moco (102).txt', 'moco (103).txt', 'moco (104).txt', 'moco (105).txt', 'moco (106).txt', 'moco (107).txt', 'moco (108).txt', 'moco (109).txt', 'moco (11).txt', 'moco (110).txt', 'moco (111).txt', 'moco (112).txt', 'moco (113).txt', 'moco (114).txt', 'moco (115).txt', 'moco (116).txt', 'moco (117).txt', 'moco (118).txt', 'moco (119).txt', 'moco (12).txt', 'moco (120).txt', 'moco (121).txt', 'moco (122).txt', 'moco (123).txt', 'moco (124).txt', 'moco (125).txt', 'moco (126).txt', 'moco (127).txt', 'moco (128).txt', 'moco (129).txt', 'moco (13).txt', 'moco (130).txt', 'moco (131).txt', 'moco (132).txt', 'moco (133).txt', 'moco (134).txt', 'moco (135).txt', 'moco (136).txt', 'moco (137).txt', 'moco (138).txt', 'moco (139).txt', 'moco (14).txt', 'moco (140).txt', 'moco (141).txt', 'moco (142).txt', 'moco (143).txt', 'moco (144).txt', 'moco (145).txt', 'moco (146).txt', 'moco (147).txt', 'moco (148).txt', 'moco (149).txt', 'moco (15).txt', 'moco (150).txt', 'moco (151).txt', 'moco (152).txt', 'moco (153).txt', 'moco (154).txt', 'moco (155).txt', 'moco (156).txt', 'moco (157).txt', 'moco (158).txt', 'moco (159).txt', 'moco (16).txt', 'moco (160).txt', 'moco (161).txt', 'moco (162).txt', 'moco (163).txt', 'moco (164).txt', 'moco (165).txt', 'moco (166).txt', 'moco (167).txt', 'moco (168).txt', 'moco (169).txt', 'moco (17).txt', 'moco (170).txt', 'moco (171).txt', 'moco (172).txt', 'moco (173).txt', 'moco (174).txt', 'moco (175).txt', 'moco (176).txt', 'moco (177).txt', 'moco (178).txt', 'moco (179).txt', 'moco (18).txt', 'moco (180).txt', 'moco (181).txt', 'moco (182).txt', 'moco (183).txt', 'moco (184).txt', 'moco (185).txt', 'moco (186).txt', 'moco (187).txt', 'moco (188).txt', 'moco (189).txt', 'moco (19).txt', 'moco (190).txt', 'moco (191).txt', 'moco (192).txt', 'moco (193).txt', 'moco (194).txt', 'moco (195).txt', 'moco (196).txt', 'moco (197).txt', 'moco (198).txt', 'moco (199).txt', 'moco (2).txt', 'moco (20).txt', 'moco (200).txt', 'moco (201).txt', 'moco (202).txt', 'moco (203).txt', 'moco (204).txt', 'moco (205).txt', 'moco (206).txt', 'moco (207).txt', 'moco (208).txt', 'moco (209).txt', 'moco (21).txt', 'moco (210).txt', 'moco (211).txt', 'moco (212).txt', 'moco (213).txt', 'moco (214).txt', 'moco (215).txt', 'moco (216).txt', 'moco (217).txt', 'moco (218).txt', 'moco (219).txt', 'moco (22).txt', 'moco (220).txt', 'moco (221).txt', 'moco (222).txt', 'moco (223).txt', 'moco (224).txt', 'moco (225).txt', 'moco (226).txt', 'moco (227).txt', 'moco (228).txt', 'moco (229).txt', 'moco (23).txt', 'moco (230).txt', 'moco (231).txt', 'moco (232).txt', 'moco (233).txt', 'moco (234).txt', 'moco (235).txt', 'moco (236).txt', 'moco (237).txt', 'moco (238).txt', 'moco (239).txt', 'moco (24).txt', 'moco (240).txt', 'moco (241).txt', 'moco (242).txt', 'moco (243).txt', 'moco (244).txt', 'moco (245).txt', 'moco (246).txt', 'moco (247).txt', 'moco (248).txt', 'moco (249).txt', 'moco (25).txt', 'moco (250).txt', 'moco (251).txt', 'moco (252).txt', 'moco (253).txt', 'moco (254).txt', 'moco (255).txt', 'moco (256).txt', 'moco (257).txt', 'moco (258).txt', 'moco (259).txt', 'moco (26).txt', 'moco (260).txt', 'moco (261).txt', 'moco (262).txt', 'moco (263).txt', 'moco (264).txt', 'moco (265).txt', 'moco (266).txt', 'moco (267).txt', 'moco (268).txt', 'moco (269).txt', 'moco (27).txt', 'moco (270).txt', 'moco (271).txt', 'moco (272).txt', 'moco (273).txt', 'moco (274).txt', 'moco (275).txt', 'moco (276).txt', 'moco (277).txt', 'moco (278).txt', 'moco (279).txt', 'moco (28).txt', 'moco (280).txt', 'moco (281).txt', 'moco (282).txt', 'moco (283).txt', 'moco (284).txt', 'moco (285).txt', 'moco (286).txt', 'moco (287).txt', 'moco (288).txt', 'moco (289).txt', 'moco (29).txt', 'moco (290).txt', 'moco (3).txt', 'moco (30).txt', 'moco (31).txt', 'moco (32).txt', 'moco (33).txt', 'moco (34).txt', 'moco (35).txt', 'moco (36).txt', 'moco (37).txt', 'moco (38).txt', 'moco (39).txt', 'moco (4).txt', 'moco (40).txt', 'moco (41).txt', 'moco (42).txt', 'moco (43).txt', 'moco (44).txt', 'moco (45).txt', 'moco (46).txt', 'moco (47).txt', 'moco (48).txt', 'moco (49).txt', 'moco (5).txt', 'moco (50).txt', 'moco (51).txt', 'moco (52).txt', 'moco (53).txt', 'moco (54).txt', 'moco (55).txt', 'moco (56).txt', 'moco (57).txt', 'moco (58).txt', 'moco (59).txt', 'moco (6).txt', 'moco (60).txt', 'moco (61).txt', 'moco (62).txt', 'moco (63).txt', 'moco (64).txt', 'moco (65).txt', 'moco (66).txt', 'moco (67).txt', 'moco (68).txt', 'moco (69).txt', 'moco (7).txt', 'moco (70).txt', 'moco (71).txt', 'moco (72).txt', 'moco (73).txt', 'moco (74).txt', 'moco (75).txt', 'moco (76).txt', 'moco (77).txt', 'moco (78).txt', 'moco (79).txt', 'moco (8).txt', 'moco (80).txt', 'moco (81).txt', 'moco (82).txt', 'moco (83).txt', 'moco (84).txt', 'moco (85).txt', 'moco (86).txt', 'moco (87).txt', 'moco (88).txt', 'moco (89).txt', 'moco (9).txt', 'moco (90).txt', 'moco (91).txt', 'moco (92).txt', 'moco (93).txt', 'moco (94).txt']\n"
     ]
    }
   ],
   "source": [
    "# OUT 파일들을 병합하여 하나의 파일로 만듬.\n",
    "import os\n",
    "#out_folder_path = '../../../korpora/moco/re-txt'\n",
    "\n",
    "# 입력 폴더 말뭉치 파일명들을 리스트로 얻어옴\n",
    "file_list = os.listdir(out_folder_path)\n",
    "print(file_list)\n",
    "\n",
    "out_file = '../../../korpora/moco/re-txt/0-moco-corpus2-t.txt'\n",
    "\n",
    "with open(out_file, 'w', encoding='utf8') as outfile:\n",
    "    for filename in file_list:\n",
    "        in_txt_path = out_folder_path+'/'+filename  # 출력 파일 풀경로 \n",
    "        with open(in_txt_path, 'r', encoding='utf8') as file:\n",
    "            for line in file:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ea157-7b39-48b7-a6a9-c64706a2922a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
