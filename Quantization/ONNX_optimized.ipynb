{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5984a5d9-f4c8-41d2-8b1e-faf3ac726899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:../../log/bwdataset_2022-05-26.log\n",
      "logfilepath:../../log/qnadataset_2022-05-26.log\n",
      "logfilepath:distilbertnlitest_2022-05-26.log\n"
     ]
    }
   ],
   "source": [
    "#===============================================================================================\n",
    "# Huggingface와 ONNX 런타임을 이용한 동적 양자화 예시 3\n",
    "# => 훈련된 bert 모델을 가지고, ONNX 모데로 만든 후, 테스트 하는 예시\n",
    "# => 분류모델(NLI포함)이면 ORTModelForSequenceClassification 이용\n",
    "#\n",
    "#\n",
    "#\n",
    "## 참고 : https://huggingface.co/blog/optimum-inference\n",
    "##\n",
    "## 아래 패키지들을 설치해야 함\n",
    "'''\n",
    "!pip install datasets\n",
    "!pip install optimum\n",
    "!pip install optimum[onnxruntime]\n",
    "!pip install optimum[onnxruntime-gpu]  #gpu 사용인 경우\n",
    "\n",
    "'''    \n",
    "#===============================================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "from myutils import seed_everything, GPU_info, mlogging\n",
    "logger = mlogging(loggername=\"distilbertnlitest\", logfilename=\"distilbertnlitest\")\n",
    "seed_everything(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a74e8be-9335-4c1d-8f6c-511ccd221ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./onnxfolder\\\\tokenizer_config.json',\n",
       " './onnxfolder\\\\special_tokens_map.json',\n",
       " './onnxfolder\\\\vocab.txt',\n",
       " './onnxfolder\\\\added_tokens.json',\n",
       " './onnxfolder\\\\tokenizer.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. ONNX 모델로 변환 \n",
    "# => huggingface ORTModelForSequenceClassification 를 이용하여, ONNX 모델로 쉽게 저장할수 있다.(*단 여기서 ONNX 모델은 양자화된 모델은 아니고, 형식만 변경한 것임)\n",
    "# => 양자화 하려면. 위에서 처럼 ORTQuantizer 이용해야 함.\n",
    "\n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"./distilbert-1\"\n",
    "\n",
    "# Load model from hub and export it through the ONNX format \n",
    "model = ORTModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=3,\n",
    "    from_transformers=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Save the exported model\n",
    "onnx_path = './onnxfolder'\n",
    "model.save_pretrained(onnx_path)\n",
    "tokenizer.save_pretrained(onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56453a32-3b47-45e5-ad27-d1ffacc53294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('onnxfolder/model-optimized.onnx')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. 최적화 적용\n",
    "from optimum.onnxruntime import ORTOptimizer\n",
    "from optimum.onnxruntime.configuration import OptimizationConfig\n",
    "\n",
    "# optimization 최적화 실행\n",
    "# optimization_config=99 enables all available graph optimisations(99이면 모든 것을 최적화 시킴)\n",
    "optimization_config = OptimizationConfig(optimization_level=99)\n",
    "\n",
    "optimizer = ORTOptimizer.from_pretrained(model_checkpoint, feature=\"sequence-classification\")\n",
    "\n",
    "optimizer.export(\n",
    "    onnx_model_path='./onnxfolder/model.onnx',   # 앞에서 만든 ONNX 모델 경로\n",
    "    onnx_optimized_model_output_path='./onnxfolder/model-optimized.onnx',  # 새롭게 만들 optimized 모델 경로\n",
    "    optimization_config=optimization_config,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a63346-37f8-4b87-8900-c725686cacba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('onnxfolder/model-quantized.onnx')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 양자화 \n",
    "from optimum.onnxruntime import ORTConfig, ORTQuantizer\n",
    "from optimum.onnxruntime.configuration import AutoQuantizationConfig\n",
    "\n",
    "\n",
    "# 동적 양자화인 경우 is_static = False로 해야 함.\n",
    "qconfig = AutoQuantizationConfig.arm64(is_static=False, per_channel=False)\n",
    "\n",
    "# 분류 모델인 경우에는 feature=\"sequence-classification\"\n",
    "quantizer = ORTQuantizer.from_pretrained(model_checkpoint, feature=\"sequence-classification\")\n",
    "\n",
    "# ONNX 모델로 만들고 양자화 함\n",
    "quantizer.export(\n",
    "    onnx_model_path='./onnxfolder/model-optimized.onnx',   # optimized 모델 경로\n",
    "    onnx_quantized_model_output_path=\"./onnxfolder/model-quantized.onnx\",  \n",
    "    quantization_config=qconfig,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ed1140-6e37-455c-8646-751e69dbc287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<optimum.onnxruntime.modeling_ort.ORTModelForSequenceClassification object at 0x000001D5BA1C5F40>\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# 양자화 모델 불러옴\n",
    "# => 양자화 모델은 model.eval() 하면 에러남.\n",
    "#============================================================\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from optimum.onnxruntime import ORTModelForFeatureExtraction, ORTModelForSequenceClassification\n",
    "\n",
    "vocab_path = \"./onnxfolder\"\n",
    "model_path = \"./onnxfolder\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(vocab_path)\n",
    "\n",
    "# 분류모델이면, ORTModelForSequenceClassification\n",
    "# 문장임베딩이면, ORTModelForFeatureExtraction 호출\n",
    "model = ORTModelForSequenceClassification.from_pretrained(model_path, num_labels=3)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96472c5-e655-4d73-9764-2f58d5bc792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#================================================================\n",
    "# 기존 bert 모델 불러옴\n",
    "#================================================================\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "vocab_path = \"./distilbert-0331-TS-nli-0.1-10\"\n",
    "model_path = \"./distilbert-0331-TS-nli-0.1-10\"\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(vocab_path, do_lower_case=False)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path, num_labels=3)\n",
    "model.eval()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5814633a-294e-4eab-93c0-6515b053e982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 16:25:44,727 - bwpdataset - INFO - Creating features from dataset file at ./korpora\\xnli.test.ko.tsv\n",
      "INFO:bwpdataset:Creating features from dataset file at ./korpora\\xnli.test.ko.tsv\n",
      "2022-05-26 16:25:44,736 - bwpdataset - INFO - loading data... LOOKING AT ./korpora\\xnli.test.ko.tsv\n",
      "INFO:bwpdataset:loading data... LOOKING AT ./korpora\\xnli.test.ko.tsv\n",
      "2022-05-26 16:25:44,783 - bwpdataset - INFO - tokenize sentences, it could take a lot of time...\n",
      "INFO:bwpdataset:tokenize sentences, it could take a lot of time...\n",
      "2022-05-26 16:25:45,925 - bwpdataset - INFO - tokenize sentences [took 1.139 s]\n",
      "INFO:bwpdataset:tokenize sentences [took 1.139 s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35580c37a3424846b856f599c9610ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5010 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 16:25:46,044 - bwpdataset - INFO - *** Example ***\n",
      "INFO:bwpdataset:*** Example ***\n",
      "2022-05-26 16:25:46,050 - bwpdataset - INFO - sentence A, B: 글쎄, 나는 그것에 관해 생각조차 하지 않았지만, 나는 너무 좌절했고, 결국 그에게 다시 이야기하게 되었다. + 나는 그와 다시 이야기하지 않았다.\n",
      "INFO:bwpdataset:sentence A, B: 글쎄, 나는 그것에 관해 생각조차 하지 않았지만, 나는 너무 좌절했고, 결국 그에게 다시 이야기하게 되었다. + 나는 그와 다시 이야기하지 않았다.\n",
      "2022-05-26 16:25:46,057 - bwpdataset - INFO - tokens: [CLS] [UNK] , 나는 그것 ##에 관 ##해 생각 ##조 ##차 하지 않 ##았 ##지만 , 나는 너 ##무 좌절 ##했고 , 결국 그 ##에게 다시 이야기 ##하게 되었다 . [SEP] 나는 그 ##와 다시 이야기 ##하지 않았다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "INFO:bwpdataset:tokens: [CLS] [UNK] , 나는 그것 ##에 관 ##해 생각 ##조 ##차 하지 않 ##았 ##지만 , 나는 너 ##무 좌절 ##했고 , 결국 그 ##에게 다시 이야기 ##하게 되었다 . [SEP] 나는 그 ##와 다시 이야기 ##하지 않았다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "2022-05-26 16:25:46,061 - bwpdataset - INFO - label: contradiction\n",
      "INFO:bwpdataset:label: contradiction\n",
      "2022-05-26 16:25:46,065 - bwpdataset - INFO - features: ClassificationFeatures(input_ids=[101, 100, 117, 100585, 119663, 10530, 8900, 14523, 119576, 20626, 23466, 89093, 9523, 119118, 28578, 117, 100585, 9004, 32537, 123050, 38181, 117, 50342, 8924, 26212, 25805, 110148, 17594, 17737, 119, 102, 100585, 8924, 12638, 25805, 110148, 23665, 49137, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)\n",
      "INFO:bwpdataset:features: ClassificationFeatures(input_ids=[101, 100, 117, 100585, 119663, 10530, 8900, 14523, 119576, 20626, 23466, 89093, 9523, 119118, 28578, 117, 100585, 9004, 32537, 123050, 38181, 117, 50342, 8924, 26212, 25805, 110148, 17594, 17737, 119, 102, 100585, 8924, 12638, 25805, 110148, 23665, 49137, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)\n",
      "2022-05-26 16:25:46,071 - bwpdataset - INFO - *** Example ***\n",
      "INFO:bwpdataset:*** Example ***\n",
      "2022-05-26 16:25:46,074 - bwpdataset - INFO - sentence A, B: 글쎄, 나는 그것에 관해 생각조차 하지 않았지만, 나는 너무 좌절했고, 결국 그에게 다시 이야기하게 되었다. + 나는 다시 그와 이야기를 하기 시작했다는 것에 너무 화가 났다.\n",
      "INFO:bwpdataset:sentence A, B: 글쎄, 나는 그것에 관해 생각조차 하지 않았지만, 나는 너무 좌절했고, 결국 그에게 다시 이야기하게 되었다. + 나는 다시 그와 이야기를 하기 시작했다는 것에 너무 화가 났다.\n",
      "2022-05-26 16:25:46,080 - bwpdataset - INFO - tokens: [CLS] [UNK] , 나는 그것 ##에 관 ##해 생각 ##조 ##차 하지 않 ##았 ##지만 , 나는 너 ##무 좌절 ##했고 , 결국 그 ##에게 다시 이야기 ##하게 되었다 . [SEP] 나는 다시 그 ##와 이야기 ##를 하 ##기 시작했다 ##는 것에 너 ##무 화가 났 ##다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "INFO:bwpdataset:tokens: [CLS] [UNK] , 나는 그것 ##에 관 ##해 생각 ##조 ##차 하지 않 ##았 ##지만 , 나는 너 ##무 좌절 ##했고 , 결국 그 ##에게 다시 이야기 ##하게 되었다 . [SEP] 나는 다시 그 ##와 이야기 ##를 하 ##기 시작했다 ##는 것에 너 ##무 화가 났 ##다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "2022-05-26 16:25:46,084 - bwpdataset - INFO - label: entailment\n",
      "INFO:bwpdataset:label: entailment\n",
      "2022-05-26 16:25:46,088 - bwpdataset - INFO - features: ClassificationFeatures(input_ids=[101, 100, 117, 100585, 119663, 10530, 8900, 14523, 119576, 20626, 23466, 89093, 9523, 119118, 28578, 117, 100585, 9004, 32537, 123050, 38181, 117, 50342, 8924, 26212, 25805, 110148, 17594, 17737, 119, 102, 100585, 25805, 8924, 12638, 110148, 11513, 9952, 12310, 70927, 11018, 100158, 9004, 32537, 121271, 8990, 11903, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)\n",
      "INFO:bwpdataset:features: ClassificationFeatures(input_ids=[101, 100, 117, 100585, 119663, 10530, 8900, 14523, 119576, 20626, 23466, 89093, 9523, 119118, 28578, 117, 100585, 9004, 32537, 123050, 38181, 117, 50342, 8924, 26212, 25805, 110148, 17594, 17737, 119, 102, 100585, 25805, 8924, 12638, 110148, 11513, 9952, 12310, 70927, 11018, 100158, 9004, 32537, 121271, 8990, 11903, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)\n",
      "2022-05-26 16:25:46,206 - bwpdataset - INFO - Saving features into cached file, it could take a lot of time...\n",
      "INFO:bwpdataset:Saving features into cached file, it could take a lot of time...\n",
      "2022-05-26 16:25:47,487 - bwpdataset - INFO - Saving features into cached file ./korpora\\cached_DistilBertTokenizerFast_128_xnli.test.ko.tsv [took 1.281 s]\n",
      "INFO:bwpdataset:Saving features into cached file ./korpora\\cached_DistilBertTokenizerFast_128_xnli.test.ko.tsv [took 1.281 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loader_len: 157\n"
     ]
    }
   ],
   "source": [
    "# 평가 data loader 생성\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "from myutils import ClassificationDataset, KlueNLICorpus, data_collator, KorNLICorpus\n",
    "#############################################################################\n",
    "# 변수 설정\n",
    "#############################################################################\n",
    "max_seq_len = 128   # 글자 최대 토큰 길이 해당 토큰 길이 이상은 잘린다.\n",
    "batch_size = 32        # 배치 사이즈(64면 GUP Memory 오류 나므로, 32 이하로 설정할것=>max_seq_length 를 줄이면, 64도 가능함)\n",
    "cache = True   # 캐쉬파일 생성할거면 True로 (True이면 loding할때 캐쉬파일있어도 이용안함)\n",
    "#############################################################################\n",
    "\n",
    "# corpus 파일 설정\n",
    "#corpus = KlueNLICorpus()\n",
    "corpus = KorNLICorpus()\n",
    "\n",
    "# 평가 dataset 생성\n",
    "#file_fpath = '../../korpora/klue-nli/klue-nli-v1.1_dev.json'\n",
    "file_fpath = './korpora/xnli.test.ko.tsv'\n",
    "    \n",
    "dataset = ClassificationDataset(file_fpath=file_fpath, max_seq_length=max_seq_len, tokenizer=tokenizer, corpus=corpus, overwrite_cache=cache)\n",
    "\n",
    "# 평가 dataloader 생성\n",
    "eval_loader = DataLoader(dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          #shuffle=True, # dataset을 섞음\n",
    "                          sampler=RandomSampler(dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                          collate_fn=data_collator, # dataset을 tensor로 변환(예시 {'input_ids':tensor[0,1,2,3,1,], 'token_type_id:tensor[0,0,0,0,0], 'attention_mask:tensor[1,1,1,1,1], 'labels':tensor[5]}\n",
    "                          num_workers=4)\n",
    "\n",
    "print('eval_loader_len: {}'.format(len(eval_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e278588-d0a8-4e8a-aa39-d91d54d633f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 16:25:51,624 - distilbertnlitest - INFO - === model: ./onnxfolder ===\n",
      "INFO:distilbertnlitest:=== model: ./onnxfolder ===\n",
      "2022-05-26 16:25:51,638 - distilbertnlitest - INFO - eval_file : ./korpora/xnli.test.ko.tsv\n",
      "INFO:distilbertnlitest:eval_file : ./korpora/xnli.test.ko.tsv\n",
      "2022-05-26 16:25:51,640 - distilbertnlitest - INFO - ---------------------------------------------------------\n",
      "INFO:distilbertnlitest:---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1289b4f93f4477810313c63dd29417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bong9\\AppData\\Local\\Temp/ipykernel_13492/3622772955.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred = torch.argmax(F.softmax(logits), dim=1)\n",
      "2022-05-26 16:41:07,911 - distilbertnlitest - INFO - eval-accuracy: 0.7289421157684631\n",
      "INFO:distilbertnlitest:eval-accuracy: 0.7289421157684631\n",
      "2022-05-26 16:41:07,916 - distilbertnlitest - INFO - ---------------------------------------------------------\n",
      "INFO:distilbertnlitest:---------------------------------------------------------\n",
      "2022-05-26 16:41:07,925 - distilbertnlitest - INFO - === 처리시간: 916.284 초 ===\n",
      "INFO:distilbertnlitest:=== 처리시간: 916.284 초 ===\n",
      "2022-05-26 16:41:07,930 - distilbertnlitest - INFO - -END-\n",
      "\n",
      "INFO:distilbertnlitest:-END-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "logger.info(f\"=== model: {model_path} ===\")\n",
    "logger.info(f\"eval_file : {file_fpath}\")\n",
    "#logger.info(f\"num_parameters: {model.num_parameters()}\")\n",
    "\n",
    "# 평가 시작\n",
    "#model.eval()\n",
    "\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "start = time.time()\n",
    "logger.info(f'---------------------------------------------------------')\n",
    "\n",
    "for data in tqdm(eval_loader):\n",
    "    # 입력 값 설정\n",
    "    # =>**distilbert에는 token_type_ids가 없다\n",
    "    labels = data['labels']\n",
    "    input_ids = data['input_ids']\n",
    "    attention_mask = data['attention_mask']\n",
    " \n",
    "    # 손실률 계산하는 부분은 no_grade 시켜서, 계산량을 줄임.\n",
    "    # => torch.no_grad()는 gradient을 계산하는 autograd engine를 비활성화 하여 \n",
    "    # 필요한 메모리를 줄이고, 연산속도를 증가시키는 역활을 함\n",
    "    with torch.no_grad():\n",
    "        # 모델 실행\n",
    "        outputs = model(input_ids=input_ids, \n",
    "                       attention_mask=attention_mask,\n",
    "                       labels=labels)\n",
    "    \n",
    "        # 출력값 loss,logits를 outputs에서 얻어옴\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "        correct = pred.eq(labels)\n",
    "        total_correct += correct.sum().item()\n",
    "        total_len += len(labels)\n",
    "\n",
    "logger.info(f\"eval-accuracy: {total_correct / total_len}\")\n",
    "logger.info(f'---------------------------------------------------------')\n",
    "logger.info(f'=== 처리시간: {time.time() - start:.3f} 초 ===')\n",
    "logger.info(f'-END-\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf3dc80-13e9-4b40-acd3-633f86b3c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 모델 추론 테스트 \n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "inputs = tokenizer(\"날씨가 흐리다\", \"비가 내린다\",return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "print(outputs)\n",
    "logits = outputs.logits\n",
    "print(logits)\n",
    "\n",
    "pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "print(pred)\n",
    "\n",
    "if pred == 0:\n",
    "    print('참(수반:entailment)')\n",
    "elif pred == 1:\n",
    "    print('거짓(모순:contradiction)')\n",
    "elif pred == 2:\n",
    "     print('모름(중립:neutral)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4638e352-af21-4cf0-8e0b-882ec3500b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 참고\n",
    "# => huggingface ORTModelForSequenceClassification 를 이용하여, ONNX 모델로 쉽게 저장할수 있다.(*단 여기서 ONNX 모델은 양자화된 모델은 아니고, 형식만 변경한 것임)\n",
    "# => 양자화 하려면. 위에서 처럼 ORTQuantizer 이용해야 함.\n",
    "\n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "\n",
    "model_checkpoint = \"./distilbert-0331-TS-nli-0.1-10\"\n",
    "\n",
    "# Load model from hub and export it through the ONNX format \n",
    "model = ORTModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=3,\n",
    "    from_transformers=True\n",
    ")\n",
    "\n",
    "# Save the exported model\n",
    "model.save_pretrained(\"./onnxfolder\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c14f1-32a4-404e-ae36-35a9a706538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# onnx 모델 구조 로딩 해봄.\n",
    "# => 맨 뒤에 return %last_hidden_state 리턴되면 => ORTModelForFeatureExtraction 사용 가능\n",
    "import onnx\n",
    "model = onnx.load(\"./distilbert-nli/model.onnx\")\n",
    "onnx.checker.check_model(model)\n",
    "print(onnx.helper.printable_graph(model.graph))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
