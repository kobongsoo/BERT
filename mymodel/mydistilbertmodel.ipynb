{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc727ae-1a85-4f24-b8df-3664eda6b575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:bwdataset_2022-04-13.log\n",
      "logfilepath:qnadataset_2022-04-13.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "logfilepath:../log/test_2022-04-13.log\n"
     ]
    }
   ],
   "source": [
    "#====================================================================================================\n",
    "# by kobongsoo . 2022-04-13\n",
    "# 기존 distilbert 모델에 출력 dimension=768을 128 로 줄이는 예제임 \n",
    "#\n",
    "# => semantic search시, cosin simility 유사도 측정시, 기존 embedding dimenision을 768로 저장해 두어야 하는데,\n",
    "# 이때 저장공간이 db이거나 메모리이면, 데이터가 많은 경우 메모리 낭비가 심하므로, 이를 128처럼 줄이는 방법이 필요함\n",
    "#\n",
    "# => 여기서는 기존 distilbert를 가지고, mydistilbert 128차원으로 줄여 embedding 값을 출력하고,\n",
    "# 이때 실제 cosin 유사도를 측정 테스트 해보는 예시임.\n",
    "#\n",
    "# => cosin 유사도 측정시, 768이나 128일때 별반 차이 없은 것으로 여겨짐. \n",
    "#====================================================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "#os.sys.path.append('..')\n",
    "from myutils import GPU_info, seed_everything, mlogging, pytorch_cos_sim\n",
    "\n",
    "device = GPU_info()\n",
    "seed_everything(111)\n",
    "logger=mlogging(loggername=\"test\", logfilename=\"../log/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c5d80bb-10d7-4a93-bd5f-eee2292df89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distilbert에 dimension을 줄여서 last_hidden_state를 출력하는 class\n",
    "class MyDistilBertModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                model_path: str,      # 기존 huggingface distilbert 모델 경로\n",
    "                in_dim: int = 768,    # 입력 dimension(기본=768)\n",
    "                out_dim: int = 768,   # 출력 dimension(기본=768)\n",
    "                nlabel: int = 2,      # 혹시 classificaiton에 사용하는 경우 label 계수  \n",
    "                drop_rate: int = 0.1):# dropout 비율(기본=0.1)\n",
    "        \n",
    "        \n",
    "        super().__init__()  #nn.Module 호출시 반드시 호출해야함\n",
    "        \n",
    "        # bert 모델 정의 : huggingface에 distilbert pretrained 모델 불러옴\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "        \n",
    "        \n",
    "        self.activefunc = nn.Tanh()            # activefunc 함수 정의 : activation function은 Tanh 이용\n",
    "        self.drop = nn.Dropout(drop_rate)      # dropout 레이어 정의\n",
    "        self.fc = nn.Linear(in_dim, out_dim)   # fullyconnect 레이어 정의 : 입력 dim, 출력 dim\n",
    "        \n",
    "        #self.classifier = nn.Linear(out_dim, nlabel)  # classification 레이어 정의\n",
    "        \n",
    "    def forward(self,\n",
    "               input_ids,\n",
    "               #token_type_ids = None,  #distilbert에는 token_type_ids가 없다.\n",
    "               attention_mask \n",
    "               ):\n",
    "        output = self.model(input_ids, attention_mask)\n",
    "        h = output.last_hidden_state  #distilber는 맨마지막 hidden state만 리턴한다.\n",
    "      \n",
    "        out1 = self.drop(h)\n",
    "        out2 = self.activefunc(self.fc(out1))\n",
    "        \n",
    "        #logits = self.classifier(self.drop(pooled_h))\n",
    "        return out2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189b6460-9fc4-4f05-ae52-72e8e7c3fcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDistilBertModel(\n",
      "  (model): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(167550, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (activefunc): Tanh()\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (fc): Linear(in_features=768, out_features=128, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델과 tokenizer 설정\n",
    "model_path = '../model/distilbert/distilbert-0331-TS-nli-0.1-10'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "mymodel = MyDistilBertModel(model_path=model_path, in_dim=768, out_dim=128)\n",
    "#mymodel = AutoModel.from_pretrained(model_path)\n",
    "\n",
    "print(mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d8e8078-9420-49d0-a426-1b6d92da24e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   101, 122278,  10892,   9379,  11287,   9580,  11664, 123665,  11287,\n",
      "          10015,  12692, 118632,  11903,    102,      0,      0,      0,      0],\n",
      "        [   101, 122278,  10892,   9034,  10739,   9580,  11664, 123665,  11287,\n",
      "          10015,  12692, 118632,  11903,    102,      0,      0,      0,      0],\n",
      "        [   101, 122278,  10892,   8843, 118707,  10015,  62211,    117,   9034,\n",
      "          10739,   9583,  15891,  11506,    102,      0,      0,      0,      0],\n",
      "        [   101, 119676, 123323,  10892, 136093,  11287,   9254,  76820,    102,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0],\n",
      "        [   101, 122278, 140417,  11018, 131258,  11467, 121653,  28750,    102,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0],\n",
      "        [   101, 129345,  10892, 120578,  15303,  10015, 154112,  19105,    117,\n",
      "         120233,  15303, 123665,  11287,   9685, 118632,  11903,    102,      0],\n",
      "        [   101,  48253,  10892,  26168,  10530,  69283,  33542,    117, 119581,\n",
      "         119603, 120640,  11925,    102,      0,      0,      0,      0,      0],\n",
      "        [   101, 136591, 119603, 119803,  10892,    125,    110,   9069, 119803,\n",
      "          10622,   9638, 118891,  41521,  17342, 120364,  22096,    102,      0],\n",
      "        [   101,  47364, 120035,  11018, 126336,  21611, 122626,  20173, 120558,\n",
      "           9737,  11018, 121362, 120466,  11925,    102,      0,      0,      0],\n",
      "        [   101, 128051,  15303,  70672, 119674,  12638, 105383, 121057,  11287,\n",
      "          58248,  66421,  11903,    102,      0,      0,      0,      0,      0],\n",
      "        [   101, 122278, 123665,  11018,   9379,  11287, 123658,  11664,  42608,\n",
      "            100,    102,      0,      0,      0,      0,      0,      0,      0],\n",
      "        [   101,   9450, 119444, 159780,  50266, 121456,  37905,  81785,  10193,\n",
      "          48506,   8892,  10622,   9010,  17706,    102,      0,      0,      0],\n",
      "        [   101, 120824,  11102, 123665,  10530, 134288,  10622, 126551, 108436,\n",
      "          16139,    102,      0,      0,      0,      0,      0,      0,      0],\n",
      "        [   101, 120569,  37115,  18398,  10530, 121752, 119643,  10622, 119850,\n",
      "          28750,    102,      0,      0,      0,      0,      0,      0,      0],\n",
      "        [   101, 138367,  10892, 128051, 126550, 133359,  11513, 132086,  12490,\n",
      "            102,      0,      0,      0,      0,      0,      0,      0,      0],\n",
      "        [   101, 123665,  11287,   9685,  11903,    102,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0],\n",
      "        [   101,   9521,   8924,  37388,  12092,  54780,  28911,   9303,    119,\n",
      "           8904, 119250,  16985,    119,    102,      0,      0,      0,      0],\n",
      "        [   101, 129345, 121492,  18382, 120426, 120053,  11287,   8977,  41919,\n",
      "          23925, 120364,  33188,  48345,    119,    102,      0,      0,      0],\n",
      "        [   101, 121467,  33188,  48345,    119, 127364,  40364, 119583,  10739,\n",
      "           9100, 136592,    119,    102,      0,      0,      0,      0,      0],\n",
      "        [   101,   8924,  30873,  14867, 120578,  10150, 131192, 119994,  31398,\n",
      "           9952, 119217,    119, 129345,    100,    119,    102,      0,      0],\n",
      "        [   101, 139896, 134170,  11287,   9056,   9141,  12965, 119210, 119081,\n",
      "          48345,    119,   9074, 121962,  14843, 118671,  48549,    136,    102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# cosin 유사도 측정을 위한 문장들 정의\n",
    "\n",
    "test_sentence = [\n",
    "    '오늘은 비가 오고 날씨가 흐리겠다',\n",
    "    '오늘은 눈이 오고 날씨가 흐리겠다',\n",
    "    '오늘은 가끔 흐리고, 눈이 올수 있다',\n",
    "    '여기 식당은 파스타가 맛있다',\n",
    "    '오늘 증시는 내림으로 마감 하였다',\n",
    "    '내일은 오전에는 흐리지만, 오후에는 날씨가 좋겠다',\n",
    "    '서울은 대한민국에 수도이며, 정치 경제 중심지이다',\n",
    "    '내년 경제 성장은 4%대 성장을 이룰거라 예상된다',\n",
    "    '프랑스 파리는 전세계 관광객들이 매년 찾는 관광도시이다',\n",
    "    '올해에는 대통령 선거와 지방선거가 동시에 열린다',\n",
    "    '오늘 날씨는 비가 내리고 매우 춥다',\n",
    "    '손홍민이 영국 프리미어 축구 경기에서 11번째 골을 넣었다',\n",
    "    '건조한 날씨에 산불을 조심해야 한다',\n",
    "    '윈도우11 OS에 검색 기능을 강화 하였다',\n",
    "    '한국은행은 올해 하반기 금리를 동결했다',\n",
    "    '날씨가 좋다',\n",
    "    '안 그래도 되는데 뭐. 괜찮아.',\n",
    "    '내일 저녁까지 보수 공사가 끝날 것으로 예상합니다.',\n",
    "    '감사합니다. 후회 없는 결정이 될 겁니다.',\n",
    "    '그러면 오전 10시에 보도록 하죠. 내일 뵙겠습니다.',\n",
    "    '프린트 카트리지가 다 떨어졌습니다. 더 주문할까요?'\n",
    "    ]\n",
    "\n",
    "# ** 멀티로 한번에 tokenizer 할때는 반드시 padding=True 해야 함.(그래야 최대 길이 token에 맞춰서 padding 됨)\n",
    "test = tokenizer(test_sentence, \n",
    "                 add_special_tokens=True, \n",
    "                 truncation=True, \n",
    "                 padding=True,   \n",
    "                 max_length=256, \n",
    "                 return_tensors=\"pt\")\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5ee5571-0746-4043-9cdd-21c0af1b7a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([21, 18, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my모델에 출력값 추출\n",
    "last_hidden_state = mymodel(**test)\n",
    "#output = mymodel(**test)\n",
    "#last_hidden_state = output.last_hidden_state\n",
    "\n",
    "print(type(last_hidden_state)), print(last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f8d9fb0-f67f-4137-bac9-4a569d7fef1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 10:38:47,654 - test - INFO - ---------------------------------------------------------\n",
      "2022-04-13 10:38:47,656 - test - INFO - 오늘은 비가 오고 날씨가 흐리겠다, 유사도:1.000000238418579\n",
      "2022-04-13 10:38:47,657 - test - INFO - 오늘은 눈이 오고 날씨가 흐리겠다, 유사도:0.9396036863327026\n",
      "2022-04-13 10:38:47,657 - test - INFO - 오늘 날씨는 비가 내리고 매우 춥다, 유사도:0.8798013925552368\n",
      "2022-04-13 10:38:47,658 - test - INFO - 안 그래도 되는데 뭐. 괜찮아., 유사도:0.8244172930717468\n",
      "2022-04-13 10:38:47,659 - test - INFO - 그러면 오전 10시에 보도록 하죠. 내일 뵙겠습니다., 유사도:0.7822104096412659\n",
      "2022-04-13 10:38:47,660 - test - INFO - 감사합니다. 후회 없는 결정이 될 겁니다., 유사도:0.7809420824050903\n",
      "2022-04-13 10:38:47,661 - test - INFO - 내일 저녁까지 보수 공사가 끝날 것으로 예상합니다., 유사도:0.683722734451294\n",
      "2022-04-13 10:38:47,661 - test - INFO - 내일은 오전에는 흐리지만, 오후에는 날씨가 좋겠다, 유사도:0.643785834312439\n",
      "2022-04-13 10:38:47,662 - test - INFO - 건조한 날씨에 산불을 조심해야 한다, 유사도:0.6342536807060242\n",
      "2022-04-13 10:38:47,663 - test - INFO - 한국은행은 올해 하반기 금리를 동결했다, 유사도:0.588422417640686\n",
      "2022-04-13 10:38:47,664 - test - INFO - 프린트 카트리지가 다 떨어졌습니다. 더 주문할까요?, 유사도:0.5849332213401794\n",
      "2022-04-13 10:38:47,664 - test - INFO - 오늘 증시는 내림으로 마감 하였다, 유사도:0.5775327682495117\n",
      "2022-04-13 10:38:47,665 - test - INFO - 손홍민이 영국 프리미어 축구 경기에서 11번째 골을 넣었다, 유사도:0.5421240925788879\n",
      "2022-04-13 10:38:47,666 - test - INFO - 여기 식당은 파스타가 맛있다, 유사도:0.4792359471321106\n",
      "2022-04-13 10:38:47,669 - test - INFO - 오늘은 가끔 흐리고, 눈이 올수 있다, 유사도:0.4267120361328125\n",
      "2022-04-13 10:38:47,670 - test - INFO - 올해에는 대통령 선거와 지방선거가 동시에 열린다, 유사도:0.40479275584220886\n",
      "2022-04-13 10:38:47,670 - test - INFO - 프랑스 파리는 전세계 관광객들이 매년 찾는 관광도시이다, 유사도:0.3914756178855896\n",
      "2022-04-13 10:38:47,671 - test - INFO - 내년 경제 성장은 4%대 성장을 이룰거라 예상된다, 유사도:0.34773704409599304\n",
      "2022-04-13 10:38:47,672 - test - INFO - 서울은 대한민국에 수도이며, 정치 경제 중심지이다, 유사도:0.32549849152565\n",
      "2022-04-13 10:38:47,673 - test - INFO - 날씨가 좋다, 유사도:0.25048670172691345\n",
      "2022-04-13 10:38:47,673 - test - INFO - 윈도우11 OS에 검색 기능을 강화 하였다, 유사도:0.18336428701877594\n",
      "2022-04-13 10:38:47,674 - test - INFO - ---------------------------------------------------------\n",
      "2022-04-13 10:38:47,675 - test - INFO - === 유사도 처리시간: 0.029 초 ===\n",
      "2022-04-13 10:38:47,676 - test - INFO - -END-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 문장 유사도 비교\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# 첫번째 문장을 query로 지정함\n",
    "in_mean_sequence = torch.mean(last_hidden_state[0], dim=0)\n",
    "#print(in_mean_sequence.shape)\n",
    "\n",
    "out_dict = {}\n",
    "# for문을 돌면서 유사도 비교\n",
    "for idx, hidden in enumerate(last_hidden_state):\n",
    "    out_mean_sequence = torch.mean(hidden, dim=0)\n",
    "    simul_score = pytorch_cos_sim(in_mean_sequence, out_mean_sequence)\n",
    "    #print(\"input vs {:d} 유사도:{}\".format(idx, simul_score))\n",
    "    \n",
    "     # 사전 key로 순번으로 하고, 유사도를 저장함\n",
    "    key = str(idx+1)\n",
    "    out_dict[key] = simul_score\n",
    "    #print(\"input vs {:d} 유사도:{}\".format(idx, simul_score))\n",
    "    \n",
    "#print(out_dict)\n",
    "\n",
    "# 사전 정렬(value(유사도)로 reverse=True 하여 내림차순으로 정렬함)\n",
    "sorted_dict = sorted(out_dict.items(), key = lambda item: item[1], reverse = True)\n",
    "#print(sorted_dict)\n",
    "\n",
    "# 내립차순으로 정렬된 사전출력 \n",
    "logger.info(f'---------------------------------------------------------')\n",
    "for count in (sorted_dict):\n",
    "    value = count[1].tolist() # count[1]은 2차원 tensor이므로 이를 list로 변환\n",
    "    index = int(count[0])\n",
    "    #print(test_sentence[index-1])\n",
    "    logger.info(f'{test_sentence[index-1]}, 유사도:{value[0][0]}')\n",
    "\n",
    "logger.info(f'---------------------------------------------------------')\n",
    "logger.info(f'=== 유사도 처리시간: {time.time() - start:.3f} 초 ===')\n",
    "logger.info(f'-END-\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd6fef9c-b6d4-41e2-9fd7-02297e4068c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../model/distilbert/mydistilbert/tokenizer_config.json',\n",
       " '../model/distilbert/mydistilbert/special_tokens_map.json',\n",
       " '../model/distilbert/mydistilbert/vocab.txt',\n",
       " '../model/distilbert/mydistilbert/added_tokens.json',\n",
       " '../model/distilbert/mydistilbert/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mydistilbertmodel 저장\n",
    "# => mydistilbertmodel은 새로 정의한 model이므로, save_pretrained 함수 이용 못함.따라서 torch.save로 모델 저정해야 함\n",
    "OUTPATH = '../model/distilbert/mydistilbert/'\n",
    "os.makedirs(OUTPATH, exist_ok=True)\n",
    "torch.save(mymodel, OUTPATH + 'pytorch_model.bin') \n",
    "#mymodel.save_pretrained(OUTPATH)  # save_pretrained 로 저장하면 config.json, pytorch_model.bin 2개의 파일이 생성됨\n",
    "tokenizer.save_pretrained(OUTPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed8a7ac2-90d5-4f34-abac-820bc3e02908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDistilBertModel(\n",
      "  (model): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(167550, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (activefunc): Tanh()\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (fc): Linear(in_features=768, out_features=128, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 불러올때는 torch.load로 불러옴\n",
    "model = torch.load(OUTPATH+'pytorch_model.bin')\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
