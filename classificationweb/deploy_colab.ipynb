{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oaGGhdmYKqt"
   },
   "source": [
    "# 패키지 설치\n",
    "pip 명령어로 의존성 있는 패키지를 설치합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8TJkXkpDnSq"
   },
   "outputs": [],
   "source": [
    "!pip install ratsnlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppGzJeg_x12T"
   },
   "source": [
    "# 구글 드라이브 연동하기\n",
    "모델 체크포인트 등을 저장해 둘 구글 드라이브를 연결합니다. 자신의 구글 계정에 적용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgSyL_BsVTfl"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eC5OwyKMx_l9"
   },
   "source": [
    "# 각종 설정\n",
    "모델 하이퍼파라메터(hyperparameter)와 저장 위치 등 설정 정보를 선언합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fKybDwDqFIX5"
   },
   "outputs": [],
   "source": [
    "from ratsnlp.nlpbook.classification import ClassificationDeployArguments\n",
    "args = ClassificationDeployArguments(\n",
    "    pretrained_model_name=\"beomi/kcbert-base\",\n",
    "    downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-doccls\",\n",
    "    max_seq_length=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3mThtbxyNyO"
   },
   "source": [
    "# 모델 로딩\n",
    "파인튜닝을 마친 모델과 토크나이저를 읽어 들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFV031RZFRgD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertConfig, BertForSequenceClassification\n",
    "fine_tuned_model_ckpt = torch.load(\n",
    "    args.downstream_model_checkpoint_fpath,\n",
    "    map_location=torch.device(\"cpu\")\n",
    ")\n",
    "pretrained_model_config = BertConfig.from_pretrained(\n",
    "    args.pretrained_model_name,\n",
    "    num_labels=fine_tuned_model_ckpt['state_dict']['model.classifier.bias'].shape.numel(),\n",
    ")\n",
    "model = BertForSequenceClassification(pretrained_model_config)\n",
    "model.load_state_dict({k.replace(\"model.\", \"\"): v for k, v in fine_tuned_model_ckpt['state_dict'].items()})\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3amlsjpFd9i"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    args.pretrained_model_name,\n",
    "    do_lower_case=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWVsdmThyV_p"
   },
   "source": [
    "# 인퍼런스 함수 선언\n",
    "인퍼런스 함수를 선언합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnzR9NMtFiAz"
   },
   "outputs": [],
   "source": [
    "def inference_fn(sentence):\n",
    "    inputs = tokenizer(\n",
    "        [sentence],\n",
    "        max_length=args.max_seq_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**{k: torch.tensor(v) for k, v in inputs.items()})\n",
    "        prob = outputs.logits.softmax(dim=1)\n",
    "        positive_prob = round(prob[0][1].item(), 4)\n",
    "        negative_prob = round(prob[0][0].item(), 4)\n",
    "        pred = \"긍정 (positive)\" if torch.argmax(prob) == 1 else \"부정 (negative)\"\n",
    "    return {\n",
    "        'sentence': sentence,\n",
    "        'prediction': pred,\n",
    "        'positive_data': f\"긍정 {positive_prob}\",\n",
    "        'negative_data': f\"부정 {negative_prob}\",\n",
    "        'positive_width': f\"{positive_prob * 100}%\",\n",
    "        'negative_width': f\"{negative_prob * 100}%\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xt7Z7G0dB7yY"
   },
   "source": [
    "# 웹서비스 만들기 준비\n",
    "\n",
    "`ngrok`은 코랩 로컬에서 실행 중인 웹서비스를 안전하게 외부에서 접근 가능하도록 해주는 도구입니다. `ngrok`을 실행하려면 [회원가입](https://dashboard.ngrok.com/signup) 후 [로그인](https://dashboard.ngrok.com/login)을 한 뒤 [이곳](https://dashboard.ngrok.com/get-started/your-authtoken)에 접속해 인증 토큰(authtoken)을 확인해야 합니다. 예를 들어 확인된 `authtoken`이 `test111`이라면 다음과 같이 실행합니다.\n",
    "\n",
    "```bash\n",
    "!mkdir /root/.ngrok2 && echo \"authtoken: test111\" > /root/.ngrok2/ngrok.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KshHb4P_0wj"
   },
   "outputs": [],
   "source": [
    "!mkdir /root/.ngrok2 && echo \"authtoken: {이곳에 확인된 인증 토큰을 입력하세요}\" > /root/.ngrok2/ngrok.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPP6ZAaSybge"
   },
   "source": [
    "# 웹서비스 개시\n",
    "아래처럼 실행해 인퍼런스 함수를 웹서비스로 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_up1ARoHFwLN"
   },
   "outputs": [],
   "source": [
    "from ratsnlp.nlpbook.classification import get_web_service_app\n",
    "app = get_web_service_app(inference_fn)\n",
    "app.run()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "doc-cls-deploy-colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
