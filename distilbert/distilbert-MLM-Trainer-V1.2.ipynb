{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59d8373-51fc-4e45-bf92-fbf670af3bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================================================================================================================\n",
    "# Huggingface load_dataset 으로 MLM 훈련 하기\n",
    "#\n",
    "# => load_dataset 으로 wiki 말뭉치를 로딩하고, 이를 토크화 시키고, \n",
    "# input_ids 에 대해 15% 확률로 [MASK]를 씌워서, 실제 모델을 훈련시키는 예제 \n",
    "#\n",
    "# => MLM 훈련 말뭉치는 bongsoo/moco-corpus-kowiki202206 사용, 평가 말뭉치는 bongsoo/bongevalsmall 사용\n",
    "#\n",
    "# 출처 : https://wikidocs.net/166817\n",
    "#=======================================================================================================================================\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer, DistilBertTokenizerFast, BertConfig, DistilBertForMaskedLM\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from myutils import GPU_info, seed_everything, mlogging\n",
    "\n",
    "# wand 비활성화 \n",
    "# => trainer 로 훈련시키면 기본이 wandb 활성화이므로, 비활성화 시킴\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e4848b4-5068-43d4-8737-9419ec13fb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "cuda:0\n",
      "logfilepath:../../log/distilbert-MLM-Trainer_2022-09-25.log\n"
     ]
    }
   ],
   "source": [
    "# 훈련시킬 말뭉치(사전 만들때 동일한 말뭉치 이용)\n",
    "#input_corpus = \"../../data11/my_corpus/my/pre-kowiki-20220620-1줄.txt\"\n",
    "#input_corpus = \"bongsoo/moco-corpus\"  # huggingface에 등록된 말뭉치 이용\n",
    "input_corpus = \"../../data11/my_corpus/moco-corpus-kowiki2022.txt\"\n",
    "\n",
    "# eval 말뭉치 \n",
    "#eval_corpus = \"../../data11/my_corpus/bong_small_eval.txt\"\n",
    "eval_corpus = \"bongsoo/bongevalsmall\"\n",
    "\n",
    "# 기존 사전훈련된 모델\n",
    "model_path = \"../../data11/model/distilbert/checkpoint\"\n",
    "\n",
    "# 기존 사전 + 추가된 사전 파일\n",
    "vocab_path = \"../../data11/model/distilbert/checkpoint\"\n",
    "\n",
    "# 출력\n",
    "OUTPATH = '../../data11/model/distilbert/mdistilbertV2.1.1-temp/'\n",
    "\n",
    "############################################################################\n",
    "# tokenizer 관련 hyper parameter 설정\n",
    "############################################################################\n",
    "batch_size = 32       # batch_size (32 이상이면 CUDA MEMORY 부족 함)\n",
    "token_max_len = 128   # token_seq_len\n",
    "epoch = 1             # epoch\n",
    "lr = 3e-5             # learning rate(기본:5e-5)\n",
    "############################################################################\n",
    "\n",
    "\n",
    "device = GPU_info()\n",
    "print(device)\n",
    "\n",
    "#seed 설정\n",
    "seed_everything(333)\n",
    "\n",
    "#logging 설정\n",
    "logger =  mlogging(loggername=\"distilbert-MLM-Trainer\", logfilename=\"../../log/distilbert-MLM-Trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d3d1638-7c83-46bd-bd34-c6d1382e8f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data11/model/distilbert/checkpoint is_fast:True\n",
      "*special_token_size: 5, *tokenizer.vocab_size: 152537\n",
      "*vocab_size: 152538\n",
      "*tokenizer_len: 152537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForMaskedLM(\n",
       "  (activation): GELUActivation()\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(152537, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vocab_transform): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (vocab_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (vocab_projector): Linear(in_features=768, out_features=152537, bias=True)\n",
       "  (mlm_loss_fct): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokeinzier 생성\n",
    "# tokenizer 생성\n",
    "# => BertTokenizer, BertTokenizerFast 둘중 사용하면됨\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(vocab_path, max_len=token_max_len, do_lower_case=False)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(vocab_path, max_len=token_max_len, do_lower_case=False)\n",
    "# fast 토크너나이즈인지 확인\n",
    "print(f'{vocab_path} is_fast:{tokenizer.is_fast}')\n",
    "\n",
    "# speical 토큰 계수 + vocab 계수 - 이미 vocab에 포함된 speical 토큰 계수(5)\n",
    "vocab_size = len(tokenizer.all_special_tokens) + tokenizer.vocab_size - 5 + 1\n",
    "#vocab_size = len(tokenizer.all_special_tokens) + tokenizer.vocab_size - 5\n",
    "print('*special_token_size: {}, *tokenizer.vocab_size: {}'.format(len(tokenizer.all_special_tokens), tokenizer.vocab_size))\n",
    "print('*vocab_size: {}'.format(vocab_size))\n",
    "print('*tokenizer_len: {}'.format(len(tokenizer)))\n",
    "\n",
    "# 모델 로딩 further pre-training \n",
    "#config = BertConfig.from_pretrained(model_path)\n",
    "model = DistilBertForMaskedLM.from_pretrained(model_path, from_tf=bool(\".ckpt\" in model_path)) \n",
    "#model = BertForMaskedLM.from_pretrained('bert-base-multilingual-cased')    \n",
    "\n",
    "#################################################################################\n",
    "# 모델 embedding 사이즈를 tokenizer 크기 만큼 재 설정함.\n",
    "# 재설정하지 않으면, 다음과 같은 에러 발생함\n",
    "# CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)` CUDA 에러가 발생함\n",
    "#  indexSelectLargeIndex: block: [306,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
    "#\n",
    "#     해당 오류는 기존 Embedding(8002, 768, padding_idx=1) 처럼 입력 vocab 사이즈가 8002인데,\n",
    "#     0~8001 사이를 초과하는 word idx 값이 들어가면 에러 발생함.\n",
    "#################################################################################\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c678ff-b876-4432-91af-6ca2e11f70d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ad754964b5cc2b3a\n",
      "Reusing dataset text (/MOCOMSYS/.cache/huggingface/datasets/text/default-ad754964b5cc2b3a/0.0.0/08f6fb1dd2dab0a18ea441c359e1d63794ea8cb53e7863e6edf8fc5655e47ec4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a40388fcae4f708cf083ddcfb4544b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration bongsoo--bongevalsmall-cfa82c943ea1c946\n",
      "Reusing dataset text (/MOCOMSYS/.cache/huggingface/datasets/text/bongsoo--bongevalsmall-cfa82c943ea1c946/0.0.0/08f6fb1dd2dab0a18ea441c359e1d63794ea8cb53e7863e6edf8fc5655e47ec4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d8a2c22f7340bea6be711400274a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset=======================================\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 7680008\n",
      "    })\n",
      "})\n",
      "['Refer to the V$SYSTEM_EVENT view for time waited and average waits for thefollowing actions:', 'To estimate the time waited for reads incurred by rereading data blocks that had tobe written to disk because of a request from another instance, multiply the statistic(for example, the time waited for db ﬁle sequential reads) by the percentage of readI/O caused by previous cache ﬂushes as shown in this formula:', 'Where \"lock buffers for read\" is the value for lock converts from N to S derived fromV$LOCK_ACTIVITY and \"physical reads\" is from the V$SYSSTAT view.']\n",
      "\n",
      "\n",
      "\n",
      "eval_dataset========================================\n",
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "})\n",
      "['국토교통부 관계자는  실무기구에서는 각 업계별로 규제혁신형 플랫폼 택시를 하기 위해서는 어떤 규제를 풀어야 한다는 자기 안이 있어야 한다 고 말했다 ', '국책연구기관의 한 관계자는  위원회가 전문성과 대표성을 갖추고 본연의 장점을 최대한 살리기 위해서는 외부 감시와 통제가 보다 활성화돼야 한다 고 지적했다 ', '게임업계 관계자는  현장 수요보다 의료진 등 특정한 누군가의 이익을 위해 게임을 중독물질  질병으로 만들려 한다는 합리적 의심이 든다 고 꼬집었다 ']\n"
     ]
    }
   ],
   "source": [
    "#==================================================================================================\n",
    "# load_dataset을 이용하여, 훈련/평가 dataset 로딩.\n",
    "#\n",
    "# [로컬 데이터 파일 로딩]\n",
    "# => dataset = load_dataset(\"text\", data_files='로컬.txt')       # text 로컬 파일 로딩\n",
    "# => dataset = load_dataset(\"csv\", data_files='로컬.csv')        # csv 로컬 파일 로딩\n",
    "# => dataset = load_dataset(\"csv\", data_files='로컬.tsv', delimiter=\"\\t\")  # tsv 로컬 파일 로딩\n",
    "# => dataset = load_dataset(\"json\", data_files='로컬.json')      # json 로컬 파일 로딩\n",
    "# => dataset = load_dataset(\"pandas\", data_files='로컬.pkl')     # pickled dataframe 로컬 파일 로딩\n",
    "#\n",
    "# [원격 데이터 파일 로딩]\n",
    "# url = \"https://github.com/crux82/squad-it/raw/master/\"\n",
    "# data_files = {\n",
    "#    \"train\": url + \"SQuAD_it-train.json.gz\",\n",
    "#    \"test\": url + \"SQuAD_it-test.json.gz\",\n",
    "# }\n",
    "# squad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")\n",
    "#\n",
    "# 출처 : https://wikidocs.net/166816\n",
    "#==================================================================================================\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 훈련 말뭉치 로딩\n",
    "#train_dataset = load_dataset(input_corpus)\n",
    "train_dataset = load_dataset(\"text\", data_files=input_corpus) # text 로컬 파일 로딩\n",
    "\n",
    "# 평가 말뭉치 로딩\n",
    "eval_dataset = load_dataset(eval_corpus)\n",
    "\n",
    "# train_dataset 출력해봄\n",
    "print(f\"train_dataset=======================================\")\n",
    "print(train_dataset)\n",
    "print(train_dataset['train']['text'][0:3])\n",
    "\n",
    "print(f'\\r\\n\\r\\n')\n",
    "\n",
    "# eval_dataset 출력해봄\n",
    "print(f\"eval_dataset========================================\")\n",
    "print(eval_dataset)\n",
    "print(eval_dataset['test']['text'][0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ca75da5-1048-4522-a13f-60d306741a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aedacb537074367a57f9cd118c46e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7681 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 40s, sys: 26min 34s, total: 46min 15s\n",
      "Wall time: 3min 54s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e9b041baf8436bb65e2b1988c1815f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 139 ms, sys: 101 ms, total: 240 ms\n",
      "Wall time: 84.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n%time tokenized_dataset = text_dataset.map(tokenizer_function, batched=False)\\nprint(tokenized_dataset_fast['train']['text'][0:2])\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer 처리\n",
    "def tokenizer_function(examples):\n",
    "    result =  tokenizer(examples['text'], truncation=True, max_length=token_max_len, return_overflowing_tokens=True)\n",
    "    \n",
    "    # 신규 인덱스와 이전 인덱스와의 매핑 추출\n",
    "    sample_map = result.pop(\"overflow_to_sample_mapping\")\n",
    "    for key, values in examples.items():\n",
    "        result[key] = [values[i] for i in sample_map]\n",
    "    return result\n",
    "\n",
    "\n",
    "# batched=True 하면 빠른 tokenizer 이용(Rust)\n",
    "%time train_dataset_fast = train_dataset.map(tokenizer_function, batched=True)\n",
    "\n",
    "%time eval_dataset_fast = eval_dataset.map(tokenizer_function, batched=True)\n",
    "\n",
    "'''\n",
    "%time tokenized_dataset = text_dataset.map(tokenizer_function, batched=False)\n",
    "print(tokenized_dataset_fast['train']['text'][0:2])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa658e47-c0d5-47c6-a355-1097244ac3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset_fast=======================================\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 7686298\n",
      "    })\n",
      "})\n",
      "*fast_len:7686298, len:7680008\n",
      "{'text': ['Refer to the V$SYSTEM_EVENT view for time waited and average waits for thefollowing actions:', 'To estimate the time waited for reads incurred by rereading data blocks that had tobe written to disk because of a request from another instance, multiply the statistic(for example, the time waited for db ﬁle sequential reads) by the percentage of readI/O caused by previous cache ﬂushes as shown in this formula:'], 'input_ids': [[101, 142678, 10114, 10105, 159, 109, 122321, 168, 149821, 17904, 10142, 10635, 83279, 10336, 10111, 13551, 126341, 10142, 124429, 22115, 131, 102], [101, 11469, 78059, 10105, 10635, 83279, 10336, 10142, 91160, 10106, 12352, 19243, 10162, 10155, 11639, 66058, 10230, 11165, 47352, 10189, 10374, 136004, 13398, 10114, 50169, 12373, 10108, 169, 37449, 10188, 12864, 34469, 117, 21247, 59146, 10105, 17431, 26666, 113, 10142, 14351, 117, 10105, 10635, 83279, 10336, 10142, 49625, 119855, 10284, 134312, 91160, 114, 10155, 10105, 46971, 10108, 24944, 11281, 120, 152, 19513, 10155, 16741, 62070, 126429, 37026, 10171, 10146, 19989, 10106, 10531, 29659, 131, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "\n",
      "\n",
      "\n",
      "eval_dataset_fast=======================================\n",
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "})\n",
      "*fast_len:200, len:200\n",
      "{'text': ['국토교통부 관계자는  실무기구에서는 각 업계별로 규제혁신형 플랫폼 택시를 하기 위해서는 어떤 규제를 풀어야 한다는 자기 안이 있어야 한다 고 말했다 ', '국책연구기관의 한 관계자는  위원회가 전문성과 대표성을 갖추고 본연의 장점을 최대한 살리기 위해서는 외부 감시와 통제가 보다 활성화돼야 한다 고 지적했다 '], 'input_ids': [[101, 123067, 130404, 123101, 11018, 126024, 122076, 23635, 8844, 123998, 61844, 11261, 121905, 127469, 27506, 122160, 126962, 11513, 9952, 12310, 119754, 11018, 55910, 121905, 11513, 9937, 119684, 120812, 119926, 9521, 10739, 45893, 21711, 16139, 8888, 102055, 102], [101, 145342, 120752, 119691, 10459, 9954, 123101, 11018, 121015, 11287, 119653, 120718, 119629, 36456, 120624, 11664, 9358, 123106, 121850, 10622, 122739, 127473, 12310, 119754, 11018, 119946, 121640, 12638, 120291, 11287, 106154, 120284, 18227, 142462, 16139, 8888, 120313, 12490, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_dataset_fast=======================================\")\n",
    "print(train_dataset_fast)\n",
    "print(f'*fast_len:{len(train_dataset_fast[\"train\"])}, len:{len(train_dataset[\"train\"])}')  # fast_dataset과 dataset 길이를 비교함\n",
    "print(train_dataset_fast['train'][0:2])\n",
    "\n",
    "print(f'\\r\\n\\r\\n')\n",
    "\n",
    "print(f\"eval_dataset_fast=======================================\")\n",
    "print(eval_dataset_fast)\n",
    "print(f'*fast_len:{len(eval_dataset_fast[\"test\"])}, len:{len(eval_dataset[\"test\"])}')  # fast_dataset과 dataset 길이를 비교함\n",
    "print(eval_dataset_fast['test'][0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "651e30a6-0601-4272-bd40-0fdb9ce7be16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset_fast(MLM)=======================================\n",
      "tensor([   101, 142678,  10114,  10105,    159,    109,    103,    168, 149821,\n",
      "         17904,    103,  10635,  83279,  10336,  10111,  13551,    103,  10142,\n",
      "        124429,  22115,    131,    102,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0])\n",
      "{'text': 'Refer to the V$SYSTEM_EVENT view for time waited and average waits for thefollowing actions:', 'input_ids': [101, 142678, 10114, 10105, 159, 109, 122321, 168, 149821, 17904, 10142, 10635, 83279, 10336, 10111, 13551, 126341, 10142, 124429, 22115, 131, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "\n",
      "\n",
      "\n",
      "eval_dataset_fast(MLM)=======================================\n",
      "tensor([   101, 123067, 130404, 123101,  11018, 126024, 122076,  23635,   8844,\n",
      "        123998,    103,  11261, 121905, 127469,  27506, 122160,    103,  11513,\n",
      "          9952,  12310, 119754,  11018,  55910, 121905,  11513,   9937, 119684,\n",
      "        120812,    103,   9521,  10739,  45893,  21711,  16139,    103, 102055,\n",
      "           102,      0,      0])\n",
      "{'text': '국토교통부 관계자는  실무기구에서는 각 업계별로 규제혁신형 플랫폼 택시를 하기 위해서는 어떤 규제를 풀어야 한다는 자기 안이 있어야 한다 고 말했다 ', 'input_ids': [101, 123067, 130404, 123101, 11018, 126024, 122076, 23635, 8844, 123998, 61844, 11261, 121905, 127469, 27506, 122160, 126962, 11513, 9952, 12310, 119754, 11018, 55910, 121905, 11513, 9937, 119684, 120812, 119926, 9521, 10739, 45893, 21711, 16139, 8888, 102055, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# MLM을 위한 DataCollatorForLangunageModeling 호출\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# input_ids에 대해 MLM 만들기\n",
    "data_collator = DataCollatorForLanguageModeling(    # [MASK] 를 씌우는 것은 저희가 구현하지 않아도 됩니다! :-)\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "# input_ids MLM 만들고 출력 해봄\n",
    "mlm_train_sample = data_collator(train_dataset_fast['train']['input_ids'][0:2])\n",
    "mlm_eval_sample = data_collator(eval_dataset_fast['test']['input_ids'][0:2])\n",
    "\n",
    "print(f\"train_dataset_fast(MLM)=======================================\")\n",
    "print(mlm_train_sample['input_ids'][0])\n",
    "print(train_dataset_fast['train'][0])\n",
    "\n",
    "print(f'\\r\\n\\r\\n')\n",
    "\n",
    "print(f\"eval_dataset_fast(MLM)=======================================\")\n",
    "print(mlm_eval_sample['input_ids'][0])\n",
    "print(eval_dataset_fast['test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b1b230b-62af-4ee2-81a9-aaea54697a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*total_optim_steps: 240196, *eval_steps:2401, *logging_steps:2401, *save_steps:24019\n",
      "*no_cuda: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
     ]
    }
   ],
   "source": [
    "# 훈련 trainer 설정 \n",
    "# trainer \n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "#########################################################################################\n",
    "# hyper parameter 설정\n",
    "#########################################################################################\n",
    "\n",
    "epochs = epoch          # epochs\n",
    "\n",
    "total_optim_steps = len(train_dataset_fast[\"train\"]) * epochs // batch_size   # 총 optimize(역전파) 스탭수 = 훈련dataset 계수 * epochs // 배치 크기\n",
    "eval_steps=int(total_optim_steps * 0.02)           # 평가 스탭수\n",
    "logging_steps=eval_steps                           # 로깅 스탭수(*평가스탭수 출력할때는 평가스탭수와 동일하게)\n",
    "save_steps=int(total_optim_steps * 0.1)            # 저장 스탭수 \n",
    "#save_total_limit=5                                # 마지막 5개 남기고 삭제 \n",
    "\n",
    "print(f'*total_optim_steps: {total_optim_steps}, *eval_steps:{eval_steps}, *logging_steps:{logging_steps}, *save_steps:{save_steps}')\n",
    "#########################################################################################\n",
    "\n",
    "# cpu 사용이면 'no_cuda = True' 설정함.\n",
    "no_cuda = False\n",
    "if device == 'cpu':\n",
    "    no_cuda = True\n",
    "print(f'*no_cuda: {no_cuda}')\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    no_cuda = no_cuda,                      # GPU 사용  안함\n",
    "    output_dir = OUTPATH,                   # 출력 모델 저장 경로 \n",
    "    overwrite_output_dir=True,         \n",
    "    num_train_epochs=epochs,                # 에폭\n",
    "    learning_rate=lr,                       # lr: 기본 5e-5\n",
    "    per_gpu_train_batch_size=batch_size,    # 배치 사이즈 \n",
    "    save_strategy=\"steps\",                  # 저장 전략 (no, epoch, steps 기본=steps) \n",
    "    save_steps=save_steps,                  # step 수마다 모델을 저장\n",
    "    #save_total_limit=save_total_limit,     # 마지막 x개 모델 빼고 과거 모델은 삭제\n",
    "    evaluation_strategy=\"steps\",            # 평가 전략 (no, epoch, steps 기본=no)  \n",
    "    eval_steps=eval_steps,                  # 평가할 스텝수\n",
    "    logging_steps=logging_steps             # 로깅할 스탭수\n",
    ")\n",
    "\n",
    "# trainer로 훈련할때는 [mask] 처리된 input_ids 만 dataset으로 넘겨주면 됨.\n",
    "train_dataset_fast_input_ids = train_dataset_fast['train']['input_ids']\n",
    "eval_dataset_fast_input_ids = eval_dataset_fast['test']['input_ids']\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,  #MLM(Masked Language Model)\n",
    "    train_dataset=train_dataset_fast_input_ids,   # 훈련 데이터셋\n",
    "    eval_dataset=eval_dataset_fast_input_ids      # 평가 데이터셋\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "927efe3d-6472-4c37-825e-c14ef5ce2797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "/MOCOMSYS/anaconda3/envs/bong/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 7686298\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 240197\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240197' max='240197' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240197/240197 7:50:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2401</td>\n",
       "      <td>1.984200</td>\n",
       "      <td>3.359025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4802</td>\n",
       "      <td>2.373200</td>\n",
       "      <td>3.141898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7203</td>\n",
       "      <td>2.354500</td>\n",
       "      <td>3.216889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9604</td>\n",
       "      <td>2.372800</td>\n",
       "      <td>3.209530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12005</td>\n",
       "      <td>2.358700</td>\n",
       "      <td>3.109837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14406</td>\n",
       "      <td>2.372900</td>\n",
       "      <td>3.364009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16807</td>\n",
       "      <td>2.354500</td>\n",
       "      <td>3.308257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19208</td>\n",
       "      <td>2.351000</td>\n",
       "      <td>3.225958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21609</td>\n",
       "      <td>2.352100</td>\n",
       "      <td>3.127059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24010</td>\n",
       "      <td>2.353600</td>\n",
       "      <td>3.404438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26411</td>\n",
       "      <td>2.341100</td>\n",
       "      <td>3.255192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28812</td>\n",
       "      <td>2.341700</td>\n",
       "      <td>3.095204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31213</td>\n",
       "      <td>2.340800</td>\n",
       "      <td>3.313098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33614</td>\n",
       "      <td>2.337100</td>\n",
       "      <td>3.169626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36015</td>\n",
       "      <td>2.335200</td>\n",
       "      <td>3.332578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38416</td>\n",
       "      <td>2.346300</td>\n",
       "      <td>3.212209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40817</td>\n",
       "      <td>2.339500</td>\n",
       "      <td>3.115085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43218</td>\n",
       "      <td>2.322100</td>\n",
       "      <td>3.434353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45619</td>\n",
       "      <td>2.333300</td>\n",
       "      <td>3.311914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48020</td>\n",
       "      <td>2.326900</td>\n",
       "      <td>3.212235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50421</td>\n",
       "      <td>2.327400</td>\n",
       "      <td>2.988585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52822</td>\n",
       "      <td>2.324400</td>\n",
       "      <td>3.407705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55223</td>\n",
       "      <td>2.319900</td>\n",
       "      <td>3.217405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57624</td>\n",
       "      <td>2.323200</td>\n",
       "      <td>3.217536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60025</td>\n",
       "      <td>2.325100</td>\n",
       "      <td>3.149025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62426</td>\n",
       "      <td>2.306400</td>\n",
       "      <td>3.260631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64827</td>\n",
       "      <td>2.326000</td>\n",
       "      <td>3.150786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67228</td>\n",
       "      <td>2.320300</td>\n",
       "      <td>3.309325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69629</td>\n",
       "      <td>2.303900</td>\n",
       "      <td>3.165668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72030</td>\n",
       "      <td>2.301700</td>\n",
       "      <td>3.075313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74431</td>\n",
       "      <td>2.294200</td>\n",
       "      <td>2.997208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76832</td>\n",
       "      <td>2.300100</td>\n",
       "      <td>3.221213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79233</td>\n",
       "      <td>2.293000</td>\n",
       "      <td>3.140970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81634</td>\n",
       "      <td>2.291900</td>\n",
       "      <td>3.219567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84035</td>\n",
       "      <td>2.286400</td>\n",
       "      <td>3.292521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86436</td>\n",
       "      <td>2.303300</td>\n",
       "      <td>3.022191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88837</td>\n",
       "      <td>2.298100</td>\n",
       "      <td>3.126282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91238</td>\n",
       "      <td>2.286700</td>\n",
       "      <td>3.194754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93639</td>\n",
       "      <td>2.290100</td>\n",
       "      <td>3.287109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96040</td>\n",
       "      <td>2.281800</td>\n",
       "      <td>3.055910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98441</td>\n",
       "      <td>2.277700</td>\n",
       "      <td>3.084945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100842</td>\n",
       "      <td>2.266000</td>\n",
       "      <td>3.226429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103243</td>\n",
       "      <td>2.269400</td>\n",
       "      <td>3.005729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105644</td>\n",
       "      <td>2.270300</td>\n",
       "      <td>3.206096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108045</td>\n",
       "      <td>2.274500</td>\n",
       "      <td>3.142713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110446</td>\n",
       "      <td>2.278200</td>\n",
       "      <td>3.022606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112847</td>\n",
       "      <td>2.265100</td>\n",
       "      <td>3.153153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115248</td>\n",
       "      <td>2.267800</td>\n",
       "      <td>3.316340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117649</td>\n",
       "      <td>2.258600</td>\n",
       "      <td>3.370902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120050</td>\n",
       "      <td>2.269600</td>\n",
       "      <td>3.047851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122451</td>\n",
       "      <td>2.254900</td>\n",
       "      <td>3.167206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124852</td>\n",
       "      <td>2.253500</td>\n",
       "      <td>3.303380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127253</td>\n",
       "      <td>2.252600</td>\n",
       "      <td>3.054735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129654</td>\n",
       "      <td>2.259300</td>\n",
       "      <td>3.211139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132055</td>\n",
       "      <td>2.247200</td>\n",
       "      <td>3.013503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134456</td>\n",
       "      <td>2.247300</td>\n",
       "      <td>3.210209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136857</td>\n",
       "      <td>2.225900</td>\n",
       "      <td>3.121293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139258</td>\n",
       "      <td>2.231600</td>\n",
       "      <td>3.241191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141659</td>\n",
       "      <td>2.239700</td>\n",
       "      <td>3.074834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144060</td>\n",
       "      <td>2.225300</td>\n",
       "      <td>3.107566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146461</td>\n",
       "      <td>2.236700</td>\n",
       "      <td>3.100566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148862</td>\n",
       "      <td>2.235500</td>\n",
       "      <td>2.976072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151263</td>\n",
       "      <td>2.228200</td>\n",
       "      <td>3.182798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153664</td>\n",
       "      <td>2.229800</td>\n",
       "      <td>3.071882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156065</td>\n",
       "      <td>2.223500</td>\n",
       "      <td>3.193105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158466</td>\n",
       "      <td>2.218700</td>\n",
       "      <td>3.214017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160867</td>\n",
       "      <td>2.218500</td>\n",
       "      <td>3.167861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163268</td>\n",
       "      <td>2.213200</td>\n",
       "      <td>3.082542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165669</td>\n",
       "      <td>2.214800</td>\n",
       "      <td>3.145131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168070</td>\n",
       "      <td>2.212800</td>\n",
       "      <td>3.116158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170471</td>\n",
       "      <td>2.205000</td>\n",
       "      <td>3.189294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172872</td>\n",
       "      <td>2.206700</td>\n",
       "      <td>3.126891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175273</td>\n",
       "      <td>2.205900</td>\n",
       "      <td>3.157254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177674</td>\n",
       "      <td>2.201100</td>\n",
       "      <td>3.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180075</td>\n",
       "      <td>2.188200</td>\n",
       "      <td>3.253646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182476</td>\n",
       "      <td>2.205400</td>\n",
       "      <td>3.059529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184877</td>\n",
       "      <td>2.193500</td>\n",
       "      <td>3.147620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187278</td>\n",
       "      <td>2.185700</td>\n",
       "      <td>3.162665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189679</td>\n",
       "      <td>2.183600</td>\n",
       "      <td>3.112362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192080</td>\n",
       "      <td>2.201600</td>\n",
       "      <td>3.141255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194481</td>\n",
       "      <td>2.182900</td>\n",
       "      <td>3.171419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196882</td>\n",
       "      <td>2.169900</td>\n",
       "      <td>2.975651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199283</td>\n",
       "      <td>2.182900</td>\n",
       "      <td>2.962344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201684</td>\n",
       "      <td>2.176600</td>\n",
       "      <td>3.159677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204085</td>\n",
       "      <td>2.182100</td>\n",
       "      <td>2.904819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206486</td>\n",
       "      <td>2.176700</td>\n",
       "      <td>2.943424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208887</td>\n",
       "      <td>2.177800</td>\n",
       "      <td>2.886857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211288</td>\n",
       "      <td>2.165000</td>\n",
       "      <td>3.015980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213689</td>\n",
       "      <td>2.164600</td>\n",
       "      <td>3.005939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216090</td>\n",
       "      <td>2.158300</td>\n",
       "      <td>3.232389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218491</td>\n",
       "      <td>2.169300</td>\n",
       "      <td>2.927637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220892</td>\n",
       "      <td>2.166600</td>\n",
       "      <td>3.127890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223293</td>\n",
       "      <td>2.168400</td>\n",
       "      <td>2.897465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225694</td>\n",
       "      <td>2.170100</td>\n",
       "      <td>3.070137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228095</td>\n",
       "      <td>2.157600</td>\n",
       "      <td>2.971714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230496</td>\n",
       "      <td>2.160800</td>\n",
       "      <td>3.020386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232897</td>\n",
       "      <td>2.161800</td>\n",
       "      <td>3.008582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235298</td>\n",
       "      <td>2.151600</td>\n",
       "      <td>3.299904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237699</td>\n",
       "      <td>2.159100</td>\n",
       "      <td>2.880636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240100</td>\n",
       "      <td>2.144300</td>\n",
       "      <td>3.194242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-24019\n",
      "Configuration saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-24019/config.json\n",
      "Model weights saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-24019/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-48038\n",
      "Configuration saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-48038/config.json\n",
      "Model weights saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-48038/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-72057\n",
      "Configuration saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-72057/config.json\n",
      "Model weights saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-72057/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-96076\n",
      "Configuration saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-96076/config.json\n",
      "Model weights saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-96076/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-120095\n",
      "Configuration saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-120095/config.json\n",
      "Model weights saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-120095/pytorch_model.bin\n",
      "Deleting older checkpoint [../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-24019] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-144114\n",
      "Configuration saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-144114/config.json\n",
      "Model weights saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-144114/pytorch_model.bin\n",
      "Deleting older checkpoint [../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-48038] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-168133\n",
      "Configuration saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-168133/config.json\n",
      "Model weights saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-168133/pytorch_model.bin\n",
      "Deleting older checkpoint [../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-72057] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-192152\n",
      "Configuration saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-192152/config.json\n",
      "Model weights saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-192152/pytorch_model.bin\n",
      "Deleting older checkpoint [../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-96076] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-216171\n",
      "Configuration saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-216171/config.json\n",
      "Model weights saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-216171/pytorch_model.bin\n",
      "Deleting older checkpoint [../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-120095] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-240190\n",
      "Configuration saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-240190/config.json\n",
      "Model weights saved in ../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-240190/pytorch_model.bin\n",
      "Deleting older checkpoint [../../data11/model/distilbert/mdistilbertV2.1.1-temp/checkpoint-144114] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=240197, training_loss=2.2538148615442317, metrics={'train_runtime': 28240.208, 'train_samples_per_second': 272.176, 'train_steps_per_second': 8.505, 'total_flos': 1.382243463953452e+17, 'train_loss': 2.2538148615442317, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 시작\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be7243c-1c77-403c-bb71-281612b8db36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../../data11/model/distilbert/mdistilbertV2.1.1/config.json\n",
      "Model weights saved in ../../data11/model/distilbert/mdistilbertV2.1.1/pytorch_model.bin\n",
      "tokenizer config file saved in ../../data11/model/distilbert/mdistilbertV2.1.1/tokenizer_config.json\n",
      "Special tokens file saved in ../../data11/model/distilbert/mdistilbertV2.1.1/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> save_model : ../../data11/model/distilbert/mdistilbertV2.1.1/\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "### 전체모델 저장\n",
    "TMP_OUT_PATH = '../../data11/model/distilbert/mdistilbertV2.1.1/'\n",
    "os.makedirs(TMP_OUT_PATH, exist_ok=True)\n",
    "#torch.save(model, OUTPATH + 'pytorch_model.bin') \n",
    "# save_pretrained 로 저장하면 config.json, pytorch_model.bin 2개의 파일이 생성됨\n",
    "model.save_pretrained(TMP_OUT_PATH)\n",
    "\n",
    "# tokeinizer 파일 저장(vocab)\n",
    "VOCAB_PATH = TMP_OUT_PATH\n",
    "tokenizer.save_pretrained(VOCAB_PATH)\n",
    "print(f'==> save_model : {TMP_OUT_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a8a66c-831a-44f4-a063-9932aeaf7d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
