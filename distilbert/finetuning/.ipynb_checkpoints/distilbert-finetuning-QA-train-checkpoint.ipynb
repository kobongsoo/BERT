{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159bc54e-0c70-4cc7-b3ff-cb2b3683cbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:bwdataset_2022-03-15.log\n",
      "logfilepath:qnadataset_2022-03-15.log\n",
      "logfilepath:bertQAtrain_2022-03-15.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "# Question & Answer 훈련 예제\n",
    "#\n",
    "# => input_ids : [CLS]질문[SEP]지문[SEP]\n",
    "# => attention_mask : 1111111111(질문, 지문 모두 1)\n",
    "# => token_type_ids : 0000000(질문)1111111(지문)\n",
    "# => start_positions : 45 (질문에 대한 지문에서의 답변 시작 위치)\n",
    "# => end_positions : 60 (질문에 대한 지문에서의 답변 끝 위치)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import sys\n",
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append('..')\n",
    "from myutils import seed_everything, GPU_info, mlogging, QADataset\n",
    "\n",
    "logger = mlogging(loggername=\"bertQAtrain\", logfilname=\"bertQAtrain\")\n",
    "device = GPU_info()\n",
    "seed_everything(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731f6745-a2f4-4b2d-9a19-1fa2efa6f3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../model/distilbert/distilbert-fpt-wiki_20190620-mecab-model-0313 were not used when initializing DistilBertForQuestionAnswering: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at ../model/distilbert/distilbert-fpt-wiki_20190620-mecab-model-0313 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(143772, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################################\n",
    "# 변수들 설정\n",
    "# - model_path : from_pretrained() 로 호출하는 경우에는 모델파일이 있는 폴더 경로나 \n",
    "#          huggingface에 등록된 모델명(예:'bert-base-multilingual-cased')\n",
    "#          torch.load(model)로 로딩하는 경우에는 모델 파일 풀 경로\n",
    "#\n",
    "# - vocab_path : from_pretrained() 호출하는 경우에는 모델파일이 있는 폴더 경로나\n",
    "#          huggingface에 등록된 모델명(예:'bert-base-multilingual-cased')   \n",
    "#          BertTokenizer() 로 호출하는 경우에는 vocab.txt 파일 풀 경로,\n",
    "#\n",
    "# - OUTPATH : 출력 모델, vocab 저장할 폴더 경로\n",
    "#############################################################################################\n",
    "\n",
    "model_path = '../model/distilbert/distilbert-fpt-wiki_20190620-mecab-model-0313'\n",
    "vocab_path = '../model/distilbert/distilbert-fpt-wiki_20190620-mecab-model-0313'\n",
    "OUTPATH = '../model/distibert/distilbert-fpt-wiki_20190620-mecab-model-0313-QA-0315/'\n",
    "\n",
    "# tokeniaer 및 model 설정\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# strip_accents=False : True로 하면, 가자 => ㄱ ㅏ ㅈ ㅏ 식으로 토큰화 되어 버림(*따라서 한국어에서는 반드시 False)\n",
    "# do_lower_case=False : # 소문자 입력 사용 안함(한국어에서는 반드시 False)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(vocab_path, strip_accents=False, do_lower_case=False) \n",
    "   \n",
    "model = DistilBertForQuestionAnswering.from_pretrained(model_path)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918a05d8-aee5-42df-9a1c-1dc2443f655d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153340418"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65d611fe-b906-45ee-afc2-dcbfcd760751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 16:53:23,431 - qnadataset - INFO - Creating features from dataset file at ../korpora/korQuAD/KorQuAD_v1.0_train.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create train_loader===========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1420/1420 [00:00<00:00, 21295.83it/s]\n",
      "convert squad examples to features: 100%|█| 57688/57688 [01:09<00:00, 828.12it/s\n",
      "2022-03-15 16:54:34,777 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:34,780 - qnadataset - INFO - question & context: [CLS] 바그너 ##는 괴테 ##의 파우스트 ##를 읽 ##고 무엇 ##을 쓰 ##고 ##자 했 ##는 ##가 ? [SEP] 1839 ##년 바그너 ##는 괴테 ##의 파우스트 ##을 처음 읽 ##고 그 내용 ##에 마음 ##이 끌려 이를 소재 ##로 해서 하나의 교향곡 ##을 쓰 ##려 ##는 뜻 ##을 갖 ##는다 . 이 시기 바그너 ##는 1838 ##년에 빛 독 ##촉 ##으로 산전 ##수 ##전을 다 [UNK] 상황 ##이 ##라 좌절 ##과 실망 ##에 가득 ##했으며 메 ##피스 ##토 ##펠 ##레스 ##를 만나 ##는 파우스트 ##의 심경 ##에 공감 ##했다 ##고 한다 . 또한 파리 ##에서 아브 ##네 ##크 ##의 지휘 ##로 파리 음악원 관현악단 ##이 연주 ##하는 베토벤 ##의 교향곡 9 ##번 ##을 듣 ##고 깊 ##은 감명 ##을 받 ##았 ##는데 , 이것 ##이 이듬해 1월 [SEP]\n",
      "2022-03-15 16:54:34,781 - qnadataset - INFO - answer: 교향곡\n",
      "2022-03-15 16:54:34,782 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 131787, 11018, 143664, 10459, 141463, 11513, 9642, 11664, 120950, 10622, 9511, 11664, 13764, 9965, 11018, 11287, 136, 102, 16221, 10954, 131787, 11018, 143664, 10459, 141463, 10622, 62849, 9642, 11664, 8924, 119632, 10530, 119916, 10739, 126940, 35756, 120286, 11261, 119687, 90387, 124556, 10622, 9511, 26737, 11018, 9153, 10622, 8854, 40410, 119, 9638, 119876, 131787, 11018, 16347, 27056, 9387, 9088, 119267, 11467, 142025, 15891, 54918, 9056, 100, 119803, 10739, 17342, 126431, 11882, 126981, 10530, 124809, 51491, 9272, 121657, 26444, 119394, 100929, 11513, 120312, 11018, 141463, 10459, 141726, 10530, 124618, 12490, 11664, 16139, 119, 19789, 120425, 11489, 130625, 77884, 20308, 10459, 120154, 11261, 120425, 137413, 133390, 10739, 120441, 12178, 128268, 10459, 124556, 130, 35465, 10622, 9116, 11664, 8938, 10892, 139954, 10622, 9322, 119118, 41850, 117, 119757, 10739, 120897, 17206, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=41, end_positions=41)\n",
      "2022-03-15 16:54:34,782 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:34,784 - qnadataset - INFO - question & context: [CLS] 바그너 ##는 괴테 ##의 파우스트 ##를 읽 ##고 무엇 ##을 쓰 ##고 ##자 했 ##는 ##가 ? [SEP] 파우스트 ##의 심경 ##에 공감 ##했다 ##고 한다 . 또한 파리 ##에서 아브 ##네 ##크 ##의 지휘 ##로 파리 음악원 관현악단 ##이 연주 ##하는 베토벤 ##의 교향곡 9 ##번 ##을 듣 ##고 깊 ##은 감명 ##을 받 ##았 ##는데 , 이것 ##이 이듬해 1월 ##에 파우스트 ##의 서곡 ##으로 쓰여진 이 작품 ##에 조금 ##이 ##라도 영향을 끼쳤 ##으 ##리 ##라는 것은 의심 ##할 여지 ##가 없다 . 여기 ##의 라 ##단조 조성 ##의 경우 ##에도 그의 전기 ##에 적혀 있는 것 ##처럼 단순 ##한 정신 ##적 피로 ##나 실 ##의 ##가 반영 ##된 것이 아니라 베토벤 ##의 합창 ##교 ##향 ##곡 조성 ##의 영향을 받은 것을 볼 [SEP]\n",
      "2022-03-15 16:54:34,784 - qnadataset - INFO - answer: [CLS]\n",
      "2022-03-15 16:54:34,785 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 131787, 11018, 143664, 10459, 141463, 11513, 9642, 11664, 120950, 10622, 9511, 11664, 13764, 9965, 11018, 11287, 136, 102, 141463, 10459, 141726, 10530, 124618, 12490, 11664, 16139, 119, 19789, 120425, 11489, 130625, 77884, 20308, 10459, 120154, 11261, 120425, 137413, 133390, 10739, 120441, 12178, 128268, 10459, 124556, 130, 35465, 10622, 9116, 11664, 8938, 10892, 139954, 10622, 9322, 119118, 41850, 117, 119757, 10739, 120897, 17206, 10530, 141463, 10459, 137473, 11467, 131367, 9638, 119626, 10530, 120893, 10739, 120365, 58088, 130331, 119185, 12692, 60362, 30050, 121471, 14843, 124889, 11287, 39218, 119, 119777, 10459, 9157, 136161, 120668, 10459, 28467, 35979, 21555, 119942, 10530, 127086, 13767, 8870, 92383, 120543, 11102, 120174, 14801, 128478, 16439, 9489, 10459, 11287, 122102, 13441, 27487, 45021, 128268, 10459, 124616, 25242, 79544, 55670, 120668, 10459, 58088, 74141, 21371, 9359, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n",
      "2022-03-15 16:54:34,786 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:34,789 - qnadataset - INFO - question & context: [CLS] 바그너 ##는 괴테 ##의 파우스트 ##를 읽 ##고 무엇 ##을 쓰 ##고 ##자 했 ##는 ##가 ? [SEP] 여지 ##가 없다 . 여기 ##의 라 ##단조 조성 ##의 경우 ##에도 그의 전기 ##에 적혀 있는 것 ##처럼 단순 ##한 정신 ##적 피로 ##나 실 ##의 ##가 반영 ##된 것이 아니라 베토벤 ##의 합창 ##교 ##향 ##곡 조성 ##의 영향을 받은 것을 볼 수 있다 . 그렇게 교향곡 작곡 ##을 1839 ##년부터 40 ##년에 걸쳐 파리 ##에서 착수 ##했 ##으나 1 ##악 ##장을 쓴 뒤 ##에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서곡 ( 1 ##악 ##장 ) 을 파리 음악원 ##의 연주회 ##에서 연주 ##할 파트 ##보 ##까지 준비 ##하 ##였으나 , 실제로 ##는 이루어지 ##지는 않았다 . 결국 초연 ##은 [SEP]\n",
      "2022-03-15 16:54:34,790 - qnadataset - INFO - answer: [CLS]\n",
      "2022-03-15 16:54:34,791 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 131787, 11018, 143664, 10459, 141463, 11513, 9642, 11664, 120950, 10622, 9511, 11664, 13764, 9965, 11018, 11287, 136, 102, 124889, 11287, 39218, 119, 119777, 10459, 9157, 136161, 120668, 10459, 28467, 35979, 21555, 119942, 10530, 127086, 13767, 8870, 92383, 120543, 11102, 120174, 14801, 128478, 16439, 9489, 10459, 11287, 122102, 13441, 27487, 45021, 128268, 10459, 124616, 25242, 79544, 55670, 120668, 10459, 58088, 74141, 21371, 9359, 9460, 11506, 119, 121608, 124556, 76512, 10622, 16221, 87188, 10533, 27056, 92210, 120425, 11489, 125385, 119424, 35466, 122, 119110, 35963, 9512, 9109, 10530, 120604, 12490, 119, 19789, 119626, 10459, 120899, 11882, 58248, 17889, 9638, 137473, 113, 122, 119110, 13890, 114, 9633, 120425, 137413, 10459, 132695, 11489, 120441, 14843, 121425, 30005, 18382, 120339, 35506, 74519, 117, 120603, 11018, 121661, 32815, 49137, 119, 50342, 127134, 10892, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n",
      "2022-03-15 16:54:34,791 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:34,793 - qnadataset - INFO - question & context: [CLS] 바그너 ##는 괴테 ##의 파우스트 ##를 읽 ##고 무엇 ##을 쓰 ##고 ##자 했 ##는 ##가 ? [SEP] 쓴 뒤 ##에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서곡 ( 1 ##악 ##장 ) 을 파리 음악원 ##의 연주회 ##에서 연주 ##할 파트 ##보 ##까지 준비 ##하 ##였으나 , 실제로 ##는 이루어지 ##지는 않았다 . 결국 초연 ##은 4 ##년 반 ##이 지난 후에 드레스 ##덴 ##에서 연주 ##되었고 재연 ##도 이루 ##어졌 ##지만 , 이후 ##에 그대로 방치 ##되고 말 ##았다 . 그 사이에 그는 리엔 ##치 ##와 방황 ##하는 네덜란드인 ##을 완성 ##하고 탄 ##호 ##이 ##저 ##에도 착수 ##하는 등 분 ##주 ##한 시간 ##을 보냈 ##는데 , 그런 바 ##쁜 생활 ##이 이 곡 ##을 잊 ##게 한 [SEP]\n",
      "2022-03-15 16:54:34,794 - qnadataset - INFO - answer: [CLS]\n",
      "2022-03-15 16:54:34,795 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 131787, 11018, 143664, 10459, 141463, 11513, 9642, 11664, 120950, 10622, 9511, 11664, 13764, 9965, 11018, 11287, 136, 102, 9512, 9109, 10530, 120604, 12490, 119, 19789, 119626, 10459, 120899, 11882, 58248, 17889, 9638, 137473, 113, 122, 119110, 13890, 114, 9633, 120425, 137413, 10459, 132695, 11489, 120441, 14843, 121425, 30005, 18382, 120339, 35506, 74519, 117, 120603, 11018, 121661, 32815, 49137, 119, 50342, 127134, 10892, 125, 10954, 9321, 10739, 120600, 56528, 126715, 118790, 11489, 120441, 49953, 142552, 12092, 119661, 121022, 28578, 117, 18347, 10530, 110589, 128194, 29208, 9251, 27303, 119, 8924, 64932, 17889, 143091, 18622, 12638, 135821, 12178, 140872, 10622, 120899, 12453, 9847, 20309, 10739, 48387, 35979, 125385, 12178, 9121, 9367, 16323, 11102, 119610, 10622, 121357, 41850, 117, 119989, 9318, 119023, 119782, 10739, 9638, 8889, 10622, 9649, 14153, 9954, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n",
      "2022-03-15 16:54:34,796 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:34,797 - qnadataset - INFO - question & context: [CLS] 바그너 ##는 괴테 ##의 파우스트 ##를 읽 ##고 무엇 ##을 쓰 ##고 ##자 했 ##는 ##가 ? [SEP] 방치 ##되고 말 ##았다 . 그 사이에 그는 리엔 ##치 ##와 방황 ##하는 네덜란드인 ##을 완성 ##하고 탄 ##호 ##이 ##저 ##에도 착수 ##하는 등 분 ##주 ##한 시간 ##을 보냈 ##는데 , 그런 바 ##쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것이 아닌가 하는 의견 ##도 있다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "2022-03-15 16:54:34,799 - qnadataset - INFO - answer: [CLS]\n",
      "2022-03-15 16:54:34,799 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 131787, 11018, 143664, 10459, 141463, 11513, 9642, 11664, 120950, 10622, 9511, 11664, 13764, 9965, 11018, 11287, 136, 102, 128194, 29208, 9251, 27303, 119, 8924, 64932, 17889, 143091, 18622, 12638, 135821, 12178, 140872, 10622, 120899, 12453, 9847, 20309, 10739, 48387, 35979, 125385, 12178, 9121, 9367, 16323, 11102, 119610, 10622, 121357, 41850, 117, 119989, 9318, 119023, 119782, 10739, 9638, 8889, 10622, 9649, 14153, 9954, 27487, 127780, 23969, 119743, 12092, 11506, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=0, end_positions=0)\n",
      "2022-03-15 16:54:34,800 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:34,801 - qnadataset - INFO - question & context: [CLS] 바그너 ##는 교향곡 작곡 ##을 어디 ##까지 쓴 뒤 ##에 중단 ##했 ##는 ##가 ? [SEP] 1839 ##년 바그너 ##는 괴테 ##의 파우스트 ##을 처음 읽 ##고 그 내용 ##에 마음 ##이 끌려 이를 소재 ##로 해서 하나의 교향곡 ##을 쓰 ##려 ##는 뜻 ##을 갖 ##는다 . 이 시기 바그너 ##는 1838 ##년에 빛 독 ##촉 ##으로 산전 ##수 ##전을 다 [UNK] 상황 ##이 ##라 좌절 ##과 실망 ##에 가득 ##했으며 메 ##피스 ##토 ##펠 ##레스 ##를 만나 ##는 파우스트 ##의 심경 ##에 공감 ##했다 ##고 한다 . 또한 파리 ##에서 아브 ##네 ##크 ##의 지휘 ##로 파리 음악원 관현악단 ##이 연주 ##하는 베토벤 ##의 교향곡 9 ##번 ##을 듣 ##고 깊 ##은 감명 ##을 받 ##았 ##는데 , 이것 ##이 이듬해 1월 ##에 파우스트 [SEP]\n",
      "2022-03-15 16:54:34,802 - qnadataset - INFO - answer: [CLS]\n",
      "2022-03-15 16:54:34,803 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 131787, 11018, 124556, 76512, 10622, 121328, 18382, 9512, 9109, 10530, 120604, 119424, 11018, 11287, 136, 102, 16221, 10954, 131787, 11018, 143664, 10459, 141463, 10622, 62849, 9642, 11664, 8924, 119632, 10530, 119916, 10739, 126940, 35756, 120286, 11261, 119687, 90387, 124556, 10622, 9511, 26737, 11018, 9153, 10622, 8854, 40410, 119, 9638, 119876, 131787, 11018, 16347, 27056, 9387, 9088, 119267, 11467, 142025, 15891, 54918, 9056, 100, 119803, 10739, 17342, 126431, 11882, 126981, 10530, 124809, 51491, 9272, 121657, 26444, 119394, 100929, 11513, 120312, 11018, 141463, 10459, 141726, 10530, 124618, 12490, 11664, 16139, 119, 19789, 120425, 11489, 130625, 77884, 20308, 10459, 120154, 11261, 120425, 137413, 133390, 10739, 120441, 12178, 128268, 10459, 124556, 130, 35465, 10622, 9116, 11664, 8938, 10892, 139954, 10622, 9322, 119118, 41850, 117, 119757, 10739, 120897, 17206, 10530, 141463, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n",
      "2022-03-15 16:54:34,804 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:34,805 - qnadataset - INFO - question & context: [CLS] 바그너 ##는 교향곡 작곡 ##을 어디 ##까지 쓴 뒤 ##에 중단 ##했 ##는 ##가 ? [SEP] 파우스트 ##의 심경 ##에 공감 ##했다 ##고 한다 . 또한 파리 ##에서 아브 ##네 ##크 ##의 지휘 ##로 파리 음악원 관현악단 ##이 연주 ##하는 베토벤 ##의 교향곡 9 ##번 ##을 듣 ##고 깊 ##은 감명 ##을 받 ##았 ##는데 , 이것 ##이 이듬해 1월 ##에 파우스트 ##의 서곡 ##으로 쓰여진 이 작품 ##에 조금 ##이 ##라도 영향을 끼쳤 ##으 ##리 ##라는 것은 의심 ##할 여지 ##가 없다 . 여기 ##의 라 ##단조 조성 ##의 경우 ##에도 그의 전기 ##에 적혀 있는 것 ##처럼 단순 ##한 정신 ##적 피로 ##나 실 ##의 ##가 반영 ##된 것이 아니라 베토벤 ##의 합창 ##교 ##향 ##곡 조성 ##의 영향을 받은 것을 볼 수 있다 [SEP]\n",
      "2022-03-15 16:54:34,806 - qnadataset - INFO - answer: [CLS]\n",
      "2022-03-15 16:54:34,806 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 131787, 11018, 124556, 76512, 10622, 121328, 18382, 9512, 9109, 10530, 120604, 119424, 11018, 11287, 136, 102, 141463, 10459, 141726, 10530, 124618, 12490, 11664, 16139, 119, 19789, 120425, 11489, 130625, 77884, 20308, 10459, 120154, 11261, 120425, 137413, 133390, 10739, 120441, 12178, 128268, 10459, 124556, 130, 35465, 10622, 9116, 11664, 8938, 10892, 139954, 10622, 9322, 119118, 41850, 117, 119757, 10739, 120897, 17206, 10530, 141463, 10459, 137473, 11467, 131367, 9638, 119626, 10530, 120893, 10739, 120365, 58088, 130331, 119185, 12692, 60362, 30050, 121471, 14843, 124889, 11287, 39218, 119, 119777, 10459, 9157, 136161, 120668, 10459, 28467, 35979, 21555, 119942, 10530, 127086, 13767, 8870, 92383, 120543, 11102, 120174, 14801, 128478, 16439, 9489, 10459, 11287, 122102, 13441, 27487, 45021, 128268, 10459, 124616, 25242, 79544, 55670, 120668, 10459, 58088, 74141, 21371, 9359, 9460, 11506, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n",
      "2022-03-15 16:54:34,807 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:34,808 - qnadataset - INFO - question & context: [CLS] 바그너 ##는 교향곡 작곡 ##을 어디 ##까지 쓴 뒤 ##에 중단 ##했 ##는 ##가 ? [SEP] 여지 ##가 없다 . 여기 ##의 라 ##단조 조성 ##의 경우 ##에도 그의 전기 ##에 적혀 있는 것 ##처럼 단순 ##한 정신 ##적 피로 ##나 실 ##의 ##가 반영 ##된 것이 아니라 베토벤 ##의 합창 ##교 ##향 ##곡 조성 ##의 영향을 받은 것을 볼 수 있다 . 그렇게 교향곡 작곡 ##을 1839 ##년부터 40 ##년에 걸쳐 파리 ##에서 착수 ##했 ##으나 1 ##악 ##장을 쓴 뒤 ##에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서곡 ( 1 ##악 ##장 ) 을 파리 음악원 ##의 연주회 ##에서 연주 ##할 파트 ##보 ##까지 준비 ##하 ##였으나 , 실제로 ##는 이루어지 ##지는 않았다 . 결국 초연 ##은 4 ##년 [SEP]\n",
      "2022-03-15 16:54:34,810 - qnadataset - INFO - answer: 1 ##악 ##장을\n",
      "2022-03-15 16:54:34,811 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 131787, 11018, 124556, 76512, 10622, 121328, 18382, 9512, 9109, 10530, 120604, 119424, 11018, 11287, 136, 102, 124889, 11287, 39218, 119, 119777, 10459, 9157, 136161, 120668, 10459, 28467, 35979, 21555, 119942, 10530, 127086, 13767, 8870, 92383, 120543, 11102, 120174, 14801, 128478, 16439, 9489, 10459, 11287, 122102, 13441, 27487, 45021, 128268, 10459, 124616, 25242, 79544, 55670, 120668, 10459, 58088, 74141, 21371, 9359, 9460, 11506, 119, 121608, 124556, 76512, 10622, 16221, 87188, 10533, 27056, 92210, 120425, 11489, 125385, 119424, 35466, 122, 119110, 35963, 9512, 9109, 10530, 120604, 12490, 119, 19789, 119626, 10459, 120899, 11882, 58248, 17889, 9638, 137473, 113, 122, 119110, 13890, 114, 9633, 120425, 137413, 10459, 132695, 11489, 120441, 14843, 121425, 30005, 18382, 120339, 35506, 74519, 117, 120603, 11018, 121661, 32815, 49137, 119, 50342, 127134, 10892, 125, 10954, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=78, end_positions=80)\n",
      "2022-03-15 16:54:34,811 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:34,813 - qnadataset - INFO - question & context: [CLS] 바그너 ##는 교향곡 작곡 ##을 어디 ##까지 쓴 뒤 ##에 중단 ##했 ##는 ##가 ? [SEP] 쓴 뒤 ##에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서곡 ( 1 ##악 ##장 ) 을 파리 음악원 ##의 연주회 ##에서 연주 ##할 파트 ##보 ##까지 준비 ##하 ##였으나 , 실제로 ##는 이루어지 ##지는 않았다 . 결국 초연 ##은 4 ##년 반 ##이 지난 후에 드레스 ##덴 ##에서 연주 ##되었고 재연 ##도 이루 ##어졌 ##지만 , 이후 ##에 그대로 방치 ##되고 말 ##았다 . 그 사이에 그는 리엔 ##치 ##와 방황 ##하는 네덜란드인 ##을 완성 ##하고 탄 ##호 ##이 ##저 ##에도 착수 ##하는 등 분 ##주 ##한 시간 ##을 보냈 ##는데 , 그런 바 ##쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것이 아닌가 [SEP]\n",
      "2022-03-15 16:54:34,813 - qnadataset - INFO - answer: [CLS]\n",
      "2022-03-15 16:54:34,814 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 131787, 11018, 124556, 76512, 10622, 121328, 18382, 9512, 9109, 10530, 120604, 119424, 11018, 11287, 136, 102, 9512, 9109, 10530, 120604, 12490, 119, 19789, 119626, 10459, 120899, 11882, 58248, 17889, 9638, 137473, 113, 122, 119110, 13890, 114, 9633, 120425, 137413, 10459, 132695, 11489, 120441, 14843, 121425, 30005, 18382, 120339, 35506, 74519, 117, 120603, 11018, 121661, 32815, 49137, 119, 50342, 127134, 10892, 125, 10954, 9321, 10739, 120600, 56528, 126715, 118790, 11489, 120441, 49953, 142552, 12092, 119661, 121022, 28578, 117, 18347, 10530, 110589, 128194, 29208, 9251, 27303, 119, 8924, 64932, 17889, 143091, 18622, 12638, 135821, 12178, 140872, 10622, 120899, 12453, 9847, 20309, 10739, 48387, 35979, 125385, 12178, 9121, 9367, 16323, 11102, 119610, 10622, 121357, 41850, 117, 119989, 9318, 119023, 119782, 10739, 9638, 8889, 10622, 9649, 14153, 9954, 27487, 127780, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n",
      "2022-03-15 16:54:34,815 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:34,816 - qnadataset - INFO - question & context: [CLS] 바그너 ##는 교향곡 작곡 ##을 어디 ##까지 쓴 뒤 ##에 중단 ##했 ##는 ##가 ? [SEP] 방치 ##되고 말 ##았다 . 그 사이에 그는 리엔 ##치 ##와 방황 ##하는 네덜란드인 ##을 완성 ##하고 탄 ##호 ##이 ##저 ##에도 착수 ##하는 등 분 ##주 ##한 시간 ##을 보냈 ##는데 , 그런 바 ##쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것이 아닌가 하는 의견 ##도 있다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "2022-03-15 16:54:34,817 - qnadataset - INFO - answer: [CLS]\n",
      "2022-03-15 16:54:34,817 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 131787, 11018, 124556, 76512, 10622, 121328, 18382, 9512, 9109, 10530, 120604, 119424, 11018, 11287, 136, 102, 128194, 29208, 9251, 27303, 119, 8924, 64932, 17889, 143091, 18622, 12638, 135821, 12178, 140872, 10622, 120899, 12453, 9847, 20309, 10739, 48387, 35979, 125385, 12178, 9121, 9367, 16323, 11102, 119610, 10622, 121357, 41850, 117, 119989, 9318, 119023, 119782, 10739, 9638, 8889, 10622, 9649, 14153, 9954, 27487, 127780, 23969, 119743, 12092, 11506, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=0, end_positions=0)\n",
      "2022-03-15 16:54:34,819 - qnadataset - INFO - Saving features into cached file, it could take a lot of time...\n",
      "2022-03-15 16:54:50,291 - qnadataset - INFO - Saving features into cached file ../korpora/korQuAD/cached_DistilBertTokenizer_128_32_64_KorQuAD_v1.0_train.json [took 15.472 s]\n",
      "2022-03-15 16:54:50,337 - qnadataset - INFO - Creating features from dataset file at ../korpora/korQuAD/KorQuAD_v1.0_dev.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end train_loader===========================================================\n",
      "create eval_loader===========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 140/140 [00:00<00:00, 15665.84it/s]\n",
      "convert squad examples to features: 100%|██| 5533/5533 [00:06<00:00, 821.29it/s]\n",
      "2022-03-15 16:54:57,805 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:57,808 - qnadataset - INFO - question & context: [CLS] 1989년 6월 30일 평양 ##축 ##전에 대표 ##로 파견 된 인물 ##은 ? [SEP] 1989년 2월 15일 여의도 농민 폭력 시위 ##를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처 ##벌 ##에 ##관 ##한 ##법 ##률 ##위 ##반 ) 으로 지명 ##수 ##배 ##되었다 . 1989년 3월 12일 서울 ##지 ##방 ##검 ##찰청 공안 ##부는 임종 ##석 ##의 사전 ##구 ##속 ##영 ##장을 발부 ##받 ##았다 . 같은 해 6월 30일 평양 ##축 ##전에 임수 ##경 ##을 대표 ##로 파견 ##하여 국가 ##보 ##안 ##법 ##위 ##반 혐의 ##가 추가 ##되었다 . 경찰 ##은 12월 18일 ~ 20일 사이 서울 경희대 ##학교 ##에서 임종 ##석 ##이 성명 발표 ##를 추진 ##하고 있다는 첩보 ##를 입수 ##했고 , 12월 18일 오전 7 ##시 40 ##분 경 가스 [SEP]\n",
      "2022-03-15 16:54:57,810 - qnadataset - INFO - answer: 임수 ##경\n",
      "2022-03-15 16:54:57,811 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 76485, 17253, 40636, 121340, 70122, 68767, 119597, 11261, 120811, 9099, 119664, 10892, 136, 102, 76485, 17520, 37912, 127473, 122083, 121735, 120889, 11513, 120495, 11102, 121207, 113, 121735, 125686, 101322, 60469, 68773, 10530, 20595, 11102, 33768, 88350, 19855, 30134, 114, 29805, 120160, 15891, 76036, 13628, 119, 76485, 15361, 46026, 48253, 12508, 42337, 118625, 137233, 129249, 58904, 130960, 40958, 10459, 120455, 17196, 43962, 30858, 35963, 140525, 118965, 27303, 119, 18589, 9960, 17253, 40636, 121340, 70122, 68767, 135306, 31720, 10622, 119597, 11261, 120811, 13374, 93222, 30005, 34951, 33768, 19855, 30134, 121207, 11287, 119720, 13628, 119, 119772, 10892, 16367, 45972, 198, 41518, 119580, 48253, 127764, 46599, 11489, 130960, 40958, 10739, 122767, 119696, 11513, 120363, 12453, 77324, 132685, 11513, 128273, 38181, 117, 16367, 45972, 121408, 128, 14040, 10533, 37712, 8885, 121206, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=75, end_positions=76)\n",
      "2022-03-15 16:54:57,812 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:57,813 - qnadataset - INFO - question & context: [CLS] 1989년 6월 30일 평양 ##축 ##전에 대표 ##로 파견 된 인물 ##은 ? [SEP] ##로 파견 ##하여 국가 ##보 ##안 ##법 ##위 ##반 혐의 ##가 추가 ##되었다 . 경찰 ##은 12월 18일 ~ 20일 사이 서울 경희대 ##학교 ##에서 임종 ##석 ##이 성명 발표 ##를 추진 ##하고 있다는 첩보 ##를 입수 ##했고 , 12월 18일 오전 7 ##시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특공 ##조 및 대공 ##과 직원 12 ##명 등 22 ##명의 사복 경찰 ##을 승용차 8 ##대에 나누 ##어 경희대 ##학교 ##에 투입 ##했다 . 1989년 12월 18일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경희대 ##학교 학생회 ##관 건물 계단 ##을 내려오 ##는 임종 ##석 [SEP]\n",
      "2022-03-15 16:54:57,814 - qnadataset - INFO - answer: [CLS]\n",
      "2022-03-15 16:54:57,815 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 76485, 17253, 40636, 121340, 70122, 68767, 119597, 11261, 120811, 9099, 119664, 10892, 136, 102, 11261, 120811, 13374, 93222, 30005, 34951, 33768, 19855, 30134, 121207, 11287, 119720, 13628, 119, 119772, 10892, 16367, 45972, 198, 41518, 119580, 48253, 127764, 46599, 11489, 130960, 40958, 10739, 122767, 119696, 11513, 120363, 12453, 77324, 132685, 11513, 128273, 38181, 117, 16367, 45972, 121408, 128, 14040, 10533, 37712, 8885, 121206, 119270, 11882, 119970, 118989, 11467, 120937, 11102, 128019, 20626, 9316, 122739, 11882, 120801, 10186, 16758, 9121, 10306, 45441, 140897, 119772, 10622, 132797, 129, 81980, 121118, 12965, 127764, 46599, 10530, 121627, 12490, 119, 76485, 16367, 45972, 121408, 129, 14040, 10208, 37712, 8885, 48253, 40311, 44321, 12692, 132021, 37321, 125967, 119843, 126, 16758, 11882, 19653, 127764, 46599, 129899, 20595, 120007, 125235, 10622, 128359, 11018, 130960, 40958, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n",
      "2022-03-15 16:54:57,816 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:57,817 - qnadataset - INFO - question & context: [CLS] 1989년 6월 30일 평양 ##축 ##전에 대표 ##로 파견 된 인물 ##은 ? [SEP] 22 ##명의 사복 경찰 ##을 승용차 8 ##대에 나누 ##어 경희대 ##학교 ##에 투입 ##했다 . 1989년 12월 18일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경희대 ##학교 학생회 ##관 건물 계단 ##을 내려오 ##는 임종 ##석 ##을 발견 , 검거 ##해 구속 ##을 집행 ##했다 . 임종 ##석 ##은 청량리 ##경찰 ##서 ##에서 약 1 ##시간 동안 조사 ##를 받은 뒤 오전 9 ##시 50 ##분 경 서울 장안 ##동 ##의 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실 ##로 인계 ##되었다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "2022-03-15 16:54:57,818 - qnadataset - INFO - answer: [CLS]\n",
      "2022-03-15 16:54:57,819 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 76485, 17253, 40636, 121340, 70122, 68767, 119597, 11261, 120811, 9099, 119664, 10892, 136, 102, 10306, 45441, 140897, 119772, 10622, 132797, 129, 81980, 121118, 12965, 127764, 46599, 10530, 121627, 12490, 119, 76485, 16367, 45972, 121408, 129, 14040, 10208, 37712, 8885, 48253, 40311, 44321, 12692, 132021, 37321, 125967, 119843, 126, 16758, 11882, 19653, 127764, 46599, 129899, 20595, 120007, 125235, 10622, 128359, 11018, 130960, 40958, 10622, 119729, 117, 129189, 14523, 121675, 10622, 121158, 12490, 119, 130960, 40958, 10892, 134328, 132021, 12424, 11489, 9539, 122, 100699, 41886, 119781, 11513, 74141, 9109, 121408, 130, 14040, 10462, 37712, 8885, 48253, 126157, 18778, 10459, 48253, 12508, 42337, 132021, 40311, 129249, 37712, 31503, 11261, 135140, 13628, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=0, end_positions=0)\n",
      "2022-03-15 16:54:57,820 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:57,821 - qnadataset - INFO - question & context: [CLS] 임종 ##석 ##을 검거 ##한 장소 ##는 경희대 내 어디 ##인 ##가 ? [SEP] 1989년 2월 15일 여의도 농민 폭력 시위 ##를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처 ##벌 ##에 ##관 ##한 ##법 ##률 ##위 ##반 ) 으로 지명 ##수 ##배 ##되었다 . 1989년 3월 12일 서울 ##지 ##방 ##검 ##찰청 공안 ##부는 임종 ##석 ##의 사전 ##구 ##속 ##영 ##장을 발부 ##받 ##았다 . 같은 해 6월 30일 평양 ##축 ##전에 임수 ##경 ##을 대표 ##로 파견 ##하여 국가 ##보 ##안 ##법 ##위 ##반 혐의 ##가 추가 ##되었다 . 경찰 ##은 12월 18일 ~ 20일 사이 서울 경희대 ##학교 ##에서 임종 ##석 ##이 성명 발표 ##를 추진 ##하고 있다는 첩보 ##를 입수 ##했고 , 12월 18일 오전 7 ##시 40 ##분 경 가스 [SEP]\n",
      "2022-03-15 16:54:57,822 - qnadataset - INFO - answer: [CLS]\n",
      "2022-03-15 16:54:57,823 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 130960, 40958, 10622, 129189, 11102, 120319, 11018, 127764, 8996, 121328, 12030, 11287, 136, 102, 76485, 17520, 37912, 127473, 122083, 121735, 120889, 11513, 120495, 11102, 121207, 113, 121735, 125686, 101322, 60469, 68773, 10530, 20595, 11102, 33768, 88350, 19855, 30134, 114, 29805, 120160, 15891, 76036, 13628, 119, 76485, 15361, 46026, 48253, 12508, 42337, 118625, 137233, 129249, 58904, 130960, 40958, 10459, 120455, 17196, 43962, 30858, 35963, 140525, 118965, 27303, 119, 18589, 9960, 17253, 40636, 121340, 70122, 68767, 135306, 31720, 10622, 119597, 11261, 120811, 13374, 93222, 30005, 34951, 33768, 19855, 30134, 121207, 11287, 119720, 13628, 119, 119772, 10892, 16367, 45972, 198, 41518, 119580, 48253, 127764, 46599, 11489, 130960, 40958, 10739, 122767, 119696, 11513, 120363, 12453, 77324, 132685, 11513, 128273, 38181, 117, 16367, 45972, 121408, 128, 14040, 10533, 37712, 8885, 121206, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n",
      "2022-03-15 16:54:57,824 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:57,825 - qnadataset - INFO - question & context: [CLS] 임종 ##석 ##을 검거 ##한 장소 ##는 경희대 내 어디 ##인 ##가 ? [SEP] ##로 파견 ##하여 국가 ##보 ##안 ##법 ##위 ##반 혐의 ##가 추가 ##되었다 . 경찰 ##은 12월 18일 ~ 20일 사이 서울 경희대 ##학교 ##에서 임종 ##석 ##이 성명 발표 ##를 추진 ##하고 있다는 첩보 ##를 입수 ##했고 , 12월 18일 오전 7 ##시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특공 ##조 및 대공 ##과 직원 12 ##명 등 22 ##명의 사복 경찰 ##을 승용차 8 ##대에 나누 ##어 경희대 ##학교 ##에 투입 ##했다 . 1989년 12월 18일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경희대 ##학교 학생회 ##관 건물 계단 ##을 내려오 ##는 임종 ##석 [SEP]\n",
      "2022-03-15 16:54:57,826 - qnadataset - INFO - answer: 학생회 ##관 건물 계단\n",
      "2022-03-15 16:54:57,827 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 130960, 40958, 10622, 129189, 11102, 120319, 11018, 127764, 8996, 121328, 12030, 11287, 136, 102, 11261, 120811, 13374, 93222, 30005, 34951, 33768, 19855, 30134, 121207, 11287, 119720, 13628, 119, 119772, 10892, 16367, 45972, 198, 41518, 119580, 48253, 127764, 46599, 11489, 130960, 40958, 10739, 122767, 119696, 11513, 120363, 12453, 77324, 132685, 11513, 128273, 38181, 117, 16367, 45972, 121408, 128, 14040, 10533, 37712, 8885, 121206, 119270, 11882, 119970, 118989, 11467, 120937, 11102, 128019, 20626, 9316, 122739, 11882, 120801, 10186, 16758, 9121, 10306, 45441, 140897, 119772, 10622, 132797, 129, 81980, 121118, 12965, 127764, 46599, 10530, 121627, 12490, 119, 76485, 16367, 45972, 121408, 129, 14040, 10208, 37712, 8885, 48253, 40311, 44321, 12692, 132021, 37321, 125967, 119843, 126, 16758, 11882, 19653, 127764, 46599, 129899, 20595, 120007, 125235, 10622, 128359, 11018, 130960, 40958, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=118, end_positions=121)\n",
      "2022-03-15 16:54:57,828 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:57,829 - qnadataset - INFO - question & context: [CLS] 임종 ##석 ##을 검거 ##한 장소 ##는 경희대 내 어디 ##인 ##가 ? [SEP] 22 ##명의 사복 경찰 ##을 승용차 8 ##대에 나누 ##어 경희대 ##학교 ##에 투입 ##했다 . 1989년 12월 18일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경희대 ##학교 학생회 ##관 건물 계단 ##을 내려오 ##는 임종 ##석 ##을 발견 , 검거 ##해 구속 ##을 집행 ##했다 . 임종 ##석 ##은 청량리 ##경찰 ##서 ##에서 약 1 ##시간 동안 조사 ##를 받은 뒤 오전 9 ##시 50 ##분 경 서울 장안 ##동 ##의 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실 ##로 인계 ##되었다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "2022-03-15 16:54:57,830 - qnadataset - INFO - answer: 학생회 ##관 건물 계단\n",
      "2022-03-15 16:54:57,831 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 130960, 40958, 10622, 129189, 11102, 120319, 11018, 127764, 8996, 121328, 12030, 11287, 136, 102, 10306, 45441, 140897, 119772, 10622, 132797, 129, 81980, 121118, 12965, 127764, 46599, 10530, 121627, 12490, 119, 76485, 16367, 45972, 121408, 129, 14040, 10208, 37712, 8885, 48253, 40311, 44321, 12692, 132021, 37321, 125967, 119843, 126, 16758, 11882, 19653, 127764, 46599, 129899, 20595, 120007, 125235, 10622, 128359, 11018, 130960, 40958, 10622, 119729, 117, 129189, 14523, 121675, 10622, 121158, 12490, 119, 130960, 40958, 10892, 134328, 132021, 12424, 11489, 9539, 122, 100699, 41886, 119781, 11513, 74141, 9109, 121408, 130, 14040, 10462, 37712, 8885, 48253, 126157, 18778, 10459, 48253, 12508, 42337, 132021, 40311, 129249, 37712, 31503, 11261, 135140, 13628, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=54, end_positions=57)\n",
      "2022-03-15 16:54:57,832 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:57,833 - qnadataset - INFO - question & context: [CLS] 임종 ##석 ##이 조사 ##를 받은 뒤 인계 ##된 곳 ##은 어딘가 ? [SEP] 1989년 2월 15일 여의도 농민 폭력 시위 ##를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처 ##벌 ##에 ##관 ##한 ##법 ##률 ##위 ##반 ) 으로 지명 ##수 ##배 ##되었다 . 1989년 3월 12일 서울 ##지 ##방 ##검 ##찰청 공안 ##부는 임종 ##석 ##의 사전 ##구 ##속 ##영 ##장을 발부 ##받 ##았다 . 같은 해 6월 30일 평양 ##축 ##전에 임수 ##경 ##을 대표 ##로 파견 ##하여 국가 ##보 ##안 ##법 ##위 ##반 혐의 ##가 추가 ##되었다 . 경찰 ##은 12월 18일 ~ 20일 사이 서울 경희대 ##학교 ##에서 임종 ##석 ##이 성명 발표 ##를 추진 ##하고 있다는 첩보 ##를 입수 ##했고 , 12월 18일 오전 7 ##시 40 ##분 경 가스 [SEP]\n",
      "2022-03-15 16:54:57,834 - qnadataset - INFO - answer: [CLS]\n",
      "2022-03-15 16:54:57,834 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 130960, 40958, 10739, 119781, 11513, 74141, 9109, 135140, 13441, 8895, 10892, 135834, 136, 102, 76485, 17520, 37912, 127473, 122083, 121735, 120889, 11513, 120495, 11102, 121207, 113, 121735, 125686, 101322, 60469, 68773, 10530, 20595, 11102, 33768, 88350, 19855, 30134, 114, 29805, 120160, 15891, 76036, 13628, 119, 76485, 15361, 46026, 48253, 12508, 42337, 118625, 137233, 129249, 58904, 130960, 40958, 10459, 120455, 17196, 43962, 30858, 35963, 140525, 118965, 27303, 119, 18589, 9960, 17253, 40636, 121340, 70122, 68767, 135306, 31720, 10622, 119597, 11261, 120811, 13374, 93222, 30005, 34951, 33768, 19855, 30134, 121207, 11287, 119720, 13628, 119, 119772, 10892, 16367, 45972, 198, 41518, 119580, 48253, 127764, 46599, 11489, 130960, 40958, 10739, 122767, 119696, 11513, 120363, 12453, 77324, 132685, 11513, 128273, 38181, 117, 16367, 45972, 121408, 128, 14040, 10533, 37712, 8885, 121206, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n",
      "2022-03-15 16:54:57,835 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:57,836 - qnadataset - INFO - question & context: [CLS] 임종 ##석 ##이 조사 ##를 받은 뒤 인계 ##된 곳 ##은 어딘가 ? [SEP] ##로 파견 ##하여 국가 ##보 ##안 ##법 ##위 ##반 혐의 ##가 추가 ##되었다 . 경찰 ##은 12월 18일 ~ 20일 사이 서울 경희대 ##학교 ##에서 임종 ##석 ##이 성명 발표 ##를 추진 ##하고 있다는 첩보 ##를 입수 ##했고 , 12월 18일 오전 7 ##시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특공 ##조 및 대공 ##과 직원 12 ##명 등 22 ##명의 사복 경찰 ##을 승용차 8 ##대에 나누 ##어 경희대 ##학교 ##에 투입 ##했다 . 1989년 12월 18일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경희대 ##학교 학생회 ##관 건물 계단 ##을 내려오 ##는 임종 ##석 [SEP]\n",
      "2022-03-15 16:54:57,837 - qnadataset - INFO - answer: [CLS]\n",
      "2022-03-15 16:54:57,838 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 130960, 40958, 10739, 119781, 11513, 74141, 9109, 135140, 13441, 8895, 10892, 135834, 136, 102, 11261, 120811, 13374, 93222, 30005, 34951, 33768, 19855, 30134, 121207, 11287, 119720, 13628, 119, 119772, 10892, 16367, 45972, 198, 41518, 119580, 48253, 127764, 46599, 11489, 130960, 40958, 10739, 122767, 119696, 11513, 120363, 12453, 77324, 132685, 11513, 128273, 38181, 117, 16367, 45972, 121408, 128, 14040, 10533, 37712, 8885, 121206, 119270, 11882, 119970, 118989, 11467, 120937, 11102, 128019, 20626, 9316, 122739, 11882, 120801, 10186, 16758, 9121, 10306, 45441, 140897, 119772, 10622, 132797, 129, 81980, 121118, 12965, 127764, 46599, 10530, 121627, 12490, 119, 76485, 16367, 45972, 121408, 129, 14040, 10208, 37712, 8885, 48253, 40311, 44321, 12692, 132021, 37321, 125967, 119843, 126, 16758, 11882, 19653, 127764, 46599, 129899, 20595, 120007, 125235, 10622, 128359, 11018, 130960, 40958, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n",
      "2022-03-15 16:54:57,839 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:57,839 - qnadataset - INFO - question & context: [CLS] 임종 ##석 ##이 조사 ##를 받은 뒤 인계 ##된 곳 ##은 어딘가 ? [SEP] 22 ##명의 사복 경찰 ##을 승용차 8 ##대에 나누 ##어 경희대 ##학교 ##에 투입 ##했다 . 1989년 12월 18일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경희대 ##학교 학생회 ##관 건물 계단 ##을 내려오 ##는 임종 ##석 ##을 발견 , 검거 ##해 구속 ##을 집행 ##했다 . 임종 ##석 ##은 청량리 ##경찰 ##서 ##에서 약 1 ##시간 동안 조사 ##를 받은 뒤 오전 9 ##시 50 ##분 경 서울 장안 ##동 ##의 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실 ##로 인계 ##되었다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "2022-03-15 16:54:57,840 - qnadataset - INFO - answer: 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실\n",
      "2022-03-15 16:54:57,841 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 130960, 40958, 10739, 119781, 11513, 74141, 9109, 135140, 13441, 8895, 10892, 135834, 136, 102, 10306, 45441, 140897, 119772, 10622, 132797, 129, 81980, 121118, 12965, 127764, 46599, 10530, 121627, 12490, 119, 76485, 16367, 45972, 121408, 129, 14040, 10208, 37712, 8885, 48253, 40311, 44321, 12692, 132021, 37321, 125967, 119843, 126, 16758, 11882, 19653, 127764, 46599, 129899, 20595, 120007, 125235, 10622, 128359, 11018, 130960, 40958, 10622, 119729, 117, 129189, 14523, 121675, 10622, 121158, 12490, 119, 130960, 40958, 10892, 134328, 132021, 12424, 11489, 9539, 122, 100699, 41886, 119781, 11513, 74141, 9109, 121408, 130, 14040, 10462, 37712, 8885, 48253, 126157, 18778, 10459, 48253, 12508, 42337, 132021, 40311, 129249, 37712, 31503, 11261, 135140, 13628, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=98, end_positions=105)\n",
      "2022-03-15 16:54:57,842 - qnadataset - INFO - *** Example ***\n",
      "2022-03-15 16:54:57,843 - qnadataset - INFO - question & context: [CLS] 1989년 2월 15일 여의도 농민 폭력 시위 ##를 주도 ##한 혐의 ##로 지명 ##수 ##배 ##된 사람 ##의 이름은 ? [SEP] 1989년 2월 15일 여의도 농민 폭력 시위 ##를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처 ##벌 ##에 ##관 ##한 ##법 ##률 ##위 ##반 ) 으로 지명 ##수 ##배 ##되었다 . 1989년 3월 12일 서울 ##지 ##방 ##검 ##찰청 공안 ##부는 임종 ##석 ##의 사전 ##구 ##속 ##영 ##장을 발부 ##받 ##았다 . 같은 해 6월 30일 평양 ##축 ##전에 임수 ##경 ##을 대표 ##로 파견 ##하여 국가 ##보 ##안 ##법 ##위 ##반 혐의 ##가 추가 ##되었다 . 경찰 ##은 12월 18일 ~ 20일 사이 서울 경희대 ##학교 ##에서 임종 ##석 ##이 성명 발표 ##를 추진 ##하고 있다는 첩보 ##를 입수 ##했고 , 12월 18일 [SEP]\n",
      "2022-03-15 16:54:57,843 - qnadataset - INFO - answer: 임종 ##석\n",
      "2022-03-15 16:54:57,844 - qnadataset - INFO - features: QAFeatures(input_ids=[101, 76485, 17520, 37912, 127473, 122083, 121735, 120889, 11513, 120495, 11102, 121207, 11261, 120160, 15891, 76036, 13441, 119578, 10459, 78199, 136, 102, 76485, 17520, 37912, 127473, 122083, 121735, 120889, 11513, 120495, 11102, 121207, 113, 121735, 125686, 101322, 60469, 68773, 10530, 20595, 11102, 33768, 88350, 19855, 30134, 114, 29805, 120160, 15891, 76036, 13628, 119, 76485, 15361, 46026, 48253, 12508, 42337, 118625, 137233, 129249, 58904, 130960, 40958, 10459, 120455, 17196, 43962, 30858, 35963, 140525, 118965, 27303, 119, 18589, 9960, 17253, 40636, 121340, 70122, 68767, 135306, 31720, 10622, 119597, 11261, 120811, 13374, 93222, 30005, 34951, 33768, 19855, 30134, 121207, 11287, 119720, 13628, 119, 119772, 10892, 16367, 45972, 198, 41518, 119580, 48253, 127764, 46599, 11489, 130960, 40958, 10739, 122767, 119696, 11513, 120363, 12453, 77324, 132685, 11513, 128273, 38181, 117, 16367, 45972, 102], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=63, end_positions=64)\n",
      "2022-03-15 16:54:57,846 - qnadataset - INFO - Saving features into cached file, it could take a lot of time...\n",
      "2022-03-15 16:54:59,470 - qnadataset - INFO - Saving features into cached file ../korpora/korQuAD/cached_DistilBertTokenizer_128_32_64_KorQuAD_v1.0_dev.json [took 1.624 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end eval_loader===========================================================\n",
      "train_loader_len: 653, eval_loader_len: 653\n"
     ]
    }
   ],
   "source": [
    "# 학습 data loader 생성\n",
    "sys.path.append('..')\n",
    "from myutils import KorQuADCorpus, QADataset, data_collator\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "#############################################################################\n",
    "# 변수 설정\n",
    "#############################################################################\n",
    "max_seq_len = 128   # 질문 + 지문 최대 크기\n",
    "max_query_length = 32  # 질문 최대 크기\n",
    "doc_stride = 64     # 지문이 128을 넘을 경우, 얼만큼씩 다음 지문으로 대체할지\n",
    "\n",
    "batch_size = 32        # 배치 사이즈(64면 GUP Memory 오류 나므로, 32 이하로 설정할것=>max_seq_length 를 줄이면, 64도 가능함)\n",
    "cache = True   # 캐쉬파일 생성할거면 True로 \n",
    "#############################################################################\n",
    "\n",
    "# corpus 파일 설정\n",
    "corpus = KorQuADCorpus()\n",
    "\n",
    "\n",
    "# 학습 dataset 생성\n",
    "print('create train_loader===========================================================')\n",
    "train_file_fpath = '../korpora/korQuAD/KorQuAD_v1.0_train.json'\n",
    "train_dataset = QADataset(file_fpath=train_file_fpath, tokenizer=tokenizer, corpus=corpus, max_seq_length=max_seq_len, max_query_length = max_query_length, doc_stride= doc_stride, overwrite_cache=cache)\n",
    "\n",
    "\n",
    "# 학습 dataloader 생성\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          #shuffle=True, # dataset을 섞음\n",
    "                          sampler=RandomSampler(dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                          collate_fn=data_collator, # dataset을 tensor로 변환(예시 {'input_ids':tensor[0,1,2,3,1,], 'token_type_id:tensor[0,0,0,0,0], 'attention_mask:tensor[1,1,1,1,1], 'labels':tensor[5]}\n",
    "                          num_workers=4)\n",
    "\n",
    "print('end train_loader===========================================================')\n",
    "\n",
    "print('create eval_loader===========================================================')\n",
    "eval_file_fpath = '../korpora/korQuAD/KorQuAD_v1.0_dev.json'\n",
    "eval_dataset = QADataset(file_fpath=eval_file_fpath, tokenizer=tokenizer, corpus=corpus, max_seq_length=max_seq_len, max_query_length = max_query_length, doc_stride= doc_stride, overwrite_cache=cache)\n",
    "\n",
    "\n",
    "# 평가 dataloader 생성\n",
    "eval_loader = DataLoader(eval_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          #shuffle=True, # dataset을 섞음\n",
    "                          sampler=RandomSampler(dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                          collate_fn=data_collator, # dataset을 tensor로 변환(예시 {'input_ids':tensor[0,1,2,3,1,], 'token_type_id:tensor[0,0,0,0,0], 'attention_mask:tensor[1,1,1,1,1], 'labels':tensor[5]}\n",
    "                          num_workers=4)\n",
    "print('end eval_loader===========================================================')\n",
    "\n",
    "print('train_loader_len: {}, eval_loader_len: {}'.format(len(train_loader), len(eval_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fec919e-d8b7-4b20-a20b-28cf66a49a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143772\n",
      "[101, 9034, 10530, 119728, 11018, 128441, 10739, 69708, 42428, 10459, 10020, 12030, 28143, 10892, 124227, 12508, 49137, 102, 122108, 131027, 11903, 102]\n",
      "재미있\n",
      "122108\n"
     ]
    }
   ],
   "source": [
    "# tokenier 테스트\n",
    "print(len(tokenizer))\n",
    "print(tokenizer.encode(\"눈에 보이는 반전이었지만 영화의 흡인력은 사라지지 않았다\", \"정말 재미있다\"))\n",
    "print(tokenizer.convert_ids_to_tokens(131027))\n",
    "print(tokenizer.convert_tokens_to_ids('정말'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2068553-5650-47a4-bdd6-c9e79e1580cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_steps:6530, warmup_steps: 653.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062a3a0d9aa5470795cd5c4b71e085f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c8b4b80b7440a99bf35e1ece0558b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/653 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24487/2090246669.py:78: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  start_pred = torch.argmax(F.softmax(start_scores), dim=1)\n",
      "/tmp/ipykernel_24487/2090246669.py:82: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  end_pred = torch.argmax(F.softmax(end_scores), dim=1)\n",
      "2022-03-15 17:57:33,590 - bertQAtrain - INFO - [Epoch 1/10] Iteration 200 -> Train Loss: 3.3384, Train Accuracy: 0.542\n",
      "2022-03-15 17:57:49,247 - bertQAtrain - INFO - [Epoch 1/10] Iteration 400 -> Train Loss: 1.8241, Train Accuracy: 0.613\n",
      "2022-03-15 17:58:04,899 - bertQAtrain - INFO - [Epoch 1/10] Iteration 600 -> Train Loss: 1.2214, Train Accuracy: 0.650\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab46af085b644608b04d51de4a23263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/653 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24487/2090246669.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mstart_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_positions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mend_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_positions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'labels'"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "\n",
    "##################################################\n",
    "# 변수 설정\n",
    "##################################################\n",
    "epochs = 10            # epochs\n",
    "learning_rate = 2e-5  # 학습률\n",
    "p_itr = 200           # 손실률 보여줄 step 수\n",
    "##################################################\n",
    "\n",
    "# optimizer 적용\n",
    "optimizer = AdamW(model.parameters(), \n",
    "                 lr=learning_rate, \n",
    "                 eps=1e-8) # 0으로 나누는 것을 방지하기 위한 epsilon 값(10^-6 ~ 10^-8 사이 이값 입력합)\n",
    "\n",
    "# 총 훈련과정에서 반복할 스탭\n",
    "total_steps = len(train_loader)*epochs\n",
    "\n",
    "warmup_steps = total_steps * 0.1 #10% of train data for warm-up\n",
    "\n",
    "print(f'total_steps:{total_steps}, warmup_steps: {warmup_steps}')\n",
    "\n",
    "# 스캐줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=warmup_steps, \n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "itr = 1\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "list_training_loss = []\n",
    "list_acc_loss = []\n",
    "list_validation_acc_loss = []\n",
    "\n",
    "\n",
    "model.zero_grad()# 그래디언트 초기화\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    count1 = 0\n",
    "    model.train() # 훈련모드로 변환\n",
    "    for data in tqdm(train_loader):\n",
    "    \n",
    "        #optimizer.zero_grad()\n",
    "        model.zero_grad()# 그래디언트 초기화\n",
    "        \n",
    "        # 입력 값 설정\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        #token_type_ids = data['token_type_ids'].to(device)  # distilbert에는 token_type_id가 없음\n",
    "        start_positions = data['start_positions'].to(device)\n",
    "        end_positions = data['end_positions'].to(device)\n",
    "        \n",
    "        # 모델 실행\n",
    "        outputs = model(input_ids=input_ids, \n",
    "                        attention_mask=attention_mask,\n",
    "                        #token_type_id=token_type_id,      # distilbert에는 token_type_id가 없음\n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "        \n",
    "        # 출력값 loss,logits를 outputs에서 얻어옴\n",
    "        loss = outputs.loss\n",
    "        start_scores = outputs.start_logits\n",
    "        end_scores = outputs.end_logits\n",
    "        \n",
    "        # optimizer 과 scheduler 업데이트 시킴\n",
    "        loss.backward()   # backward 구함\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)   # 그래디언트 클리핑 (gradient vanishing이나 gradient exploding 방지하기 위한 기법)\n",
    "        optimizer.step()  # 가중치 파라미터 업데이트(optimizer 이동)\n",
    "        scheduler.step()  # 학습률 감소\n",
    "        \n",
    "        # 정확도와 손실률 계산하는 부분은 no_grade 시켜서, 계산량을 줄임.\n",
    "        # => torch.no_grad()는 gradient을 계산하는 autograd engine를 비활성화 하여 \n",
    "        # 필요한 메모리를 줄이고, 연산속도를 증가시키는 역활을 함\n",
    "        with torch.no_grad():\n",
    "           \n",
    "            # 정확도와 총 손실률 계산\n",
    "            \n",
    "            # start 포지션 정확도 구함\n",
    "            # argmax = 최대 인덱스값 리턴함\n",
    "            start_pred = torch.argmax(F.softmax(start_scores), dim=1)\n",
    "            start_correct = start_pred.eq(start_positions)\n",
    "            \n",
    "            # end 포지션 정확도 구함\n",
    "            end_pred = torch.argmax(F.softmax(end_scores), dim=1)\n",
    "            end_correct = start_pred.eq(end_positions)\n",
    "            \n",
    "            # start 포지션과 end 포지션 정확도를 더하고 2로 나줌\n",
    "            total_correct += (start_correct.sum().item() + end_correct.sum().item()) / 2\n",
    "                \n",
    "            total_len += len(start_positions)    \n",
    "            total_loss += loss.item()\n",
    "            #print('pred:{}, correct:{}'.format(pred, correct))\n",
    "\n",
    "            # 주기마다 test(validataion) 데이터로 평가하여 손실류 계산함.\n",
    "            if itr % p_itr == 0:\n",
    "\n",
    "                logger.info('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Train Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
    "\n",
    "                list_training_loss.append(total_loss/p_itr)\n",
    "                list_acc_loss.append(total_correct/total_len)\n",
    "\n",
    "                total_loss = 0\n",
    "                total_len = 0\n",
    "                total_correct = 0\n",
    "\n",
    "        itr+=1\n",
    "        \n",
    "        #if itr > 5:\n",
    "        #    break\n",
    "\n",
    "    ####################################################################\n",
    "    # 1epochs 마다 실제 test(validattion)데이터로 평가 해봄\n",
    "    # 평가 시작\n",
    "    model.eval()\n",
    "    \n",
    "    total_test_correct = 0\n",
    "    total_test_len = 0\n",
    "    \n",
    "    for data in tqdm(eval_loader):\n",
    "        # 입력 값 설정\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        #token_type_ids = data['token_type_ids'].to(device)  \n",
    "        start_positions = data['start_positions'].to(device)\n",
    "        end_positions = data['end_positions'].to(device)\n",
    "    \n",
    "        # 손실률 계산하는 부분은 no_grade 시켜서, 계산량을 줄임.\n",
    "        # => torch.no_grad()는 gradient을 계산하는 autograd engine를 비활성화 하여 \n",
    "        # 필요한 메모리를 줄이고, 연산속도를 증가시키는 역활을 함\n",
    "        with torch.no_grad():\n",
    "            # 모델 실행\n",
    "            outputs = model(input_ids=input_ids, \n",
    "                            attention_mask=attention_mask,\n",
    "                            #token_type_id=token_type_id,      # distilbert에는 token_type_id가 없음\n",
    "                            start_positions=start_positions,\n",
    "                            end_positions=end_positions)\n",
    "    \n",
    "            # 출력값 loss,logits를 outputs에서 얻어옴\n",
    "            loss = outputs.loss\n",
    "            start_scores = outputs.start_logits\n",
    "            end_scores = outputs.end_logits\n",
    "    \n",
    "            # 총 손실류 구함\n",
    "            # start 포지션 정확도 구함\n",
    "            start_pred = torch.argmax(F.softmax(start_scores), dim=1)\n",
    "            start_correct = start_pred.eq(start_positions)\n",
    "            \n",
    "            # end 포지션 정확도 구함\n",
    "            end_pred = torch.argmax(F.softmax(end_scores), dim=1)\n",
    "            end_correct = start_pred.eq(end_positions)\n",
    "            \n",
    "            # start 포지션과 end 포지션 정확도를 더하고 2로 나줌\n",
    "            total_test_correct += (start_correct.sum().item() + end_correct.sum().item()) / 2\n",
    "            total_test_len += len(start_positions)\n",
    "    \n",
    "    list_validation_acc_loss.append(total_test_correct/total_test_len)\n",
    "    logger.info(\"[Epoch {}/{}] Validatation Accuracy:{}\".format(epoch+1, epochs, total_test_correct / total_test_len))\n",
    "    \n",
    "    ####################################################################\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e56cc12-2914-4fea-a6c9-15bec647112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프로 loss 표기\n",
    "#!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_training_loss, label='Train Loss')\n",
    "plt.plot(list_acc_loss, label='Train Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86681fcb-84e3-428c-82ea-fb08f5ea4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loss와 Validatiaon acc 출력\n",
    "plt.plot(list_training_loss, label='Train Loss')\n",
    "plt.plot(list_validation_acc_loss, label='Validatiaon Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e2215-3eda-471e-be76-bace043b0770",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 전체모델 저장\n",
    "os.makedirs(OUTPATH)\n",
    "#torch.save(model, OUTPATH + 'pytorch_model.bin') \n",
    "model.save_pretrained(OUTPATH)  # save_pretrained 로 저장하면 config.json, pytorch_model.bin 2개의 파일이 생성됨\n",
    "\n",
    "# tokeinizer 파일 저장(vocab)\n",
    "VOCAB_PATH = OUTPATH\n",
    "os.makedirs(VOCAB_PATH)\n",
    "tokenizer.save_pretrained(VOCAB_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
