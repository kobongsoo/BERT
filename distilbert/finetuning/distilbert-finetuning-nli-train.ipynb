{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159bc54e-0c70-4cc7-b3ff-cb2b3683cbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:../../../log/distilbertftmultitrain_2022-10-27.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "# NLI(Natural Language Interference:자연어 추론) 훈련 예제\n",
    "#\n",
    "# => input_ids : [CLS]senetence1(전제)[SEP]sentence2(가설)\n",
    "# => attention_mask : 1111111111(전체,가설)0000000(그외)\n",
    "# => token_type_ids : 0000000(전제)1111111(가설)00000000(그외)\n",
    "# => laels : 참(수반:entailment), 거짓(모순:contradiction), 모름(중립:neutral)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, DistilBertConfig, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from myutils import seed_everything, GPU_info, mlogging\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "logger = mlogging(loggername=\"distilbertfttrain\", logfilename=\"../../../log/distilbertftmultitrain\")\n",
    "device = GPU_info()\n",
    "# Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731f6745-a2f4-4b2d-9a19-1fa2efa6f3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at jinmang2/kpfbert and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(36440, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################################\n",
    "# 변수들 설정\n",
    "# - model_path : from_pretrained() 로 호출하는 경우에는 모델파일이 있는 폴더 경로나 \n",
    "#          huggingface에 등록된 모델명(예:'bert-base-multilingual-cased')\n",
    "#          torch.load(model)로 로딩하는 경우에는 모델 파일 풀 경로\n",
    "#\n",
    "# - vocab_path : from_pretrained() 호출하는 경우에는 모델파일이 있는 폴더 경로나\n",
    "#          huggingface에 등록된 모델명(예:'bert-base-multilingual-cased')   \n",
    "#          BertTokenizer() 로 호출하는 경우에는 vocab.txt 파일 풀 경로,\n",
    "#\n",
    "# - OUTPATH : 출력 모델, vocab 저장할 폴더 경로\n",
    "#############################################################################################\n",
    "\n",
    "##################################################\n",
    "# 변수 설정\n",
    "##################################################\n",
    "seed = 111\n",
    "epochs = 3            # epochs\n",
    "lr = 3e-5  # 학습률\n",
    "eps = 1e-8\n",
    "max_seq_len = 72     # 글자 최대 토큰 길이 해당 토큰 길이 이상은 잘린다.\n",
    "train_batch_size = 32      # 배치 사이즈(64면 GUP Memory 오류 나므로, 32 이하로 설정할것=>max_seq_length 를 줄이면, 64도 가능함)\n",
    "eval_batch_size = 64\n",
    "##################################################\n",
    "\n",
    "seed_everything(seed) # seed 설정\n",
    "\n",
    "cache = True   # 캐쉬파일 생성할거면 True로 (True이면 loding할때 캐쉬파일있어도 이용안함)\n",
    "\n",
    "use_kornli = 1     #  kornli 파일\n",
    "use_kluenli = 1    # kluests_v1.1 파일\n",
    "use_gluenli = 1    # glue 파일\n",
    "\n",
    "kor_train_file_fpath = '../../../data11/korpora/kornli/snli_1.0_train.ko.tsv'\n",
    "kor_eval_file_fpath = '../../../data11/korpora/kornli/xnli.dev.ko.tsv'\n",
    "\n",
    "klue_train_file_fpath = '../../../data11/korpora/klue-nli/klue-nli-v1.1_train.json'\n",
    "klue_eval_file_fpath = '../../../data11/korpora/klue-nli/klue-nli-v1.1_dev.json'\n",
    "\n",
    "glue_train_file_fpath = '../../../data11/korpora/gluemnli/glue-mnli-train.tsv'\n",
    "glue_eval_file_fpath = '../../../data11/korpora/gluemnli/glue-mnli-valid.tsv'\n",
    "\n",
    "\n",
    "# model 타입 : 0=distilbert, 1=bert, 2=Roberta\n",
    "#=>Roberta 모델에는 distilbert처럼 token_type_id 입력 없음.\n",
    "model_type = 1\n",
    "model_path = 'jinmang2/kpfbert' #  #distilbert-base-multilingual-cased #bert-re-kowiki-bert-mecab \n",
    "vocab_path = 'jinmang2/kpfbert'\n",
    "OUTPATH = '../../../data11/model/NLI/kpfbert-nli'\n",
    "\n",
    "# tokeniaer 및 model 설정\n",
    "# strip_accents=False : True로 하면, 가자 => ㄱ ㅏ ㅈ ㅏ 식으로 토큰화 되어 버림(*따라서 한국어에서는 반드시 False)\n",
    "# do_lower_case=False : # 소문자 입력 사용 안함(한국어에서는 반드시 False)\n",
    "tokenizer = AutoTokenizer.from_pretrained(vocab_path, strip_accents=False, do_lower_case=False) \n",
    "                        \n",
    "# NLI 모델에서 레벨은 3개지(참,거짓,모름) 이므로, num_labels=3을 입력함\n",
    "\n",
    "if model_type == 0:\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(model_path, num_labels=3)\n",
    "elif model_type == 1:\n",
    "    model = BertForSequenceClassification.from_pretrained(model_path, num_labels=3)\n",
    "\n",
    "# 레벨을 멀티로 선택해야 하는 경우\n",
    "#model = BertForSequenceClassification.from_pretrained(model_path, problem_type=\"multi_label_classification\",num_labels=6)\n",
    "                   \n",
    "#기존 모델 파일을 로딩하는 경우    \n",
    "#model = torch.load(model_path) \n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918a05d8-aee5-42df-9a1c-1dc2443f655d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114029571"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d611fe-b906-45ee-afc2-dcbfcd760751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features from cached file ../../../data11/korpora/kornli/cached_BertTokenizerFast_72_snli_1.0_train.ko.tsv [took %.3f s] 14.711094617843628\n",
      "Loading features from cached file ../../../data11/korpora/klue-nli/cached_BertTokenizerFast_72_klue-nli-v1.1_train.json [took %.3f s] 0.5000684261322021\n",
      "Loading features from cached file ../../../data11/korpora/gluemnli/cached_BertTokenizerFast_72_glue-mnli-train.tsv [took %.3f s] 12.976846933364868\n",
      "Loading features from cached file ../../../data11/korpora/kornli/cached_BertTokenizerFast_72_xnli.dev.ko.tsv [took %.3f s] 0.05015277862548828\n",
      "Loading features from cached file ../../../data11/korpora/klue-nli/cached_BertTokenizerFast_72_klue-nli-v1.1_dev.json [took %.3f s] 0.05783700942993164\n",
      "Loading features from cached file ../../../data11/korpora/gluemnli/cached_BertTokenizerFast_72_glue-mnli-valid.tsv [took %.3f s] 0.20394062995910645\n",
      "train_loader_len: 30246, eval_loader_len: 240\n"
     ]
    }
   ],
   "source": [
    "# 학습 data loader 생성\n",
    "sys.path.append('..')\n",
    "from myutils import ClassificationDataset, KorNLICorpus, KlueNLICorpus, GlueMNLICorpus, data_collator\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "train_dataset = []\n",
    "\n",
    "# 훈련 NLI dataset 생성\n",
    "if use_kornli == 1:\n",
    "    corpus = KorNLICorpus()\n",
    "    train_dataset += ClassificationDataset(file_fpath=kor_train_file_fpath, max_seq_length=max_seq_len, tokenizer=tokenizer, corpus=corpus, overwrite_cache=cache)\n",
    "\n",
    "if use_kluenli == 1:\n",
    "    corpus = KlueNLICorpus()\n",
    "    train_dataset += ClassificationDataset(file_fpath=klue_train_file_fpath, max_seq_length=max_seq_len, tokenizer=tokenizer, corpus=corpus, overwrite_cache=cache)\n",
    "    \n",
    "if use_gluenli == 1:\n",
    "    corpus = GlueMNLICorpus()\n",
    "    train_dataset += ClassificationDataset(file_fpath=glue_train_file_fpath, max_seq_length=max_seq_len, tokenizer=tokenizer, corpus=corpus, overwrite_cache=cache)\n",
    "    \n",
    "\n",
    "# 훈련 dataloader 생성\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=train_batch_size, \n",
    "                          #shuffle=True, # dataset을 섞음\n",
    "                          sampler=RandomSampler(train_dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                          collate_fn=data_collator, # dataset을 tensor로 변환(예시 {'input_ids':tensor[0,1,2,3,1,], 'token_type_id:tensor[0,0,0,0,0], 'attention_mask:tensor[1,1,1,1,1], 'labels':tensor[5]}\n",
    "                          num_workers=4)\n",
    "\n",
    "# 평가 dataset 생성\n",
    "eval_dataset = []\n",
    "\n",
    "if use_kornli == 1:\n",
    "    corpus = KorNLICorpus()\n",
    "    eval_dataset += ClassificationDataset(file_fpath=kor_eval_file_fpath, max_seq_length=max_seq_len, tokenizer=tokenizer, corpus=corpus, overwrite_cache=cache)\n",
    "\n",
    "if use_kluenli == 1:\n",
    "    corpus = KlueNLICorpus()\n",
    "    eval_dataset += ClassificationDataset(file_fpath=klue_eval_file_fpath, max_seq_length=max_seq_len, tokenizer=tokenizer, corpus=corpus, overwrite_cache=cache)\n",
    "    \n",
    "if use_gluenli == 1:\n",
    "    corpus = GlueMNLICorpus()\n",
    "    eval_dataset += ClassificationDataset(file_fpath=glue_eval_file_fpath, max_seq_length=max_seq_len, tokenizer=tokenizer, corpus=corpus, overwrite_cache=cache)\n",
    "\n",
    "# 평가 dataloader 생성\n",
    "\n",
    "    \n",
    "eval_loader = DataLoader(eval_dataset, \n",
    "                          batch_size=eval_batch_size, \n",
    "                          #shuffle=True, # dataset을 섞음\n",
    "                          sampler=RandomSampler(eval_dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                          collate_fn=data_collator, # dataset을 tensor로 변환(예시 {'input_ids':tensor[0,1,2,3,1,], 'token_type_id:tensor[0,0,0,0,0], 'attention_mask:tensor[1,1,1,1,1], 'labels':tensor[5]}\n",
    "                          num_workers=4)\n",
    "\n",
    "print('train_loader_len: {}, eval_loader_len: {}'.format(len(train_loader), len(eval_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fec919e-d8b7-4b20-a20b-28cf66a49a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36440\n",
      "[2, 2856, 4524, 6993, 4753, 12512, 4534, 4884, 6890, 6947, 4610, 4327, 4673, 4853, 4769, 9632, 4760, 3583, 6005, 4577, 3, 7186, 9421, 4577, 3]\n",
      "None\n",
      "7186\n"
     ]
    }
   ],
   "source": [
    "# tokenier 테스트\n",
    "print(len(tokenizer))\n",
    "print(tokenizer.encode(\"눈에 보이는 반전이었지만 영화의 흡인력은 사라지지 않았다\", \"정말 재미있다\"))\n",
    "print(tokenizer.convert_ids_to_tokens(131027))\n",
    "print(tokenizer.convert_tokens_to_ids('정말'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2068553-5650-47a4-bdd6-c9e79e1580cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 10:31:52,019 - distilbertfttrain - INFO - === model: jinmang2/kpfbert ===\n",
      "2022-10-27 10:31:52,022 - distilbertfttrain - INFO - num_parameters: 114029571\n",
      "/MOCOMSYS/anaconda3/envs/bong/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d359aa5b15d413e89521a49bc7bf3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d894ffcfe94a446fb1dace5ceb5d029d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_242951/3150600645.py:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred = torch.argmax(F.softmax(logits), dim=1)\n",
      "2022-10-27 10:47:56,915 - distilbertfttrain - INFO - [Epoch 1/3] Iteration 9073 -> Train Loss: 0.7074, Train Accuracy: 0.686\n",
      "2022-10-27 11:02:53,176 - distilbertfttrain - INFO - [Epoch 1/3] Iteration 18146 -> Train Loss: 0.5804, Train Accuracy: 0.762\n",
      "2022-10-27 11:20:45,832 - distilbertfttrain - INFO - [Epoch 1/3] Iteration 27219 -> Train Loss: 0.5406, Train Accuracy: 0.780\n",
      "2022-10-27 11:26:31,924 - distilbertfttrain - INFO - ---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e0c471b055476db55912079753e898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_242951/3150600645.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred = torch.argmax(F.softmax(logits), dim=1)\n",
      "2022-10-27 11:26:52,326 - distilbertfttrain - INFO - [Epoch 1/3] Validatation Accuracy:0.7498856582816074\n",
      "2022-10-27 11:26:52,328 - distilbertfttrain - INFO - ---------------------------------------------------------\n",
      "2022-10-27 11:26:52,329 - distilbertfttrain - INFO - === 처리시간: 20.405 초 ===\n",
      "2022-10-27 11:26:52,330 - distilbertfttrain - INFO - -END-\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d76ebe7b9fc48a9a4a3c19daff0ebfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 11:48:54,062 - distilbertfttrain - INFO - [Epoch 2/3] Iteration 36292 -> Train Loss: 0.4844, Train Accuracy: 0.807\n",
      "2022-10-27 12:23:06,333 - distilbertfttrain - INFO - [Epoch 2/3] Iteration 45365 -> Train Loss: 0.4610, Train Accuracy: 0.818\n",
      "2022-10-27 12:57:13,294 - distilbertfttrain - INFO - [Epoch 2/3] Iteration 54438 -> Train Loss: 0.4510, Train Accuracy: 0.821\n",
      "2022-10-27 13:20:01,056 - distilbertfttrain - INFO - ---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c3604de1244f45b6aca1c19b52bce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 13:20:31,843 - distilbertfttrain - INFO - [Epoch 2/3] Validatation Accuracy:0.764717412610258\n",
      "2022-10-27 13:20:31,846 - distilbertfttrain - INFO - ---------------------------------------------------------\n",
      "2022-10-27 13:20:31,847 - distilbertfttrain - INFO - === 처리시간: 30.791 초 ===\n",
      "2022-10-27 13:20:31,848 - distilbertfttrain - INFO - -END-\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931c5a636be44697b221c663ed51c75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 13:31:52,283 - distilbertfttrain - INFO - [Epoch 3/3] Iteration 63511 -> Train Loss: 0.4206, Train Accuracy: 0.835\n",
      "2022-10-27 14:06:00,971 - distilbertfttrain - INFO - [Epoch 3/3] Iteration 72584 -> Train Loss: 0.3720, Train Accuracy: 0.857\n",
      "2022-10-27 14:40:13,142 - distilbertfttrain - INFO - [Epoch 3/3] Iteration 81657 -> Train Loss: 0.3659, Train Accuracy: 0.859\n",
      "2022-10-27 15:14:22,581 - distilbertfttrain - INFO - [Epoch 3/3] Iteration 90730 -> Train Loss: 0.3599, Train Accuracy: 0.861\n",
      "2022-10-27 15:14:24,630 - distilbertfttrain - INFO - ---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac99d97237444bb5b13972394fba12ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 15:14:49,994 - distilbertfttrain - INFO - [Epoch 3/3] Validatation Accuracy:0.7776543613198301\n",
      "2022-10-27 15:14:49,996 - distilbertfttrain - INFO - ---------------------------------------------------------\n",
      "2022-10-27 15:14:49,997 - distilbertfttrain - INFO - === 처리시간: 25.367 초 ===\n",
      "2022-10-27 15:14:49,998 - distilbertfttrain - INFO - -END-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "logger.info(f\"=== model: {model_path} ===\")\n",
    "logger.info(f\"num_parameters: {model.num_parameters()}\")\n",
    "\n",
    "# 학습 시작\n",
    "\n",
    "# optimizer 적용\n",
    "optimizer = AdamW(model.parameters(), \n",
    "                 lr=lr, \n",
    "                 eps=eps) # 0으로 나누는 것을 방지하기 위한 epsilon 값(10^-6 ~ 10^-8 사이 이값 입력합)\n",
    "\n",
    "# 총 훈련과정에서 반복할 스탭\n",
    "total_steps = len(train_loader)*epochs\n",
    "\n",
    "num_warmup_steps = total_steps * 0.1\n",
    "p_itr = int(total_steps * 0.1)           # 손실률 보여줄 step 수\n",
    "\n",
    "# 스캐줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=num_warmup_steps, \n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "itr = 1\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "list_training_loss = []\n",
    "list_acc_loss = []\n",
    "list_validation_acc_loss = []\n",
    "\n",
    "model.zero_grad()# 그래디언트 초기화\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    model.train() # 훈련모드로 변환\n",
    "    for data in tqdm(train_loader):\n",
    "    \n",
    "        #optimizer.zero_grad()\n",
    "        model.zero_grad()# 그래디언트 초기화\n",
    "        \n",
    "        # 입력 값 설정\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        if model_type == 1:\n",
    "            token_type_ids = data['token_type_ids'].to(device) \n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        labels = data['labels'].to(device)\n",
    "        #print('Labels:{}'.format(labels))\n",
    "        \n",
    "        # 모델 실행\n",
    "        if model_type == 0:\n",
    "            outputs = model(input_ids=input_ids, \n",
    "                            attention_mask=attention_mask,\n",
    "                            labels=labels)\n",
    "        else:\n",
    "            outputs = model(input_ids=input_ids, \n",
    "                            token_type_ids=token_type_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            labels=labels)\n",
    "        \n",
    "        # 출력값 loss,logits를 outputs에서 얻어옴\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        #print('Loss:{}, logits:{}'.format(loss, logits))\n",
    "        \n",
    "        # optimizer 과 scheduler 업데이트 시킴\n",
    "        loss.backward()   # backward 구함\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)   # 그래디언트 클리핑 (gradient vanishing이나 gradient exploding 방지하기 위한 기법)\n",
    "        optimizer.step()  # 가중치 파라미터 업데이트(optimizer 이동)\n",
    "        scheduler.step()  # 학습률 감소\n",
    "        \n",
    "        # 정확도와 손실률 계산하는 부분은 no_grade 시켜서, 계산량을 줄임.\n",
    "        # => torch.no_grad()는 gradient을 계산하는 autograd engine를 비활성화 하여 \n",
    "        # 필요한 메모리를 줄이고, 연산속도를 증가시키는 역활을 함\n",
    "        with torch.no_grad():\n",
    "            # 정확도와 총 손실률 계산\n",
    "            pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "            correct = pred.eq(labels)\n",
    "            total_correct += correct.sum().item()\n",
    "            total_len += len(labels)    \n",
    "            total_loss += loss.item()\n",
    "            #print('pred:{}, correct:{}'.format(pred, correct))\n",
    "\n",
    "            # 주기마다 test(validataion) 데이터로 평가하여 손실류 계산함.\n",
    "            if itr % p_itr == 0:\n",
    "\n",
    "                logger.info('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Train Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
    "\n",
    "                list_training_loss.append(total_loss/p_itr)\n",
    "                list_acc_loss.append(total_correct/total_len)\n",
    "\n",
    "                total_loss = 0\n",
    "                total_len = 0\n",
    "                total_correct = 0\n",
    "\n",
    "        itr+=1\n",
    "        \n",
    "        #if itr > 5:\n",
    "        #    break\n",
    "   \n",
    "    ####################################################################\n",
    "    # 1epochs 마다 실제 test(validattion)데이터로 평가 해봄\n",
    "    # 평가 시작\n",
    "    \n",
    "    start = time.time()\n",
    "    logger.info(f'---------------------------------------------------------')\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    total_test_correct = 0\n",
    "    total_test_len = 0\n",
    "    \n",
    "    for data in tqdm(eval_loader):\n",
    "        # 입력 값 설정\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        if model_type == 1:\n",
    "            token_type_ids = data['token_type_ids'].to(device) \n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        labels = data['labels'].to(device)\n",
    " \n",
    "        # 손실률 계산하는 부분은 no_grade 시켜서, 계산량을 줄임.\n",
    "        # => torch.no_grad()는 gradient을 계산하는 autograd engine를 비활성화 하여 \n",
    "        # 필요한 메모리를 줄이고, 연산속도를 증가시키는 역활을 함\n",
    "        with torch.no_grad():\n",
    "            # 모델 실행\n",
    "              # 모델 실행\n",
    "            if model_type == 0:\n",
    "                outputs = model(input_ids=input_ids, \n",
    "                                attention_mask=attention_mask,\n",
    "                                labels=labels)\n",
    "            else:\n",
    "                outputs = model(input_ids=input_ids, \n",
    "                                token_type_ids=token_type_ids,\n",
    "                                attention_mask=attention_mask,\n",
    "                                labels=labels)\n",
    "    \n",
    "            # 출력값 loss,logits를 outputs에서 얻어옴\n",
    "            #loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "    \n",
    "            # 총 손실류 구함\n",
    "            pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "            correct = pred.eq(labels)\n",
    "            total_test_correct += correct.sum().item()\n",
    "            total_test_len += len(labels)\n",
    "    \n",
    "    list_validation_acc_loss.append(total_test_correct/total_test_len)\n",
    "    logger.info(\"[Epoch {}/{}] Validatation Accuracy:{}\".format(epoch+1, epochs, total_test_correct / total_test_len))\n",
    "    logger.info(f'---------------------------------------------------------')\n",
    "    logger.info(f'=== 처리시간: {time.time() - start:.3f} 초 ===')\n",
    "    logger.info(f'-END-\\n')\n",
    "    ####################################################################\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e56cc12-2914-4fea-a6c9-15bec647112f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프로 loss 표기\n",
    "#!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_training_loss, label='Train Loss')\n",
    "plt.plot(list_acc_loss, label='Train Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86681fcb-84e3-428c-82ea-fb08f5ea4a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train loss와 Validatiaon acc 출력\n",
    "plt.plot(list_training_loss, label='Train Loss')\n",
    "plt.plot(list_validation_acc_loss, label='Validatiaon Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "986e2215-3eda-471e-be76-bace043b0770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../../data11/model/NLI/kpfbert-nli/tokenizer_config.json',\n",
       " '../../../data11/model/NLI/kpfbert-nli/special_tokens_map.json',\n",
       " '../../../data11/model/NLI/kpfbert-nli/vocab.txt',\n",
       " '../../../data11/model/NLI/kpfbert-nli/added_tokens.json',\n",
       " '../../../data11/model/NLI/kpfbert-nli/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 전체모델 저장\n",
    "#OUTPATH = '../model/distilbert/distilbert-model-0317-distillation-best-nli'\n",
    "\n",
    "os.makedirs(OUTPATH, exist_ok=True)\n",
    "#torch.save(model, OUTPATH + 'pytorch_model.bin') \n",
    "model.save_pretrained(OUTPATH)  # save_pretrained 로 저장하면 config.json, pytorch_model.bin 2개의 파일이 생성됨\n",
    "\n",
    "# tokeinizer 파일 저장\n",
    "VOCAB_PATH = OUTPATH\n",
    "os.makedirs(VOCAB_PATH, exist_ok=True)\n",
    "tokenizer.save_pretrained(VOCAB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d4a3a-a213-4018-bc1f-3d6e34a76887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
