{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f250b0-7d83-41d5-b899-ad59a2f3131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================================\n",
    "# catalyst는 버전 20.09 설치해야 함\n",
    "# => 이후 버전에는 check_ddp_wrapped 함수(from catalyst.dl.utils import check_ddp_wrapped ) 가 없어서, \n",
    "# 오류 발생함\n",
    "#===================================================================================\n",
    "\n",
    "#!pip install catalyst==20.09.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed70a4dd-a35e-40d8-9e5d-d136aae5c6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:bwdataset_2022-03-18.log\n",
      "logfilepath:qnadataset_2022-03-18.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "cuda:0\n",
      "logfilepath:distilbertembedding_2022-03-18.log\n"
     ]
    }
   ],
   "source": [
    "#===================================================================================\n",
    "# pytorch 에 Catalyst를 이용한 bert distillation 예제\n",
    "#\n",
    "# catalyst 설치해야 함\n",
    "#\n",
    "# 참고자료 : https://medium.com/pytorch/bert-distillation-with-catalyst-c6f30c985854\n",
    "# 소스 : https://github.com/elephantmipt/bert-distillation\n",
    "# \n",
    "# => myutils.distillation 필요\n",
    "#===================================================================================\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "from catalyst import dl\n",
    "sys.path.append('..')\n",
    "from myutils.distillation.runners import DistilMLMRunner\n",
    "from myutils.distillation.models import DistilbertStudentModel, BertForMLM\n",
    "from catalyst.core import MetricAggregationCallback\n",
    "from torch.utils.data import DataLoader\n",
    "from myutils.distillation.callbacks import (\n",
    "    CosineLossCallback,\n",
    "    KLDivLossCallback,\n",
    "    MaskedLanguageModelCallback,\n",
    "    MSELossCallback,\n",
    "    PerplexityMetricCallbackDistillation,\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "# myutils 패키지 import\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from myutils import seed_everything, GPU_info, pytorch_cos_sim, mlogging\n",
    "\n",
    "device = GPU_info()\n",
    "print(device)\n",
    "\n",
    "#seed 설정\n",
    "seed_everything(111)\n",
    "\n",
    "#logging 설정\n",
    "logger =  mlogging(loggername=\"distilbertembedding\", logfilname=\"distilbertembedding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987a0533-8af8-4c98-ac2d-42d1bf78b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================================\n",
    "# 교사모델과 학생모델은 tokenizer는 같아야 하며, word_embedding 사이즈도 같아야 한다.\n",
    "# =>서로 다른 size인 경우에는 증류할수 없음\n",
    "#===================================================================================\n",
    "\n",
    "# 교사 모델 과 tokenizer 경로 \n",
    "#teacher_model_name = \"bert-base-cased\"\n",
    "teacher_model_name = '../model/bert/bmc_fpt_kowiki20200920.train_model_0225'\n",
    "\n",
    "# 학생 모델 경로 \n",
    "student_model_name = '../model/distilbert/distilbert-0318-10'\n",
    "\n",
    "# new 학생 출력 파일 경로\n",
    "OUTPATH = '../model/distilbert/distilbert-0318-10-ts-1'\n",
    "\n",
    "# 훈련/평가 corpus 경로\n",
    "input_corpus = '../my_data/wiki_20190620_small_1.txt'\n",
    "eval_corpus = '../my_data/wiki_20190620_small_2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d98fba-1959-4076-bd8c-969e33845108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLSid:101, SEPid:102, UNKid:100, PADid:0, MASKid:103\n",
      "*corpus:../my_data/wiki_20190620_small_1.txt\n",
      "*max_sequence_len:128\n",
      "*mlm_probability:0.15\n",
      "*CLStokenid:101, SEPtokenid:102, UNKtokenid:100, PADtokeinid:0, Masktokeid:103\n",
      "*total_line: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c545c69f5b04f61bd158dfa6fcd7c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747d963922b440148e98aabd551220cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*corpus:../my_data/wiki_20190620_small_2.txt\n",
      "*max_sequence_len:128\n",
      "*mlm_probability:0.15\n",
      "*CLStokenid:101, SEPtokenid:102, UNKtokenid:100, PADtokeinid:0, Masktokeid:103\n",
      "*total_line: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849734f0f9834595910c824fa6e33cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6dcf72aa7b4c95abfd52c4f837587a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([   101, 120728,   9551,    107, 125356,    107, 128174, 122840,  11018,\n",
      "        120274, 119711,  23545,  11303,  48506,  70672,    103,    103,    102,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'masked_lm_labels': tensor([   101, 120728,   9551,    107, 125356,    107, 128174, 122840,  11018,\n",
      "        120274, 119711,  23545,  11303,  48506,  70672,  30919,    119,    102,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0])}\n"
     ]
    }
   ],
   "source": [
    "#==========================================================================\n",
    "# 학습/평가 dataloader 생성\n",
    "# => input_ids, token_type_ids, attention_mask, masked_lm_labels 얻어옴\n",
    "# => label 대신에 masked_lm_labels 로 변경해야 함.\n",
    "#==========================================================================\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "sys.path.append('..')\n",
    "from  myutils import MLMDatasetDistillation\n",
    "\n",
    "#== 교사 모델 Tokenizer 설정\n",
    "tokenizer = AutoTokenizer.from_pretrained(teacher_model_name, do_lower_case=False)\n",
    "\n",
    "# 각 스페셜 tokenid를 구함\n",
    "CLStokenid = tokenizer.convert_tokens_to_ids('[CLS]')\n",
    "SEPtokenid = tokenizer.convert_tokens_to_ids('[SEP]')\n",
    "UNKtokenid = tokenizer.convert_tokens_to_ids('[UNK]')\n",
    "PADtokenid = tokenizer.convert_tokens_to_ids('[PAD]')\n",
    "MASKtokenid = tokenizer.convert_tokens_to_ids('[MASK]')\n",
    "print('CLSid:{}, SEPid:{}, UNKid:{}, PADid:{}, MASKid:{}'.format(CLStokenid, SEPtokenid, UNKtokenid, PADtokenid, MASKtokenid))\n",
    "\n",
    "\n",
    "train_dataset = MLMDatasetDistillation(corpus_path = input_corpus,\n",
    "                           tokenizer = tokenizer, \n",
    "                           CLStokeinid = CLStokenid ,   # [CLS] 토큰 id\n",
    "                           SEPtokenid = SEPtokenid ,    # [SEP] 토큰 id\n",
    "                           UNKtokenid = UNKtokenid ,    # [UNK] 토큰 id\n",
    "                           PADtokenid = PADtokenid,    # [PAD] 토큰 id\n",
    "                           Masktokenid = MASKtokenid,   # [MASK] 토큰 id\n",
    "                           max_sequence_len=128,  # max_sequence_len)\n",
    "                           mlm_probability=0.15,\n",
    "                           overwrite_cache=False\n",
    "                          )\n",
    "\n",
    "\n",
    "# 학습 dataloader 생성\n",
    "# => tenosor로 만듬\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                          batch_size=16, \n",
    "                          #shuffle=True, # dataset을 섞음\n",
    "                          sampler=RandomSampler(train_dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                          num_workers=3\n",
    "                         )\n",
    "\n",
    "\n",
    "\n",
    "eval_dataset = MLMDatasetDistillation(corpus_path = eval_corpus,\n",
    "                           tokenizer = tokenizer, \n",
    "                           CLStokeinid = CLStokenid ,   # [CLS] 토큰 id\n",
    "                           SEPtokenid = SEPtokenid ,    # [SEP] 토큰 id\n",
    "                           UNKtokenid = UNKtokenid ,    # [UNK] 토큰 id\n",
    "                           PADtokenid = PADtokenid,    # [PAD] 토큰 id\n",
    "                           Masktokenid = MASKtokenid,   # [MASK] 토큰 id\n",
    "                           max_sequence_len=128,  # max_sequence_len)\n",
    "                           mlm_probability=0.15,\n",
    "                           overwrite_cache=False\n",
    "                          )\n",
    "\n",
    "# 평가 dataloader 생성\n",
    "valid_dataloader = DataLoader(eval_dataset, \n",
    "                          batch_size=16, \n",
    "                          #shuffle=True, # dataset을 섞음\n",
    "                          sampler=RandomSampler(train_dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                          num_workers=3\n",
    "                         )\n",
    "\n",
    "print(train_dataset[0])\n",
    "\n",
    "loaders = {\"train\": train_dataloader, \"valid\": valid_dataloader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d21cf0-b04a-4c67-a2df-9244b094f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for data in train_dataloader:\n",
    "    print(data)\n",
    "    count += 1\n",
    "    if count > 2:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a74dc94f-9035-4d10-b0b9-0403359fe6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143772\n"
     ]
    }
   ],
   "source": [
    "# 교사모델 생성\n",
    "teacher = BertForMLM(teacher_model_name)\n",
    "\n",
    "# state_dict 출력 해봄\n",
    "teacher_dict = teacher.state_dict()\n",
    "\n",
    "#print('bert.bert.embeddings.position_ids')\n",
    "#print(teacher_dict[\"bert.bert.embeddings.position_ids\"].shape)\n",
    "#print(teacher_dict[\"bert.bert.embeddings.position_ids\"])\n",
    "\n",
    "#print('bert.bert.embeddings.word_embeddings.weight')\n",
    "#print(teacher_dict[\"bert.bert.embeddings.word_embeddings.weight\"].shape)\n",
    "#print(teacher_dict[\"bert.bert.embeddings.word_embeddings.weight\"])\n",
    "\n",
    "tearch_word_embeddings_weigth_len = len(teacher_dict[\"bert.bert.embeddings.word_embeddings.weight\"])\n",
    "print(tearch_word_embeddings_weigth_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37ae2bd-9d4d-4542-b442-e0b1879352b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_model_name:../model/distilbert/distilbert-0318-10\n"
     ]
    }
   ],
   "source": [
    "#============================================================================================================\n",
    "# 학생모델 생성\n",
    "# => 학생모델을 생성하기 전에 교사모델의 weigth와 bias들을 복사하는 과정이 이루어짐. \n",
    "# => layers =[0,2,4,7,9,11] 하면 교사모델이 0,2,4,7,9,11 hidden layer를 학생 hidden layer(6개)로 복사하게 됨.\n",
    "# => 교사는 12개의 hidden_layer를 가지는 bert 모델이어야하며, 학생은 hidden_layer가 6개인 distilbert 이어야 한다.\n",
    "#============================================================================================================\n",
    "student = DistilbertStudentModel(teacher_model_name=teacher_model_name, \n",
    "                                 student_model_name=student_model_name,\n",
    "                                 layers = [0, 2, 4, 7, 9, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19cb39b9-34da-4941-a0ff-0b3a82aae80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교사모델과 학생모델을 연결\n",
    "model = torch.nn.ModuleDict({\"teacher\": teacher, \"student\": student})\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6635d1-0071-4a8c-bbe8-bd3ff5a60b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콜백 함수 정의\n",
    "callbacks = {\n",
    "    \"masked_lm_loss\": MaskedLanguageModelCallback(),\n",
    "    \"mse_loss\": MSELossCallback(),\n",
    "    \"cosine_loss\": CosineLossCallback(),\n",
    "    \"kl_div_loss\": KLDivLossCallback(),\n",
    "    \"loss\": MetricAggregationCallback(\n",
    "        prefix=\"loss\",\n",
    "        mode=\"weighted_sum\",\n",
    "        metrics={\n",
    "            \"cosine_loss\": 1.0,\n",
    "            \"masked_lm_loss\": 1.0,\n",
    "            \"kl_div_loss\": 1.0,\n",
    "            \"mse_loss\": 1.0\n",
    "        }\n",
    "    ),\n",
    "    \"optimizer\": dl.OptimizerCallback(),\n",
    "    \"perplexity\": PerplexityMetricCallbackDistillation()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b683e8ef-4e5c-4673-85ca-4dd59c8aeeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행\n",
    "runner = DistilMLMRunner(device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "runner.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    verbose=True,\n",
    "    check=True,\n",
    "    callbacks=callbacks,\n",
    "    num_epochs=10,\n",
    "    #logdir=\"./logs\",  # * log 폴더에 static_dict 이 자동으로 생성됨\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b738ad9-76f0-4a57-a39d-bba03ddef1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../model/distilbert/distilbert-0318-10 were not used when initializing DistilBertModel: ['student.distilbert.transformer.layer.1.attention.out_lin.weight', 'student.distilbert.transformer.layer.0.sa_layer_norm.weight', 'student.vocab_projector.weight', 'student.distilbert.transformer.layer.5.output_layer_norm.bias', 'student.distilbert.transformer.layer.1.attention.k_lin.bias', 'student.distilbert.transformer.layer.3.attention.q_lin.bias', 'student.distilbert.transformer.layer.2.attention.k_lin.weight', 'student.distilbert.transformer.layer.3.attention.q_lin.weight', 'student.distilbert.transformer.layer.3.sa_layer_norm.bias', 'student.distilbert.transformer.layer.3.attention.k_lin.bias', 'student.distilbert.transformer.layer.5.attention.v_lin.bias', 'student.distilbert.transformer.layer.1.sa_layer_norm.weight', 'student.vocab_layer_norm.weight', 'student.distilbert.transformer.layer.4.output_layer_norm.bias', 'student.distilbert.transformer.layer.5.ffn.lin2.weight', 'student.distilbert.transformer.layer.0.attention.k_lin.weight', 'student.distilbert.transformer.layer.3.ffn.lin2.bias', 'student.distilbert.transformer.layer.3.output_layer_norm.bias', 'student.vocab_projector.bias', 'student.distilbert.transformer.layer.0.attention.k_lin.bias', 'student.distilbert.transformer.layer.2.attention.out_lin.weight', 'student.distilbert.transformer.layer.4.ffn.lin1.weight', 'student.distilbert.transformer.layer.1.ffn.lin1.weight', 'student.distilbert.transformer.layer.2.sa_layer_norm.bias', 'student.distilbert.transformer.layer.5.sa_layer_norm.bias', 'student.distilbert.transformer.layer.0.attention.q_lin.bias', 'student.distilbert.transformer.layer.0.attention.out_lin.weight', 'student.distilbert.transformer.layer.4.attention.v_lin.weight', 'student.distilbert.transformer.layer.3.ffn.lin1.bias', 'student.distilbert.transformer.layer.4.ffn.lin2.bias', 'student.distilbert.transformer.layer.4.attention.q_lin.bias', 'student.distilbert.transformer.layer.2.ffn.lin2.bias', 'student.distilbert.transformer.layer.2.ffn.lin1.bias', 'student.distilbert.transformer.layer.0.ffn.lin2.weight', 'student.distilbert.transformer.layer.1.sa_layer_norm.bias', 'student.distilbert.transformer.layer.3.attention.v_lin.bias', 'student.distilbert.transformer.layer.0.attention.out_lin.bias', 'student.distilbert.transformer.layer.1.attention.v_lin.bias', 'student.distilbert.transformer.layer.4.ffn.lin2.weight', 'student.distilbert.transformer.layer.5.attention.q_lin.bias', 'student.distilbert.transformer.layer.4.ffn.lin1.bias', 'student.distilbert.transformer.layer.2.output_layer_norm.bias', 'student.distilbert.transformer.layer.3.attention.out_lin.weight', 'student.distilbert.transformer.layer.4.attention.k_lin.bias', 'student.distilbert.transformer.layer.0.output_layer_norm.weight', 'student.distilbert.transformer.layer.1.ffn.lin2.weight', 'student.distilbert.transformer.layer.1.attention.k_lin.weight', 'student.distilbert.transformer.layer.5.ffn.lin2.bias', 'student.distilbert.transformer.layer.3.output_layer_norm.weight', 'student.vocab_layer_norm.bias', 'student.distilbert.transformer.layer.1.ffn.lin1.bias', 'student.distilbert.transformer.layer.5.attention.out_lin.bias', 'student.distilbert.transformer.layer.5.attention.v_lin.weight', 'student.distilbert.transformer.layer.0.output_layer_norm.bias', 'student.distilbert.transformer.layer.2.sa_layer_norm.weight', 'student.distilbert.embeddings.word_embeddings.weight', 'student.distilbert.transformer.layer.2.ffn.lin1.weight', 'student.distilbert.transformer.layer.0.attention.q_lin.weight', 'student.distilbert.embeddings.LayerNorm.bias', 'student.distilbert.transformer.layer.2.attention.q_lin.bias', 'student.distilbert.transformer.layer.2.attention.k_lin.bias', 'student.distilbert.transformer.layer.4.sa_layer_norm.bias', 'student.distilbert.transformer.layer.0.ffn.lin1.weight', 'student.distilbert.transformer.layer.5.attention.k_lin.weight', 'student.distilbert.transformer.layer.2.output_layer_norm.weight', 'student.distilbert.transformer.layer.5.output_layer_norm.weight', 'student.distilbert.transformer.layer.4.attention.v_lin.bias', 'student.distilbert.transformer.layer.5.attention.k_lin.bias', 'student.distilbert.transformer.layer.4.attention.out_lin.bias', 'student.distilbert.transformer.layer.1.output_layer_norm.weight', 'student.distilbert.transformer.layer.0.attention.v_lin.weight', 'student.distilbert.transformer.layer.3.sa_layer_norm.weight', 'student.distilbert.transformer.layer.5.ffn.lin1.weight', 'student.distilbert.transformer.layer.0.ffn.lin1.bias', 'student.distilbert.transformer.layer.2.ffn.lin2.weight', 'student.distilbert.transformer.layer.3.attention.k_lin.weight', 'student.distilbert.transformer.layer.3.ffn.lin1.weight', 'student.distilbert.transformer.layer.5.attention.q_lin.weight', 'student.distilbert.transformer.layer.4.attention.k_lin.weight', 'student.distilbert.transformer.layer.0.attention.v_lin.bias', 'student.distilbert.transformer.layer.4.sa_layer_norm.weight', 'student.distilbert.transformer.layer.1.ffn.lin2.bias', 'student.vocab_transform.weight', 'student.distilbert.transformer.layer.2.attention.out_lin.bias', 'student.distilbert.transformer.layer.1.attention.q_lin.bias', 'student.distilbert.embeddings.LayerNorm.weight', 'student.distilbert.transformer.layer.1.attention.v_lin.weight', 'student.distilbert.transformer.layer.4.attention.out_lin.weight', 'student.distilbert.transformer.layer.3.ffn.lin2.weight', 'student.distilbert.transformer.layer.2.attention.q_lin.weight', 'student.distilbert.embeddings.position_embeddings.weight', 'student.distilbert.transformer.layer.1.output_layer_norm.bias', 'student.distilbert.transformer.layer.5.sa_layer_norm.weight', 'student.distilbert.transformer.layer.1.attention.out_lin.bias', 'student.distilbert.transformer.layer.4.attention.q_lin.weight', 'student.vocab_transform.bias', 'student.distilbert.transformer.layer.3.attention.out_lin.bias', 'student.distilbert.transformer.layer.5.attention.out_lin.weight', 'student.distilbert.transformer.layer.2.attention.v_lin.bias', 'student.distilbert.transformer.layer.4.output_layer_norm.weight', 'student.distilbert.transformer.layer.3.attention.v_lin.weight', 'student.distilbert.transformer.layer.2.attention.v_lin.weight', 'student.distilbert.transformer.layer.0.sa_layer_norm.bias', 'student.distilbert.transformer.layer.1.attention.q_lin.weight', 'student.distilbert.transformer.layer.5.ffn.lin1.bias', 'student.distilbert.transformer.layer.0.ffn.lin2.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertModel were not initialized from the model checkpoint at ../model/distilbert/distilbert-0318-10 and are newly initialized: ['transformer.layer.2.attention.out_lin.bias', 'transformer.layer.4.attention.q_lin.weight', 'transformer.layer.5.attention.k_lin.weight', 'transformer.layer.5.attention.v_lin.bias', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.4.sa_layer_norm.bias', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.4.ffn.lin1.bias', 'transformer.layer.4.attention.k_lin.weight', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.3.attention.out_lin.bias', 'transformer.layer.2.attention.v_lin.weight', 'embeddings.LayerNorm.weight', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.3.sa_layer_norm.weight', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.4.attention.q_lin.bias', 'transformer.layer.5.ffn.lin2.bias', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.5.output_layer_norm.weight', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.3.output_layer_norm.weight', 'transformer.layer.5.sa_layer_norm.bias', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.2.output_layer_norm.bias', 'transformer.layer.3.sa_layer_norm.bias', 'transformer.layer.4.ffn.lin2.bias', 'embeddings.word_embeddings.weight', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.5.attention.q_lin.weight', 'transformer.layer.5.attention.out_lin.weight', 'transformer.layer.1.attention.v_lin.bias', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.5.attention.k_lin.bias', 'transformer.layer.5.output_layer_norm.bias', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.3.output_layer_norm.bias', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.5.attention.out_lin.bias', 'transformer.layer.3.attention.v_lin.weight', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.5.ffn.lin1.bias', 'transformer.layer.5.attention.v_lin.weight', 'transformer.layer.4.output_layer_norm.bias', 'transformer.layer.3.attention.k_lin.weight', 'transformer.layer.3.ffn.lin1.bias', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.3.attention.q_lin.weight', 'transformer.layer.4.ffn.lin2.weight', 'transformer.layer.3.attention.out_lin.weight', 'transformer.layer.5.ffn.lin1.weight', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.4.output_layer_norm.weight', 'transformer.layer.4.attention.out_lin.bias', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.4.ffn.lin1.weight', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.3.ffn.lin1.weight', 'embeddings.position_embeddings.weight', 'transformer.layer.4.attention.v_lin.bias', 'transformer.layer.5.sa_layer_norm.weight', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.5.attention.q_lin.bias', 'transformer.layer.3.attention.q_lin.bias', 'transformer.layer.4.attention.out_lin.weight', 'transformer.layer.3.attention.v_lin.bias', 'embeddings.LayerNorm.bias', 'transformer.layer.4.sa_layer_norm.weight', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.3.ffn.lin2.bias', 'transformer.layer.5.ffn.lin2.weight', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.3.attention.k_lin.bias', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.3.ffn.lin2.weight', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.4.attention.k_lin.bias', 'transformer.layer.4.attention.v_lin.weight', 'transformer.layer.2.sa_layer_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertModel(\n",
      "  (embeddings): Embeddings(\n",
      "    (word_embeddings): Embedding(143772, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (layer): ModuleList(\n",
      "      (0): TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../model/distilbert/distilbert-0318-10-ts-1/tokenizer_config.json',\n",
       " '../model/distilbert/distilbert-0318-10-ts-1/special_tokens_map.json',\n",
       " '../model/distilbert/distilbert-0318-10-ts-1/vocab.txt',\n",
       " '../model/distilbert/distilbert-0318-10-ts-1/added_tokens.json',\n",
       " '../model/distilbert/distilbert-0318-10-ts-1/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학생 모델을 저장함.\n",
    "# => 학생모델을 바로 저장할수 없어서, 일단 state_dict으로 저장후 \n",
    "import os\n",
    "from transformers import DistilBertModel   \n",
    "os.makedirs(OUTPATH, exist_ok=True)\n",
    "\n",
    "# 학생모델 state_dict 만 저장.\n",
    "state_dict_fpath = OUTPATH + '/state_dict.pt'\n",
    "torch.save(model[\"student\"].state_dict(), state_dict_fpath)\n",
    "                      \n",
    "# 기존 학생 모델에서, 증류학습한 state_dict 를 적용함.\n",
    "new_student_model = DistilBertModel.from_pretrained(student_model_name, state_dict=torch.load(state_dict_fpath))\n",
    "print(new_student_model)\n",
    "\n",
    "### 신규 학생 모델 저장\n",
    "os.makedirs(OUTPATH, exist_ok=True)\n",
    "# save_pretrained 로 저장하면 config.json, pytorch_model.bin 2개의 파일이 생성됨\n",
    "new_student_model.save_pretrained(OUTPATH)\n",
    "\n",
    "# tokeinizer 파일 저장(vocab)\n",
    "os.makedirs(OUTPATH, exist_ok=True)\n",
    "tokenizer.save_pretrained(OUTPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2235656d-aa88-4714-bf20-b19a2f3df981",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 학습한 모델 static_dict.pt 저장함\n",
    "import os\n",
    "\n",
    "OUTPATH = '../model/distilbert/distilbert-model-0317-distillation-2'\n",
    "static_dict_fpath = OUTPATH + '/static_dict.pt'\n",
    "\n",
    "os.makedirs(OUTPATH, exist_ok=True)\n",
    "torch.save(model.state_dict(), static_dict_fpath) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecadba19-6d6f-475d-8c30-0752473d9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "# 저장한 static_dict.pt를 불러와서 기존 학생모델에 적용 한후, 저장함\n",
    "import os\n",
    "from transformers import DistilBertModel         \n",
    "\n",
    "# static_dict 저정경로에 있는 dict 종류중에 best.pth를 설정함.\n",
    "# static_dict 아래 3가지가 생성됨.\n",
    "# => logs/checkpoints/train.2.pth\n",
    "# => logs/checkpoints/last.pth \n",
    "# => logs/checkpoints/best.pth \n",
    "static_dict_fpath = './logs/checkpoints/best.pth'\n",
    "\n",
    "# 기존 학생 모델에서, 증류학습한 state_dict 를 적용함.\n",
    "new_student_model = DistilBertModel.from_pretrained(student_model_name, state_dict=torch.load(static_dict_fpath))\n",
    "print(new_student_model)\n",
    "\n",
    "### 신규 학생 모델 저장\n",
    "new_student_model_fpath = ''\n",
    "os.makedirs(OUTPATH, exist_ok=True)\n",
    "# save_pretrained 로 저장하면 config.json, pytorch_model.bin 2개의 파일이 생성됨\n",
    "new_student_model.save_pretrained(OUTPATH)\n",
    "\n",
    "# tokeinizer 파일 저장(vocab)\n",
    "os.makedirs(OUTPATH, exist_ok=True)\n",
    "tokenizer.save_pretrained(OUTPATH)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
