2022-03-31 15:49:54,812 - bwpdataset - INFO - Creating features from dataset file at ../../korpora/kornli/multinli.train.ko.tsv
2022-03-31 15:49:54,814 - bwpdataset - INFO - loading data... LOOKING AT ../../korpora/kornli/multinli.train.ko.tsv
2022-03-31 15:53:06,788 - bwpdataset - INFO - Creating features from dataset file at ../../korpora/kornli/multinli.train.ko.tsv
2022-03-31 15:53:06,790 - bwpdataset - INFO - loading data... LOOKING AT ../../korpora/kornli/multinli.train.ko.tsv
2022-03-31 15:57:29,114 - bwpdataset - INFO - Creating features from dataset file at ../../korpora/kornli/multinli.train.ko.tsv
2022-03-31 15:57:29,116 - bwpdataset - INFO - loading data... LOOKING AT ../../korpora/kornli/multinli.train.ko.tsv
2022-03-31 15:58:38,320 - bwpdataset - INFO - Creating features from dataset file at ../../korpora/kornli/multinli.train.ko.tsv
2022-03-31 15:58:38,323 - bwpdataset - INFO - loading data... LOOKING AT ../../korpora/kornli/multinli.train.ko.tsv
2022-03-31 15:58:40,398 - bwpdataset - INFO - tokenize sentences, it could take a lot of time...
2022-03-31 16:00:46,150 - bwpdataset - INFO - tokenize sentences [took 125.750 s]
2022-03-31 16:00:48,110 - bwpdataset - INFO - *** Example ***
2022-03-31 16:00:48,111 - bwpdataset - INFO - sentence A, B: 개념적으로 크림 스키밍은 제품과 지리라는 두 가지 기본 차원을 가지고 있다. + 제품과 지리학은 크림 스키밍을 작동시키는 것이다.
2022-03-31 16:00:48,112 - bwpdataset - INFO - tokens: [CLS] 개념 ##적으로 크림 스키 ##밍 ##은 제품 ##과 지리 ##라는 두 가지 기본 차원 ##을 가지고 있다 . [SEP] 제품 ##과 지리학 ##은 크림 스키 ##밍 ##을 작동 ##시키 ##는 것이다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
2022-03-31 16:00:48,112 - bwpdataset - INFO - label: neutral
2022-03-31 16:00:48,113 - bwpdataset - INFO - features: ClassificationFeatures(input_ids=[101, 119747, 17022, 123033, 123664, 118960, 10892, 119982, 11882, 121825, 60362, 9102, 69164, 119688, 119968, 10622, 44270, 11506, 119, 102, 119982, 11882, 127883, 10892, 123033, 123664, 118960, 10622, 121232, 162537, 11018, 24190, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=2)
2022-03-31 16:00:48,114 - bwpdataset - INFO - *** Example ***
2022-03-31 16:00:48,114 - bwpdataset - INFO - sentence A, B: 시즌 중에 알고 있는 거 알아? 네 레벨에서 다음 레벨로 잃어버리는 거야 브레이브스가 모팀을 떠올리기로 결정하면 브레이브스가 트리플 A에서 한 남자를 떠올리기로 결정하면 더블 A가 그를 대신하러 올라가고 A 한 명이 그를 대신하러 올라간다. + 사람들이 기억하면 다음 수준으로 물건을 잃는다.
2022-03-31 16:00:48,115 - bwpdataset - INFO - tokens: [CLS] 시즌 중에 알 ##고 있는 거 알 ##아 ? 네 레벨 ##에서 다음 레벨로 잃 ##어 ##버리 ##는 거야 브레이브 ##스가 모 ##팀 ##을 떠 ##올리 ##기로 결정 ##하면 브레이브 ##스가 트리플 A ##에서 한 남자 ##를 떠 ##올리 ##기로 결정 ##하면 더블 A ##가 그를 대신 ##하 ##러 올 ##라가 ##고 A 한 명이 그를 대신 ##하 ##러 올 ##라 ##간 ##다 . [SEP] 사람 ##들이 기억 ##하면 다음 수준 ##으로 물건 ##을 잃 ##는다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
2022-03-31 16:00:48,115 - bwpdataset - INFO - label: entailment
2022-03-31 16:00:48,116 - bwpdataset - INFO - features: ClassificationFeatures(input_ids=[101, 45742, 102246, 9524, 11664, 13767, 8863, 9524, 16985, 136, 9011, 121905, 11489, 52292, 158109, 9643, 12965, 136841, 11018, 148705, 150896, 122917, 9283, 74399, 10622, 9138, 163125, 62675, 119583, 38378, 150896, 122917, 124233, 138, 11489, 9954, 76854, 11513, 9138, 163125, 62675, 119583, 38378, 122789, 138, 11287, 76203, 82642, 35506, 30873, 9583, 128123, 11664, 138, 9954, 120680, 76203, 82642, 35506, 30873, 9583, 17342, 18784, 11903, 119, 102, 119550, 20173, 120467, 38378, 52292, 120133, 11467, 121425, 10622, 9643, 40410, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)
2022-03-31 16:00:48,131 - bwpdataset - INFO - Saving features into cached file, it could take a lot of time...
2022-03-31 16:01:15,403 - bwpdataset - INFO - Saving features into cached file ../../korpora/kornli/cached_BertTokenizer_128_multinli.train.ko.tsv [took 27.272 s]
2022-03-31 16:01:15,475 - bwpdataset - INFO - Creating features from dataset file at ../../korpora/kornli/xnli.test.ko.tsv
2022-03-31 16:01:15,476 - bwpdataset - INFO - loading data... LOOKING AT ../../korpora/kornli/xnli.test.ko.tsv
2022-03-31 16:01:15,488 - bwpdataset - INFO - tokenize sentences, it could take a lot of time...
2022-03-31 16:01:18,212 - bwpdataset - INFO - tokenize sentences [took 2.723 s]
2022-03-31 16:01:18,239 - bwpdataset - INFO - *** Example ***
2022-03-31 16:01:18,240 - bwpdataset - INFO - sentence A, B: 글쎄, 나는 그것에 관해 생각조차 하지 않았지만, 나는 너무 좌절했고, 결국 그에게 다시 이야기하게 되었다. + 나는 그와 다시 이야기하지 않았다.
2022-03-31 16:01:18,241 - bwpdataset - INFO - tokens: [CLS] [UNK] , 나는 그것 ##에 관 ##해 생각 ##조 ##차 하지 않 ##았 ##지만 , 나는 너 ##무 좌절 ##했고 , 결국 그 ##에게 다시 이야기 ##하게 되었다 . [SEP] 나는 그 ##와 다시 이야기 ##하지 않았다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
2022-03-31 16:01:18,241 - bwpdataset - INFO - label: contradiction
2022-03-31 16:01:18,242 - bwpdataset - INFO - features: ClassificationFeatures(input_ids=[101, 100, 117, 100585, 119663, 10530, 8900, 14523, 119576, 20626, 23466, 89093, 9523, 119118, 28578, 117, 100585, 9004, 32537, 123050, 38181, 117, 50342, 8924, 26212, 25805, 110148, 17594, 17737, 119, 102, 100585, 8924, 12638, 25805, 110148, 23665, 49137, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)
2022-03-31 16:01:18,242 - bwpdataset - INFO - *** Example ***
2022-03-31 16:01:18,243 - bwpdataset - INFO - sentence A, B: 글쎄, 나는 그것에 관해 생각조차 하지 않았지만, 나는 너무 좌절했고, 결국 그에게 다시 이야기하게 되었다. + 나는 다시 그와 이야기를 하기 시작했다는 것에 너무 화가 났다.
2022-03-31 16:01:18,244 - bwpdataset - INFO - tokens: [CLS] [UNK] , 나는 그것 ##에 관 ##해 생각 ##조 ##차 하지 않 ##았 ##지만 , 나는 너 ##무 좌절 ##했고 , 결국 그 ##에게 다시 이야기 ##하게 되었다 . [SEP] 나는 다시 그 ##와 이야기 ##를 하 ##기 시작했다 ##는 것에 너 ##무 화가 났 ##다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
2022-03-31 16:01:18,244 - bwpdataset - INFO - label: entailment
2022-03-31 16:01:18,245 - bwpdataset - INFO - features: ClassificationFeatures(input_ids=[101, 100, 117, 100585, 119663, 10530, 8900, 14523, 119576, 20626, 23466, 89093, 9523, 119118, 28578, 117, 100585, 9004, 32537, 123050, 38181, 117, 50342, 8924, 26212, 25805, 110148, 17594, 17737, 119, 102, 100585, 25805, 8924, 12638, 110148, 11513, 9952, 12310, 70927, 11018, 100158, 9004, 32537, 121271, 8990, 11903, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)
2022-03-31 16:01:18,245 - bwpdataset - INFO - Saving features into cached file, it could take a lot of time...
2022-03-31 16:01:18,710 - bwpdataset - INFO - Saving features into cached file ../../korpora/kornli/cached_BertTokenizer_128_xnli.test.ko.tsv [took 0.465 s]
2022-03-31 18:04:52,714 - bwpdataset - INFO - Loading features from cached file ../../korpora/kornli/cached_BertTokenizer_128_multinli.train.ko.tsv [took 16.947 s]
2022-03-31 18:04:52,872 - bwpdataset - INFO - Loading features from cached file ../../korpora/kornli/cached_BertTokenizer_128_xnli.test.ko.tsv [took 0.155 s]
2022-03-31 18:06:15,018 - bwpdataset - INFO - Loading features from cached file ../../korpora/kornli/cached_BertTokenizer_128_multinli.train.ko.tsv [took 17.111 s]
2022-03-31 18:06:15,171 - bwpdataset - INFO - Loading features from cached file ../../korpora/kornli/cached_BertTokenizer_128_xnli.test.ko.tsv [took 0.151 s]
2022-03-31 18:37:19,125 - bwpdataset - INFO - Loading features from cached file ../../korpora/kornli/cached_BertTokenizer_128_multinli.train.ko.tsv [took 16.097 s]
2022-03-31 18:37:19,279 - bwpdataset - INFO - Loading features from cached file ../../korpora/kornli/cached_BertTokenizer_128_xnli.test.ko.tsv [took 0.151 s]
