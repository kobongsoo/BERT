{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e57fb5-7735-44e1-a200-0caa3fa6c941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:bwdataset_2022-03-28.log\n",
      "logfilepath:qnadataset_2022-03-28.log\n"
     ]
    }
   ],
   "source": [
    "#==================================================================================\n",
    "# Distillation 예제(증류)\n",
    "#\n",
    "#: 교사 모델(BertModel) -> 학생모델(DistilBertModel) 로 distillation 하는 예시임\n",
    "# 여기서는 훈련은 하지 않고, 교사모델 레이어들의 weigth와 bias들을 불러와서, \n",
    "# 학생모델 레이어에 적용하는 예시\n",
    "#\n",
    "# - state_dict를 이용하여, 필요한 교사 레이어들의 weigth, bias을 학생 레이어로 복사함\n",
    "# - *make_sate_dict_bertmodel_to_distillbertmodel 함수 참고, \n",
    "# 해당 함수는 교사가 bertmodel이고 학생이 dstilbertmodel인 경우에만 사용 가능.\n",
    "# 교사/학생 모델 이 bertformaskedlm 식으로 변경되는 경우에는 state_dict 에 keys를 확인해서 수정해야함.\n",
    "#\n",
    "#==================================================================================\n",
    "\n",
    "from transformers import BertModel, DistilBertModel\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from myutils import seed_everything, make_sate_dict_bertmodel_to_distillbertmodel\n",
    "\n",
    "seed_everything(111)\n",
    "#logging 설정\n",
    "#logger =  mlogging(loggername=\"state_dict\", logfilname=\"state_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "907a8b4a-a02c-4d2f-8738-796139a42e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../model/bert/bmc-fpt-wiki_20190620_mecab_false_0311-nouns-0327 were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ../../model/bert/bmc-fpt-wiki_20190620_mecab_false_0311-nouns-0327 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.modeling_bert.BertModel'>\n",
      "odict_keys(['embeddings.position_ids', 'embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias'])\n",
      "tensor([[ 0.0269, -0.0009, -0.0439,  ...,  0.0020, -0.0098,  0.0094],\n",
      "        [-0.0190, -0.0209, -0.0088,  ..., -0.0216, -0.0193, -0.0079],\n",
      "        [-0.0118, -0.0189, -0.0004,  ..., -0.0270, -0.0167, -0.0258],\n",
      "        ...,\n",
      "        [-0.0197, -0.0128, -0.0483,  ..., -0.0389, -0.0192, -0.0250],\n",
      "        [-0.0253, -0.0202, -0.0244,  ..., -0.0371, -0.0323, -0.0193],\n",
      "        [ 0.0077, -0.0302, -0.0408,  ..., -0.0224, -0.0575, -0.0220]])\n"
     ]
    }
   ],
   "source": [
    "# 교사 모델에서 state_dict 만 뽑아냄\n",
    "tearch_model_path='../../model/bert/bmc-fpt-wiki_20190620_mecab_false_0311-nouns-0327'\n",
    "tearch_model = BertModel.from_pretrained(tearch_model_path, output_hidden_states=True)\n",
    "\n",
    "print(type(tearch_model))\n",
    "\n",
    "#state_dict 뽑아냄\n",
    "tearch_state_dict = tearch_model.state_dict()\n",
    "print(tearch_state_dict.keys())\n",
    "print(tearch_state_dict['embeddings.word_embeddings.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a51c6671-ab9d-4506-b873-fcde9d3a0a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "distil_sd = None\n",
    "layers = [0, 2, 4, 7, 9, 11]\n",
    "distil_sd = make_sate_dict_bertmodel_to_distillbertmodel(tearch_model, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "366c9ea5-f8ab-4241-aee6-aaf687f7f544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.1.attention.v_lin.bias', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.2.sa_layer_norm.weight', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.2.output_layer_norm.bias', 'transformer.layer.3.attention.q_lin.weight', 'transformer.layer.3.attention.k_lin.weight', 'transformer.layer.3.attention.v_lin.weight', 'transformer.layer.3.attention.out_lin.weight', 'transformer.layer.3.sa_layer_norm.weight', 'transformer.layer.3.ffn.lin1.weight', 'transformer.layer.3.ffn.lin2.weight', 'transformer.layer.3.output_layer_norm.weight', 'transformer.layer.3.attention.q_lin.bias', 'transformer.layer.3.attention.k_lin.bias', 'transformer.layer.3.attention.v_lin.bias', 'transformer.layer.3.attention.out_lin.bias', 'transformer.layer.3.sa_layer_norm.bias', 'transformer.layer.3.ffn.lin1.bias', 'transformer.layer.3.ffn.lin2.bias', 'transformer.layer.3.output_layer_norm.bias', 'transformer.layer.4.attention.q_lin.weight', 'transformer.layer.4.attention.k_lin.weight', 'transformer.layer.4.attention.v_lin.weight', 'transformer.layer.4.attention.out_lin.weight', 'transformer.layer.4.sa_layer_norm.weight', 'transformer.layer.4.ffn.lin1.weight', 'transformer.layer.4.ffn.lin2.weight', 'transformer.layer.4.output_layer_norm.weight', 'transformer.layer.4.attention.q_lin.bias', 'transformer.layer.4.attention.k_lin.bias', 'transformer.layer.4.attention.v_lin.bias', 'transformer.layer.4.attention.out_lin.bias', 'transformer.layer.4.sa_layer_norm.bias', 'transformer.layer.4.ffn.lin1.bias', 'transformer.layer.4.ffn.lin2.bias', 'transformer.layer.4.output_layer_norm.bias', 'transformer.layer.5.attention.q_lin.weight', 'transformer.layer.5.attention.k_lin.weight', 'transformer.layer.5.attention.v_lin.weight', 'transformer.layer.5.attention.out_lin.weight', 'transformer.layer.5.sa_layer_norm.weight', 'transformer.layer.5.ffn.lin1.weight', 'transformer.layer.5.ffn.lin2.weight', 'transformer.layer.5.output_layer_norm.weight', 'transformer.layer.5.attention.q_lin.bias', 'transformer.layer.5.attention.k_lin.bias', 'transformer.layer.5.attention.v_lin.bias', 'transformer.layer.5.attention.out_lin.bias', 'transformer.layer.5.sa_layer_norm.bias', 'transformer.layer.5.ffn.lin1.bias', 'transformer.layer.5.ffn.lin2.bias', 'transformer.layer.5.output_layer_norm.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(distil_sd.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5719c22-a55c-480d-9d74-165d3bad8d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.1.attention.v_lin.bias', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.2.sa_layer_norm.weight', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.2.output_layer_norm.bias', 'transformer.layer.3.attention.q_lin.weight', 'transformer.layer.3.attention.q_lin.bias', 'transformer.layer.3.attention.k_lin.weight', 'transformer.layer.3.attention.k_lin.bias', 'transformer.layer.3.attention.v_lin.weight', 'transformer.layer.3.attention.v_lin.bias', 'transformer.layer.3.attention.out_lin.weight', 'transformer.layer.3.attention.out_lin.bias', 'transformer.layer.3.sa_layer_norm.weight', 'transformer.layer.3.sa_layer_norm.bias', 'transformer.layer.3.ffn.lin1.weight', 'transformer.layer.3.ffn.lin1.bias', 'transformer.layer.3.ffn.lin2.weight', 'transformer.layer.3.ffn.lin2.bias', 'transformer.layer.3.output_layer_norm.weight', 'transformer.layer.3.output_layer_norm.bias', 'transformer.layer.4.attention.q_lin.weight', 'transformer.layer.4.attention.q_lin.bias', 'transformer.layer.4.attention.k_lin.weight', 'transformer.layer.4.attention.k_lin.bias', 'transformer.layer.4.attention.v_lin.weight', 'transformer.layer.4.attention.v_lin.bias', 'transformer.layer.4.attention.out_lin.weight', 'transformer.layer.4.attention.out_lin.bias', 'transformer.layer.4.sa_layer_norm.weight', 'transformer.layer.4.sa_layer_norm.bias', 'transformer.layer.4.ffn.lin1.weight', 'transformer.layer.4.ffn.lin1.bias', 'transformer.layer.4.ffn.lin2.weight', 'transformer.layer.4.ffn.lin2.bias', 'transformer.layer.4.output_layer_norm.weight', 'transformer.layer.4.output_layer_norm.bias', 'transformer.layer.5.attention.q_lin.weight', 'transformer.layer.5.attention.q_lin.bias', 'transformer.layer.5.attention.k_lin.weight', 'transformer.layer.5.attention.k_lin.bias', 'transformer.layer.5.attention.v_lin.weight', 'transformer.layer.5.attention.v_lin.bias', 'transformer.layer.5.attention.out_lin.weight', 'transformer.layer.5.attention.out_lin.bias', 'transformer.layer.5.sa_layer_norm.weight', 'transformer.layer.5.sa_layer_norm.bias', 'transformer.layer.5.ffn.lin1.weight', 'transformer.layer.5.ffn.lin1.bias', 'transformer.layer.5.ffn.lin2.weight', 'transformer.layer.5.ffn.lin2.bias', 'transformer.layer.5.output_layer_norm.weight', 'transformer.layer.5.output_layer_norm.bias'])\n",
      "tensor([[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [  4.6951,   7.9118,  -2.2909,  ...,   1.2087,   5.5990,  -6.2665],\n",
      "        [  5.9853,  14.1727,  -0.7380,  ...,  11.4669,  11.1134,  -7.8186],\n",
      "        ...,\n",
      "        [  0.0751,  -9.8991,  -9.5650,  ...,   3.8927,   2.9925,  -6.4232],\n",
      "        [ 11.6854,   6.4417,  10.3435,  ...,  -1.5523,  15.6353,   1.3810],\n",
      "        [ -5.5161,  -4.8009,  -9.1509,  ...,  -2.9011,  -1.4914, -15.1198]])\n"
     ]
    }
   ],
   "source": [
    "# 학생모델\n",
    "student_model_path='../../model/distilbert/distilbert-0327'\n",
    "student_model = DistilBertModel.from_pretrained(student_model_path, output_hidden_states=True)\n",
    "\n",
    "#state_dict 뽑아냄\n",
    "student_state_dict = student_model.state_dict()\n",
    "print(student_state_dict.keys())\n",
    "print(student_state_dict['embeddings.word_embeddings.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a9070c3-0072-47ef-b47e-6b382e332e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.1.attention.v_lin.bias', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.2.sa_layer_norm.weight', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.2.output_layer_norm.bias', 'transformer.layer.3.attention.q_lin.weight', 'transformer.layer.3.attention.q_lin.bias', 'transformer.layer.3.attention.k_lin.weight', 'transformer.layer.3.attention.k_lin.bias', 'transformer.layer.3.attention.v_lin.weight', 'transformer.layer.3.attention.v_lin.bias', 'transformer.layer.3.attention.out_lin.weight', 'transformer.layer.3.attention.out_lin.bias', 'transformer.layer.3.sa_layer_norm.weight', 'transformer.layer.3.sa_layer_norm.bias', 'transformer.layer.3.ffn.lin1.weight', 'transformer.layer.3.ffn.lin1.bias', 'transformer.layer.3.ffn.lin2.weight', 'transformer.layer.3.ffn.lin2.bias', 'transformer.layer.3.output_layer_norm.weight', 'transformer.layer.3.output_layer_norm.bias', 'transformer.layer.4.attention.q_lin.weight', 'transformer.layer.4.attention.q_lin.bias', 'transformer.layer.4.attention.k_lin.weight', 'transformer.layer.4.attention.k_lin.bias', 'transformer.layer.4.attention.v_lin.weight', 'transformer.layer.4.attention.v_lin.bias', 'transformer.layer.4.attention.out_lin.weight', 'transformer.layer.4.attention.out_lin.bias', 'transformer.layer.4.sa_layer_norm.weight', 'transformer.layer.4.sa_layer_norm.bias', 'transformer.layer.4.ffn.lin1.weight', 'transformer.layer.4.ffn.lin1.bias', 'transformer.layer.4.ffn.lin2.weight', 'transformer.layer.4.ffn.lin2.bias', 'transformer.layer.4.output_layer_norm.weight', 'transformer.layer.4.output_layer_norm.bias', 'transformer.layer.5.attention.q_lin.weight', 'transformer.layer.5.attention.q_lin.bias', 'transformer.layer.5.attention.k_lin.weight', 'transformer.layer.5.attention.k_lin.bias', 'transformer.layer.5.attention.v_lin.weight', 'transformer.layer.5.attention.v_lin.bias', 'transformer.layer.5.attention.out_lin.weight', 'transformer.layer.5.attention.out_lin.bias', 'transformer.layer.5.sa_layer_norm.weight', 'transformer.layer.5.sa_layer_norm.bias', 'transformer.layer.5.ffn.lin1.weight', 'transformer.layer.5.ffn.lin1.bias', 'transformer.layer.5.ffn.lin2.weight', 'transformer.layer.5.ffn.lin2.bias', 'transformer.layer.5.output_layer_norm.weight', 'transformer.layer.5.output_layer_norm.bias'])\n",
      "tensor([[ 0.0269, -0.0009, -0.0439,  ...,  0.0020, -0.0098,  0.0094],\n",
      "        [-0.0190, -0.0209, -0.0088,  ..., -0.0216, -0.0193, -0.0079],\n",
      "        [-0.0118, -0.0189, -0.0004,  ..., -0.0270, -0.0167, -0.0258],\n",
      "        ...,\n",
      "        [-0.0197, -0.0128, -0.0483,  ..., -0.0389, -0.0192, -0.0250],\n",
      "        [-0.0253, -0.0202, -0.0244,  ..., -0.0371, -0.0323, -0.0193],\n",
      "        [ 0.0077, -0.0302, -0.0408,  ..., -0.0224, -0.0575, -0.0220]])\n"
     ]
    }
   ],
   "source": [
    "# 학생모델\n",
    "student_model_path='../../model/distilbert/distilbert-0327'\n",
    "student_model = DistilBertModel.from_pretrained(student_model_path, state_dict=distil_sd, output_hidden_states=True)\n",
    "\n",
    "#state_dict 뽑아냄\n",
    "student_state_dict = student_model.state_dict()\n",
    "print(student_state_dict.keys())\n",
    "print(student_state_dict['embeddings.word_embeddings.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b310b63-321d-4c38-b73d-27996aa763de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "import os\n",
    "OUTPATH = '../../model/distilbert/distilbert-0327-TS'\n",
    "\n",
    "os.makedirs(OUTPATH, exist_ok=True)\n",
    "# save_pretrained 로 저장하면 config.json, pytorch_model.bin 2개의 파일이 생성됨\n",
    "student_model.save_pretrained(OUTPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e5321-a778-4e76-b634-1166b1c52a11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
