{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd66b12-3efc-49a7-bdeb-739ff11bd456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:../../log/bwdataset_2022-04-18.log\n",
      "logfilepath:../../log/qnadataset_2022-04-18.log\n"
     ]
    }
   ],
   "source": [
    "# MLM 방식을 이용한 Further pre-traning 방식 구현 예제\n",
    "# 참고 소스 : https://towardsdatascience.com/masked-language-modelling-with-bert-7d49793e5d2c 참조 바람\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import DistilBertTokenizer, BertConfig, DistilBertForMaskedLM\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from myutils import GPU_info, seed_everything, mlogging, MLMDatasetbyDistilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3321a0d-57d3-400b-be05-619e1bf63842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "cuda:0\n",
      "logfilepath:../../log/distilbertfpt-1_2022-04-18.log\n"
     ]
    }
   ],
   "source": [
    "# 훈련시킬 말뭉치(사전 만들때 동일한 말뭉치 이용)\n",
    "input_corpus = \"../../korpora/kowiki_20190620/wiki_20190620_small.txt\"\n",
    "#input_corpus = \"../../korpora/kowiki_20190620/wiki_20190620_mecab_false_0311.txt\"\n",
    "\n",
    "# eval 말뭉치 \n",
    "eval_corpus = \"../../korpora/kowiki_20190620/wiki_eval_test.txt\"\n",
    "\n",
    "# 기존 사전훈련된 모델\n",
    "model_path = \"../../model/distilbert/distilbert-0331-TS-nli-0.1-10/\"\n",
    "\n",
    "# 기존 사전 + 추가된 사전 파일\n",
    "vocab_path=\"../../model/distilbert/distilbert-0331-TS-nli-0.1-10/\"\n",
    "\n",
    "# 출력\n",
    "OUTPATH = '../../model/distilbert/distilbert-0331-TS-nli-0.1-10-04-19/'\n",
    "\n",
    "batch_size = 32\n",
    "token_max_len = 128\n",
    "\n",
    "device = GPU_info()\n",
    "print(device)\n",
    "\n",
    "#seed 설정\n",
    "seed_everything(111)\n",
    "\n",
    "#logging 설정\n",
    "logger =  mlogging(loggername=\"distilbertfpt-1\", logfilename=\"../../log/distilbertfpt-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd6fad4a-7b5b-4502-93bc-7564f197398e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special_token_size: 27, tokenizer.vocab_size: 167537\n",
      "vocab_size: 167560\n",
      "tokenizer_len: 167550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../model/distilbert/distilbert-0331-TS-nli-0.1-10/ were not used when initializing DistilBertForMaskedLM: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing DistilBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForMaskedLM were not initialized from the model checkpoint at ../../model/distilbert/distilbert-0331-TS-nli-0.1-10/ and are newly initialized: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForMaskedLM(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(167550, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vocab_transform): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (vocab_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (vocab_projector): Linear(in_features=768, out_features=167550, bias=True)\n",
       "  (mlm_loss_fct): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokeinzier 생성\n",
    "# tokenizer 생성\n",
    "# => BertTokenizer, BertTokenizerFast 둘중 사용하면됨\n",
    "\n",
    "#tokenizer = DistilBertTokenizer(vocab_file=vocab_path, max_len=token_max_len, do_lower_case=False)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(vocab_path, max_len=token_max_len, do_lower_case=False)\n",
    "#tokenizer = BertTokenizerFast(vocab_speical_path)\n",
    "# tokenizer = BertTokenizerFast(vocab_file=vocab_file, max_len=token_max_len, do_lower_case=False)\n",
    "\n",
    "\n",
    "# speical 토큰 계수 + vocab 계수 - 이미 vocab에 포함된 speical 토큰 계수(5)\n",
    "vocab_size = len(tokenizer.all_special_tokens) + tokenizer.vocab_size - 5 + 1\n",
    "#vocab_size = len(tokenizer.all_special_tokens) + tokenizer.vocab_size - 5\n",
    "print('special_token_size: {}, tokenizer.vocab_size: {}'.format(len(tokenizer.all_special_tokens), tokenizer.vocab_size))\n",
    "print('vocab_size: {}'.format(vocab_size))\n",
    "print('tokenizer_len: {}'.format(len(tokenizer)))\n",
    "\n",
    "# 모델 로딩 further pre-training \n",
    "#config = BertConfig.from_pretrained(model_path)\n",
    "model = DistilBertForMaskedLM.from_pretrained(model_path, from_tf=bool(\".ckpt\" in model_path)) \n",
    "#model = BertForMaskedLM.from_pretrained('bert-base-multilingual-cased')    \n",
    "\n",
    "#################################################################################\n",
    "# 모델 embedding 사이즈를 tokenizer 크기 만큼 재 설정함.\n",
    "# 재설정하지 않으면, 다음과 같은 에러 발생함\n",
    "# CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)` CUDA 에러가 발생함\n",
    "#  indexSelectLargeIndex: block: [306,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
    "#\n",
    "#     해당 오류는 기존 Embedding(8002, 768, padding_idx=1) 처럼 입력 vocab 사이즈가 8002인데,\n",
    "#     0~8001 사이를 초과하는 word idx 값이 들어가면 에러 발생함.\n",
    "#################################################################################\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e41cf1f-4010-4348-8921-67d0f21ea09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLSid:101, SEPid:102, UNKid:100, PADid:0, MASKid:103\n",
      "*corpus:../../korpora/kowiki_20190620/wiki_20190620_small.txt\n",
      "*max_sequence_len:128\n",
      "*mlm_probability:0.15\n",
      "*CLStokenid:101, SEPtokenid:102, UNKtokenid:100, PADtokeinid:0, Masktokeid:103\n",
      "*total_line: 10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2fb03a4dd74bc2a89296fe57e4ca62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a182029ca9c4a879fb9ac276d822b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*corpus:../../korpora/kowiki_20190620/wiki_eval_test.txt\n",
      "*max_sequence_len:128\n",
      "*mlm_probability:0.15\n",
      "*CLStokenid:101, SEPtokenid:102, UNKtokenid:100, PADtokeinid:0, Masktokeid:103\n",
      "*total_line: 114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22cd7b3ca23a4f0984eb299eb79a71a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639b1083a2c147ecbe0dc2cc1446955a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([   101,    103,   9551,    107, 125318,    107, 125598, 122449,  11018,\n",
      "           103,    103,    103,  11303,  48506,    103,  30919,    119,    102,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([   101, 120501,   9551,    107, 125318,    107, 125598, 122449,  11018,\n",
      "        120397, 119606,  23545,  11303,  48506,  70672,  30919,    119,    102,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0])}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "# true이면, 무조건 원본파일 읽고, cache 파일을 만듬.\n",
    "# False로 하면 cache파일이 있으면 cache파일 이용함. cache파일 없으면 원본파일 일고, cache파일은 만들지 않음\n",
    "overwrite_cache = False\n",
    "\n",
    "# 각 스페셜 tokenid를 구함\n",
    "CLStokenid = tokenizer.convert_tokens_to_ids('[CLS]')\n",
    "SEPtokenid = tokenizer.convert_tokens_to_ids('[SEP]')\n",
    "UNKtokenid = tokenizer.convert_tokens_to_ids('[UNK]')\n",
    "PADtokenid = tokenizer.convert_tokens_to_ids('[PAD]')\n",
    "MASKtokenid = tokenizer.convert_tokens_to_ids('[MASK]')\n",
    "print('CLSid:{}, SEPid:{}, UNKid:{}, PADid:{}, MASKid:{}'.format(CLStokenid, SEPtokenid, UNKtokenid, PADtokenid, MASKtokenid))\n",
    "\n",
    "# distilberttoknizer에는 token_type_ids(문장구분자) 가 없음\n",
    "# 따라서 MLMDatasetbyDistilBert 함수를 이용하여 MLM 생성함\n",
    "train_dataset = MLMDatasetbyDistilBert(corpus_path = input_corpus,\n",
    "                           tokenizer = tokenizer, \n",
    "                           CLStokeinid = CLStokenid ,   # [CLS] 토큰 id\n",
    "                           SEPtokenid = SEPtokenid ,    # [SEP] 토큰 id\n",
    "                           UNKtokenid = UNKtokenid ,    # [UNK] 토큰 id\n",
    "                           PADtokenid = PADtokenid,    # [PAD] 토큰 id\n",
    "                           Masktokenid = MASKtokenid,   # [MASK] 토큰 id\n",
    "                           max_sequence_len=token_max_len,  # max_sequence_len)\n",
    "                           mlm_probability=0.15,\n",
    "                           overwrite_cache=overwrite_cache\n",
    "                          )\n",
    "\n",
    "\n",
    "# 학습 dataloader 생성\n",
    "# => tenosor로 만듬\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          #shuffle=True, # dataset을 섞음\n",
    "                          sampler=RandomSampler(train_dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                          num_workers=3\n",
    "                         )\n",
    "#===============================================================================\n",
    "# eval dataloader 생성\n",
    "eval_dataset = MLMDatasetbyDistilBert(corpus_path = eval_corpus,\n",
    "                        tokenizer = tokenizer, \n",
    "                        CLStokeinid = CLStokenid ,   # [CLS] 토큰 id\n",
    "                        SEPtokenid = SEPtokenid ,    # [SEP] 토큰 id\n",
    "                        UNKtokenid = UNKtokenid ,    # [UNK] 토큰 id\n",
    "                        PADtokenid = PADtokenid,    # [PAD] 토큰 id\n",
    "                        Masktokenid = MASKtokenid,   # [MASK] 토큰 id\n",
    "                        max_sequence_len=token_max_len,  # max_sequence_len)\n",
    "                        mlm_probability=0.15,\n",
    "                        overwrite_cache=False\n",
    "                        )\n",
    "\n",
    "\n",
    "# eval dataloader 생성\n",
    "# => tenosor로 만듬\n",
    "eval_loader = DataLoader(eval_dataset, \n",
    "                         batch_size=batch_size, \n",
    "                         #shuffle=True, # dataset을 섞음\n",
    "                         sampler=RandomSampler(eval_dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                         num_workers=3\n",
    "                        )\n",
    "     #===============================================================================\n",
    "\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "619daf32-2925-4c31-a321-ed1098142bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def save_model(model, tokenizer, OUTPATH, epochs, lr, batch_size):\n",
    "    \n",
    "    # 현재 local 시간 얻어옴(20220414-12-20)\n",
    "    tm = time.localtime(time.time())  \n",
    "    tt = f\"batch:{batch_size}-ep:{epochs}-lr:{lr:.9f}-{tm.tm_mon}m{tm.tm_mday}d-{tm.tm_hour}:{tm.tm_min}\"\n",
    "                \n",
    "    TMP_OUT_PATH = OUTPATH + tt\n",
    "    \n",
    "    ### 전체모델 저장\n",
    "    os.makedirs(TMP_OUT_PATH, exist_ok=True)\n",
    "    #torch.save(model, OUTPATH + 'pytorch_model.bin') \n",
    "    # save_pretrained 로 저장하면 config.json, pytorch_model.bin 2개의 파일이 생성됨\n",
    "    model.save_pretrained(TMP_OUT_PATH)\n",
    "\n",
    "    # tokeinizer 파일 저장(vocab)\n",
    "    VOCAB_PATH = TMP_OUT_PATH\n",
    "    tokenizer.save_pretrained(VOCAB_PATH)\n",
    "    \n",
    "    logger.info(f'==> save_model : {TMP_OUT_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89756e9c-7002-4d63-b2ef-a3431486fb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70d23ed696e47dcbfb124fdef8bef8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d83285a6f44b5298eadc24da2b50f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 14:05:51,422 - distilbertfpt-1 - INFO - [Epoch 1/4] Iteration 30 -> Train Loss: 11.3976, Train Acc: 0.0000, Val Acc:0.0003197953309881676\n",
      "2022-04-18 14:05:58,361 - distilbertfpt-1 - INFO - [Epoch 1/4] Iteration 60 -> Train Loss: 6.0669, Train Acc: 0.0000, Val Acc:0.0\n",
      "2022-04-18 14:06:05,287 - distilbertfpt-1 - INFO - [Epoch 1/4] Iteration 90 -> Train Loss: 2.3384, Train Acc: 0.0075, Val Acc:0.0354972817396866\n",
      "2022-04-18 14:06:12,450 - distilbertfpt-1 - INFO - [Epoch 1/4] Iteration 120 -> Train Loss: 1.7250, Train Acc: 0.1146, Val Acc:0.17620722737448033\n",
      "2022-04-18 14:06:19,400 - distilbertfpt-1 - INFO - [Epoch 1/4] Iteration 150 -> Train Loss: 1.3626, Train Acc: 0.2564, Val Acc:0.2807803006076111\n",
      "2022-04-18 14:06:26,349 - distilbertfpt-1 - INFO - [Epoch 1/4] Iteration 180 -> Train Loss: 1.1119, Train Acc: 0.3858, Val Acc:0.3895107131435881\n",
      "2022-04-18 14:06:33,248 - distilbertfpt-1 - INFO - [Epoch 1/4] Iteration 210 -> Train Loss: 0.9769, Train Acc: 0.4635, Val Acc:0.45314998401023343\n",
      "2022-04-18 14:06:40,191 - distilbertfpt-1 - INFO - [Epoch 1/4] Iteration 240 -> Train Loss: 0.8497, Train Acc: 0.5257, Val Acc:0.4931244003837544\n",
      "2022-04-18 14:06:47,175 - distilbertfpt-1 - INFO - [Epoch 1/4] Iteration 270 -> Train Loss: 0.8111, Train Acc: 0.5624, Val Acc:0.5225455708346658\n",
      "2022-04-18 14:06:54,094 - distilbertfpt-1 - INFO - [Epoch 1/4] Iteration 300 -> Train Loss: 0.7322, Train Acc: 0.6041, Val Acc:0.5580428525743524\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0feb76d577f0414fb6dc010880a00acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 14:07:01,606 - distilbertfpt-1 - INFO - [Epoch 2/4] Iteration 330 -> Train Loss: 0.8667, Train Acc: 0.5722, Val Acc:0.5516469459545891\n",
      "2022-04-18 14:07:08,600 - distilbertfpt-1 - INFO - [Epoch 2/4] Iteration 360 -> Train Loss: 0.6649, Train Acc: 0.6447, Val Acc:0.5871442276942757\n",
      "2022-04-18 14:07:15,579 - distilbertfpt-1 - INFO - [Epoch 2/4] Iteration 390 -> Train Loss: 0.6121, Train Acc: 0.6766, Val Acc:0.6120882635113527\n",
      "2022-04-18 14:07:22,559 - distilbertfpt-1 - INFO - [Epoch 2/4] Iteration 420 -> Train Loss: 0.6202, Train Acc: 0.6973, Val Acc:0.6267988487368085\n",
      "2022-04-18 14:07:29,556 - distilbertfpt-1 - INFO - [Epoch 2/4] Iteration 450 -> Train Loss: 0.5689, Train Acc: 0.7222, Val Acc:0.6459865685960985\n",
      "2022-04-18 14:07:36,542 - distilbertfpt-1 - INFO - [Epoch 2/4] Iteration 480 -> Train Loss: 0.5667, Train Acc: 0.7391, Val Acc:0.660377358490566\n",
      "2022-04-18 14:07:43,511 - distilbertfpt-1 - INFO - [Epoch 2/4] Iteration 510 -> Train Loss: 0.5397, Train Acc: 0.7518, Val Acc:0.6642149024624241\n",
      "2022-04-18 14:07:50,464 - distilbertfpt-1 - INFO - [Epoch 2/4] Iteration 540 -> Train Loss: 0.5191, Train Acc: 0.7640, Val Acc:0.6763671250399744\n",
      "2022-04-18 14:07:57,446 - distilbertfpt-1 - INFO - [Epoch 2/4] Iteration 570 -> Train Loss: 0.5014, Train Acc: 0.7819, Val Acc:0.688839142948513\n",
      "2022-04-18 14:08:04,436 - distilbertfpt-1 - INFO - [Epoch 2/4] Iteration 600 -> Train Loss: 0.4904, Train Acc: 0.7858, Val Acc:0.6993923888711224\n",
      "2022-04-18 14:08:08,736 - distilbertfpt-1 - INFO - ==> save_model : ../../model/distilbert/distilbert-0331-TS-nli-0.1-10-04-19/batch:32-ep:4-lr:0.000020000-4m18d-14:8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcd022bb91e40079168fab2637c6b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 14:08:13,365 - distilbertfpt-1 - INFO - [Epoch 3/4] Iteration 630 -> Train Loss: 0.5708, Train Acc: 0.7529, Val Acc:0.6683722417652702\n",
      "2022-04-18 14:08:20,350 - distilbertfpt-1 - INFO - [Epoch 3/4] Iteration 660 -> Train Loss: 0.4687, Train Acc: 0.7948, Val Acc:0.7086664534697793\n",
      "2022-04-18 14:08:27,312 - distilbertfpt-1 - INFO - [Epoch 3/4] Iteration 690 -> Train Loss: 0.4474, Train Acc: 0.8137, Val Acc:0.7121842021106491\n",
      "2022-04-18 14:08:34,311 - distilbertfpt-1 - INFO - [Epoch 3/4] Iteration 720 -> Train Loss: 0.4789, Train Acc: 0.8160, Val Acc:0.7217780620402943\n",
      "2022-04-18 14:08:41,298 - distilbertfpt-1 - INFO - [Epoch 3/4] Iteration 750 -> Train Loss: 0.4303, Train Acc: 0.8250, Val Acc:0.7249760153501759\n",
      "2022-04-18 14:08:48,291 - distilbertfpt-1 - INFO - [Epoch 3/4] Iteration 780 -> Train Loss: 0.4240, Train Acc: 0.8283, Val Acc:0.7304125359769748\n",
      "2022-04-18 14:08:55,285 - distilbertfpt-1 - INFO - [Epoch 3/4] Iteration 810 -> Train Loss: 0.4230, Train Acc: 0.8333, Val Acc:0.7374480332587144\n",
      "2022-04-18 14:09:02,292 - distilbertfpt-1 - INFO - [Epoch 3/4] Iteration 840 -> Train Loss: 0.4235, Train Acc: 0.8371, Val Acc:0.7406459865685961\n",
      "2022-04-18 14:09:09,285 - distilbertfpt-1 - INFO - [Epoch 3/4] Iteration 870 -> Train Loss: 0.4160, Train Acc: 0.8397, Val Acc:0.7400063959066198\n",
      "2022-04-18 14:09:16,305 - distilbertfpt-1 - INFO - [Epoch 3/4] Iteration 900 -> Train Loss: 0.4188, Train Acc: 0.8399, Val Acc:0.742244963223537\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468862dc86694c31bef935f4997cbf04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 14:09:23,841 - distilbertfpt-1 - INFO - [Epoch 4/4] Iteration 930 -> Train Loss: 0.4644, Train Acc: 0.8215, Val Acc:0.7201790853853534\n",
      "2022-04-18 14:09:30,860 - distilbertfpt-1 - INFO - [Epoch 4/4] Iteration 960 -> Train Loss: 0.4039, Train Acc: 0.8433, Val Acc:0.7515190278221938\n",
      "2022-04-18 14:09:37,885 - distilbertfpt-1 - INFO - [Epoch 4/4] Iteration 990 -> Train Loss: 0.3904, Train Acc: 0.8524, Val Acc:0.7566357531180045\n",
      "2022-04-18 14:09:44,900 - distilbertfpt-1 - INFO - [Epoch 4/4] Iteration 1020 -> Train Loss: 0.3908, Train Acc: 0.8569, Val Acc:0.7604732970898624\n",
      "2022-04-18 14:09:51,901 - distilbertfpt-1 - INFO - [Epoch 4/4] Iteration 1050 -> Train Loss: 0.3782, Train Acc: 0.8563, Val Acc:0.7607930924208507\n",
      "2022-04-18 14:09:58,906 - distilbertfpt-1 - INFO - [Epoch 4/4] Iteration 1080 -> Train Loss: 0.4010, Train Acc: 0.8572, Val Acc:0.7611128877518388\n",
      "2022-04-18 14:10:05,904 - distilbertfpt-1 - INFO - [Epoch 4/4] Iteration 1110 -> Train Loss: 0.3949, Train Acc: 0.8553, Val Acc:0.7623920690757915\n",
      "2022-04-18 14:10:12,892 - distilbertfpt-1 - INFO - [Epoch 4/4] Iteration 1140 -> Train Loss: 0.3774, Train Acc: 0.8616, Val Acc:0.7684681803645667\n",
      "2022-04-18 14:10:19,887 - distilbertfpt-1 - INFO - [Epoch 4/4] Iteration 1170 -> Train Loss: 0.3819, Train Acc: 0.8615, Val Acc:0.7675087943716021\n",
      "2022-04-18 14:10:26,883 - distilbertfpt-1 - INFO - [Epoch 4/4] Iteration 1200 -> Train Loss: 0.3878, Train Acc: 0.8598, Val Acc:0.7662296130476495\n",
      "2022-04-18 14:10:34,064 - distilbertfpt-1 - INFO - ==> save_model : ../../model/distilbert/distilbert-0331-TS-nli-0.1-10-04-19/batch:32-ep:4-lr:0.000020000-4m18d-14:10\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "epochs = 4            # epochs\n",
    "learning_rate = 2e-5  # 학습률\n",
    "##################################################\n",
    "\n",
    "# optimizer 적용\n",
    "optimizer = AdamW(model.parameters(), \n",
    "                 lr=learning_rate, \n",
    "                 eps=1e-8) # 0으로 나누는 것을 방지하기 위한 epsilon 값(10^-6 ~ 10^-8 사이 이값 입력합)\n",
    "\n",
    "# 총 훈련과정에서 반복할 스탭\n",
    "total_steps = len(train_loader)*epochs\n",
    "warmup_steps = total_steps * 0.1 #10% of train data for warm-up\n",
    "\n",
    "# 손실률 보여줄 step 수\n",
    "p_itr = int(len(train_loader)*0.1)  \n",
    "    \n",
    "# step마다 모델 저장\n",
    "save_steps = int(total_steps * 0.5)\n",
    "    \n",
    "# 스캐줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=warmup_steps, \n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "itr = 1\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "total_test_correct = 0\n",
    "total_test_len = 0\n",
    "            \n",
    "list_train_loss = []\n",
    "list_train_acc = []\n",
    "list_validation_acc = []\n",
    "\n",
    "model.zero_grad()# 그래디언트 초기화\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    model.train() # 훈련모드로 변환\n",
    "    for data in tqdm(train_loader):\n",
    "    \n",
    "        #optimizer.zero_grad()\n",
    "        model.zero_grad()# 그래디언트 초기화\n",
    "        \n",
    "        # 입력 값 설정\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        #token_type_ids = data['token_type_ids'].to(device)         \n",
    "        labels = data['labels'].to(device)\n",
    "        #print('Labels:{}'.format(labels))\n",
    "        \n",
    "        # 모델 실행\n",
    "        outputs = model(input_ids=input_ids, \n",
    "                        attention_mask=attention_mask,\n",
    "                        #token_type_ids=token_type_ids,\n",
    "                        labels=labels)\n",
    "        \n",
    "        # 출력값 loss,logits를 outputs에서 얻어옴\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        #print('Loss:{}, logits:{}'.format(loss, logits))\n",
    "        \n",
    "        # optimizer 과 scheduler 업데이트 시킴\n",
    "        loss.backward()   # backward 구함\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)   # 그래디언트 클리핑 (gradient vanishing이나 gradient exploding 방지하기 위한 기법)\n",
    "        optimizer.step()  # 가중치 파라미터 업데이트(optimizer 이동)\n",
    "        scheduler.step()  # 학습률 감소\n",
    "        \n",
    "        # ***further pretrain 에는 손실률 계산을 넣지 않음\n",
    "        # 정확도 계산하는 부분은 no_grade 시켜서, 계산량을 줄임.\n",
    "        \n",
    "        # => torch.no_grad()는 gradient을 계산하는 autograd engine를 비활성화 하여 \n",
    "        # 필요한 메모리를 줄이고, 연산속도를 증가시키는 역활을 함\n",
    "        with torch.no_grad():\n",
    "                        \n",
    "            # 손실(loss) 계산 \n",
    "            total_loss += loss.item()\n",
    "                \n",
    "            #===========================================\n",
    "            # 정확도(Accurarcy) 계산\n",
    "            pred = torch.argmax(logits, dim=2)\n",
    "            tmpcorrect = pred.eq(labels)\n",
    "\n",
    "            # 예측값 중 true인값 * attention_maks가 = 1(True)인것 중에서 True값이 합이 masked에서 알아맞춘 단어 계수임\n",
    "            correct = tmpcorrect*attention_mask \n",
    "            total_correct += correct.sum().item() \n",
    "\n",
    "            # 단어 총 수는 attension_mask가 1(True) 인 것들의 합\n",
    "            total_len += attention_mask.sum().item() \n",
    "            #=========================================   \n",
    "         \n",
    "            # 주기마다 test(validataion) 데이터로 평가하여 손실류 계산함.\n",
    "            if itr % p_itr == 0:\n",
    "                train_loss = total_loss/p_itr\n",
    "                train_acc = total_correct/total_len\n",
    "                         \n",
    "                ####################################################################\n",
    "                # 주기마다 eval(validataion) 데이터로 평가하여 손실류 계산함.\n",
    "                # 평가 시작\n",
    "                model.eval()\n",
    "\n",
    "                #for data in tqdm(eval_loader):\n",
    "                for data in eval_loader:\n",
    "                    # 입력 값 설정\n",
    "                    input_ids = data['input_ids'].to(device)\n",
    "                    attention_mask = data['attention_mask'].to(device)\n",
    "                    labels = data['labels'].to(device)\n",
    "\n",
    "                    # 손실률 계산하는 부분은 no_grade 시켜서, 계산량을 줄임.\n",
    "                    # => torch.no_grad()는 gradient을 계산하는 autograd engine를 비활성화 하여 \n",
    "                    # 필요한 메모리를 줄이고, 연산속도를 증가시키는 역활을 함\n",
    "                    with torch.no_grad():\n",
    "                        # 모델 실행\n",
    "                        outputs = model(input_ids=input_ids, \n",
    "                                       attention_mask=attention_mask,\n",
    "                                       labels=labels)\n",
    "\n",
    "                        # 출력값 loss,logits를 outputs에서 얻어옴\n",
    "                        #loss = outputs.loss\n",
    "                        logits = outputs.logits\n",
    "\n",
    "                        #===========================================\n",
    "                        # 정확도(Accurarcy) 계산\n",
    "                        pred = torch.argmax(logits, dim=2)\n",
    "                        tmpcorrect = pred.eq(labels)\n",
    "\n",
    "                        # 예측값 중 true인값 * attention_maks가 = 1(True)인것 중에서 True값이 합이 masked에서 알아맞춘 단어 계수임\n",
    "                        correct = tmpcorrect*attention_mask \n",
    "                        total_test_correct += correct.sum().item() \n",
    "\n",
    "                        # 단어 총 수는 attension_mask가 1(True) 인 것들의 합\n",
    "                        total_test_len += attention_mask.sum().item() \n",
    "                        #========================================= \n",
    "\n",
    "                val_acc = total_test_correct/total_test_len\n",
    "                    \n",
    "                logger.info('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Train Acc: {:.4f}, Val Acc:{}'.format(epoch+1, epochs, itr, train_loss, train_acc, val_acc))\n",
    "                    \n",
    "                list_train_loss.append(train_loss)\n",
    "                list_train_acc.append(train_acc)\n",
    "                list_validation_acc.append(val_acc)\n",
    "                 \n",
    "                total_loss = 0\n",
    "                total_len = 0\n",
    "                total_correct = 0\n",
    "                total_test_correct = 0\n",
    "                total_test_len = 0\n",
    "                ####################################################################\n",
    "\n",
    "            # 모델 저장\n",
    "            if itr % save_steps == 0:\n",
    "                save_model(model, tokenizer, OUTPATH, epochs, learning_rate, batch_size)\n",
    "\n",
    "        itr+=1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "869e6f6d-064e-49c4-b851-6af50aa127eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA0/0lEQVR4nO3dd3xUVf7/8dfJpIeQTkun9xAMoakgWBCxIFLURbChrrqy6rq6KrK2n3V39auLXQQ0KItSpCOiKL2JJLQYShLSgTRSJjPn98cdQoBAQphkJsnn+XjM4965czPzySW8c3PuuecorTVCCCEaPxdHFyCEEMI+JNCFEKKJkEAXQogmQgJdCCGaCAl0IYRoIlwd9cHBwcE6KirKUR8vhBCN0rZt23K11iHVveawQI+KimLr1q2O+nghhGiUlFKHz/eaNLkIIUQTIYEuhBBNhAS6EEI0EQ5rQ6+O2WwmLS2N0tJSR5ciasHT05OwsDDc3NwcXYoQAicL9LS0NHx9fYmKikIp5ehyxAVorcnLyyMtLY3o6GhHlyOEwMmaXEpLSwkKCpIwbwSUUgQFBclfU0I4EacKdEDCvBGRfyshnItTNbkIIYSzKiw1szezkD0ZBeQWlgHGSY1SoDi1BKXAw9WEj4crPh4mWni44u3uSosqz/283fBwNdm9Rgn0KvLy8hg+fDgAmZmZmEwmQkKMG7I2b96Mu7v7eb9269atzJo1i3ffffeiPnPnzp3ExsaybNkyRowYUffihWjiKixWMvJLOXLsJEeOnaTMbMHV5IKbSeHq4oKrSeFmcsHVxViaLVbKLVbKK6yUVRjL8gpjW4VF4+NhwtfTFV9PN1p4uNrWjedmi5U9GUZ4Jx0tICmjgCPHTtrte3nx5h7cNTDKbu93igR6FUFBQezcuROA6dOn06JFC5588snK1ysqKnB1rf6QxcXFERcXd9GfmZCQwOWXX05CQkK9BrrFYsFksv8ZgRD2VlJuYfOhY+zNKODwsZOk2gI8/XgJFdaGnZBHKYgK8qFXqB/j+4XTra0v3dv60bqlR2WTo9YaqzaWGtAayiosFJdZKCqroLisguLyCorLLBSXVVBUVkF8dGC91CuBXoPJkyfj6enJjh07GDx4MBMmTOCxxx6jtLQULy8vPv/8c7p06cLatWt56623+P7775k+fTpHjhwhJSWFI0eOMHXqVP7yl7+c895aa+bNm8eqVau44oorKC0txdPTE4DXX3+dOXPm4OLiwvXXX89rr71GcnIyDz74IDk5OZhMJubNm0dqamrl5wI88sgjxMXFMXnyZKKiohg/fjyrVq3iqaeeorCwkI8++ojy8nI6duzI7Nmz8fb2JisriwcffJCUlBQAZsyYwfLlywkMDGTq1KkAPPvss7Rq1YrHHnusYQ68aDYsVs3u9Hx+Sc7llwO5bDt8nHKLFYAAbzciAr3pHebPqN5tiQz0ITzQm/BAL7zdXamwWDFbtbG0aCqsxtm32WLFzeSCu6sLHq7G0t323N3VBVcXF4ps4VpYaqawtIKi0goKbOtKQdc2LenaxhcfjwvHpFIKkwKjwcXg7uqCr2fDd+d12kD/5+JEko4W2PU9u7dryQs39rjor0tLS2P9+vWYTCYKCgpYt24drq6urF69mn/84x/Mnz//nK/Zu3cvP/74I4WFhXTp0oWHHnronP7a69evJzo6mg4dOjB06FCWLFnCmDFjWLZsGQsXLmTTpk14e3tz7NgxAO68806efvppRo8eTWlpKVarldTU1AvWHhQUxPbt2wGjSen+++8H4LnnnuPTTz/l0Ucf5S9/+QtDhgzhu+++w2KxUFRURLt27bj11luZOnUqVquVuXPnsnnz5os+dkJU58TJcpb8nsEvB3JZ/0ce+SVmALq1bcmkQZEM7hhMbEQAfl71F4p+Xm629/eqt89oaE4b6M5k7Nixlc0V+fn5TJo0iQMHDqCUwmw2V/s1N9xwAx4eHnh4eNCqVSuysrIICws7Y5+EhAQmTJgAwIQJE5g1axZjxoxh9erV3H333Xh7ewMQGBhIYWEh6enpjB49GqDyTL4m48ePr1zfvXs3zz33HCdOnKCoqIjrrrsOgDVr1jBr1iwATCYTfn5++Pn5ERQUxI4dO8jKyiI2NpagoKDaHjLRiFismvwSM8eKyzlxsty2NHP8ZDnlFdbKZgSrrUkB29JFKW6MaUfHVi1q/VlaaxbvyuCfixLJKy6nrZ8n13ZvzeWdghnUIZgQX496+i6bB6cN9LqcSdcXHx+fyvXnn3+eq666iu+++45Dhw4xdOjQar/Gw+P0D6bJZKKiouKM1y0WC/Pnz2fhwoW88sorlTfqFBYWXlRtrq6uWK3Wyudn9wuvWvvkyZNZsGABMTExzJw5k7Vr117wve+77z5mzpxJZmYm99xzz0XVJZxDYamZjPxS43GixLZeUrktp7CMglIzFzNX/KneHFYN/7fmAOP7hfPY8M608bvwSUb6iRKeX7CbNXuziQnz4/O7+9Er1E+6v9qR0wa6s8rPzyc0NBSAmTNn1vl9fvjhB3r37s2KFSsqt02aNInvvvuOa665hhdffJE777yzssklMDCQsLAwFixYwC233EJZWRkWi4XIyEiSkpIoKyujpKSEH374gcsvv7zazywsLKRt27aYzWa+/PLLyu9j+PDhzJgxg6lTp1Y2ufj5+TF69GimTZuG2Wzmq6++qvP3KurXyfIKDuWe5FBeMQdzi0nJKeZgbhEHc4s5fvLMvyCVgpAWHrT196JTqxYM6hBEgLc7Ad5uBPi429bd8bc993B1QWGcjSt15r0HeUVlvPdjMnM2Hubb7encc3k0Dw7pcE4zicWqmb3hEG+u2IdVw/OjujN5UBQmFwlye5NAv0hPPfUUkyZN4uWXX+aGG26o8/skJCRUNp+cMmbMGGbMmMGyZcvYuXMncXFxuLu7M3LkSF599VVmz57NAw88wLRp03Bzc2PevHm0b9+ecePG0bNnT6Kjo4mNjT3vZ7700kv079+fkJAQ+vfvX/nXwDvvvMOUKVP49NNPMZlMzJgxg4EDB+Lu7s5VV12Fv7+/9JBxkNyiMo6eKCG7oIycojKyC8rILjTOrLMLy8jMLyWz4My/ylq39CA62IcRPdsSGeRNO38v2vp50tbPk9YtPXEz2ed+wqAWHrxwYw/uGRzNv1bt54Of/uCrTUd45KqOTBwYiaebiX2Zhfx9/i52pp5gSOcQXr6lJ+GB3nb5fHEupS/mby07iouL02dPcLFnzx66devmkHrEuaxWK3379mXevHl06tSp2n3k38y+8kvMbEzJ49fkXH5JziUlp/icfQK83Qjx9aCVryetWnoQHeRDdIgP0cE+RAX51Ngro74kHs3njeX7+Gl/Du38PBnSpRXztqbS0suNF27szk0x7aR5xQ6UUtu01tX2kZYzdFGtpKQkRo0axejRo88b5uLSlVVY2HHkBL8m57LuQC670k5g1eDtbqJ/dCC394sgMsibVi09CfH1ILiFe73cYWgPPdr58cU98az/I5fXl+0lYfMRbo0N5blR3Qn0Of9NecJ+JNBFtbp3717ZL13UjdWqWbY7kx1HjpNfYj7jUWBbFpdbADC5KPqE+/PIsE5c3jGYPuH+uLs63VBLtTKoQzALHh5MfokZf28J8oZUq0BXSo0A3gFMwCda69fOej0C+ALwt+3ztNZ6qX1LFaLx2JSSxytL97ArLR9PNxf8vdyNfs/eboQHelf2gfbzcqN725b0bx/okBtR6otSSsLcAWoMdKWUCXgfuAZIA7YopRZprZOq7PYc8I3WeoZSqjuwFIiqh3qFcGopOUX8v2V7WZWURVs/T/41LoZb+oTiIj06RAOozRl6PJCstU4BUErNBW4Gqga6Blra1v2Ao/YsUghnl1dUxrs/HODLTUfwcHXhb9d14Z7B0Xi5O2d7t2iaahPooUDV+8vTgP5n7TMdWKmUehTwAa6u7o2UUlOAKQAREREXW6sQTqfUbGHm+kO8vyaZk2YLE/qFM/XqznLHo3AIe111uR2YqbUOA0YCs5VS57y31vojrXWc1jru1LC0zsZkMtGnT5/Kx2uvvVbzF1Vj6NChnN0t85Tc3Fzc3Nz44IMPLqVU4WAWq+aB2dt4bdle4qMDWf7YFbwyupeEuXCY2pyhpwPhVZ6H2bZVdS8wAkBrvUEp5QkEA9n2KLIheXl5VQ6hW1/mzZvHgAEDSEhI4MEHH6y3z7nQcL/CUGGxUlxuqdMgUG8s38tP+3N46eYeTKyHsa2FuFi1OUPfAnRSSkUrpdyBCcCis/Y5AgwHUEp1AzyBHHsW6kjLly9n7Nixlc/Xrl3LqFGjAHjooYeIi4ujR48evPDCC7V6v4SEBN5++23S09NJS0ur3D5r1ix69+5NTEwMEydOBCArK4vRo0cTExNDTEwM69ev59ChQ/Ts2bPy69566y2mT58OGH8ZTJ06lbi4ON555x0WL15M//79iY2N5eqrryYrKwuAoqIi7r77bnr16kXv3r2ZP38+n332WeVwuQAff/wxf/3rX+t0zJzJodxilu/O5PNfD/LKkiQe/mo7t/73Vwa8+gOdn1tGzD9X8vbKfVzMTXYLdqTz4c8p/GlAhIS5cBo1nr5prSuUUo8AKzC6JH6mtU5USr0IbNVaLwKeAD5WSv0V4wLpZH2pt6Auexoyf7+ktzhHm15w/YWbUEpKSujTp0/l82eeeYYxY8YwZcoUiouL8fHx4euvv64cJfGVV14hMDAQi8XC8OHD2bVrF7179z7v+6emppKRkUF8fDzjxo3j66+/5oknniAxMZGXX36Z9evXExwcXDlkbnVD2x4/fvyC30N5eXllc8/x48fZuHEjSik++eQT3njjDd5++21eeukl/Pz8+P333yv3c3Nz45VXXuHNN9/Ezc2Nzz//nA8//LDGw+qsUnKK+Neq/Xy/K6Nym4erS+Wt8IM7BhPq70lKbjH/tyaZUrOFf4zsVuPdjLvSTvD3+buIjw50qkHkhKjV3+O2PuVLz9o2rcp6EjDYvqU5xvmaXEaMGMHixYu57bbbWLJkCW+88QYA33zzDR999BEVFRVkZGSQlJR0wUD/+uuvGTduHGAMmXvPPffwxBNPsGbNGsaOHUtwcDBgDJkL1Q9tW1OgVx0yNy0tjfHjx5ORkUF5eTnR0dEArF69mrlz51buFxAQAMCwYcP4/vvv6datG2azmV69el3ws5zR0RMlvPvDAeZtS8PD1YVHh3Xkuh5taOvnSaCP+zmBbbVqgnzc+XjdQcoqrEy/scd5uxlmF5bywOxtBLfwYMadfe02LooQ9uC8Daw1nEk3tAkTJvDee+8RGBhIXFwcvr6+HDx4kLfeeostW7YQEBDA5MmTzxm+9mwJCQlkZmby5ZdfAnD06FEOHDhwUbVczJC5jz76KI8//jg33XQTa9eurWyaOZ/77ruPV199la5du3L33XdfVF2OlldUxn/X/sHsjYdBw10DI/nz0I41XqR0cVFMv6kHnm4mPvw5hTKzlVdv7XXOaIBlFRYemrOd4yfLmf/QIIJayMXPZqm0AEqOgckDXG0PkweYHB+njq+gkRgyZAj33HMPH3/8cWVzS0FBAT4+Pvj5+ZGVlcWyZcvOOz46wP79+ykqKiI9/fQ15RdeeIGEhATGjBnD6NGjefzxxwkKCqocMre6oW1bt25NdnY2eXl5tGjRgu+///6885FWHe73iy++qNx+zTXX8P777/Of//wHMJpcAgIC6N+/P6mpqWzfvp1du3Zd4lFrGIWlZj5Zd5BP1qVQYrYwpm8Yj13dibCA2o/qp5Ti6eu74uHqwrtrkimrsPDW2BhcbWfgWmteWJjItsPHee+OWHq086uvb0c4C0sFHPsDsnZDViJkJRnL/CPV769cbCHvDq5e4OYFbt7g5mlb2ra5ekGfO6D9ELuXLIF+lrPb0EeMGMFrr72GyWRi1KhRzJw5szIYY2JiiI2NpWvXroSHhzN48IVbnc43ZO748eOZNm0azz77LEOGDMFkMhEbG8vMmTPPO7TttGnTiI+PJzQ0lK5du573M6dPn87YsWMJCAhg2LBhHDx4EDCmoHv44Yfp2bMnJpOJF154gVtvvRWAcePGsXPnzspmGGdUYbGyLjmXBTvSWZmYRYnZwvU92/DEtZ3p2Mq3Tu+plOLxa7vg4WbizRX7KLdY+c/4WNxdXZiz8TBzt6Ty8FUdGNW7nZ2/G1FrZUVQkG48yk+CtoC22h4arFWf29bP2GZ7WCvAXArmk1BhW5pLTj+KsyFnP1jKjM9VJgjuDOHxEHc3tGhtvFZRblvaHpXrpWe+n7kEinNOr3ccXi+HR4bPFecYNWoUf/3rXxk+vOYfuob8N9Na81taPgt2pPP9rqPkFpXj5+XGyF5tuSM+gl5h9jtr/mRdCi8v2cPV3VoxcWAU987cwpDOIXx8V5zcxl+fSvMhLxny/oDjh6EgDfLTT4d4ab59P8/kfvpM2rXKmbSXP7TqBq17QuseRpi7OkcTmwyfK2rlxIkTxMfHExMTU6swbyhH8k7y3Y50FuxM52BuMe6uLlzdrRW39AllSJeQehlO9r4r2uPhZuL5BbtZvSebDiE+/HtCHwlzeyk/CQd/gtwDkHfACPDcA8aZcVXeweAXCgHREDnYWG8ZZizdWxjNHMoFXEyn15WLbZ48U5XttqWLy+nnbl7G602IBLqo5O/vz/79+x1dBgDFZRUs/T2DedvS2HzwGErBgOggHhrSgRG92tCyAUYmnDggEk9XFz7/9RDv3RHbIJ/ZLBTlwJxbIdN2jcY7GII6QudrjWVQJ2MZEGmErqg1pwt0rbXMatJI2Lu5zmrVbDp4jP9tS2PZ7gxOlltoH+zD367rwujYUNr5N/x/7rFx4YyNC695x+ZEaygrNNqJfUKMs+HaOnEEZt0CBUfhts+gwzDwct5rNY2NUwW6p6cneXl5BAUFSag7Oa01eXl5eHpeeKb32sguLOWrTUeYvz2N1GMltPBw5eY+7bjtsjD6RgTIz8KlKC2AomwoyrI9ss9cmkuM7nYubmByM5ogKtfdwFwMJSeg9ITRfl1iW2pjYg66jIQb3oaWtbhQnL0HZt9qvOddCyHi7DH+xKVyqkAPCwsjLS2NnJwmM2pAk+bp6UlYWFidvz6roLRyYuFyi5XBHYJ54pouXNejjQw7Wxcnj8HRHXB0O6TbloUZ5+7n4go+rcC3tXERsPwkWM1Gzw9LhbFusT138wJPf/AOgsAO4OlnXDD09IeyAlj/HrzfH659CfpOOv/ZeuoW+PI248Lj3cuMC43C7pwq0N3c3CrvZBRNV0Z+CR+s/YOELalYrJpbY0P581UdiQ72qfmLhdHkkZ8GufuMs96jOyB9Oxw/eHqfoI4QdYURnL5toUUro6tdi9ZGE4eLne5wjbkdFj9mPH7/H9z0LgS2P3Of5B/g6z8Zn33XAgiIss9ni3M4VbdF0bSlnyhhxtpkvtmShlVrbrssjD8P7UhEUO1vAGo2tDbOgAsyjF4gOfsgd79tecBotjilZRiExkK7vhDaF9r2Mc6iG4rVCjtmwcrnjTP7Yc/CgD8bzTe7v4Vvp0BIV5j4rfGLRVySC3VblEAX9S7/pJk3Vuzlm63GPClj48J5aEgHwgObeZAXZkLKWjh+6Kz2bdt6xVnDSLQMNfpDh3Q5vQzpCj7Bjqj+XAVH4fvHYf8y45dL5+tg7WsQMRBuT2jYXzJNmPRDFw6z7fAx/pKwk6yCUm6Pj+DBoR0IdUBvFadQUQ6pmyB5tdEMkXVqNFFltFG3aG2cwUZ0OLOJJKi9EeAedbsDtsG0bGcEd+K3sPQpWPv/oPP1MPZz6X7YQCTQRb2wWDUf/PQH/1q1n1B/L+Y/NIiYcH9Hl9VwtDYuUhYehbQtRoCn/ATlhcZFyYiBcPV06Hi1cZZtaiJ93JWCnmMgeij8sQZ63NJ0vrdGQAJd2F12YSl//XonvybncWNMO14d3RPfpnpTTn6a0U5ccNToUVL5yARL+en9/CKg91gjwKOvdP6z7UvlE2R8v6JBSaALu/ppfw5PfLOTorIKXh/Ti3Fx4U23H3lxLnw+Ek4cNm5D920Lvm2Ms2/fNuDbzli26g7BnS7uBhwh6kACXdiF2WLlrZX7+PCnFLq09iXh/gF0at0IzkLLTxq9R1r3vLjxrCvKYO6dxgXMe1cZo/AJ4WAS6OKSJR7N5x/f/s5vafnc2T+C50d1x9PNiW8MKs6D/cth7xKjnbeixLh4d9tn4F6Lnjdaw6K/QOpGuO1zCXPhNCTQRZ0VlJr518r9zNpwiABvd/57Z19G9mrr6LKqdywF9i6FfUvhyAZjTOyWoRD7J6OHyU+vw+zRcMfcmscWWfc27JoLVz0HPW9tmPqFqAUJdHHRtNYs+u0oLy/ZQ25RGX/qH8mT13bBz9vJLnwWZMDv82DX18asM2A0rVzxJHQdadyAc6pdu1VXmH+/0Sb+p2+h5Xl+MSUugDUvQa9xcOWTDfFdCFFrEujioiRnF/L8gkQ2pOTRO8yPTyfF0TvM39FlnVZ+0mhK+S0BUn40zsTD4uG6/2eE+PluO+8x2jgzn3snfHotTPwOgjueuU/6NvjuQQjvDzf9n1zkFE5H7hQVtVJSbuH/1hzg43UpeLmZeGpEV26PjzhnImWHsFrh8C/w21xIWgjlReAfAb0nQMwECOpQ+/c6ugPm3AZouPN/xq30YHRP/HiYMWvNfWugRUi9fCtC1ETuFBWXJCO/hImfbiY5u4gxfcN4ZmRXgp1hxvusRNj1jTEoVEEauPsaZ9oxtxtdB+syAFW7WLh3Jcy+Bb64EcbPgbB+kDDBGGr2roUS5sJpSaCLCzqYW8yfPtlEQYmZOff25/JODh43JD/N1i4+D7ITjanEOl4N1/zTGJu7Nr1UahLUAe5ZCXPGwJdjoU0v45fHnfOMeSaFcFIS6OK89mQUMPHTzVi1JmHKAHqG2m8S5lorLzYmCT6y3gjxw78C2jhrHvmWcUZeH4NTtWwLdy+FhNuNzx75lvGLQwgnJoEuqrXt8HHu/nwz3u6uzLlvAB1btai/DyvOMwasyk81ZnY/Nct7fpoxU84pQR1h6DPQ67aLaxevKy9/4+JoViKEXVb/nyfEJZJAF+dYdyCHKbO20bqlB7Pv7V9/w9we3QGbPoLd88FSZmzzCrDN6h5m9CY5Nct7SBdoG9PwPUvcPCXMRaMhgS7OsHx3Jn9J2EH7EB9m3RtPK99LnzP0DBXlRk+UzR8aoxC6+Rg39/S9yxgi1h5t4EI0UxLootK8ran8ff4uYsL9mTk53r43ChVkwNbPYNtMKM425qcc8Rr0ucOYp1IIcckk0AUA87el8bf/7eLyjsF8OPEyfDzs9KNx8hj8/CZs/tiYdLjzdRB/P7QfZr95LYUQgAS6AErNFl5bvpfLIgP4dHIcHq52GFjLYoYtnxhTkJUVGM0ql//13AmEhRB2I4Eu+G5HOjmFZfx7XJ9LD3OtYd8yWPU85CVD+6Fw7SvQpqddahVCnJ8EejNnsWo+/OkPeoX6Mbhj0KW9WcYuWPksHPwZgjrBHd9Ap2tlzBMhGogEejO3fHcmh/JOMuPOvnWfWSgrCTa8Bzu/MvpuX/8mxN0tc0kK0cAk0JsxrTUzfkqmfbAP1/Zoc3FfbLXAgZWwcQYc/AlcPWHAn2HI32oeT1wIUS8k0JuxX5Jz2Z1ewOtjetV+1MTSfNjxpdGP/PghY97M4dOg72RjYmAhhMNIoDdj//3xD1q39OCW2NCadz52EDb+12hWKS8y7uIc/gJ0u1GaVoRwErUKdKXUCOAdwAR8orV+rZp9xgHTAQ38prW+w451CjvbceQ4G1LyeHZktwv3bNEats+CZX83+pH3HAP9Hzg9TrgQwmnUGOhKKRPwPnANkAZsUUot0lonVdmnE/AMMFhrfVwp1aq+ChbVM1us/LAniyGdW+HlXnPXww9++oOWnq7c3j/i/DuV5sPiqZD4LURfCbd8YIytIoRwSrW5VS8eSNZap2ity4G5wM1n7XM/8L7W+jiA1jrbvmWKmvxzcSIPztnOpM82U1BqvuC+ydmFrEjMYtKgKFqc747QtG3wwRXGuCvDnoeJCyTMhXBytQn0UCC1yvM027aqOgOdlVK/KqU22ppozqGUmqKU2qqU2pqTk1O3isU5vtx0mDkbj3BVlxB2pB7n9o82kldUdt79P/wpBU83FyYPijr3RasVfn0HPrvWmI/z7mXGZMgudrh7VAhRr+w1mIYr0AkYCtwOfKyU8j97J631R1rrOK11XEiITONlD5tS8nhhYSJDu4TwyaR+fHxXHH/kFDHuww0cPVFyzv5HT5SwYGc6E/pFEHT2NHJFOfDlbbBqGnS5Hh5cBxH9G+g7EUJcqtoEejoQXuV5mG1bVWnAIq21WWt9ENiPEfCiHqUdP8mfv9xORJA370yIxeSiGNqlFbPv7U92QRljP9jAwdziM77mk3UHsWq474roM9/s8Hr4YDAc+gVueBvGzZb+5EI0MrUJ9C1AJ6VUtFLKHZgALDprnwUYZ+copYIxmmBS7FemONvJ8gqmzNpGeYWVj++Kw8/rdNfBflGBJEwZQInZwtgPNrAnowCA48XlJGw+ws0x7QgLqDLu+JFNxkz3Hr5w/xrod5/cri9EI1RjoGutK4BHgBXAHuAbrXWiUupFpdRNtt1WAHlKqSTgR+BvWuu8+iq6udNa87d5u9iTWcC7t8fSIeTc6eF6hvrxzQMDcTMpxn+4gW2Hj/PFhkOUmC08MKTK9G1HdxjNLL5tYPJSGURLiEZMaa0d8sFxcXF669atDvnsxu69NQd4a+V+nr6+Kw8OufDcmmnHTzLx081k5pfialL0jw7kk0n9jBezEmHmDeDuC/csM6Z9E0I4NaXUNq11XHWvyQwDjcyqpCzeWrmfW/q044Erax5bPCzAm28eGEhkkDeFpRU8NNT2CyA3GWbdYozBMmmRhLkQTYDc+t+I7M8qZOrcHfQO8+O1Mb1rPTpiiK8H8x4cyL7MQi6LDDTGYJl1k9Et8a4lEBhd43sIIZyfBHojkVtUxv2ztuLl7sqHEy/D0+3i+oX7eroRFxUI+enwxU1QXgyTl0BI53qqWAjR0CTQG4GCUjN3fbqZrIJSvrp/AG39vM7d6egOY7wVr0Bo2xva9DIe/pGne6wUZcOsm415PictlAugQjQxEuhOrqTcwn0zt3Igu5BPJvWjb0Q1fcOzEmH2aDB5GOOvHFhhNKcAeLQ8He4H10FBOvzpWwi9rGG/ESFEvZNAd2Jmi5WHv9rOlsPHeHdCLEM6V3N3bdWLm3cvM9rDzSWQnWRMCZf5u/HYPgtQMOEriBzY0N+KEKIBSKA7KatV8+S831izN5tXRvfkxph25+50voubbl7GGXjVs3CrBSxmcPNskPqFEA1PAt0Jaa2ZvjiRhTuP8rfrunBn/8hzd7rYi5suJhlgS4gmTgLdCf171X5mbTjMlCvb8+eh1dw4JBc3hRDVkEB3Mp/+cpB31yQzPi6cZ67vem5f85PHjDZzubgphDiLBLoT+XZ7Gi99n8SIHm14ZXTPc8O8NB/m3Ap5yXDH13JxUwhxBgl0J5FdWMpzC3YzoH0g79zeB1fTWaMylByHryYYPVbGfwkdrnJMoUIIpyWB7iTeWX2A8gorr93a+9xJm48fgi/HwrGDMOZT6FLthFBCiGZOAt0JJGcXMXdLKhMHRBIV7HPmi2nbIGE8WMph4ncQfYVjihRCOD0ZbdEJvLF8L15uJh4d1vHMF/YsNoa3dfOGe1dLmAshLkgC3cG2HDrGyqQsHhzS/vQcn1rDhvfh64nQugfc94MMoiWEqJE0uTiQ1ppXl+6hdUsP7r3cNra5pQKWPw1bPoZuN8GtHxl3fgohRA0k0B1o+e5Mdhw5wetjeuHlboKyIph/L+xfDoMehatfBBf5I0oIUTsS6A5itlh5ffleOrduwZi+YVB+EmbfAunb4Ia3jYmahRDiIkigO0jC5iMcyjvJZ5PjcFXAdw9A2lYY9wV0v9nR5QkhGiH5e94BCkvNvLP6AAPaB3JVl1aw5kXYswiufVnCXAhRZ3KG7gAf/ZxCXnE5n13fDbXzS/jl33DZ3TDwYUeXJoRoxOQMvYFlFZTy8boUboxpR0zFLlj8GLS/Cka+eXqqOCGEqAMJ9Ab271X7sVg1z/QzGf3MgzrC2JlgcnN0aUKIRk4CvQHtzyrkm62pTInzp92Su8DF1Rg10cvf0aUJIZoAaUNvQP9ZvR9/d83UvH9CwVGYtBgCohxdlhCiiZBAbyCpx06yfHcGi0Ln4Ja20Rg1MaK/o8sSQjQh0uTSQGZtOMS9pmX0zF0GVz0LvW5zdElCiCZGztAbQFFZBSu2JLLSbT50GgFX/s3RJQkhmiA5Q28A87elMbnif3hQBte8JN0ThRD1QgK9nlmtmmXrNjLRdTWqz50yDK4Qot5IoNezH/dlM7ZoNi4uJhj6jKPLEUI0YRLo9WzV2jWMNv0K/aeAX6ijyxFCNGES6PVob2YBVx/9ELNrC0xXPO7ocoQQTZwEej36ccUirjbtwDroMfAOdHQ5QogmTgK9nuQVlhKf8g4FbsF4XS6jKAoh6p8Eej3ZsGwOl6n9lA76G7h7O7ocIUQzUKtAV0qNUErtU0olK6WevsB+Y5RSWikVZ78SG5+y8nK6Jf2HDNcwWl0pU8kJIRpGjYGulDIB7wPXA92B25VS3avZzxd4DNhk7yIbm9+XfkgHUjk+4Ckwyc24QoiGUZsz9HggWWudorUuB+YC1c2T9hLwOlBqx/oaHW0uIWLXO+xz6Ui3YRMdXY4QohmpTaCHAqlVnqfZtlVSSvUFwrXWSy70RkqpKUqprUqprTk5ORddbGNwZMV7tLLmkHbZ31EucolCCNFwLjlxlFIuwL+AJ2raV2v9kdY6TmsdFxIScqkf7XxK8wna/i4b6M2ga8Y4uhohRDNTm0BPB8KrPA+zbTvFF+gJrFVKHQIGAIua44XRE798SgtrAQd6PY6Xu8nR5QghmpnaXLHbAnRSSkVjBPkE4I5TL2qt84HgU8+VUmuBJ7XWW+1bqvM7ues7Uq1RXHv19Y4uRQjRDNV4hq61rgAeAVYAe4BvtNaJSqkXlVI31XeBjUZhFm0Kfuc3n8tp4+fp6GqEEM1QrfrUaa2XAkvP2jbtPPsOvfSyGp+ypCV4oCntOMLRpQghminpJG0nRTsXkGltReeeMk+oEMIxpF+dPZQW4Je5nh90P/pFBzm6GiFEMyWBbg/Jq3HVZo60ukp6twghHEaaXOygLHExhbolwd2ucHQpQohmTM7QL1VFOS4HVrLa0peBnVo7uhohRDMmgX6pDq3DraKIdab+xIT5OboaIUQzJoF+qfYu4SSeWKOuxNUkh1MI4TiSQJfCasWyZwlrLb3p10kmgBZCOJYE+qU4ugNTcSYrLXEM7hhc8/5CCFGPJNAvxd7vseDCb1796dy6haOrEUI0cxLol0DvXcJW1YPenSJRSjm6HCFEMyeBXle5B1C5+1hS3pfBHaS5RQjheBLodbXXmJxplSWOwZ0k0IUQjid3itbV3iUcdO+Mh084of5ejq5GCCHkDL1OCjMhbTOLy/oySHq3CCGchAR6XewzhoZfLO3nQggnIoFeF3uXcMIznGRCGdhBhssVQjgHCfSLVVoAKT/xsyme7m39CPRxd3RFQggBSKBfvORVYDXzVX5vuTtUCOFUJNAv1t4llHsGsbmiA4OkuUUI4UQk0C9GRRnsX0mS72BMJhPx0YGOrkgIISpJoF+Mg+ugvJAFpbHERgTg7S7d+IUQzkMC/WLsWYh2b0FCbnvpriiEcDoS6LVlqYA933O09VDKtBuDO0r7uRDCuUig19bhX6HkGGtdBuLjbiIm3N/RFQkhxBmkEbi29iwCN29m53aif/tA3GS6OSGEk5FUqg2rFfYspiTyKvbmVUh3RSGEU5JAr43UTVCUxe9+QwHkdn8hhFOSQK+NPYvA5MH3Jb3x9XSla5uWjq5ICCHOIYFeE60haRF0GMYvqaX0iwrE5CLTzQkhnI8Eek3St0NBGoXtryclp5h+UXJ3qBDCOUmg12TPQnBxZaNbfwC53V8I4bQk0C/kVHNL9BDWH7Xg6eZCr1A/R1clhBDVkkC/kKzdcPwgdL+JLYeO0SfcH3dXOWRCCOck6XQhSQtBuVAUfR1JRwuIj5buikII5yWBfiFJiyByMFtzTFg1xMsFUSGEE5NAP5/svZC7D7rfzOaDx3B1UfSN9Hd0VUIIcV61CnSl1Ail1D6lVLJS6ulqXn9cKZWklNqllPpBKRVp/1Ib2J5FxrLrKLYcOkaPUD8Z/1wI4dRqDHSllAl4H7ge6A7crpTqftZuO4A4rXVv4H/AG/YutMElLYLw/pR6teK31HziowIcXZEQQlxQbc7Q44FkrXWK1rocmAvcXHUHrfWPWuuTtqcbgTD7ltnAjqVA1u/Q7SZ+Sz1BucUqF0SFEE6vNoEeCqRWeZ5m23Y+9wLLqntBKTVFKbVVKbU1Jyen9lU2tCRbc4utuyJAXKScoQshnJtdL4oqpf4ExAFvVve61vojrXWc1jouJCTEnh9tX0kLoV0s+Eew+dBxurT2JcDH3dFVCSHEBdUm0NOB8CrPw2zbzqCUuhp4FrhJa11mn/Ic4EQqHN0O3W6iwmJl26Fj9IuWs3MhhPOrTaBvAToppaKVUu7ABGBR1R2UUrHAhxhhnm3/MhvQnsXGsvvN7MkopLjcIgNyCSEahRoDXWtdATwCrAD2AN9orROVUi8qpW6y7fYm0AKYp5TaqZRadJ63c357FkHrnhDUgc229nMZkEsI0RjUqmO11nopsPSsbdOqrF9t57ocozgPjmyEoUZX+80H8wgP9KKtn5eDCxNCiJrJnaJVHdkAaIgegtaaLYeOEx8l3RWFEI2DBHpVh9eDyQNC+/JHThHHisuJlwuiQohGQgK9qsO/Qlg/cPVg88HjAHJBVAjRaEign1JWCJm7IHIQAFsOHSO4hQfRwT4OLkwIIWpHAv2U1E2grZWBvvngMeKjA1BKJoQWQjQOEuinHF4PLq4QHk/6iRLST5RIc4sQolGRQD/l8Hpo2wfcfdhyUPqfCyEaHwl0AHMJpG+rbG7ZdPAYvh6udG3T0sGFCSFE7UmggxHmlnKIHAwYF0TjogIwuUj7uRCi8ZBAB6O5BQUR/ckrKiM5u4h+0twihGhkJNDB6H/eugd4BbDlkNH/XCaEFkI0NhLoFjOkbj6j/7mHqwu9wvwcXJgQQlwcCfSM38B88oz+533C/fFwNTm4MCGEuDgS6Id/NZYRg8gvMZN4NF+6KwohGiUJ9MMbIKgj+LZmzd4srBqu6trK0VUJIcRFa96BbrXCkfWVzS0rdmfRuqUHfcL8HVuXEELUQfMO9OwkKM2HyMGUlFv4aX8O13Zvg4v0PxdCNELNO9APrzeWkYP4+UAOJWYL1/Vo49iahBCijpp5oP8KfuHgH8GKxEz8vNzo314uiAohGqfmG+haG2fokYMwW6z8sCeb4d1a4WZqvodECNG4Nd/0yvsDirMhchCbUo6RX2KW5hYhRKPWfAO9Sv/zFYmZeLmZuLJTiGNrEkKIS9CMA309eAdjDezIisRMhnQOwctd7g4VQjRezTvQIwexMz2f7MIyruvZ2tEVCSHEJWmegX4iFfKPQORgViRm4uqiGNZVAl0I0bg1z0A/sgEAHTmQFbszGdghCD8vNwcXJYQQl6Z5BvrhX8HDj/06kkN5J6V3ixCiSWimgb4eIgawPCkHpeDa7tLcIoRo/JpfoBflQO5+iDS6K/aNCKBVS09HVyWEEJes+QX6EWP8lqyAy0jKKOC6HnJ2LoRoGppfoB9eD27eLMk1xjyX9nMhRFPRvAL95DHYtxTC4li2J4+ubXyJDPJxdFVCCGEXzSfQSwtgzhgozORE3FS2Hj4uZ+dCiCaleQR6eTF8NR4yd8HYL1ha1AmtYURPCXQhRNPR9APdXApz74TUjXDrR9B1JCsSM4kI9KZrG19HVyeEEHbTtAPdYoZ5kyHlR7j5feg5hoJSM+v/yOW6Hq1RSqaaE0I0HU030K0W+PZ+2L8MRr4Ffe4A4Me92ZgtWppbhBBNTq0CXSk1Qim1TymVrJR6uprXPZRSX9te36SUirJ7pRfDaoWFj0Did3DtyxB/P4WlZtYdyGH2hsOE+HoQGx7g0BKFEMLeXGvaQSllAt4HrgHSgC1KqUVa66Qqu90LHNdad1RKTQBeB8bXR8E10hq99EnUb1+xu/PDzMkYwo5//8z+7EK0Nnb5+4iuuLhIc4sQommpMdCBeCBZa50CoJSaC9wMVA30m4HptvX/Ae8ppZTWpyLUfrbPe4OopPfRuGBFYa2y1MoFF22lnc7kg4obeW3XIPy8MomN8Gdkr7bERvgTE+4vIysKIZqk2gR6KJBa5Xka0P98+2itK5RS+UAQkFt1J6XUFGAKQERERJ0K1oHtSfS9AoUFFzRKn4p0jdLGtp2+txLU9yF+iAokOshHzsaFEM1CbQLdbrTWHwEfAcTFxdXp7P2y4bfB8NvsWpcQQjQFtbkomg6EV3keZttW7T5KKVfAD8izR4FCCCFqpzaBvgXopJSKVkq5AxOARWftswiYZFu/DVhTH+3nQgghzq/GJhdbm/gjwArABHymtU5USr0IbNVaLwI+BWYrpZKBYxihL4QQogHVqg1da70UWHrWtmlV1kuBsfYtTQghxMVouneKCiFEMyOBLoQQTYQEuhBCNBES6EII0UQoR/UuVErlAIfr+OXBnHUXqhOR2upGaqsbqa1uGnNtkVrrkOpecFigXwql1FatdZyj66iO1FY3UlvdSG1101RrkyYXIYRoIiTQhRCiiWisgf6Rowu4AKmtbqS2upHa6qZJ1tYo29CFEEKcq7GeoQshhDiLBLoQQjQRjS7Qa5qw2pGUUoeUUr8rpXYqpbY6uJbPlFLZSqndVbYFKqVWKaUO2JYOmSn7PLVNV0ql247dTqXUSAfVFq6U+lEplaSUSlRKPWbb7vBjd4HaHH7slFKeSqnNSqnfbLX907Y92jZxfLJtInl3J6ptplLqYJXj1qeha6tSo0kptUMp9b3ted2Om9a60Twwhu/9A2gPuAO/Ad0dXVeV+g4BwY6uw1bLlUBfYHeVbW8AT9vWnwZed6LapgNPOsFxawv0ta37AvuB7s5w7C5Qm8OPHaCAFrZ1N2ATMAD4Bphg2/4B8JAT1TYTuM3RP3O2uh4HvgK+tz2v03FrbGfolRNWa63LgVMTVouzaK1/xhibvqqbgS9s618AtzRkTaecpzanoLXO0Fpvt60XAnsw5sx1+LG7QG0Opw1FtqdutocGhmFMHA+OO27nq80pKKXCgBuAT2zPFXU8bo0t0KubsNopfqBtNLBSKbXNNiG2s2mttc6wrWcCrR1ZTDUeUUrtsjXJOKQ5qCqlVBQQi3FG51TH7qzawAmOna3ZYCeQDazC+Gv6hNa6wraLw/6/nl2b1vrUcXvFdtz+rZTycERtwH+ApwCr7XkQdTxujS3Qnd3lWuu+wPXAw0qpKx1d0Plo4285pzlLAWYAHYA+QAbwtiOLUUq1AOYDU7XWBVVfc/Sxq6Y2pzh2WmuL1roPxrzD8UBXR9RRnbNrU0r1BJ7BqLEfEAj8vaHrUkqNArK11tvs8X6NLdBrM2G1w2it023LbOA7jB9qZ5KllGoLYFtmO7ieSlrrLNt/OivwMQ48dkopN4zA/FJr/a1ts1Mcu+pqc6ZjZ6vnBPAjMBDwt00cD07w/7VKbSNsTVhaa10GfI5jjttg4Cal1CGMJuRhwDvU8bg1tkCvzYTVDqGU8lFK+Z5aB64Fdl/4qxpc1cm8JwELHVjLGU6Fpc1oHHTsbO2XnwJ7tNb/qvKSw4/d+WpzhmOnlApRSvnb1r2AazDa+H/EmDgeHHfcqqttb5Vf0AqjjbrBj5vW+hmtdZjWOgojz9Zore+krsfN0Vd363A1eCTG1f0/gGcdXU+Vutpj9Lr5DUh0dG1AAsaf32aMNrh7MdrmfgAOAKuBQCeqbTbwO7ALIzzbOqi2yzGaU3YBO22Pkc5w7C5Qm8OPHdAb2GGrYTcwzba9PbAZSAbmAR5OVNsa23HbDczB1hPGUQ9gKKd7udTpuMmt/0II0UQ0tiYXIYQQ5yGBLoQQTYQEuhBCNBES6EII0URIoAshRBMhgS6EEE2EBLoQQjQR/x8hmu+cL5k1TAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프로 loss 표기\n",
    "#!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_train_loss, label='Train Loss')\n",
    "#plt.plot(list_train_acc, label='Train Accuracy')\n",
    "#plt.plot(list_validation_acc, label='Eval Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list_train_acc, label='Train Accuracy')\n",
    "plt.plot(list_validation_acc, label='Eval Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59891576-ff4e-4826-b5b3-90468005a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 전체모델 저장\n",
    "#save_model(model, tokenizer, OUTPATH, epochs, learning_rate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111fac71-a6d8-4eb6-bc77-e1bca6b19225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
