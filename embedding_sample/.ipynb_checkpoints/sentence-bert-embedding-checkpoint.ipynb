{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636ee32c-db97-4810-8084-2d11566e7226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:bwdataset_2022-04-13.log\n",
      "logfilepath:qnadataset_2022-04-13.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "logfilepath:../../log/sbert-embedding_2022-04-13.log\n"
     ]
    }
   ],
   "source": [
    "#=============================================================================\n",
    "# sentence-bert를 가지고 유사도 측정하는 예제임\n",
    "#SemanticSearch.py는 주어진 문장과 유사한 문장을 찾는 작업입니다.\n",
    "# 참고 소스 : https://github.com/BM-K/KoSentenceBERT-ETRI\n",
    "#=============================================================================\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "from os import sys\n",
    "sys.path.append('..')\n",
    "from myutils import GPU_info, seed_everything, mlogging\n",
    "\n",
    "device = GPU_info()\n",
    "seed_everything(111)\n",
    "logger = mlogging(loggername='sbertembedding', logfilename='../../log/sbert-embedding')\n",
    "\n",
    "model_path = \"../../model/sbert/sbert-ts2022-distiluse-7-paraphrase-multilingual-mpnet-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a50cc6-0bbd-489a-86be-358f22dc6c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embedder = SentenceTransformer(model_path)\n",
    "embedder.to(device)\n",
    "print(embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a24601e-1b52-4547-bad0-aa282da38bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Corpus with example sentences\n",
    "corpus = ['오늘은 날씨가 흐리고 비가 온다',\n",
    "          '식당에서 밥을 먹었다',\n",
    "          '관광 버스를 타고 여행을 한다',\n",
    "          '낚시를 해서 물고기를 많이 잡았다',\n",
    "          '동물원에서 호랑이를 보았다',\n",
    "          '선거일에는 투표하러 가야 한다',\n",
    "          '마트에 가서 맛있는 배를 샀다',\n",
    "          '도서관에서 시험 공부 하고 있다',\n",
    "          '야구장에 가서 열심히 응원 했다']\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['구름 많고 매우 춥다',\n",
    "           '비행기를 타고 간다',\n",
    "           '어제 산에서 사슴를 봤다']\n",
    "'''\n",
    "'''\n",
    "corpus = ['정치',\n",
    "          '경제',\n",
    "          '여행',\n",
    "          '선거',\n",
    "          '날씨',\n",
    "          '서울',\n",
    "          '축구',\n",
    "          'IT',\n",
    "          '금융']\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['가장 가보고 싶은 여행지는?',\n",
    "           '내 지역 투표장은 어디?',\n",
    "           '요즘 가장 핫한 증권 소식은?']\n",
    "'''\n",
    "'''\n",
    "corpus = ['서울은 대한민국에 수도이며, 정치 경제 중심지이다',\n",
    "          '내년 경제 성장은 4%대 성장을 이룰거라 예상된다',\n",
    "          '프랑스 파리는 전세계 관광객들이 매년 찾는 관광도시이다',\n",
    "          '올해에는 대통령 선거와 지방선거가 동시에 열린다',\n",
    "          '오늘 날씨는 비가 내리고 매우 춥다',\n",
    "          '손홍민이 영국 프리미어 축구 경기에서 11번째 골을 넣었다',\n",
    "          '건조한 날씨에 산불을 조심해야 한다',\n",
    "          '윈도우11 OS에 검색 기능을 강화 하였다',\n",
    "          '한국은행은 올해 하반기 금리를 동결했다',\n",
    "          'Going on a trip',\n",
    "          'it is raining',\n",
    "          'stock market opened',\n",
    "          'There is a voting for the class president election'\n",
    "         ]\n",
    "          \n",
    "\n",
    "queries = ['여행',\n",
    "           '투표',\n",
    "           '증권',\n",
    "           'IT']\n",
    "'''\n",
    "\n",
    "corpus = [\n",
    "        'i love you', \n",
    "        'i am very happy', \n",
    "        'The weather is nice',\n",
    "        'You do not have to do that. It is okay',\n",
    "        'We expect the renovation to be finished by tomorrow evening.',\n",
    "        'Thank you. We won’t make you regret it.',\n",
    "        'Then I will see you at 10 a.m. tomorrow.',\n",
    "        'The print cartridge is exhausted. Should I order more?'\n",
    "         ]\n",
    "\n",
    "queries = [\n",
    "        '난 널 사랑해', \n",
    "        '난 매우 행복해', \n",
    "        '날씨가 좋다',\n",
    "        '안 그래도 되는데 뭐. 괜찮아.',\n",
    "        '내일 저녁까지 보수 공사가 끝날 것으로 예상합니다.',\n",
    "        '감사합니다. 후회 없는 결정이 될 겁니다.',\n",
    "        '그러면 오전 10시에 보도록 하죠. 내일 뵙겠습니다.',\n",
    "        '프린트 카트리지가 다 떨어졌습니다. 더 주문할까요?'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e98000-ec80-4ee1-b697-a498caae1534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 15:59:25,132 - sbertembedding - INFO - >>모델명: ../../model/sbert/sbert-ts2022-distiluse-7-paraphrase-multilingual-mpnet-base-v2\n",
      "2022-04-13 15:59:26,119 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-04-13 15:59:26,120 - sbertembedding - INFO - Query:난 널 사랑해\n",
      "2022-04-13 15:59:26,121 - sbertembedding - INFO - i love you (Score: 0.9526)\n",
      "2022-04-13 15:59:26,122 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.5408)\n",
      "2022-04-13 15:59:26,123 - sbertembedding - INFO - i am very happy (Score: 0.5379)\n",
      "2022-04-13 15:59:26,123 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.4255)\n",
      "2022-04-13 15:59:26,124 - sbertembedding - INFO - The weather is nice (Score: 0.3461)\n",
      "2022-04-13 15:59:26,134 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-04-13 15:59:26,135 - sbertembedding - INFO - Query:난 매우 행복해\n",
      "2022-04-13 15:59:26,136 - sbertembedding - INFO - i am very happy (Score: 0.9615)\n",
      "2022-04-13 15:59:26,136 - sbertembedding - INFO - i love you (Score: 0.5452)\n",
      "2022-04-13 15:59:26,137 - sbertembedding - INFO - The weather is nice (Score: 0.5357)\n",
      "2022-04-13 15:59:26,138 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.3694)\n",
      "2022-04-13 15:59:26,138 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.3461)\n",
      "2022-04-13 15:59:26,149 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-04-13 15:59:26,149 - sbertembedding - INFO - Query:날씨가 좋다\n",
      "2022-04-13 15:59:26,150 - sbertembedding - INFO - The weather is nice (Score: 0.9353)\n",
      "2022-04-13 15:59:26,151 - sbertembedding - INFO - i am very happy (Score: 0.5010)\n",
      "2022-04-13 15:59:26,152 - sbertembedding - INFO - i love you (Score: 0.3543)\n",
      "2022-04-13 15:59:26,152 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.3139)\n",
      "2022-04-13 15:59:26,153 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.2827)\n",
      "2022-04-13 15:59:26,163 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-04-13 15:59:26,164 - sbertembedding - INFO - Query:안 그래도 되는데 뭐. 괜찮아.\n",
      "2022-04-13 15:59:26,165 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.6357)\n",
      "2022-04-13 15:59:26,165 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.5824)\n",
      "2022-04-13 15:59:26,166 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.4066)\n",
      "2022-04-13 15:59:26,167 - sbertembedding - INFO - The weather is nice (Score: 0.3897)\n",
      "2022-04-13 15:59:26,167 - sbertembedding - INFO - i am very happy (Score: 0.3723)\n",
      "2022-04-13 15:59:26,178 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-04-13 15:59:26,178 - sbertembedding - INFO - Query:내일 저녁까지 보수 공사가 끝날 것으로 예상합니다.\n",
      "2022-04-13 15:59:26,179 - sbertembedding - INFO - We expect the renovation to be finished by tomorrow evening. (Score: 0.8999)\n",
      "2022-04-13 15:59:26,180 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.5443)\n",
      "2022-04-13 15:59:26,180 - sbertembedding - INFO - The print cartridge is exhausted. Should I order more? (Score: 0.3329)\n",
      "2022-04-13 15:59:26,181 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.2985)\n",
      "2022-04-13 15:59:26,182 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.2384)\n",
      "2022-04-13 15:59:26,192 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-04-13 15:59:26,193 - sbertembedding - INFO - Query:감사합니다. 후회 없는 결정이 될 겁니다.\n",
      "2022-04-13 15:59:26,194 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.8290)\n",
      "2022-04-13 15:59:26,195 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.5436)\n",
      "2022-04-13 15:59:26,195 - sbertembedding - INFO - i love you (Score: 0.5274)\n",
      "2022-04-13 15:59:26,196 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.4773)\n",
      "2022-04-13 15:59:26,197 - sbertembedding - INFO - i am very happy (Score: 0.3962)\n",
      "2022-04-13 15:59:26,207 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-04-13 15:59:26,207 - sbertembedding - INFO - Query:그러면 오전 10시에 보도록 하죠. 내일 뵙겠습니다.\n",
      "2022-04-13 15:59:26,208 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.8882)\n",
      "2022-04-13 15:59:26,209 - sbertembedding - INFO - We expect the renovation to be finished by tomorrow evening. (Score: 0.5730)\n",
      "2022-04-13 15:59:26,209 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.3498)\n",
      "2022-04-13 15:59:26,210 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.2779)\n",
      "2022-04-13 15:59:26,211 - sbertembedding - INFO - i love you (Score: 0.2620)\n",
      "2022-04-13 15:59:26,221 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-04-13 15:59:26,222 - sbertembedding - INFO - Query:프린트 카트리지가 다 떨어졌습니다. 더 주문할까요?\n",
      "2022-04-13 15:59:26,223 - sbertembedding - INFO - The print cartridge is exhausted. Should I order more? (Score: 0.7627)\n",
      "2022-04-13 15:59:26,223 - sbertembedding - INFO - We expect the renovation to be finished by tomorrow evening. (Score: 0.3019)\n",
      "2022-04-13 15:59:26,224 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.2737)\n",
      "2022-04-13 15:59:26,225 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.2549)\n",
      "2022-04-13 15:59:26,226 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.2247)\n",
      "2022-04-13 15:59:26,226 - sbertembedding - INFO - \n",
      "\n",
      "\n",
      "2022-04-13 15:59:26,228 - sbertembedding - INFO - >>처리시간: 1.0958\n",
      "2022-04-13 15:59:26,228 - sbertembedding - INFO - \n",
      "\n",
      "======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus_embed_type:<class 'torch.Tensor'>\n",
      "corpus_embed_shape:torch.Size([8, 768])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "logger.info(f'>>모델명: {model_path}')\n",
    "\n",
    "# corpus 임베딩\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "print(f'corpus_embed_type:{type(corpus_embeddings)}')\n",
    "print(f'corpus_embed_shape:{corpus_embeddings.shape}')\n",
    "\n",
    "# query 임베딩 하면서 corpus와 비교하여 유사도 출력\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = 5\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "\n",
    "    #We use np.argpartition, to only partially sort the top_k results\n",
    "    top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    "    logger.info(f\"\\n\\n======================\")\n",
    "    logger.info(f\"Query:{query}\")\n",
    "    #print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for idx in top_results[0:top_k]:\n",
    "        logger.info(f\"{corpus[idx].strip()} (Score: %.4f)\" % (cos_scores[idx]))\n",
    "\n",
    "logger.info(f\"\\n\\n\")\n",
    "logger.info(f'>>처리시간: {time.time()-start:.4f}')\n",
    "logger.info(f\"\\n\\n======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fd4928-458b-4509-a204-3ec5fe459b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
