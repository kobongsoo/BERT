{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636ee32c-db97-4810-8084-2d11566e7226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:bwdataset_2022-03-31.log\n",
      "logfilepath:qnadataset_2022-03-31.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "logfilepath:sbertembedding_2022-03-31.log\n"
     ]
    }
   ],
   "source": [
    "#=============================================================================\n",
    "# sentence-bert를 가지고 유사도 측정하는 예제임\n",
    "#SemanticSearch.py는 주어진 문장과 유사한 문장을 찾는 작업입니다.\n",
    "# 참고 소스 : https://github.com/BM-K/KoSentenceBERT-ETRI\n",
    "#=============================================================================\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "from os import sys\n",
    "sys.path.append('..')\n",
    "from myutils import GPU_info, seed_everything, mlogging\n",
    "\n",
    "device = GPU_info()\n",
    "seed_everything(111)\n",
    "logger = mlogging(loggername='sbertembedding', logfilename='sbertembedding')\n",
    "\n",
    "#model_path = '../model/sbert/distiluse-base-multilingual-cased-v2'\n",
    "model_path = \"../model/sbert/sbert-ts2022-03-31-dsitiluse-2\"\n",
    "#model_path = '../model/bmc_fpt_kowiki20200920.train-sbert-tsmodel-0310'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a50cc6-0bbd-489a-86be-358f22dc6c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embedder = SentenceTransformer(model_path)\n",
    "embedder.to(device)\n",
    "print(embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a24601e-1b52-4547-bad0-aa282da38bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Corpus with example sentences\n",
    "corpus = ['오늘은 날씨가 흐리고 비가 온다',\n",
    "          '식당에서 밥을 먹었다',\n",
    "          '관광 버스를 타고 여행을 한다',\n",
    "          '낚시를 해서 물고기를 많이 잡았다',\n",
    "          '동물원에서 호랑이를 보았다',\n",
    "          '선거일에는 투표하러 가야 한다',\n",
    "          '마트에 가서 맛있는 배를 샀다',\n",
    "          '도서관에서 시험 공부 하고 있다',\n",
    "          '야구장에 가서 열심히 응원 했다']\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['구름 많고 매우 춥다',\n",
    "           '비행기를 타고 간다',\n",
    "           '어제 산에서 사슴를 봤다']\n",
    "'''\n",
    "'''\n",
    "corpus = ['정치',\n",
    "          '경제',\n",
    "          '여행',\n",
    "          '선거',\n",
    "          '날씨',\n",
    "          '서울',\n",
    "          '축구',\n",
    "          'IT',\n",
    "          '금융']\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['가장 가보고 싶은 여행지는?',\n",
    "           '내 지역 투표장은 어디?',\n",
    "           '요즘 가장 핫한 증권 소식은?']\n",
    "'''\n",
    "'''\n",
    "corpus = ['서울은 대한민국에 수도이며, 정치 경제 중심지이다',\n",
    "          '내년 경제 성장은 4%대 성장을 이룰거라 예상된다',\n",
    "          '프랑스 파리는 전세계 관광객들이 매년 찾는 관광도시이다',\n",
    "          '올해에는 대통령 선거와 지방선거가 동시에 열린다',\n",
    "          '오늘 날씨는 비가 내리고 매우 춥다',\n",
    "          '손홍민이 영국 프리미어 축구 경기에서 11번째 골을 넣었다',\n",
    "          '건조한 날씨에 산불을 조심해야 한다',\n",
    "          '윈도우11 OS에 검색 기능을 강화 하였다',\n",
    "          '한국은행은 올해 하반기 금리를 동결했다',\n",
    "          'Going on a trip',\n",
    "          'it is raining',\n",
    "          'stock market opened',\n",
    "          'There is a voting for the class president election'\n",
    "         ]\n",
    "          \n",
    "\n",
    "queries = ['여행',\n",
    "           '투표',\n",
    "           '증권',\n",
    "           'IT']\n",
    "'''\n",
    "\n",
    "corpus = [\n",
    "        'i love you', \n",
    "        'i am very happy', \n",
    "        'The weather is nice',\n",
    "        'You do not have to do that. It is okay',\n",
    "        'We expect the renovation to be finished by tomorrow evening.',\n",
    "        'Thank you. We won’t make you regret it.',\n",
    "        'Then I will see you at 10 a.m. tomorrow.',\n",
    "        'The print cartridge is exhausted. Should I order more?'\n",
    "         ]\n",
    "\n",
    "queries = [\n",
    "        '난 널 사랑해', \n",
    "        '난 매우 행복해', \n",
    "        '날씨가 좋다',\n",
    "        '안 그래도 되는데 뭐. 괜찮아.',\n",
    "        '내일 저녁까지 보수 공사가 끝날 것으로 예상합니다.',\n",
    "        '감사합니다. 후회 없는 결정이 될 겁니다.',\n",
    "        '그러면 오전 10시에 보도록 하죠. 내일 뵙겠습니다.',\n",
    "        '프린트 카트리지가 다 떨어졌습니다. 더 주문할까요?'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e98000-ec80-4ee1-b697-a498caae1534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 11:55:34,996 - sbertembedding - INFO - >>모델명: ../model/sbert/sbert-ts2022-03-31-dsitiluse-2\n",
      "2022-03-31 11:55:36,094 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-03-31 11:55:36,096 - sbertembedding - INFO - Query:난 널 사랑해\n",
      "2022-03-31 11:55:36,097 - sbertembedding - INFO - i love you (Score: 0.8881)\n",
      "2022-03-31 11:55:36,098 - sbertembedding - INFO - i am very happy (Score: 0.4272)\n",
      "2022-03-31 11:55:36,099 - sbertembedding - INFO - The weather is nice (Score: 0.3270)\n",
      "2022-03-31 11:55:36,100 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.2169)\n",
      "2022-03-31 11:55:36,101 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.1272)\n",
      "2022-03-31 11:55:36,109 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-03-31 11:55:36,110 - sbertembedding - INFO - Query:난 매우 행복해\n",
      "2022-03-31 11:55:36,110 - sbertembedding - INFO - i am very happy (Score: 0.9517)\n",
      "2022-03-31 11:55:36,111 - sbertembedding - INFO - i love you (Score: 0.3963)\n",
      "2022-03-31 11:55:36,112 - sbertembedding - INFO - The weather is nice (Score: 0.3695)\n",
      "2022-03-31 11:55:36,112 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.2678)\n",
      "2022-03-31 11:55:36,113 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.0918)\n",
      "2022-03-31 11:55:36,122 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-03-31 11:55:36,123 - sbertembedding - INFO - Query:날씨가 좋다\n",
      "2022-03-31 11:55:36,123 - sbertembedding - INFO - The weather is nice (Score: 0.9206)\n",
      "2022-03-31 11:55:36,124 - sbertembedding - INFO - i am very happy (Score: 0.3316)\n",
      "2022-03-31 11:55:36,125 - sbertembedding - INFO - i love you (Score: 0.2827)\n",
      "2022-03-31 11:55:36,125 - sbertembedding - INFO - We expect the renovation to be finished by tomorrow evening. (Score: 0.1856)\n",
      "2022-03-31 11:55:36,126 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.1433)\n",
      "2022-03-31 11:55:36,135 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-03-31 11:55:36,136 - sbertembedding - INFO - Query:안 그래도 되는데 뭐. 괜찮아.\n",
      "2022-03-31 11:55:36,136 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.6377)\n",
      "2022-03-31 11:55:36,137 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.3382)\n",
      "2022-03-31 11:55:36,138 - sbertembedding - INFO - i am very happy (Score: 0.3065)\n",
      "2022-03-31 11:55:36,138 - sbertembedding - INFO - The weather is nice (Score: 0.2172)\n",
      "2022-03-31 11:55:36,139 - sbertembedding - INFO - i love you (Score: 0.1314)\n",
      "2022-03-31 11:55:36,148 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-03-31 11:55:36,149 - sbertembedding - INFO - Query:내일 저녁까지 보수 공사가 끝날 것으로 예상합니다.\n",
      "2022-03-31 11:55:36,149 - sbertembedding - INFO - We expect the renovation to be finished by tomorrow evening. (Score: 0.9149)\n",
      "2022-03-31 11:55:36,150 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.4565)\n",
      "2022-03-31 11:55:36,151 - sbertembedding - INFO - The weather is nice (Score: 0.1610)\n",
      "2022-03-31 11:55:36,151 - sbertembedding - INFO - The print cartridge is exhausted. Should I order more? (Score: 0.1185)\n",
      "2022-03-31 11:55:36,152 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.0922)\n",
      "2022-03-31 11:55:36,161 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-03-31 11:55:36,162 - sbertembedding - INFO - Query:감사합니다. 후회 없는 결정이 될 겁니다.\n",
      "2022-03-31 11:55:36,162 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.7708)\n",
      "2022-03-31 11:55:36,163 - sbertembedding - INFO - i am very happy (Score: 0.3966)\n",
      "2022-03-31 11:55:36,163 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.2985)\n",
      "2022-03-31 11:55:36,164 - sbertembedding - INFO - i love you (Score: 0.2633)\n",
      "2022-03-31 11:55:36,165 - sbertembedding - INFO - We expect the renovation to be finished by tomorrow evening. (Score: 0.1250)\n",
      "2022-03-31 11:55:36,174 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-03-31 11:55:36,174 - sbertembedding - INFO - Query:그러면 오전 10시에 보도록 하죠. 내일 뵙겠습니다.\n",
      "2022-03-31 11:55:36,175 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.8551)\n",
      "2022-03-31 11:55:36,176 - sbertembedding - INFO - We expect the renovation to be finished by tomorrow evening. (Score: 0.5050)\n",
      "2022-03-31 11:55:36,176 - sbertembedding - INFO - The weather is nice (Score: 0.1347)\n",
      "2022-03-31 11:55:36,177 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.1280)\n",
      "2022-03-31 11:55:36,178 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.1168)\n",
      "2022-03-31 11:55:36,187 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-03-31 11:55:36,187 - sbertembedding - INFO - Query:프린트 카트리지가 다 떨어졌습니다. 더 주문할까요?\n",
      "2022-03-31 11:55:36,188 - sbertembedding - INFO - The print cartridge is exhausted. Should I order more? (Score: 0.7832)\n",
      "2022-03-31 11:55:36,188 - sbertembedding - INFO - We expect the renovation to be finished by tomorrow evening. (Score: 0.1214)\n",
      "2022-03-31 11:55:36,189 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.0830)\n",
      "2022-03-31 11:55:36,190 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.0790)\n",
      "2022-03-31 11:55:36,191 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.0375)\n",
      "2022-03-31 11:55:36,192 - sbertembedding - INFO - \n",
      "\n",
      "\n",
      "2022-03-31 11:55:36,192 - sbertembedding - INFO - >>처리시간: 1.1963\n",
      "2022-03-31 11:55:36,193 - sbertembedding - INFO - \n",
      "\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "logger.info(f'>>모델명: {model_path}')\n",
    "\n",
    "# corpus 임베딩\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "# query 임베딩 하면서 corpus와 비교하여 유사도 출력\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = 5\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "\n",
    "    #We use np.argpartition, to only partially sort the top_k results\n",
    "    top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    "    logger.info(f\"\\n\\n======================\")\n",
    "    logger.info(f\"Query:{query}\")\n",
    "    #print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for idx in top_results[0:top_k]:\n",
    "        logger.info(f\"{corpus[idx].strip()} (Score: %.4f)\" % (cos_scores[idx]))\n",
    "\n",
    "logger.info(f\"\\n\\n\")\n",
    "logger.info(f'>>처리시간: {time.time()-start:.4f}')\n",
    "logger.info(f\"\\n\\n======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fd4928-458b-4509-a204-3ec5fe459b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
