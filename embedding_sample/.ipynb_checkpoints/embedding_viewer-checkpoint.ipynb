{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35adbd9d-6616-4346-85d6-4bf654d60312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:bwdataset_2022-04-11.log\n",
      "logfilepath:qnadataset_2022-04-11.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "#===================================================================================================\n",
    "# 단어 embedding 벡터들을 3D 로 보여주는 예제임\n",
    "# => 단어들은 meta.tsv 파일로 저장, 임베딩값들은 vecs.tsv 파일로 저장(*이때 임베딩 각 값들은 탭으로 띄어야 함)\n",
    "# => 이후 https://projector.tensorflow.org 접속하여, [load] 버튼 클릭->[Choose file] 버튼 클릭하여, \n",
    "#   vecs.tsv, meta.tsv 파일 선택 하면 완료\n",
    "#===================================================================================================\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os import sys\n",
    "sys.path.append('..')\n",
    "from myutils import seed_everything, GPU_info\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "device = GPU_info()\n",
    "seed_everything(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df57e58-87f5-4ca5-a785-a50f85e079fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../model/distilbert/distilbert-0331-TS-nli-0.1-10 were not used when initializing DistilBertModel: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(167550, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer와 model 설정\n",
    "model_path = '../../model/distilbert/distilbert-0331-TS-nli-0.1-10'\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_path, do_lower_cased=False)\n",
    "model = DistilBertModel.from_pretrained(model_path)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac24093-94b5-4066-95b6-5cd5504b6695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer 에서 10000개 단어만 뽑아냄.\n",
    "# 시작 단어 index, 끝 단어 index = 시작 단어 index + 1000\n",
    "start_word_len = 119547\n",
    "end_word_len = start_word_len + 10000\n",
    "\n",
    "word_list = []\n",
    "token_id_list = []\n",
    "for i in range(start_word_len, end_word_len):\n",
    "    word = tokenizer.convert_ids_to_tokens(i)  \n",
    "    #print(word)\n",
    "    #idx = tokenizer.convert_tokens_to_ids(word)\n",
    "    #print(idx)\n",
    "    \n",
    "    word_list.append(word)\n",
    "    #token_id_list.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36b5c8ba-6b4f-41a4-a254-e324d4115051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사용', '때문', '시작', '사람', '기록']\n"
     ]
    }
   ],
   "source": [
    "print(word_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f983d0b1-e27f-4575-a15b-47e1f045e65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   101, 119547,    102,  ...,      0,      0,      0],\n",
       "        [   101, 119548,    102,  ...,      0,      0,      0],\n",
       "        [   101, 119549,    102,  ...,      0,      0,      0],\n",
       "        ...,\n",
       "        [   101, 129544,    102,  ...,      0,      0,      0],\n",
       "        [   101,    108,    108,  ...,    102,      0,      0],\n",
       "        [   101,    108,    108,  ...,    102,      0,      0]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 0, 0]], device='cuda:0')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_input = tokenizer(word_list, padding=True, truncation=True, max_length=16, return_tensors='pt')\n",
    "tokenizer_input.to(device)\n",
    "#print(tokenizer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "424469a7-f971-498c-a42e-e5e2e1b48ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.modeling_outputs.BaseModelOutput'>\n",
      "torch.Size([10000, 7, 768])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "outputs = model(**tokenizer_input)\n",
    "print(type(outputs))\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "print(last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f4e911b-8022-48f3-bde8-b5dbcf3adf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = []\n",
    "for idx, hidden in enumerate(last_hidden_state):\n",
    "    #print(hidden.shape)  # [3,768]\n",
    "    means_embedding = torch.mean(hidden, dim=0)  #0번째 dim 3은 날리고, 768만 남음(즉 0번째 dim의 평균을 구함)\n",
    "    #print(means_embedding.shape) #[768]\n",
    "    embedding_list.append(means_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aea1dd7e-bfb3-4c96-a9f2-739f5b792b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_list와 embedding_list를 가지고, 각각 meta.tsv 와 vecs.tsv파일을 만듬\n",
    "import io\n",
    "import os\n",
    "\n",
    "vecs_file = 'vecs.tsv'\n",
    "meta_file = 'meta.tsv'\n",
    "\n",
    "out_v = io.open(vecs_file, 'w', encoding='utf-8')\n",
    "out_m = io.open(meta_file, 'w', encoding='utf-8')\n",
    "\n",
    "for word, embeddings in zip(word_list, embedding_list):\n",
    "    #print(word)\n",
    "    #print(len(embeddings))\n",
    "    #break\n",
    "    out_m.write(word + \"\\n\")\n",
    "    # **embedding 값은 gpu로 계산된 tensor이므로, 일단 detach().cpu() 하여 tensor를 gpu에서 cpu로 변환 이후, tensor->numpy()로 변환\n",
    "    out_v.write('\\t'.join([str(x) for x in embeddings.detach().cpu().numpy()]) + \"\\n\")\n",
    "    \n",
    "out_v.close()\n",
    "out_m.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
