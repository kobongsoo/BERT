{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c34a3b30-4cc0-4021-afc3-361c1ded8f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gluonnlp as nlp                  # GluonNLP는 버트를 간단하게 로딩하는 인터페이스를 제공하는 API 임\n",
    "import numpy as np\n",
    "\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from utils import seed_everything, GPU_info, pytorch_cos_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8a03b06-706b-4284-b35a-a3fc12c0258e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92186880"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kobert 다운받아서 압축푼 폴더(config.json, pytorch_model.bin 같이 있는 폴더 지정)\n",
    "output_hidden_states = True # 기본은 False=>output 2개 출력됨, True로 지정하면 output이 3개 출력됨\n",
    "return_dict = False\n",
    "model_path = \"model/kobertmodel\" \n",
    "model = BertModel.from_pretrained(model_path, output_hidden_states = output_hidden_states, return_dict = return_dict)\n",
    "model.eval()\n",
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3943a907-5181-4423-89a7-f8d526f66d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file=\"Tokenizer/kobert/kobert_news_wiki_ko_cased-ae5711deb3.spiece\"\n",
    "vocab = nlp.vocab.BERTVocab.from_sentencepiece(vocab_file, padding_token=\"[PAD]\")\n",
    "tokenizer = nlp.data.BERTSPTokenizer(vocab_file, vocab, lower=False)\n",
    "\n",
    "# pad는 원래 True로 했는데, 여기서는 False로 해도 마찬가지 유사도 결과가 나옴\n",
    "transform = nlp.data.BERTSentenceTransform(\n",
    "            tokenizer, max_seq_length = 128, pad=False, pair=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3def9e3d-42b0-4754-ad18-77bf19885ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids:\n",
      "tensor([[   2, 3007, 6896,  517, 5330, 6553, 2266, 7088, 2287, 2432, 5400, 2011,\n",
      "         1404, 6705, 6312, 6116, 4700,  993, 5561, 3951, 3480, 7659, 6312, 6116,\n",
      "         4700, 1080, 7088, 5010,  517, 5406,    3]], dtype=torch.int32)\n",
      "segment_ids:\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]], dtype=torch.int32)\n",
      "attention_mask:\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0]], dtype=torch.int32)\n",
      "0: [CLS]    2\n",
      "1: ▁식당    3007\n",
      "2: 에    6896\n",
      "3: ▁    517\n",
      "4: 가    5330\n",
      "5: 서    6553\n",
      "6: ▁밥    2266\n",
      "7: 을    7088\n",
      "8: ▁배    2287\n",
      "9: ▁부르    2432\n",
      "10: 게    5400\n",
      "11: ▁먹고    2011\n",
      "12: ▁낙    1404\n",
      "13: 시    6705\n",
      "14: 배    6312\n",
      "15: 를    6116\n",
      "16: ▁타고    4700\n",
      "17: ▁고    993\n",
      "18: 기    5561\n",
      "19: ▁잡고    3951\n",
      "20: ▁요    3480\n",
      "21: 트    7659\n",
      "22: 배    6312\n",
      "23: 를    6116\n",
      "24: ▁타고    4700\n",
      "25: ▁관광    1080\n",
      "26: 을    7088\n",
      "27: ▁해야    5010\n",
      "28: ▁    517\n",
      "29: 겠다    5406\n",
      "30: [SEP]    3\n"
     ]
    }
   ],
   "source": [
    "test_sentence = ['식당에 가서 밥을 배 부르게 먹고 낙시배를 타고 고기 잡고 요트배를 타고 관광을 해야 겠다']\n",
    "\n",
    "transform_data = [transform([i[0]]) for i in [test_sentence]]\n",
    "#print(transform_data)\n",
    "#print(type(transform_data))\n",
    "\n",
    "token_ids = transform_data[0][0]\n",
    "valid_length = transform_data[0][1]\n",
    "segment_ids = transform_data[0][2]\n",
    "\n",
    "\n",
    "#print(\"token_ids:{}\".format(token_ids))\n",
    "#print(\"segment_ids:{}\".format(segment_ids))\n",
    "#print(\"valid_length:{}\".format(valid_length))\n",
    "\n",
    "#print(type(token_ids))\n",
    "\n",
    "#tensor로 변환[] 묶어줘서 무조건 2차원으로 출력해야 함\n",
    "token_ids = torch.tensor([token_ids])\n",
    "segment_ids = torch.tensor([segment_ids])\n",
    "\n",
    "print(\"token_ids:\\r\\n{}\".format(token_ids))\n",
    "print(\"segment_ids:\\r\\n{}\".format(segment_ids))\n",
    "\n",
    "# attention mask 설정\n",
    "# => 토큰에 대해서는 1 PAD 토큰은 0으로 설정\n",
    "attention_mask = torch.zeros_like(token_ids)\n",
    "for v in range(valid_length):\n",
    "  attention_mask[0][:v] = 1\n",
    "attention_mask.float()\n",
    "\n",
    "print('attention_mask:\\r\\n{}'.format(attention_mask))\n",
    "\n",
    "token_ids_list = token_ids.tolist()\n",
    "#print(token_ids_list[0])\n",
    "\n",
    "count = 0\n",
    "for token in token_ids_list[0]:\n",
    "    print('{}: {}    {}'.format(count, vocab.idx_to_token[token],token))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd78ed7-e2fe-4b59-8059-d9fe0517b06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 out 길이:3\n",
      "sequence 길이: torch.Size([1, 31, 768]), pooled 길이:torch.Size([1, 768])\n",
      "hidden_states\n",
      "-레이어 수:13\n",
      "-배치 수: 1\n",
      "-토큰 수 : 31\n",
      "-hidden 유닛 수 : 768\n"
     ]
    }
   ],
   "source": [
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "#bertmodel.eval()  #모델을 평가모드로 변경후\n",
    "\n",
    "output = model(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float())\n",
    "output_len = len(output)\n",
    "print('출력 out 길이:{}'.format(output_len))\n",
    "\n",
    "sequence_output = output[0]  # tensor 임\n",
    "pooled_output = output[1]    # tensor 임\n",
    "\n",
    "print('sequence 길이: {}, pooled 길이:{}'.format(sequence_output.size(), pooled_output.size()))\n",
    "\n",
    "# output_len 길이가 2이상이면 hidden_states 출력함\n",
    "if output_len > 2:\n",
    "  hidden_states = output[2]  #hidden state 출력 (tuple임)\n",
    "  # tuple 은 size로 출력 못하므로, 아래 처럼 출력함\n",
    "  layer_idx = 0\n",
    "  batch_idx = 0\n",
    "  token_idx = 0\n",
    "  print('hidden_states')\n",
    "  print(\"-레이어 수:{}\".format(len(hidden_states)))\n",
    "  print(\"-배치 수: {}\".format(len(hidden_states[layer_idx])))\n",
    "  print(\"-토큰 수 : {}\".format(len(hidden_states[layer_idx][batch_idx])))\n",
    "  print(\"-hidden 유닛 수 : {}\".format(len(hidden_states[layer_idx][batch_idx][token_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f06bb0a3-d7ce-4135-b8a7-92b08341c8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_output size: torch.Size([31, 1, 768])\n",
      "몸에 있는배 vs 낙시배 유사도:tensor([[0.6264]])\n",
      "몸에 있는배 vs 요트배 유사도:tensor([[0.5682]])\n",
      "낙시배 vs 요트배 유사도:tensor([[0.7463]])\n"
     ]
    }
   ],
   "source": [
    "# premute를 사용하여 레이어 와 tokens 차원을 바꾼다.\n",
    "sequence_output_embedding = sequence_output.permute(1,0,2)\n",
    "print('sequence_output size: {}'.format(sequence_output_embedding.size()))\n",
    "\n",
    "# tensor -> list 로 변환\n",
    "output_list = sequence_output_embedding.tolist()\n",
    "\n",
    "# 몸에 있는배, 낙시배 비교\n",
    "simulate1 = pytorch_cos_sim(output_list[8][0], output_list[14][0])\n",
    "\n",
    "# 몸에 있는배, 요트배 비교\n",
    "simulate2 = pytorch_cos_sim(output_list[8][0], output_list[22][0])\n",
    "\n",
    "# 낙시배, 요트배 비교\n",
    "simulate3 = pytorch_cos_sim(output_list[14][0], output_list[22][0])\n",
    "\n",
    "print(\"몸에 있는배 vs 낙시배 유사도:{}\".format(simulate1))\n",
    "print(\"몸에 있는배 vs 요트배 유사도:{}\".format(simulate2))\n",
    "print(\"낙시배 vs 요트배 유사도:{}\".format(simulate3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60505d8a-fae3-4c23-a825-d556cdbce2be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
