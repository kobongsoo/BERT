{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed80905-9e79-4818-84c3-2874cf302416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gluonnlp as nlp     # GluonNLP는 버트를 간단하게 로딩하는 인터페이스를 제공하는 API 임\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertTokenizerFast, BertModel\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from myutils import seed_everything, GPU_info, pytorch_cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf737966-aa6b-491c-a603-07bcf6251e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#config.json, pytorch_model.bin 같이 있는 폴더 지정\n",
    "model_path = 'model/bert-multilingual-cased_furter_pt_model_0216' \n",
    "# voab.txt, special_tokens_map.json, tokenizer_config.json,added_tokens.json 폴더 경로 지정\n",
    "vocab_path = \"model/bert-multilingual-cased_furter_pt_model_0216/vocab\"\n",
    "'''\n",
    "\n",
    "model_path = 'model/bert-multilingual-cased' \n",
    "vocab_path = \"model/bert-multilingual-cased/vocab\"\n",
    "\n",
    "# True로 해야, hidden_states 가 출력됨\n",
    "output_hidden_states = True\n",
    "return_dict = False\n",
    "\n",
    "seed = 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ee98e5-6f42-408d-8708-b3be1bdd2217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "cuda = GPU_info()\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77964daf-f90a-4acb-8188-844ba5d29c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed 설정\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78bf7ff-109c-483c-8578-8d70254a26dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at model/bert-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# model 불러옴\n",
    "model = BertModel.from_pretrained(model_path, \n",
    "                                  output_hidden_states=output_hidden_states,\n",
    "                                  return_dict=return_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e707cc-5482-41d9-aae5-002e78eebf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(cuda)\n",
    "#model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df4e6c36-5fa4-4650-a2ef-d60359890342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177853440"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b441f344-bb46-438e-970e-df0cf4128d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize 설정\n",
    "tokenizer = BertTokenizerFast.from_pretrained(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb6f800b-199b-4128-b6ce-daf926787e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119547"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18170aaf-1080-47a7-b643-fe226ae0c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(tokenizer.vocab.keys())[8000:8010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ead3ec47-3f11-42af-82b3-27f7c59d1040",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer(\"식당에 가서 밥을 배 부르게 먹고 낙시배를 타고 고기 잡고 요트배를 타고 관광을 해야 겠다\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be9c2021-e4f3-437b-a75a-770d6f893713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[CLS]', '식', '##당', '##에', '가', '##서', '밥', '##을', '배', '부', '##르게', '먹', '##고', '낙', '##시', '##배', '##를', '타', '##고', '고', '##기', '잡', '##고', '요', '##트', '##배', '##를', '타', '##고', '관', '##광', '##을', '해', '##야', '겠', '##다', '[SEP]']]\n",
      "[[101, 9486, 21928, 10530, 8843, 12424, 9327, 10622, 9330, 9365, 78131, 9266, 11664, 8983, 14040, 76036, 11513, 9845, 11664, 8888, 12310, 9656, 11664, 9599, 15184, 76036, 11513, 9845, 11664, 8900, 118649, 10622, 9960, 21711, 8876, 11903, 102]]\n",
      "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "token_str = [[tokenizer.convert_ids_to_tokens(s) for s in tokenized_input['input_ids'].tolist()[0]]]\n",
    "\n",
    "# token indexs ( 토큰을 index로 변한한 값)\n",
    "token_ids = [tokenized_input['input_ids'].tolist()[0]]\n",
    "# attention_mask (중요토큰 : 1)\n",
    "token_attention_mask = [tokenized_input['attention_mask'].tolist()[0]]\n",
    "# segment_id (첫번째문자:0, 다음 문장:1)\n",
    "token_type_ids = [tokenized_input['token_type_ids'].tolist()[0]]\n",
    "\n",
    "print(token_str)\n",
    "print(token_ids)\n",
    "print(token_attention_mask)\n",
    "print(token_type_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99b9d7b1-6f27-4a6c-8605-c5d80d598dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'纯'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(6313)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "345c823a-edad-4d50-b58f-6ddd94f3c106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   101,   9486,  21928,  10530,   8843,  12424,   9327,  10622,   9330,\n",
      "           9365,  78131,   9266,  11664,   8983,  14040,  76036,  11513,   9845,\n",
      "          11664,   8888,  12310,   9656,  11664,   9599,  15184,  76036,  11513,\n",
      "           9845,  11664,   8900, 118649,  10622,   9960,  21711,   8876,  11903,\n",
      "            102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e41bc4c-df1c-497c-af73-66c608131ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3157f0d-89df-4126-a47d-8e4626c43fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f64fc308-2215-42db-85e2-7b748393583b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence 길이: torch.Size([1, 37, 768])\n",
      "pooled 길이:torch.Size([1, 768])\n",
      "hidden_states\n",
      "-레이어 수:13\n",
      "-배치 수: 1\n",
      "-토큰 수 : 37\n",
      "-hidden 유닛 수 : 768\n"
     ]
    }
   ],
   "source": [
    "sequence_output = outputs[0]\n",
    "print('sequence 길이: {}'.format(sequence_output.size()))\n",
    "\n",
    "pooled_output = outputs[1]\n",
    "print('pooled 길이:{}'.format(pooled_output.size()))\n",
    "\n",
    "hidden_states = outputs[2]\n",
    "layer_idx = 0\n",
    "batch_idx = 0\n",
    "token_idx = 0\n",
    "print('hidden_states')\n",
    "print(\"-레이어 수:{}\".format(len(hidden_states)))\n",
    "print(\"-배치 수: {}\".format(len(hidden_states[layer_idx])))\n",
    "print(\"-토큰 수 : {}\".format(len(hidden_states[layer_idx][batch_idx])))\n",
    "print(\"-hidden 유닛 수 : {}\".format(len(hidden_states[layer_idx][batch_idx][token_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab5b104b-9842-429b-915c-f5efa3700eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_output size: torch.Size([37, 1, 768])\n",
      "몸에 있는배 vs 낙시배 유사도:tensor([[0.6440]])\n",
      "몸에 있는배 vs 요트배 유사도:tensor([[0.6280]])\n",
      "낙시배 vs 요트배 유사도:tensor([[0.9716]])\n"
     ]
    }
   ],
   "source": [
    "##### 단어별 유사도 측정\n",
    "\n",
    "# premute를 사용하여 레이어 와 tokens 차원을 바꾼다.\n",
    "sequence_output_embedding = sequence_output.permute(1,0,2)\n",
    "print('sequence_output size: {}'.format(sequence_output_embedding.size()))\n",
    "\n",
    "# tensor -> list 로 변환\n",
    "output_list = sequence_output_embedding.tolist()\n",
    "\n",
    "word_1 = 8\n",
    "word_2 = 15\n",
    "word_3 = 25\n",
    "simul_score1 = pytorch_cos_sim(output_list[word_1][0], output_list[word_2][0])\n",
    "simul_score2 = pytorch_cos_sim(output_list[word_1][0], output_list[word_3][0])\n",
    "simul_score3 = pytorch_cos_sim(output_list[word_2][0], output_list[word_3][0])\n",
    "\n",
    "print(\"몸에 있는배 vs 낙시배 유사도:{}\".format(simul_score1))\n",
    "print(\"몸에 있는배 vs 요트배 유사도:{}\".format(simul_score2))\n",
    "print(\"낙시배 vs 요트배 유사도:{}\".format(simul_score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ba9f014-7837-4e6f-a249-b185f033d788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0133668184280396, -0.43167948722839355, 0.18542343378067017, 0.12088800966739655, 0.41148102283477783, 0.1533239185810089, -0.43989312648773193, 0.3770343065261841, 0.46202901005744934, 0.21814458072185516, -0.14310239255428314, -0.08492572605609894, 0.5519950985908508, 0.22635769844055176, -0.47427546977996826, 0.37364429235458374, 1.0226417779922485, -0.9009159207344055, 0.002453470602631569, 0.28234314918518066, 0.39326807856559753, -0.16260898113250732, 0.6133151054382324, 0.20685473084449768, -0.019095974043011665, 0.739651620388031, -1.3276050090789795, 0.4493487775325775, 0.6708970069885254, 0.11150505393743515, 0.2853521704673767, 0.3729919195175171, -0.06044900417327881, -0.4527873694896698, -0.4696868062019348, 0.7036134600639343, 0.3248489797115326, 0.41218745708465576, 0.0751100406050682, 0.3187400698661804, -0.4837758541107178, 0.6226616501808167, 0.31029072403907776, -0.058546096086502075, 0.2470712512731552, -0.43169334530830383, 0.11027448624372482, -0.5035675764083862, 0.40016594529151917, -0.216821551322937, -0.335538387298584, -0.2182030826807022, 0.448774516582489, 0.02862396463751793, -0.5905128717422485, 0.7225863933563232, 0.48862481117248535, 0.3425716161727905, 0.16767039895057678, 0.4215802252292633, -0.058279283344745636, 0.29520323872566223, 0.2041812390089035, 0.0793694332242012, -0.5539994239807129, -0.748646080493927, 0.10336263477802277, 0.2897988557815552, 0.6091671586036682, -0.0425323061645031, -0.38354456424713135, 0.11393696814775467, -0.5811879634857178, 0.6109845638275146, 0.22076144814491272, 0.7542463541030884, -0.21704794466495514, 0.5441910624504089, -0.6607550382614136, -0.30820387601852417, 0.6010520458221436, -0.12590372562408447, -0.2662017047405243, -0.21386024355888367, -0.8003321886062622, 0.530295193195343, -0.5405061841011047, 0.19934533536434174, 0.23888202011585236, -0.7269780039787292, -0.29480835795402527, -0.42837825417518616, 0.4274393320083618, 0.18000207841396332, -0.43933790922164917, 1.0116703510284424, 0.045212000608444214, 1.364630103111267, 1.2440638542175293, 0.5848256945610046, -0.24638807773590088, -0.09595345705747604, 1.200823187828064, -0.07758768647909164, 0.09714458882808685, 0.3655884861946106, -0.18259942531585693, -0.3553045392036438, 0.610028088092804, 0.5789830088615417, -0.030013637617230415, 0.1947697550058365, -0.09375736862421036, -0.25420138239860535, -0.11820706725120544, -0.15160171687602997, -1.279120683670044, 0.5245223045349121, 1.2592042684555054, -0.39702147245407104, -0.5988054871559143, 0.1950736939907074, 0.3183755874633789, 0.2570801079273224, 1.2772237062454224, -0.013751096092164516, -0.4183521270751953, 0.23594775795936584, -1.1339824199676514, -0.40260496735572815, 0.17337441444396973, -0.6856409311294556, 0.35946106910705566, 0.30646583437919617, 0.37676048278808594, 0.05859482288360596, -0.2842820882797241, -0.15430837869644165, 0.10339232534170151, 0.3856101632118225, -0.4132682979106903, -0.082978755235672, -0.5557920932769775, -0.6014602780342102, 0.11104398220777512, -0.09960689395666122, -0.2301512062549591, -0.346579372882843, -1.1841703653335571, 0.6166345477104187, 0.020703338086605072, 0.7554508447647095, 0.3383336365222931, 0.33650314807891846, -0.31802108883857727, -0.7234302759170532, 0.14052821695804596, -0.10631375014781952, 0.17195165157318115, -0.3255932331085205, 0.9664552211761475, 0.7204998135566711, -0.5805897116661072, 1.1677701473236084, -0.4478796422481537, -0.03532908484339714, 0.13809461891651154, -0.9368289113044739, -0.8619544506072998, 0.42569369077682495, -0.16247181594371796, -0.6295909285545349, -0.7943885326385498, 0.4266022741794586, 1.4434164762496948, -0.5718197226524353, 0.06205807998776436, 0.7444435358047485, 0.2634733319282532, -0.07147009670734406, 0.29215890169143677, 0.17687304317951202, -0.3007275462150574, -0.96834796667099, 0.010396775789558887, -0.2112705111503601, 0.2634357213973999, 0.9593585729598999, -0.179815411567688, 0.3559713661670685, -0.17462687194347382, 0.1721324473619461, -0.8931955099105835, 0.21875570714473724, -0.9413700103759766, 0.47763338685035706, 0.24912911653518677, 0.4461573362350464, 0.36654460430145264, 0.8822383880615234, -0.10654085129499435, -0.16395851969718933, -0.27437499165534973, 0.21460841596126556, 0.7727599143981934, 0.5695379376411438, -0.0031945917289704084, -0.7171956896781921, -0.5599921345710754, -0.05268864706158638, -0.33000120520591736, 0.3162597417831421, 0.9021546840667725, 0.10268731415271759, 0.9489101767539978, -0.525873601436615, -0.4586029648780823, -0.21383322775363922, 0.21655242145061493, -0.1320282518863678, -0.024358265101909637, -0.06495250761508942, -0.47509998083114624, -0.588062047958374, -0.7042136192321777, 0.369010865688324, -0.42006978392601013, 0.20716093480587006, 0.13384701311588287, 0.27964451909065247, 0.08036437630653381, -0.45999279618263245, -0.4864201843738556, -0.27070528268814087, -0.06647033989429474, -0.6682866215705872, 0.6370694637298584, -0.06447292864322662, -1.0960897207260132, 0.09309404343366623, 0.4719211757183075, -0.08631584048271179, -0.5164083242416382, -0.43800076842308044, 0.599495530128479, 0.8739120960235596, -0.47480490803718567, 0.3414381444454193, 0.9161735773086548, -0.40655094385147095, 0.05472623556852341, -0.03184768930077553, -0.6804943084716797, -0.02956223674118519, -1.2249023914337158, 0.4104233682155609, 0.03854217752814293, -0.44238367676734924, 0.22070008516311646, -0.7466866374015808, 0.33495083451271057, -0.5489243268966675, -0.45695775747299194, 0.4411765933036804, 0.9765045046806335, 0.06850410252809525, 0.08982996642589569, -0.026299357414245605, -0.5999780893325806, 0.7621240615844727, -1.230973482131958, 0.3536303639411926, 0.038052305579185486, 0.04887989163398743, 0.28357693552970886, 0.5004109144210815, 0.24463467299938202, -0.4007886052131653, -0.052478231489658356, 0.4294384717941284, 0.041647057980298996, 0.41790857911109924, 0.14696437120437622, -0.9813039302825928, 0.34462496638298035, 0.13263532519340515, -0.34871193766593933, -0.6790385842323303, 0.3190835118293762, -0.4616521894931793, -0.5460324883460999, -0.5767251253128052, 0.011813078075647354, -0.019772663712501526, 0.08816578984260559, -0.8501119613647461, -0.7626998424530029, -0.18354089558124542, -0.5448918342590332, -0.298755943775177, 0.8533636331558228, 0.23195216059684753, 0.5860251188278198, -0.15905453264713287, -0.3927866220474243, 0.1782512664794922, -0.5467669367790222, -0.45445317029953003, -0.11983900517225266, 0.7043813467025757, -0.25685223937034607, -0.22513507306575775, -0.3284118175506592, 0.6949570178985596, 0.2946973443031311, -0.1522664725780487, 0.6334555745124817, -0.1995704621076584, -0.7805140018463135, -0.25796225666999817, -0.3462415039539337, 0.1598624736070633, 1.0102442502975464, -0.5607472062110901, 0.7911645174026489, 0.18673278391361237, -0.5754250884056091, -0.7879775762557983, 0.0907328650355339, -0.585469663143158, -0.20166157186031342, 0.08860897272825241, -0.36592426896095276, -0.8855559825897217, -0.35685983300209045, 0.3603607416152954, 0.4429419934749603, -0.43915465474128723, -0.29047250747680664, -0.7163787484169006, 0.17562425136566162, 0.09838346391916275, 0.281296044588089, -0.02759454771876335, -0.28001168370246887, 0.09834349900484085, 0.11143723875284195, -0.5913441181182861, -0.43086472153663635, -0.14249445497989655, 0.30752032995224, 0.2317933291196823, -0.43023937940597534, 0.45184525847435, 0.8812365531921387, -0.5428499579429626, -1.2932509183883667, 0.1658293455839157, -0.6743578910827637, -0.38494208455085754, 0.07755827903747559, 0.21946412324905396, -0.07608315348625183, -0.37290704250335693, -0.8216260671615601, -0.9584028124809265, 0.12184396386146545, -0.2500494420528412, 0.1783359795808792, 0.9840613603591919, 0.25890716910362244, 0.48399725556373596, -0.49231454730033875, -0.7061678767204285, -0.6111668944358826, -0.23257651925086975, 0.03558050096035004, -0.4009925425052643, -0.5761554837226868, -0.41639748215675354, 0.28205806016921997, 0.498798131942749, 0.37551137804985046, -0.3386901617050171, 0.38981392979621887, -0.034429434686899185, 0.41776153445243835, -1.0570294857025146, 0.19295942783355713, -1.4511216878890991, 1.016150951385498, 0.04845251515507698, 0.6023034453392029, -0.16659586131572723, -0.767183244228363, 0.024827951565384865, 0.07237239181995392, -0.12763845920562744, -1.2625997066497803, -0.1375684142112732, 0.24437803030014038, 0.3004794120788574, 0.23071347177028656, 0.9638463854789734, -0.17232351005077362, 0.5575979948043823, 0.3842591345310211, -0.0705208107829094, -0.5854187607765198, -0.2919999361038208, 0.8117393255233765, 0.4298136830329895, 0.32915231585502625, 1.6242661476135254, -0.4567539691925049, 0.4508463442325592, -0.3888181447982788, 0.5510748028755188, -0.16692380607128143, -0.0403592623770237, 0.22790879011154175, -0.4391430616378784, 0.15611068904399872, -2.362482786178589, -0.5603640675544739, -0.07503480464220047, -0.028551338240504265, 0.7311752438545227, -0.8022832274436951, 0.04692545533180237, 0.004936115816235542, -0.6842495799064636, 0.7384548187255859, 0.1934414654970169, 0.27910229563713074, 0.2427058070898056, 0.30335184931755066, 0.6182233691215515, 0.1279096156358719, 0.0057494197972118855, 0.04544173553586006, 0.03222855553030968, 0.3505704998970032, -0.6958368420600891, 0.1503806859254837, -0.25705456733703613, -0.03584921360015869, -0.5308420658111572, -0.8455286622047424, 0.6990069150924683, 0.12124089151620865, -1.8036164045333862, 0.37301021814346313, -0.11106054484844208, 0.075108103454113, -0.3381681740283966, -1.1145907640457153, 0.7718803882598877, -0.03645540028810501, -0.6035794019699097, 0.14247161149978638, 1.184212565422058, 0.1363794207572937, 0.03082158789038658, -0.42106273770332336, -1.406907081604004, 0.27220144867897034, -0.022256378084421158, 0.5238537192344666, 1.1883124113082886, -0.30612507462501526, 0.017681332305073738, -0.12114731967449188, 0.2539098858833313, -0.12873168289661407, 0.6048553586006165, -0.01757696457207203, 0.25806427001953125, -0.2319566011428833, -0.44401687383651733, -0.19496586918830872, 0.06434958428144455, 1.529039740562439, -0.5196337103843689, 0.2675836682319641, 0.6788713335990906, 0.13112297654151917, 0.06920177489519119, 0.5198665857315063, 0.30433616042137146, -0.17826513946056366, -0.7390977144241333, 0.15898314118385315, -2.6070261001586914, -0.29882025718688965, 0.042091745883226395, 0.1721743792295456, 0.07686173915863037, -0.7407025694847107, -1.0463430881500244, 0.2670575976371765, 0.5897300243377686, -0.28884419798851013, -0.11761943250894547, 1.0468928813934326, 0.20139946043491364, 0.29219087958335876, -0.3278701603412628, -0.5057461857795715, 0.12014675885438919, -0.4846930205821991, -0.7410106658935547, 0.3108537197113037, 0.14577756822109222, -0.007023573853075504, 0.48685532808303833, -0.9390992522239685, -0.7571085691452026, -0.16730470955371857, -0.01819915883243084, 0.5682095289230347, 0.05607333034276962, 0.23837138712406158, -0.11120853573083878, -0.46607500314712524, -0.38599780201911926, -1.1109342575073242, -0.3549953103065491, -0.1231105700135231, 0.21686477959156036, -0.08540164679288864, 0.4335858225822449, 0.23866498470306396, 0.11068640649318695, -0.05335986241698265, 0.827899158000946, 0.2131536304950714, 0.505854070186615, -0.3232780396938324, 0.2802426815032959, 0.12383744865655899, -0.17354431748390198, -0.6275846362113953, 0.6499337553977966, 0.25859367847442627, -0.3423810601234436, 0.0589749850332737, 0.317058801651001, -0.1143135353922844, 0.4659370481967926, -0.20018643140792847, -0.044337235391139984, 0.47772374749183655, 0.5367364883422852, -0.8371315002441406, 0.3746008574962616, -0.014318810775876045, 0.02536613866686821, -0.3373849093914032, -0.5521296858787537, -0.27088817954063416, 0.6330934166908264, -0.40565600991249084, 0.14526821672916412, 0.9489875435829163, 0.09135981649160385, 0.07531925290822983, 0.0013182710390537977, -0.17922434210777283, 0.3003896176815033, 0.8243468999862671, 0.20953263342380524, 0.4821510910987854, 0.8325881958007812, -0.5641651153564453, -0.003695541061460972, -0.42128297686576843, -0.9213055372238159, 0.22788114845752716, -0.23475994169712067, -0.9257162809371948, 0.6933143138885498, 0.43835288286209106, -0.48984473943710327, -0.8883569240570068, -0.5909984707832336, -0.07431308180093765, 0.9521474242210388, 0.23412427306175232, -0.7620103359222412, -0.1299847811460495, -0.7253536581993103, -0.1933160424232483, -0.20987388491630554, -0.14444050192832947, 0.47779232263565063, 1.0520085096359253, -0.17445342242717743, 0.8090363144874573, -0.11078565567731857, 0.216872438788414, -0.32293733954429626, 0.6792778372764587, -1.562511920928955, 0.03210650011897087, -0.48541849851608276, 0.17435848712921143, 0.1370261311531067, -1.323288083076477, 0.019834989681839943, 0.17188364267349243, -0.3226478695869446, 0.26657965779304504, -0.03479449078440666, -0.1986420601606369, -0.14125391840934753, -0.92090904712677, 1.028988242149353, 0.4850063621997833, -0.16142931580543518, 0.1929464191198349, 0.5892276167869568, -0.3565029799938202, 0.21813730895519257, 0.7558363676071167, 0.008794786408543587, 0.05376512557268143, 0.08174407482147217, 0.562511146068573, 0.3887767493724823, 0.14024512469768524, -0.6653351783752441, 0.1406148076057434, -0.58876633644104, 0.0523345060646534, 0.03901268169283867, 0.11137496680021286, -0.3157995641231537, 1.0016286373138428, 0.0050690812058746815, 0.0268110241740942, 0.30912142992019653, -0.5215297341346741, -0.4329342246055603, -0.43297576904296875, -0.038002170622348785, 0.020174089819192886, 0.46621108055114746, 0.0651053711771965, 0.1976388692855835, -0.1907423585653305, -0.39437681436538696, 0.04101734235882759, -1.1992679834365845, -0.3119175434112549, 1.164448618888855, 0.2748829126358032, -0.0269525907933712, -0.2143699824810028, -0.040603265166282654, 0.2853602170944214, 0.661074697971344, 0.8332387804985046, 0.2421879917383194, 0.11628317832946777, 0.779485285282135, -0.9369021654129028, 0.49859926104545593, 0.304685115814209, -0.5098909139633179, -0.24796651303768158, 0.4544292390346527, 0.8822933435440063, -0.3316458761692047, 0.1003546342253685, -0.050632402300834656, 0.29707467555999756, -0.545218288898468, 0.5901535153388977, 0.33766913414001465, 0.998637318611145, -0.5086318850517273, 0.012293041683733463, 0.2932555377483368, -0.22399747371673584, -0.36924755573272705, 0.5290465354919434, -0.4081781804561615, -0.16073431074619293, -0.13965827226638794, 0.6555141806602478, 0.34456098079681396, 0.11831437051296234, -0.3155912756919861, -0.18156380951404572, 0.09190931916236877, -0.6931632161140442, 0.28060606122016907, 0.16329650580883026, -0.9780895113945007, -0.13316822052001953, 0.376666396856308, -0.31810006499290466, 0.05603869631886482, 0.849326491355896, -0.4730209708213806, -0.14524345099925995, 0.09999503940343857, 0.4454144537448883, -0.2877482771873474, -0.44221505522727966, -0.0429355651140213, 0.2449161261320114, 0.666857898235321, -0.199752077460289, 0.4348483979701996, -0.3767411708831787, -0.43880900740623474, 0.1721426397562027, 0.5303182601928711, 0.21683622896671295, 1.103966474533081, 0.3482397794723511, -0.2960830330848694, 0.0005276589654386044, 0.105680912733078, 0.19755277037620544, -0.14948530495166779, -0.19360843300819397, -0.27151918411254883, -0.3039005994796753, -0.6054201126098633, 0.39243537187576294, 0.5737873315811157, -0.4973107576370239, -0.014399247244000435, -0.26979851722717285, 0.8134965300559998, 0.4670599102973938, -0.25096455216407776, -0.15658539533615112, -0.06172565370798111, -0.3801650106906891, 0.06285503506660461, 0.2105528712272644, -0.09796550124883652, 0.11712757498025894, 0.16100744903087616, -0.4503941237926483, -0.023024456575512886, 0.38570523262023926, -0.3859161138534546, -0.54506516456604, -0.49094128608703613, -0.12534178793430328, 0.5738526582717896, 0.5256779193878174, 0.06112559512257576, -0.5617786645889282, -0.8930292129516602, -0.19746045768260956, -0.011712843552231789, -0.0683196410536766, -0.14437808096408844, 0.4358195662498474, 0.7765358686447144, 0.11817333102226257, 0.1771213710308075]\n"
     ]
    }
   ],
   "source": [
    "print(output_list[6][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51f4965-4b2d-4179-a361-e438febd93cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
