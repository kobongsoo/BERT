{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee1bd61-1480-4322-a670-d64bd88ff866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:bwdataset_2022-03-07.log\n"
     ]
    }
   ],
   "source": [
    "# NLP를 이용한 Zero-shot Classification 분류 예시\n",
    "# => 각 문장과 labels를 가지고, 문장(전제)과 labels(가설)간 관계가 최대 참(entailment) 일 확률을 구하는 방식\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from myutils import seed_everything, GPU_info, pytorch_cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b4d96e-7383-4801-a859-547ddfcac820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_path = '../model/classification/bmc_fpt_kowiki20200920.train_model_0225-ft-klue-nli-0303' \n",
    "vocab_path = \"../model/classification/bmc_fpt_kowiki20200920.train_model_0225-ft-klue-nli-0303/vocab\"\n",
    "\n",
    "device = GPU_info()\n",
    "print(device)\n",
    "\n",
    "#seed 설정\n",
    "seed_everything(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a405d84a-462a-4724-a7b7-2dd830f3594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize 설정\n",
    "tokenizer = BertTokenizerFast.from_pretrained(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6a9c77-2854-4bbf-8fb4-81c587c9736e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(143772, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model 불러옴\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, output_hidden_states=True, num_labels=3)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0903aac4-df6b-431b-a67a-ac8ed988f6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prameters:196460547\n"
     ]
    }
   ],
   "source": [
    "print('prameters:{}'.format(model.num_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "966abd8c-127e-4ee7-be39-1b8934e67c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "input_texts = ['오늘은 오후 부터 춥고 비가 올것 같다.']\n",
    "labels = [\n",
    "        ['오늘은 가끔 흐리고, 눈이 올수 있다'],\n",
    "        ['여기 식당은 파스타가 맛있다'],\n",
    "        ['오늘 증시는 내림으로 마감 하였다'],\n",
    "        ['내일은 오전에는 흐리지만, 오후에는 날씨가 좋겠다']\n",
    "]\n",
    "'''\n",
    "\n",
    "'''\n",
    "#input_texts = ['오늘은 오전에는 흐리고 오후부터는 가끔씩 비가 오겠다']\n",
    "input_texts = ['즐겨볼만한 스포츠']\n",
    "labels = [['축구'],['야구'],['등산'],['낚시'],['날씨'],['상품권'],['교육']]\n",
    "'''\n",
    "\n",
    "input_texts = ['서울은 대한민국에 수도이며, 정치 경제 중심지이다',\n",
    "          '내년 경제 성장은 4%대 성장을 이룰거라 예상된다',\n",
    "          '프랑스 파리는 전세계 관광객들이 매년 찾는 관광도시이다',\n",
    "          '올해에는 대통령 선거와 지방선거가 동시에 열린다',\n",
    "          '오늘 날씨는 비가 내리고 매우 춥다',\n",
    "          '손홍민이 영국 프리미어 축구 경기에서 11번째 골을 넣었다',\n",
    "          '건조한 날씨에 산불을 조심해야 한다',\n",
    "          '윈도우11 OS에 검색 기능을 강화 하였다',\n",
    "          '한국은행은 올해 하반기 금리를 동결했다']\n",
    "          \n",
    "\n",
    "labels = [\n",
    "        '여행',\n",
    "         '투표',\n",
    "         '증권',\n",
    "         'IT',\n",
    "         '날씨',\n",
    "         '스포츠',\n",
    "         '경제',\n",
    "         '정치',\n",
    "         '야구',\n",
    "         '문화',\n",
    "         '제주도'\n",
    "         ]\n",
    "\n",
    "# labels이 문장이고, input_texts가 keyword(단어)인 경우에는 True로 해줌\n",
    "reverse_tokenizer = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "805c9d1c-622e-4bc1-8c49-a797ba90edc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "투표\n",
      "9\n",
      "내년 경제 성장은 4%대 성장을 이룰거라 예상된다\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))\n",
    "print(labels[1])\n",
    "print(len(input_texts))\n",
    "print(input_texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfdcc7b0-b573-4afa-8c8a-cd9523f9c67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[CLS]', '서울', '##은', '대한민국', '##에', '수도', '##이며', ',', '정치', '경제', '중심지', '##이다', '[SEP]', '여행', '[SEP]']]\n",
      "{'input_ids': tensor([[   101,  48253,  10892,  26168,  10530,  69283,  33542,    117, 119622,\n",
      "         119641, 122451,  11925,    102, 120337,    102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# NLP 문장을 테스트 : [CLS]input_text[SEP]labels[SEP] 형식으로 tokenizer 시킴 \n",
    "tokenized_input = tokenizer([input_texts[0]], [labels[0]], return_tensors=\"pt\")\n",
    "token_str = [[tokenizer.convert_ids_to_tokens(s) for s in tokenized_input['input_ids'].tolist()[0]]]\n",
    "print(token_str)\n",
    "print(tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf7cecf1-2e5e-4158-8a57-97d6922c3583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c84bfa91d81451c988425e2f999325d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울은 대한민국에 수도이며, 정치 경제 중심지이다\n",
      "\n",
      "경제 (Score: 0.997608)\n",
      "정치 (Score: 0.991747)\n",
      "제주도 (Score: 0.000111)\n",
      "문화 (Score: 0.000086)\n",
      "IT (Score: 0.000068)\n",
      "야구 (Score: 0.000065)\n",
      "증권 (Score: 0.000052)\n",
      "투표 (Score: 0.000050)\n",
      "스포츠 (Score: 0.000050)\n",
      "여행 (Score: 0.000050)\n",
      "날씨 (Score: 0.000050)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ff802c32814f4690e7d53b284b9230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내년 경제 성장은 4%대 성장을 이룰거라 예상된다\n",
      "\n",
      "경제 (Score: 0.324677)\n",
      "정치 (Score: 0.000075)\n",
      "투표 (Score: 0.000059)\n",
      "야구 (Score: 0.000056)\n",
      "날씨 (Score: 0.000056)\n",
      "문화 (Score: 0.000053)\n",
      "여행 (Score: 0.000052)\n",
      "스포츠 (Score: 0.000048)\n",
      "증권 (Score: 0.000047)\n",
      "제주도 (Score: 0.000047)\n",
      "IT (Score: 0.000042)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e156a98cbfdf4aa28c2db355493696fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프랑스 파리는 전세계 관광객들이 매년 찾는 관광도시이다\n",
      "\n",
      "여행 (Score: 0.005320)\n",
      "문화 (Score: 0.000106)\n",
      "경제 (Score: 0.000095)\n",
      "날씨 (Score: 0.000079)\n",
      "제주도 (Score: 0.000069)\n",
      "IT (Score: 0.000067)\n",
      "야구 (Score: 0.000055)\n",
      "정치 (Score: 0.000055)\n",
      "투표 (Score: 0.000052)\n",
      "스포츠 (Score: 0.000052)\n",
      "증권 (Score: 0.000049)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ca0051c78446db916e2930d9f8c8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "올해에는 대통령 선거와 지방선거가 동시에 열린다\n",
      "\n",
      "투표 (Score: 0.001518)\n",
      "정치 (Score: 0.000156)\n",
      "경제 (Score: 0.000104)\n",
      "스포츠 (Score: 0.000073)\n",
      "여행 (Score: 0.000067)\n",
      "제주도 (Score: 0.000062)\n",
      "IT (Score: 0.000060)\n",
      "문화 (Score: 0.000058)\n",
      "증권 (Score: 0.000049)\n",
      "야구 (Score: 0.000047)\n",
      "날씨 (Score: 0.000047)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8463cbf046fa4c808dd9d0b0159a9080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘 날씨는 비가 내리고 매우 춥다\n",
      "\n",
      "날씨 (Score: 0.998735)\n",
      "스포츠 (Score: 0.000070)\n",
      "정치 (Score: 0.000058)\n",
      "IT (Score: 0.000054)\n",
      "여행 (Score: 0.000054)\n",
      "문화 (Score: 0.000052)\n",
      "증권 (Score: 0.000051)\n",
      "제주도 (Score: 0.000049)\n",
      "투표 (Score: 0.000049)\n",
      "야구 (Score: 0.000048)\n",
      "경제 (Score: 0.000042)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff9b4e4402f44e5b3e00b4cf194c909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손홍민이 영국 프리미어 축구 경기에서 11번째 골을 넣었다\n",
      "\n",
      "스포츠 (Score: 0.000114)\n",
      "IT (Score: 0.000094)\n",
      "날씨 (Score: 0.000062)\n",
      "문화 (Score: 0.000055)\n",
      "야구 (Score: 0.000052)\n",
      "증권 (Score: 0.000052)\n",
      "여행 (Score: 0.000052)\n",
      "경제 (Score: 0.000051)\n",
      "정치 (Score: 0.000051)\n",
      "제주도 (Score: 0.000045)\n",
      "투표 (Score: 0.000044)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69438e0782a7483aa75b46cabeb93c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "건조한 날씨에 산불을 조심해야 한다\n",
      "\n",
      "날씨 (Score: 0.999679)\n",
      "여행 (Score: 0.000067)\n",
      "야구 (Score: 0.000053)\n",
      "제주도 (Score: 0.000052)\n",
      "스포츠 (Score: 0.000051)\n",
      "증권 (Score: 0.000048)\n",
      "경제 (Score: 0.000048)\n",
      "정치 (Score: 0.000048)\n",
      "IT (Score: 0.000048)\n",
      "문화 (Score: 0.000046)\n",
      "투표 (Score: 0.000040)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab95680c28f34789ab1b0c14f52be4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "윈도우11 OS에 검색 기능을 강화 하였다\n",
      "\n",
      "IT (Score: 0.000084)\n",
      "여행 (Score: 0.000055)\n",
      "정치 (Score: 0.000053)\n",
      "스포츠 (Score: 0.000052)\n",
      "문화 (Score: 0.000051)\n",
      "야구 (Score: 0.000047)\n",
      "날씨 (Score: 0.000044)\n",
      "증권 (Score: 0.000043)\n",
      "제주도 (Score: 0.000041)\n",
      "투표 (Score: 0.000040)\n",
      "경제 (Score: 0.000036)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12f9307e18e4755adea3f0af2c2da17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국은행은 올해 하반기 금리를 동결했다\n",
      "\n",
      "경제 (Score: 0.002114)\n",
      "증권 (Score: 0.000109)\n",
      "정치 (Score: 0.000077)\n",
      "스포츠 (Score: 0.000059)\n",
      "문화 (Score: 0.000055)\n",
      "여행 (Score: 0.000054)\n",
      "투표 (Score: 0.000053)\n",
      "야구 (Score: 0.000051)\n",
      "IT (Score: 0.000046)\n",
      "날씨 (Score: 0.000043)\n",
      "제주도 (Score: 0.000041)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 분류 문장을 불러와서, tokenize 한 다음, 모델에 넣고 출력값을 얻어옴\n",
    "out_dict = {}\n",
    "top_k = 5\n",
    "\n",
    "for i, input_text in enumerate(input_texts):\n",
    "    for idx, label in tqdm(enumerate(labels)):\n",
    "        if reverse_tokenizer == True:\n",
    "            tokenized_input = tokenizer(label, input_text, return_tensors=\"pt\")  #역으로 표현\n",
    "        else:\n",
    "            tokenized_input = tokenizer(input_text, label, return_tensors=\"pt\")\n",
    "       \n",
    "        token_str = [[tokenizer.convert_ids_to_tokens(s) for s in tokenized_input['input_ids'].tolist()[0]]]\n",
    "        #print(token_str)\n",
    "        #print(tokenized_input)\n",
    "\n",
    "        outputs = model(**tokenized_input)\n",
    "        #print(outputs)\n",
    "        logits = outputs.logits\n",
    "        #print(logits)\n",
    "\n",
    "        '''\n",
    "        # ouput_hidden_states = True일때 출력되는 hidden_state 값을 가지고 임베딩 구할수 있음\n",
    "        hidden_states = outputs.hidden_states\n",
    "        layer_idx = 0\n",
    "        batch_idx = 0\n",
    "        token_idx = 0\n",
    "        print('hidden_states')\n",
    "        print(\"-레이어 수:{}\".format(len(hidden_states)))\n",
    "        print(\"-배치 수: {}\".format(len(hidden_states[layer_idx])))\n",
    "        print(\"-토큰 수 : {}\".format(len(hidden_states[layer_idx][batch_idx])))\n",
    "        print(\"-hidden 유닛 수 : {}\".format(len(hidden_states[layer_idx][batch_idx][token_idx])))\n",
    "        '''\n",
    "\n",
    "        # logits 에 softmax 를 취해서 총합이 1이되는 확률 분포로 만듬\n",
    "        prob = logits.softmax(dim=1)\n",
    "        #print(prob)\n",
    "\n",
    "        # entailment(참) 일 확률 중에서 가장  높은 거 선택 \n",
    "        entailment_prob = prob[0][0]      # 참(수반)일 경우 확률\n",
    "        #contradiction_prob = prob[0][1]  #거짓(모순)일 경우 확률 \n",
    "        #netral_prob = prob[0][2]         # 중립일 경우 확률\n",
    "        #print(f'input:{input_text[0]}, label:{label[0]}, 참일 확률:{entailment_prob}')\n",
    "        \n",
    "              \n",
    "        # 사전 key로 순번으로 하고, entailment(참) 일 확률를 저장함\n",
    "        key = str(idx+1)\n",
    "        out_dict[key] = entailment_prob\n",
    "      \n",
    "        '''      \n",
    "        # 확률을 소수점 2자리에서 반올림\n",
    "        entailment_prob = round(prob[0][0].item(),2) # 참(수반)일 경우 확률\n",
    "        contradiction_prob = round(prob[0][1].item(),2) # 거짓(모순)일 경우 확률\n",
    "        netral_prob = round(prob[0][2].item(),2) # 중립일 경우 확률\n",
    "\n",
    "        print(f'input:{input_text}, label:{label}')\n",
    "        print(f'참:{entailment_prob}, 거짓:{contradiction_prob}, 중립:{netral_prob}')\n",
    "\n",
    "        if torch.argmax(prob) == 0:\n",
    "            pred = \"참(entailment)\"\n",
    "        elif torch.argmax(prob) == 1:\n",
    "            pred = \"거짓(contradiction)\"\n",
    "        else: \n",
    "            pred = \"중립(netral)\"\n",
    "\n",
    "        print(f'{pred}')\n",
    "        '''      \n",
    "\n",
    "    # 사전 정렬(value(유사도)로 reverse=True 하여 내림차순으로 정렬함)\n",
    "    sorted_dict = sorted(out_dict.items(), key = lambda item: item[1], reverse = True)\n",
    "    #print(sorted_dict)\n",
    "\n",
    "    print(f'{input_text}\\n')\n",
    "\n",
    "    # 내립차순으로 정렬된 사전출력 \n",
    "    for count in (sorted_dict):\n",
    "        value = count[1].tolist() # count[1]은 2차원 tensor이므로 이를 list로 변환\n",
    "        #print(value)\n",
    "        idx = int(count[0])\n",
    "        #print(idx)\n",
    "        #print(labels[idx-1][0])\n",
    "        print(labels[idx-1].strip(), \"(Score: %.6f)\" % (value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d32aef-a886-4445-952f-5e5b97e9f4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
