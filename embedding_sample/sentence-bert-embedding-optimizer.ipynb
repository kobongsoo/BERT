{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636ee32c-db97-4810-8084-2d11566e7226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "logfilepath:../../log/sbert-embedding_2022-08-04.log\n"
     ]
    }
   ],
   "source": [
    "#=============================================================================\n",
    "# sentence-bert를 가지고 유사도 측정시, 최적화 시키는 예제임.\n",
    "# 출처 : https://towardsdatascience.com/multilingual-text-similarity-matching-using-embedding-f79037459bf2\n",
    "#\n",
    "# Optimizer 방법\n",
    "# 1. normalize_embeddings=True \n",
    "# 2. 내적 계산 : util.semantic_search \n",
    "#=============================================================================\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "from os import sys\n",
    "sys.path.append('..')\n",
    "from myutils import GPU_info, seed_everything, mlogging\n",
    "\n",
    "device = GPU_info()\n",
    "seed_everything(111)\n",
    "logger = mlogging(loggername='sbertembedding', logfilename='../../log/sbert-embedding')\n",
    "\n",
    "model_path = \"bongsoo/sentencebert_v1.2\"\n",
    "\n",
    "Optimizer = False  # 최적화 옵션 설정인 경우 True로 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a50cc6-0bbd-489a-86be-358f22dc6c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embedder = SentenceTransformer(model_path, cache_folder='./cache')\n",
    "#embedder = SentenceTransformer('bongsoo/sentencebert_v1.2', device='cpu', cache_folder='./1')\n",
    "print(embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a24601e-1b52-4547-bad0-aa282da38bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Corpus with example sentences\n",
    "corpus = ['오늘은 날씨가 흐리고 비가 온다',\n",
    "          '식당에서 밥을 먹었다',\n",
    "          '관광 버스를 타고 여행을 한다',\n",
    "          '낚시를 해서 물고기를 많이 잡았다',\n",
    "          '동물원에서 호랑이를 보았다',\n",
    "          '선거일에는 투표하러 가야 한다',\n",
    "          '마트에 가서 맛있는 배를 샀다',\n",
    "          '도서관에서 시험 공부 하고 있다',\n",
    "          '야구장에 가서 열심히 응원 했다']\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['구름 많고 매우 춥다',\n",
    "           '비행기를 타고 간다',\n",
    "           '어제 산에서 사슴를 봤다']\n",
    "'''\n",
    "'''\n",
    "corpus = ['정치',\n",
    "          '경제',\n",
    "          '여행',\n",
    "          '선거',\n",
    "          '날씨',\n",
    "          '서울',\n",
    "          '축구',\n",
    "          'IT',\n",
    "          '금융']\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['가장 가보고 싶은 여행지는?',\n",
    "           '내 지역 투표장은 어디?',\n",
    "           '요즘 가장 핫한 증권 소식은?']\n",
    "'''\n",
    "'''\n",
    "corpus = ['서울은 대한민국에 수도이며, 정치 경제 중심지이다',\n",
    "          '내년 경제 성장은 4%대 성장을 이룰거라 예상된다',\n",
    "          '프랑스 파리는 전세계 관광객들이 매년 찾는 관광도시이다',\n",
    "          '올해에는 대통령 선거와 지방선거가 동시에 열린다',\n",
    "          '오늘 날씨는 비가 내리고 매우 춥다',\n",
    "          '손홍민이 영국 프리미어 축구 경기에서 11번째 골을 넣었다',\n",
    "          '건조한 날씨에 산불을 조심해야 한다',\n",
    "          '윈도우11 OS에 검색 기능을 강화 하였다',\n",
    "          '한국은행은 올해 하반기 금리를 동결했다',\n",
    "          'Going on a trip',\n",
    "          'it is raining',\n",
    "          'stock market opened',\n",
    "          'There is a voting for the class president election'\n",
    "         ]\n",
    "          \n",
    "\n",
    "queries = ['여행',\n",
    "           '투표',\n",
    "           '증권',\n",
    "           'IT']\n",
    "'''\n",
    "\n",
    "corpus = [\n",
    "        'i love you', \n",
    "        'i am very happy', \n",
    "        'The weather is nice',\n",
    "        'You do not have to do that. It is okay',\n",
    "        'We expect the renovation to be finished by tomorrow evening.',\n",
    "        'Thank you. We won’t make you regret it.',\n",
    "        'Then I will see you at 10 a.m. tomorrow.',\n",
    "        'The print cartridge is exhausted. Should I order more?'\n",
    "         ]\n",
    "\n",
    "queries = [\n",
    "        '난 널 사랑해', \n",
    "        '난 매우 행복해', \n",
    "        '날씨가 좋다',\n",
    "        '안 그래도 되는데 뭐. 괜찮아.',\n",
    "        '내일 저녁까지 보수 공사가 끝날 것으로 예상합니다.',\n",
    "        '감사합니다. 후회 없는 결정이 될 겁니다.',\n",
    "        '그러면 오전 10시에 보도록 하죠. 내일 뵙겠습니다.',\n",
    "        '프린트 카트리지가 다 떨어졌습니다. 더 주문할까요?'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e98000-ec80-4ee1-b697-a498caae1534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 10:23:11,686 - sbertembedding - INFO - >>모델명: bongsoo/sentencebert_v1.2\n",
      "2022-08-04 10:23:11,688 - sbertembedding - INFO - >>최적화: False\n",
      "2022-08-04 10:23:11,720 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-08-04 10:23:11,721 - sbertembedding - INFO - Query:난 널 사랑해\n",
      "2022-08-04 10:23:11,722 - sbertembedding - INFO - i love you (Score: 0.6628)\n",
      "2022-08-04 10:23:11,723 - sbertembedding - INFO - i am very happy (Score: 0.5538)\n",
      "2022-08-04 10:23:11,724 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.2772)\n",
      "2022-08-04 10:23:11,724 - sbertembedding - INFO - The weather is nice (Score: 0.1496)\n",
      "2022-08-04 10:23:11,725 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.1391)\n",
      "2022-08-04 10:23:11,738 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-08-04 10:23:11,738 - sbertembedding - INFO - Query:난 매우 행복해\n",
      "2022-08-04 10:23:11,739 - sbertembedding - INFO - i am very happy (Score: 0.8904)\n",
      "2022-08-04 10:23:11,740 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.2892)\n",
      "2022-08-04 10:23:11,740 - sbertembedding - INFO - The weather is nice (Score: 0.2713)\n",
      "2022-08-04 10:23:11,741 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.2661)\n",
      "2022-08-04 10:23:11,742 - sbertembedding - INFO - i love you (Score: 0.2291)\n",
      "2022-08-04 10:23:11,753 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-08-04 10:23:11,754 - sbertembedding - INFO - Query:날씨가 좋다\n",
      "2022-08-04 10:23:11,755 - sbertembedding - INFO - The weather is nice (Score: 0.7910)\n",
      "2022-08-04 10:23:11,755 - sbertembedding - INFO - i am very happy (Score: 0.3623)\n",
      "2022-08-04 10:23:11,756 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.1835)\n",
      "2022-08-04 10:23:11,756 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.0266)\n",
      "2022-08-04 10:23:11,757 - sbertembedding - INFO - i love you (Score: 0.0260)\n",
      "2022-08-04 10:23:11,768 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-08-04 10:23:11,769 - sbertembedding - INFO - Query:안 그래도 되는데 뭐. 괜찮아.\n",
      "2022-08-04 10:23:11,770 - sbertembedding - INFO - i am very happy (Score: 0.4161)\n",
      "2022-08-04 10:23:11,771 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.3044)\n",
      "2022-08-04 10:23:11,772 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.2961)\n",
      "2022-08-04 10:23:11,773 - sbertembedding - INFO - The print cartridge is exhausted. Should I order more? (Score: 0.1837)\n",
      "2022-08-04 10:23:11,774 - sbertembedding - INFO - The weather is nice (Score: 0.1685)\n",
      "2022-08-04 10:23:11,785 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-08-04 10:23:11,786 - sbertembedding - INFO - Query:내일 저녁까지 보수 공사가 끝날 것으로 예상합니다.\n",
      "2022-08-04 10:23:11,787 - sbertembedding - INFO - We expect the renovation to be finished by tomorrow evening. (Score: 0.6868)\n",
      "2022-08-04 10:23:11,787 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.2866)\n",
      "2022-08-04 10:23:11,788 - sbertembedding - INFO - The print cartridge is exhausted. Should I order more? (Score: 0.2242)\n",
      "2022-08-04 10:23:11,788 - sbertembedding - INFO - i am very happy (Score: 0.0383)\n",
      "2022-08-04 10:23:11,789 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.0292)\n",
      "2022-08-04 10:23:11,797 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-08-04 10:23:11,797 - sbertembedding - INFO - Query:감사합니다. 후회 없는 결정이 될 겁니다.\n",
      "2022-08-04 10:23:11,798 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.5451)\n",
      "2022-08-04 10:23:11,798 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.2393)\n",
      "2022-08-04 10:23:11,799 - sbertembedding - INFO - The print cartridge is exhausted. Should I order more? (Score: 0.1876)\n",
      "2022-08-04 10:23:11,800 - sbertembedding - INFO - i am very happy (Score: 0.1628)\n",
      "2022-08-04 10:23:11,800 - sbertembedding - INFO - i love you (Score: 0.1445)\n",
      "2022-08-04 10:23:11,808 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-08-04 10:23:11,809 - sbertembedding - INFO - Query:그러면 오전 10시에 보도록 하죠. 내일 뵙겠습니다.\n",
      "2022-08-04 10:23:11,809 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.8454)\n",
      "2022-08-04 10:23:11,810 - sbertembedding - INFO - We expect the renovation to be finished by tomorrow evening. (Score: 0.2306)\n",
      "2022-08-04 10:23:11,810 - sbertembedding - INFO - i love you (Score: 0.0849)\n",
      "2022-08-04 10:23:11,811 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.0090)\n",
      "2022-08-04 10:23:11,811 - sbertembedding - INFO - The print cartridge is exhausted. Should I order more? (Score: 0.0061)\n",
      "2022-08-04 10:23:11,819 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-08-04 10:23:11,819 - sbertembedding - INFO - Query:프린트 카트리지가 다 떨어졌습니다. 더 주문할까요?\n",
      "2022-08-04 10:23:11,820 - sbertembedding - INFO - The print cartridge is exhausted. Should I order more? (Score: 0.5982)\n",
      "2022-08-04 10:23:11,821 - sbertembedding - INFO - We expect the renovation to be finished by tomorrow evening. (Score: 0.0636)\n",
      "2022-08-04 10:23:11,821 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.0549)\n",
      "2022-08-04 10:23:11,821 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.0421)\n",
      "2022-08-04 10:23:11,822 - sbertembedding - INFO - You do not have to do that. It is okay (Score: -0.0073)\n",
      "2022-08-04 10:23:11,822 - sbertembedding - INFO - \n",
      "\n",
      "\n",
      "2022-08-04 10:23:11,823 - sbertembedding - INFO - >>처리시간: 0.1375\n",
      "2022-08-04 10:23:11,824 - sbertembedding - INFO - \n",
      "\n",
      "======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus_embed_type:<class 'torch.Tensor'>\n",
      "corpus_embed_shape:torch.Size([8, 768])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "logger.info(f'>>모델명: {model_path}')\n",
    "logger.info(f'>>최적화: {Optimizer}')\n",
    "\n",
    "# corpus 임베딩\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True, normalize_embeddings=Optimizer)\n",
    "print(f'corpus_embed_type:{type(corpus_embeddings)}')\n",
    "print(f'corpus_embed_shape:{corpus_embeddings.shape}')\n",
    "\n",
    "# query 임베딩 하면서 corpus와 비교하여 유사도 출력\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "\n",
    "top_k = min(5, len(corpus))\n",
    "\n",
    "for query in queries:\n",
    "    \n",
    "    # 쿼리 임베딩 계산 \n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True, normalize_embeddings=Optimizer)\n",
    "   \n",
    "    # 최적화 처리 \n",
    "    if Optimizer == True:\n",
    "        # util.semantic_search 로 내적 계산함.\n",
    "        hits = util.semantic_search(query_embedding, corpus_embeddings, score_function=util.dot_score)\n",
    "        hits = hits[0]\n",
    "    \n",
    "        logger.info(f\"\\n\\n======================\")\n",
    "        logger.info(f\"Query:{query}\")\n",
    "\n",
    "        for hit in hits[:top_k]:\n",
    "            logger.info(f\"{corpus[hit['corpus_id']]}({round(hit['score'], 4)})\")\n",
    "            \n",
    "     # 최적화 처리가 아닌경우       \n",
    "    else:\n",
    "        cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "        cos_scores = cos_scores.cpu()\n",
    "\n",
    "        #We use np.argpartition, to only partially sort the top_k results\n",
    "        top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    "        logger.info(f\"\\n\\n======================\")\n",
    "        logger.info(f\"Query:{query}\")\n",
    "        #print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "        for idx in top_results[0:top_k]:\n",
    "            logger.info(f\"{corpus[idx].strip()} (Score: %.4f)\" % (cos_scores[idx]))\n",
    "\n",
    "logger.info(f\"\\n\\n\")\n",
    "logger.info(f'>>처리시간: {time.time()-start:.4f}')\n",
    "logger.info(f\"\\n\\n======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fd4928-458b-4509-a204-3ec5fe459b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
