{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636ee32c-db97-4810-8084-2d11566e7226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "logfilepath:../../log/sbert-embedding_2022-06-15.log\n"
     ]
    }
   ],
   "source": [
    "#=============================================================================\n",
    "# sentence-bert를 가지고 유사도 측정하는 예제임\n",
    "#SemanticSearch.py는 주어진 문장과 유사한 문장을 찾는 작업입니다.\n",
    "# 참고 소스 : https://github.com/BM-K/KoSentenceBERT-ETRI\n",
    "#=============================================================================\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "from os import sys\n",
    "sys.path.append('..')\n",
    "from myutils import GPU_info, seed_everything, mlogging\n",
    "\n",
    "device = GPU_info()\n",
    "seed_everything(111)\n",
    "logger = mlogging(loggername='sbertembedding', logfilename='../../log/sbert-embedding')\n",
    "\n",
    "model_path = \"../../data11/model/albert/albert-ts-2022-06-15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a50cc6-0bbd-489a-86be-358f22dc6c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: AlbertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embedder = SentenceTransformer(model_path)\n",
    "embedder.to(device)\n",
    "print(embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a24601e-1b52-4547-bad0-aa282da38bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Corpus with example sentences\n",
    "corpus = ['오늘은 날씨가 흐리고 비가 온다',\n",
    "          '식당에서 밥을 먹었다',\n",
    "          '관광 버스를 타고 여행을 한다',\n",
    "          '낚시를 해서 물고기를 많이 잡았다',\n",
    "          '동물원에서 호랑이를 보았다',\n",
    "          '선거일에는 투표하러 가야 한다',\n",
    "          '마트에 가서 맛있는 배를 샀다',\n",
    "          '도서관에서 시험 공부 하고 있다',\n",
    "          '야구장에 가서 열심히 응원 했다']\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['구름 많고 매우 춥다',\n",
    "           '비행기를 타고 간다',\n",
    "           '어제 산에서 사슴를 봤다']\n",
    "'''\n",
    "'''\n",
    "corpus = ['정치',\n",
    "          '경제',\n",
    "          '여행',\n",
    "          '선거',\n",
    "          '날씨',\n",
    "          '서울',\n",
    "          '축구',\n",
    "          'IT',\n",
    "          '금융']\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['가장 가보고 싶은 여행지는?',\n",
    "           '내 지역 투표장은 어디?',\n",
    "           '요즘 가장 핫한 증권 소식은?']\n",
    "'''\n",
    "'''\n",
    "corpus = ['서울은 대한민국에 수도이며, 정치 경제 중심지이다',\n",
    "          '내년 경제 성장은 4%대 성장을 이룰거라 예상된다',\n",
    "          '프랑스 파리는 전세계 관광객들이 매년 찾는 관광도시이다',\n",
    "          '올해에는 대통령 선거와 지방선거가 동시에 열린다',\n",
    "          '오늘 날씨는 비가 내리고 매우 춥다',\n",
    "          '손홍민이 영국 프리미어 축구 경기에서 11번째 골을 넣었다',\n",
    "          '건조한 날씨에 산불을 조심해야 한다',\n",
    "          '윈도우11 OS에 검색 기능을 강화 하였다',\n",
    "          '한국은행은 올해 하반기 금리를 동결했다',\n",
    "          'Going on a trip',\n",
    "          'it is raining',\n",
    "          'stock market opened',\n",
    "          'There is a voting for the class president election'\n",
    "         ]\n",
    "          \n",
    "\n",
    "queries = ['여행',\n",
    "           '투표',\n",
    "           '증권',\n",
    "           'IT']\n",
    "'''\n",
    "\n",
    "corpus = [\n",
    "        'i love you', \n",
    "        'i am very happy', \n",
    "        'The weather is nice',\n",
    "        'You do not have to do that. It is okay',\n",
    "        'We expect the renovation to be finished by tomorrow evening.',\n",
    "        'Thank you. We won’t make you regret it.',\n",
    "        'Then I will see you at 10 a.m. tomorrow.',\n",
    "        'The print cartridge is exhausted. Should I order more?'\n",
    "         ]\n",
    "\n",
    "queries = [\n",
    "        '난 널 사랑해', \n",
    "        '난 매우 행복해', \n",
    "        '날씨가 좋다',\n",
    "        '안 그래도 되는데 뭐. 괜찮아.',\n",
    "        '내일 저녁까지 보수 공사가 끝날 것으로 예상합니다.',\n",
    "        '감사합니다. 후회 없는 결정이 될 겁니다.',\n",
    "        '그러면 오전 10시에 보도록 하죠. 내일 뵙겠습니다.',\n",
    "        '프린트 카트리지가 다 떨어졌습니다. 더 주문할까요?'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e98000-ec80-4ee1-b697-a498caae1534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 08:59:45,526 - sbertembedding - INFO - >>모델명: ../../data11/model/albert/albert-ts-2022-06-15\n",
      "2022-06-16 08:59:46,605 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-06-16 08:59:46,607 - sbertembedding - INFO - Query:난 널 사랑해\n",
      "2022-06-16 08:59:46,608 - sbertembedding - INFO - i am very happy (Score: 0.4207)\n",
      "2022-06-16 08:59:46,609 - sbertembedding - INFO - The weather is nice (Score: 0.4023)\n",
      "2022-06-16 08:59:46,609 - sbertembedding - INFO - i love you (Score: 0.3619)\n",
      "2022-06-16 08:59:46,610 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.3213)\n",
      "2022-06-16 08:59:46,611 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.2857)\n",
      "2022-06-16 08:59:46,624 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-06-16 08:59:46,625 - sbertembedding - INFO - Query:난 매우 행복해\n",
      "2022-06-16 08:59:46,626 - sbertembedding - INFO - i am very happy (Score: 0.4207)\n",
      "2022-06-16 08:59:46,627 - sbertembedding - INFO - The weather is nice (Score: 0.4023)\n",
      "2022-06-16 08:59:46,628 - sbertembedding - INFO - i love you (Score: 0.3619)\n",
      "2022-06-16 08:59:46,628 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.3213)\n",
      "2022-06-16 08:59:46,629 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.2857)\n",
      "2022-06-16 08:59:46,643 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-06-16 08:59:46,644 - sbertembedding - INFO - Query:날씨가 좋다\n",
      "2022-06-16 08:59:46,644 - sbertembedding - INFO - i am very happy (Score: 0.4080)\n",
      "2022-06-16 08:59:46,645 - sbertembedding - INFO - The weather is nice (Score: 0.4046)\n",
      "2022-06-16 08:59:46,645 - sbertembedding - INFO - i love you (Score: 0.3924)\n",
      "2022-06-16 08:59:46,646 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.3025)\n",
      "2022-06-16 08:59:46,648 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.3023)\n",
      "2022-06-16 08:59:46,661 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-06-16 08:59:46,662 - sbertembedding - INFO - Query:안 그래도 되는데 뭐. 괜찮아.\n",
      "2022-06-16 08:59:46,662 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.5884)\n",
      "2022-06-16 08:59:46,664 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.3956)\n",
      "2022-06-16 08:59:46,664 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.2879)\n",
      "2022-06-16 08:59:46,665 - sbertembedding - INFO - i am very happy (Score: 0.2782)\n",
      "2022-06-16 08:59:46,665 - sbertembedding - INFO - The weather is nice (Score: 0.2552)\n",
      "2022-06-16 08:59:46,680 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-06-16 08:59:46,681 - sbertembedding - INFO - Query:내일 저녁까지 보수 공사가 끝날 것으로 예상합니다.\n",
      "2022-06-16 08:59:46,681 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.3022)\n",
      "2022-06-16 08:59:46,682 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.2977)\n",
      "2022-06-16 08:59:46,683 - sbertembedding - INFO - We expect the renovation to be finished by tomorrow evening. (Score: 0.2763)\n",
      "2022-06-16 08:59:46,684 - sbertembedding - INFO - i am very happy (Score: 0.2723)\n",
      "2022-06-16 08:59:46,684 - sbertembedding - INFO - The weather is nice (Score: 0.2388)\n",
      "2022-06-16 08:59:46,698 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-06-16 08:59:46,698 - sbertembedding - INFO - Query:감사합니다. 후회 없는 결정이 될 겁니다.\n",
      "2022-06-16 08:59:46,699 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.5299)\n",
      "2022-06-16 08:59:46,700 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.4476)\n",
      "2022-06-16 08:59:46,701 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.2896)\n",
      "2022-06-16 08:59:46,701 - sbertembedding - INFO - The print cartridge is exhausted. Should I order more? (Score: 0.2477)\n",
      "2022-06-16 08:59:46,702 - sbertembedding - INFO - i am very happy (Score: 0.2188)\n",
      "2022-06-16 08:59:46,716 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-06-16 08:59:46,717 - sbertembedding - INFO - Query:그러면 오전 10시에 보도록 하죠. 내일 뵙겠습니다.\n",
      "2022-06-16 08:59:46,718 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.6373)\n",
      "2022-06-16 08:59:46,718 - sbertembedding - INFO - The print cartridge is exhausted. Should I order more? (Score: 0.2218)\n",
      "2022-06-16 08:59:46,719 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.2139)\n",
      "2022-06-16 08:59:46,719 - sbertembedding - INFO - We expect the renovation to be finished by tomorrow evening. (Score: 0.1694)\n",
      "2022-06-16 08:59:46,720 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.1559)\n",
      "2022-06-16 08:59:46,734 - sbertembedding - INFO - \n",
      "\n",
      "======================\n",
      "2022-06-16 08:59:46,734 - sbertembedding - INFO - Query:프린트 카트리지가 다 떨어졌습니다. 더 주문할까요?\n",
      "2022-06-16 08:59:46,735 - sbertembedding - INFO - The print cartridge is exhausted. Should I order more? (Score: 0.3768)\n",
      "2022-06-16 08:59:46,736 - sbertembedding - INFO - You do not have to do that. It is okay (Score: 0.3595)\n",
      "2022-06-16 08:59:46,736 - sbertembedding - INFO - Thank you. We won’t make you regret it. (Score: 0.3470)\n",
      "2022-06-16 08:59:46,737 - sbertembedding - INFO - Then I will see you at 10 a.m. tomorrow. (Score: 0.2356)\n",
      "2022-06-16 08:59:46,738 - sbertembedding - INFO - The weather is nice (Score: 0.1013)\n",
      "2022-06-16 08:59:46,738 - sbertembedding - INFO - \n",
      "\n",
      "\n",
      "2022-06-16 08:59:46,739 - sbertembedding - INFO - >>처리시간: 1.2129\n",
      "2022-06-16 08:59:46,739 - sbertembedding - INFO - \n",
      "\n",
      "======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus_embed_type:<class 'torch.Tensor'>\n",
      "corpus_embed_shape:torch.Size([8, 768])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "logger.info(f'>>모델명: {model_path}')\n",
    "\n",
    "# corpus 임베딩\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "print(f'corpus_embed_type:{type(corpus_embeddings)}')\n",
    "print(f'corpus_embed_shape:{corpus_embeddings.shape}')\n",
    "\n",
    "# query 임베딩 하면서 corpus와 비교하여 유사도 출력\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = 5\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "\n",
    "    #We use np.argpartition, to only partially sort the top_k results\n",
    "    top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    "    logger.info(f\"\\n\\n======================\")\n",
    "    logger.info(f\"Query:{query}\")\n",
    "    #print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for idx in top_results[0:top_k]:\n",
    "        logger.info(f\"{corpus[idx].strip()} (Score: %.4f)\" % (cos_scores[idx]))\n",
    "\n",
    "logger.info(f\"\\n\\n\")\n",
    "logger.info(f'>>처리시간: {time.time()-start:.4f}')\n",
    "logger.info(f\"\\n\\n======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fd4928-458b-4509-a204-3ec5fe459b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
