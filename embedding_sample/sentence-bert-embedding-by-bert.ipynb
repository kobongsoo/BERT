{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636ee32c-db97-4810-8084-2d11566e7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Search\n",
    "# 여기서는 사전훈련된 bert 모델을 sentence-bert로 만들고(훈련은 안시킴) embedding 하는 예시임\n",
    "# 참고 소스 : https://github.com/BM-K/KoSentenceBERT-ETRI\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "model_name = '../model/bmc_fpt_kowiki20200920.train_model_0225'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a50cc6-0bbd-489a-86be-358f22dc6c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../model/bmc_fpt_kowiki20200920.train_model_0225 were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ../model/bmc_fpt_kowiki20200920.train_model_0225 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n"
     ]
    }
   ],
   "source": [
    "# 모델과 tokenizer 를 불러옴\n",
    "# => **사전파일(vocab.txt, *.json) 와 model 경로(config.json, pytorch_model.bin)가 같은 경로에 있어야 함.\n",
    "word_embedding_model = models.Transformer(model_name, max_seq_length=128)\n",
    "print(word_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc815bc9-18c8-48c1-8552-f1e2f1c4f30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n"
     ]
    }
   ],
   "source": [
    "# 2 bert 모델의 임베딩 풀링 정책을 설정(cls 이용, 워드임베딩 평균이용, 워드임베딩 max 이용)\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),  #모델이 dimension(768)\n",
    "                               pooling_mode_mean_tokens=True,  # 워드 임베딩 평균을 이용\n",
    "                               pooling_mode_cls_token=False,   # cls 를 이용\n",
    "                               pooling_mode_max_tokens=False)  # 워드 임베딩 값중 max 값을 이용\n",
    "\n",
    "print(pooling_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb7a4ea2-64e8-40d6-87f7-fc1659250a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# SBERT 모델 생성\n",
    "# word_embedding 과 pooling 모델을 연결시켜서 SBERT 생성\n",
    "embedder = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "print(embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a24601e-1b52-4547-bad0-aa282da38bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Corpus with example sentences\n",
    "corpus = ['오늘은 날씨가 흐리고 비가 온다',\n",
    "          '식당에서 밥을 먹었다',\n",
    "          '관광 버스를 타고 여행을 한다',\n",
    "          '낚시를 해서 물고기를 많이 잡았다',\n",
    "          '동물원에서 호랑이를 보았다',\n",
    "          '선거일에는 투표하러 가야 한다',\n",
    "          '마트에 가서 맛있는 배를 샀다',\n",
    "          '도서관에서 시험 공부 하고 있다',\n",
    "          '야구장에 가서 열심히 응원 했다']\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['구름 많고 매우 춥다',\n",
    "           '비행기를 타고 간다',\n",
    "           '어제 산에서 사슴를 봤다']\n",
    "'''\n",
    "'''\n",
    "corpus = ['정치',\n",
    "          '경제',\n",
    "          '여행',\n",
    "          '선거',\n",
    "          '날씨',\n",
    "          '서울',\n",
    "          '축구',\n",
    "          'IT',\n",
    "          '금융']\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['가장 가보고 싶은 여행지는?',\n",
    "           '내 지역 투표장은 어디?',\n",
    "           '요즘 가장 핫한 증권 소식은?']\n",
    "'''\n",
    "\n",
    "corpus = ['서울은 대한민국에 수도이며, 정치 경제 중심지이다',\n",
    "          '내년 경제 성장은 4%대 성장을 이룰거라 예상된다',\n",
    "          '프랑스 파리는 전세계 관광객들이 매년 찾는 관광도시이다',\n",
    "          '올해에는 대통령 선거와 지방선거가 동시에 열린다',\n",
    "          '오늘 날씨는 비가 내리고 매우 춥다',\n",
    "          '손홍민이 영국 프리미어 축구 경기에서 11번째 골을 넣었다',\n",
    "          '건조한 날씨에 산불을 조심해야 한다',\n",
    "          '윈도우11 OS에 검색 기능을 강화 하였다',\n",
    "          '한국은행은 올해 하반기 금리를 동결했다',\n",
    "          'Going on a trip',\n",
    "          'it is raining',\n",
    "          'stock market opened',\n",
    "          'There is a voting for the class president election'\n",
    "         ]\n",
    "          \n",
    "queries = ['여행',\n",
    "           '투표',\n",
    "           '증권',\n",
    "           'IT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e98000-ec80-4ee1-b697-a498caae1534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: 여행\n",
      "stock market opened (Score: 0.7146)\n",
      "Going on a trip (Score: 0.6484)\n",
      "it is raining (Score: 0.6278)\n",
      "윈도우11 OS에 검색 기능을 강화 하였다 (Score: 0.4957)\n",
      "한국은행은 올해 하반기 금리를 동결했다 (Score: 0.4849)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: 투표\n",
      "stock market opened (Score: 0.6930)\n",
      "it is raining (Score: 0.5957)\n",
      "Going on a trip (Score: 0.5681)\n",
      "올해에는 대통령 선거와 지방선거가 동시에 열린다 (Score: 0.5078)\n",
      "윈도우11 OS에 검색 기능을 강화 하였다 (Score: 0.5048)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: 증권\n",
      "stock market opened (Score: 0.7740)\n",
      "it is raining (Score: 0.6256)\n",
      "Going on a trip (Score: 0.5830)\n",
      "윈도우11 OS에 검색 기능을 강화 하였다 (Score: 0.5240)\n",
      "한국은행은 올해 하반기 금리를 동결했다 (Score: 0.5215)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: IT\n",
      "stock market opened (Score: 0.7160)\n",
      "it is raining (Score: 0.6323)\n",
      "Going on a trip (Score: 0.5875)\n",
      "윈도우11 OS에 검색 기능을 강화 하였다 (Score: 0.5444)\n",
      "한국은행은 올해 하반기 금리를 동결했다 (Score: 0.5004)\n"
     ]
    }
   ],
   "source": [
    "# corpus 임베딩\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "# query 임베딩 하면서 corpus와 비교하여 유사도 출력\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = 5\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "\n",
    "    #We use np.argpartition, to only partially sort the top_k results\n",
    "    top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    #print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for idx in top_results[0:top_k]:\n",
    "        print(corpus[idx].strip(), \"(Score: %.4f)\" % (cos_scores[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefa1295-4739-4167-8a8e-35280a936e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fd4928-458b-4509-a204-3ec5fe459b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
