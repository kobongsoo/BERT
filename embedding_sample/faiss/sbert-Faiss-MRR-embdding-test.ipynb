{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f263c8-7ae3-454a-ac8d-c160ed0c626d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:../../../log/MRR-BM25_2023-02-08.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/MOCOMSYS/anaconda3/envs/bong/lib/python3.9/site-packages/huggingface_hub/snapshot_download.py:6: FutureWarning: snapshot_download.py has been made private and will no longer be available from version 0.11. Please use `from huggingface_hub import snapshot_download` to import the only public function in this module. Other members of the file may be changed without a deprecation notice.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "################################################################################################\n",
    "# sentence-bert와 Faiss 라이브러리를 이용하여 검색 MRR(Mean Reciprocal Rank)와 BM25 측정하는 예시임\n",
    "# => bm25 설치 : !pip install rank_bm25\n",
    "#\n",
    "# 1. 검색모델 로딩\n",
    "# 2. json QuA파일 로딩 하여, 각 항목별 리스트를 출력한후, contexts df, questions df를 만듬.\n",
    "# 3. 정답리스트에 대해 임베딩 벡터 생성 후 FAISS에 인덱싱함.\n",
    "# 4. 쿼리를 list로 만들고, 검색 후 예측된 결과를 list로 만듬\n",
    "# 5. 정답리스트와 예측리스트를 가지고 MRR을 구함\n",
    "# 6. contexts df 를 BM25 인덱싱 하고 , questions df 를 쿼리로 입력하여 BM25 스코어 구함\n",
    "################################################################################################\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from os import sys\n",
    "sys.path.append('../../')\n",
    "from myutils import GPU_info, seed_everything, mlogging\n",
    "\n",
    "logger = mlogging(loggername=\"MRR-BM25\", logfilename=\"../../../log/MRR-BM25\")\n",
    "device = GPU_info()\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "# 0. param 설정\n",
    "#------------------------------------------------------------------------------------\n",
    "seed = 111\n",
    "query_num = 500            # 쿼리 최대 갯수: KorQuAD_v1.0_dev.json 최대값은 5533개임, 0이면 모든 5533개 쿼리함.\n",
    "search_k = 5               # FAISS 검색시, 검색 계수(5=쿼리와 가장 근접한 5개 결과값을 반환함)\n",
    "use_cross_encoder = True   # cross_encoder 사용할지 유.무 (true=사용함, false=사용안함)\n",
    "use_bm25 = True            # BM25 출력 할지=True. 안할지=False\n",
    "embedding_paragraph_avg = False # True = 문장 임베딩 구할때 여러문장 벡터 평균으로 구함(느림), Fals=문장 전체를 하나의 벡터로 생성(빠름)\n",
    "faiss_index_method = 0      # 0= Cosine Similarity 적용(IndexFlatIP 사용), 1= Euclidean Distance 적용(IndexFlatL2 사용)\n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "# param 인자 범위 체크\n",
    "if faiss_index_method > 1 or faiss_index_method < 0:\n",
    "    raise ValueError(f\"faiss_index_method = {faiss_index_method} is not bad!!\")\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d37af48-ce3e-40c7-864a-52707d315490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------\n",
    "# 1.sentence bert 모델 로딩\n",
    "#-------------------------------------------------------------------------------------\n",
    "from myutils import bi_encoder\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "bi_encoder_path = \"bongsoo/albert-small-kor-sbert-v1.1\" # kpf-sbert-v1.1\" # klue-sbert-v1 # albert-small-kor-sbert-v1.1 # kpf-sbert-v1.1\n",
    "pooling_mode = 'mean' # mean # cls\n",
    "\n",
    "bi_encoder = bi_encoder(model_path=bi_encoder_path, max_seq_len=256, do_lower_case=True, pooling_mode=pooling_mode)\n",
    "bi_encoder.to(device)\n",
    "\n",
    "# cross-encoder 모델 로딩\n",
    "if use_cross_encoder == True:\n",
    "    cross_encoder_path = \"bongsoo/albert-small-kor-cross-encoder-v1\"# klue-cross-encoder-v1 # albert-small-kor-cross-encoder-v1 # kpf_cross-encoder-v1\n",
    "    cross_encoder = CrossEncoder(cross_encoder_path, max_length=512, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9817b7db-b57b-4328-a521-f10fb0512295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------\n",
    "# 2. KorQuAD_v1.0_dev.json 파일 로딩 하여, 각 항목별 리스트를 출력한후, contexts df, questions df를 만듬.\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "from myutils import read_korquad_v1_json, read_aihub_qua_json\n",
    "\n",
    "# aihub QuA 파일을 불러옴.\n",
    "jsonfile = './data/VL_text_entailment.json' # VL_unanswerable.json # VL_text_entailment.json # VL_span_inference.json # KorQuAD_v1.0_dev.json\n",
    "contexts, questions, answers, contextids, qcontextids = read_aihub_qua_json(jsonfile) # read_aihub_qua_json(jsonfile)\n",
    "\n",
    "# list들을 zip 으로 묶고, dataframe 생성함\n",
    "# context, contextid를 묶어서 context df 만듬.\n",
    "df_contexts = pd.DataFrame((zip(contexts, contextids)), columns = ['context','contextid'])\n",
    "\n",
    "# question, answer, contextids를 묶어서 question df 만듬\n",
    "df_questions = pd.DataFrame((zip(questions, answers, qcontextids)), columns = ['question','answer', 'contextid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a31dca2b-0527-4c98-ad4a-72a7da4ff40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>contextid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>두올산업은 캐나다 법인 온코퀘스트의 난소암 면역 항암 신약 ‘오레고보맙’에 대한 미...</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>법무부가 '이태원발 코로나19 감염사태'와 관련해 외국인들에 대한 관리 강화에 나선...</td>\n",
       "      <td>10002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>유안타증권이 14일 미국주식 투자자들을 대상으로 글로벌 금융정보회사 레피니티브(Re...</td>\n",
       "      <td>10003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>인천 남동구에서 '이태원 클럽'을 방문한 학원강사로부터 코로나19 감염된 고3 모자...</td>\n",
       "      <td>10004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>헬스에어테크놀로지코리아(HATK)의 독일 공기청정기 브랜드 나노드론이 ‘공기의 세계...</td>\n",
       "      <td>10005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  contextid\n",
       "0  두올산업은 캐나다 법인 온코퀘스트의 난소암 면역 항암 신약 ‘오레고보맙’에 대한 미...      10001\n",
       "1  법무부가 '이태원발 코로나19 감염사태'와 관련해 외국인들에 대한 관리 강화에 나선...      10002\n",
       "2  유안타증권이 14일 미국주식 투자자들을 대상으로 글로벌 금융정보회사 레피니티브(Re...      10003\n",
       "3  인천 남동구에서 '이태원 클럽'을 방문한 학원강사로부터 코로나19 감염된 고3 모자...      10004\n",
       "4  헬스에어테크놀로지코리아(HATK)의 독일 공기청정기 브랜드 나노드론이 ‘공기의 세계...      10005"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contexts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6642f193-c571-49a4-9745-c65760e8a72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contextid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>오레고보맙의 임상이 전 세계 환자들을 상대로 실시돼</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>전 세계 환자들을 상대로 오레고보맙의 임상이 시행돼</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이태원 클럽에 간 외국인들의 코로나 자진 검사를 법무부가 유도하고 있어</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>법무부는 이태원 클럽과 관련된 외국인들에게 코로나 자진 검사를 하도록 유도했어</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>유안타증권은 미국주식 유망 종목 자동검색 시스템을 오픈했어</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      question answer  contextid\n",
       "0                 오레고보맙의 임상이 전 세계 환자들을 상대로 실시돼    Yes      10001\n",
       "1                 전 세계 환자들을 상대로 오레고보맙의 임상이 시행돼    Yes      10001\n",
       "2      이태원 클럽에 간 외국인들의 코로나 자진 검사를 법무부가 유도하고 있어    Yes      10002\n",
       "3  법무부는 이태원 클럽과 관련된 외국인들에게 코로나 자진 검사를 하도록 유도했어    Yes      10002\n",
       "4             유안타증권은 미국주식 유망 종목 자동검색 시스템을 오픈했어    Yes      10003"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4532c81d-da09-4e8c-99d0-f5cb451066e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*임베딩 할 context 계수: 3001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07aeb4ceb64429395f4ad2653756a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*임베딩 시간 : 7.3745\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------\n",
    "# 3. 임베딩 벡터 생성 후 FAISS에 인덱싱함.\n",
    "#---------------------------------------------------------\n",
    "from myutils import embed_text_avg\n",
    "\n",
    "#=============================================================================\n",
    "# 문장을 .(마침표)로 여러 문장으로 나누고 나눈문장을 1개씩 임베딩 구한후 계수만큼 나워서 평균 임베딩 구하기\n",
    "# => 속도 느림, 최대 15개만 함.(CPU 환경에서는 좋음)\n",
    "#=============================================================================\n",
    "def paragraph_index(paragraph):\n",
    "    avg_paragraph_vec = np.zeros((1,768))\n",
    "    sent_count = 0\n",
    "    \n",
    "    # ** kss로 분할할때 히브리어: מר, 기타 이상한 특수문자 있으면 에러남. \n",
    "    # 따라서 여기서는 그냥 . 기준으로 문장을 나누고 평균을 구함\n",
    "    # 하나의 문장을 읽어와서 .기준으로 나눈다.\n",
    "    sentences = [sentence for sentence in paragraph.split('. ') if sentence != '' and len(sentence) > 20]\n",
    "    \n",
    "    for sent in sentences:\n",
    "        # 문장으로 나누고, 해당 vector들의 평균을 구함.\n",
    "        #avg_paragraph_vec += embed_text([sent])\n",
    "        avg_paragraph_vec += embed_text(model=bi_encoder, contexts=[sent], return_tensor=False)\n",
    "        sent_count += 1\n",
    "  \n",
    "        # 최대 15개 문장만 처리함 \n",
    "        if sent_count >= 15:\n",
    "            break\n",
    "         \n",
    "    '''\n",
    "    # kss로 분할할때 줄바꿈 있으면, 파싱하는데 에러남.따라서 \"\\n\"는 제거함\n",
    "    paragraph = paragraph.replace(\"\\n\",\"\")\n",
    "    \n",
    "    print(\"==Start paragraph_index==\")\n",
    "    print(paragraph)\n",
    "    for sent in kss.split_sentences(paragraph):\n",
    "        # 문장으로 나누고, 해당 vector들의 평균을 구함.\n",
    "        avg_paragraph_vec += embed_text([sent])\n",
    "        sent_count += 1\n",
    "        \n",
    "        # 최대 10개 문장만 처리함 \n",
    "        if sent_count >= 10:\n",
    "            break\n",
    "    '''\n",
    " \n",
    "    # 0으로 나누면 배열이 nan(not a number)가 되어 버리므로, 반드시 0>큰지 확인해야 함\n",
    "    if sent_count > 0:\n",
    "        avg_paragraph_vec /= sent_count\n",
    "    \n",
    "    return avg_paragraph_vec.ravel(order='C') # 1차원 배열로 변경\n",
    "   \n",
    "#=============================================================================\n",
    "# 임베딩 벡터 생성하여 FAISS에 인덱싱하고 ID와 매핑 처리하는 함수\n",
    "# => IN : contextdf\n",
    "# => OUT : FASSI index\n",
    "#=============================================================================\n",
    "def embeddingforfaiss(df, use_paragraph_avg):\n",
    "           \n",
    "    # embedding 생성(인코딩)\n",
    "    start = time.time()\n",
    "    paragraphs = df.context.to_list()\n",
    "    print(f'*임베딩 할 context 계수: {len(paragraphs)}') \n",
    "    \n",
    "    # paragraph_avg == True 이면 평균 문자 임베딩 벡터 구함.\n",
    "    if use_paragraph_avg == True:\n",
    "        print(f'*----평균 문장 임베딩 벡터 구하기----')\n",
    "        embeddings = [embed_text_avg(model=bi_encoder, contexts=paragraph) for paragraph in tqdm(paragraphs)]\n",
    "    else:\n",
    "        embeddings = bi_encoder.encode(paragraphs, show_progress_bar=True, convert_to_tensor=False)\n",
    "       \n",
    "    embeddings = np.array([embedding for embedding in embeddings]).astype(\"float32\")#float32 로 embeddings 타입 변경\n",
    "    #print(type(embeddings)) #print(embeddings.shape) #print(embeddings[0])    \n",
    "    \n",
    "    # instance index 생성\n",
    "    # => IndexFlatL2 : Euclidean Distance 측정함\n",
    "    # => IndexFlatIP : cosine 유사도 측정함 => faiss.normalize_L2(embeddings) 호출해줘야 함.\n",
    "    if faiss_index_method == 0:      # 0=Cosine Similarity 적용(IndexFlatIP 사용), \n",
    "        index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "        faiss.normalize_L2(embeddings)# *cosine유사도 구할때는 반드시 normalize 처리함.\n",
    "    elif faiss_index_method == 1:    # 1=Euclidean Distance 적용(IndexFlatL2 사용)\n",
    "        index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    \n",
    "    # id를 매핑 시켜줌 => 이때 idtype은 반드시 int64 type이어야 함.\n",
    "    index = faiss.IndexIDMap2(index)\n",
    "\n",
    "    index.add_with_ids(embeddings, df.contextid.values)\n",
    "\n",
    "    print(f'*임베딩 시간 : {time.time()-start:.4f}')\n",
    "    \n",
    "    return index\n",
    "\n",
    "#df 임베딩 구하고 faiss에 추가함.\n",
    "index = embeddingforfaiss(df_contexts, use_paragraph_avg = embedding_paragraph_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d66cdf-f2c3-4a49-872b-ba6be597f808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query-----------------------------------------------------\n",
      "['막걸리 제조 회사의 지분을 플루토가 사들였어', '버핏을 속인 독일 기업에 관한조사가 시행되고 있어', '중견기업계는 국민의 요청을 인지해야 한다고 21대 국회에게 발언했어']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ead2f744114db5bab8c5d690510270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "bi-encoder 예측:500\n",
      "[[10511, 10655, 10457, 11455, 12432], [10622, 11146, 11455, 10063, 10743], [10214, 11146, 12635, 11398, 11354]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7049a252877450db517d4290bdc26a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "cross-encoder 예측:500\n",
      "[[10655, 12432, 10511, 11455, 10457], [11455, 10063, 10743, 11146, 10622], [10214, 11398, 11146, 12635, 11354]]\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------\n",
    "# 4. 쿼리를 list로 만들고, 검색 후 예측된 결과를 list로 만듬\n",
    "#----------------------------------------------------------------\n",
    "from tqdm.notebook import tqdm\n",
    "from myutils import df_sampling\n",
    "\n",
    "# Query를 list로 만들고 -> query 인코딩후->검색 결과 출력\n",
    "\n",
    "if query_num == 0:   # query_num = 0 이면 모든 쿼리(5533개)\n",
    "    user_query = df_questions['question'].values.tolist()\n",
    "else:   # query_num > 0이면 해당 계수만큼 랜덤하게 샘플링하여 쿼리 목록을 만듬.\n",
    "    df_questions = df_sampling(df=df_questions, num=query_num, seed=seed)\n",
    "    user_query = df_questions['question'].values.tolist()\n",
    "\n",
    "print(f'Query-----------------------------------------------------')\n",
    "print(user_query[0:3])\n",
    "\n",
    "vector = bi_encoder.encode(user_query)\n",
    "if faiss_index_method == 0:\n",
    "    faiss.normalize_L2(vector)              # *cosine유사도 구할때는 반드시 normalize 처리함.\n",
    "    \n",
    "distance, idx = index.search(np.array(vector).astype(\"float32\"), k=search_k)\n",
    "\n",
    "# 예측검색결과를 리스트로 만듬.\n",
    "bi_predictions_list = []\n",
    "\n",
    "for i, query in enumerate(tqdm(user_query)):\n",
    "    bi_predictions_list.append(idx[i].tolist())\n",
    "    \n",
    "print(f'----------------------------------------------------------')\n",
    "print(f'bi-encoder 예측:{len(bi_predictions_list)}')\n",
    "print(bi_predictions_list[0:3])\n",
    "\n",
    "# cross-encoder 사용인 경우에\n",
    "# - 한번더 검색된 결과에 {쿼리, 문장} 쌍으로 만들어서 cross-encoder로 스코어 출력함.\n",
    "if use_cross_encoder == True:\n",
    "    # {쿼리, 문장} 쌍 만듬.\n",
    "    #count = 0\n",
    "    cross_predictions_list = []\n",
    "    for i, predicts in enumerate(tqdm(bi_predictions_list)):\n",
    "        sentence_combinations = []\n",
    "        query = user_query[i]\n",
    "        #count += 1\n",
    "             \n",
    "        for predict in predicts:  \n",
    "             sentence_combinations.append([query, df_contexts[df_contexts.contextid == predict]['context'].values.tolist()[0]])\n",
    "                     \n",
    "        # cross-enocoder 돌려서 출력된 score 추가함.\n",
    "        cross_scores = cross_encoder.predict(sentence_combinations)+1\n",
    "        #print(f'*cross_scores:{cross_scores}')\n",
    "        \n",
    "        dec_cross_idx = reversed(np.argsort(cross_scores))\n",
    "        tmp_list = []\n",
    "        for idx in dec_cross_idx:\n",
    "            #print(f'idx:{idx}-predicts:{predicts[idx]}')\n",
    "            tmp_list.append(predicts[idx])\n",
    "         \n",
    "        cross_predictions_list.append(tmp_list)   \n",
    "    \n",
    "    print(f'----------------------------------------------------------')\n",
    "    print(f'cross-encoder 예측:{len(cross_predictions_list)}')\n",
    "    print(f'{cross_predictions_list[0:3]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e9d524d-0666-4ba9-ac56-35a59f9af7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 15:14:07,780 - MRR-BM25 - INFO - --------------------------------------------------------------------------\n",
      "2023-02-08 15:14:07,783 - MRR-BM25 - INFO - json_file:./data/VL_text_entailment.json\n",
      "2023-02-08 15:14:07,784 - MRR-BM25 - INFO - faiss 인덱싱 방식: 0(0=코사인, 1=유클리드)\n",
      "2023-02-08 15:14:07,785 - MRR-BM25 - INFO - 문장 평균 임베딩 유.무: False(true=적용됨, false=적용안됨)\n",
      "2023-02-08 15:14:07,786 - MRR-BM25 - INFO - search_k:5/query_num:500\n",
      "2023-02-08 15:14:07,788 - MRR-BM25 - INFO - --------------------------------------------------------------------------\n",
      "2023-02-08 15:14:07,789 - MRR-BM25 - INFO - *BI-ENCODER:bongsoo/albert-small-kor-sbert-v1.1\n",
      "2023-02-08 15:14:07,790 - MRR-BM25 - INFO - *BI-MRR:0.1288\n",
      "2023-02-08 15:14:07,791 - MRR-BM25 - INFO - *Ranks(500):[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3333333333333333, 0]\n",
      "2023-02-08 15:14:07,792 - MRR-BM25 - INFO - ---------------------------------------------------------------------------\n",
      "2023-02-08 15:14:07,793 - MRR-BM25 - INFO - *CROSS-ENCODER:bongsoo/albert-small-kor-cross-encoder-v1\n",
      "2023-02-08 15:14:07,794 - MRR-BM25 - INFO - *CROSS-MRR:0.1860\n",
      "2023-02-08 15:14:07,795 - MRR-BM25 - INFO - *Ranks(500):[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0]\n",
      "2023-02-08 15:14:07,796 - MRR-BM25 - INFO - *검색실패계수: 402/500(80.40%)\n",
      "2023-02-08 15:14:07,797 - MRR-BM25 - INFO - \n",
      "BI -> CROSS---------------------------------------------------------------------------\n",
      "2023-02-08 15:14:07,799 - MRR-BM25 - INFO -      bi-rank  cross-rank\n",
      "0   0.000000         0.0\n",
      "1   0.000000         0.0\n",
      "2   0.000000         0.0\n",
      "3   0.000000         0.0\n",
      "4   0.000000         0.0\n",
      "5   0.000000         0.0\n",
      "6   0.000000         0.0\n",
      "7   0.000000         0.0\n",
      "8   0.000000         0.0\n",
      "9   0.000000         0.0\n",
      "10  0.000000         0.0\n",
      "11  0.000000         0.0\n",
      "12  0.000000         0.0\n",
      "13  0.000000         0.0\n",
      "14  0.000000         0.0\n",
      "15  0.000000         0.0\n",
      "16  0.000000         0.0\n",
      "17  0.000000         0.0\n",
      "18  0.333333         1.0\n",
      "19  0.000000         0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------------------------\n",
    "# 5. MRR을 구함\n",
    "##--------------------------------------------------------------------------------------------------\n",
    "from myutils import mean_reciprocal_rank\n",
    "\n",
    "# 정답, 여기서는 contextid를 리스트로 만듬.\n",
    "ground_truths_list = df_questions['contextid'].values.tolist()\n",
    "#print(f'gtlen:{len(ground_truths_list)}')\n",
    "#print(ground_truths_list[0:9])\n",
    "\n",
    "logger.info(f'--------------------------------------------------------------------------')\n",
    "logger.info('json_file:{}'.format(jsonfile))\n",
    "logger.info(f'faiss 인덱싱 방식: {faiss_index_method}(0=코사인, 1=유클리드)')\n",
    "logger.info(f'문장 평균 임베딩 유.무: {embedding_paragraph_avg}(true=적용됨, false=적용안됨)')\n",
    "logger.info('search_k:{}/query_num:{}'.format(search_k, query_num))\n",
    "\n",
    "# MRR를 구함\n",
    "if use_cross_encoder == True:\n",
    "    predictions_list = bi_predictions_list\n",
    "    bi_ranks, bi_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "\n",
    "    # BI-MRR 출력\n",
    "    logger.info(f'--------------------------------------------------------------------------')\n",
    "    logger.info('*BI-ENCODER:{}'.format(bi_encoder_path))\n",
    "    logger.info('*BI-MRR:{:.4f}'.format(bi_score))\n",
    "    logger.info(f'*Ranks({len(bi_ranks)}):{bi_ranks[0:20]}')\n",
    "    \n",
    "    predictions_list = cross_predictions_list\n",
    "    cross_ranks, cross_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "    logger.info(f'---------------------------------------------------------------------------')\n",
    "    logger.info('*CROSS-ENCODER:{}'.format(cross_encoder_path))\n",
    "    logger.info('*CROSS-MRR:{:.4f}'.format(cross_score))\n",
    "    logger.info(f'*Ranks({len(cross_ranks)}):{cross_ranks[0:20]}')\n",
    "    \n",
    "    # 검색 못한 계슈\n",
    "    print(f'---------------------------------------------------------------------------')\n",
    "    zero_count = 0\n",
    "    for item in bi_ranks:\n",
    "        if item == 0:\n",
    "            zero_count += 1\n",
    "    \n",
    "    logger.info('*검색실패계수: {}/{}({:.2f}%)'.format(zero_count, len(bi_ranks), (zero_count/len(bi_ranks))*100))\n",
    "    print(f'---------------------------------------------------------------------------')\n",
    "    \n",
    "    logger.info(f'\\nBI -> CROSS---------------------------------------------------------------------------')\n",
    "    df_scores = pd.DataFrame((zip(bi_ranks, cross_ranks)), columns = ['bi-rank','cross-rank'])\n",
    "    logger.info(df_scores.head(20))\n",
    "\n",
    "else:\n",
    "    predictions_list = bi_predictions_list\n",
    "\n",
    "    bi_ranks, bi_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "\n",
    "    # BI-MRR 출력\n",
    "    logger.info(f'----------------------------------------------------------------------------')\n",
    "    logger.info('*BI-ENCODER:{}'.format(bi_encoder_path))\n",
    "    logger.info('*BI-MRR:{:.4f}'.format(bi_score))\n",
    "    logger.info(f'*Ranks({len(bi_ranks)}):{bi_ranks[0:20]}')\n",
    "    \n",
    "    # 검색 못한 계슈\n",
    "    logger.info(f'---------------------------------------------------------------------------')\n",
    "    zero_count = 0\n",
    "    for item in bi_ranks:\n",
    "        if item == 0:\n",
    "            zero_count += 1\n",
    "    \n",
    "    logger.info('*검색실패계수: {}/{}({:.2f}%)'.format(zero_count, len(bi_ranks), (zero_count/len(bi_ranks))*100))\n",
    "    logger.info(f'---------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0e32738-2975-4e53-8738-da92152e387d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5201405c99445008a8e1d567dc65e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*contexts_len:3001\n",
      "두 올 산업 은 캐나다 법인 온 코 퀘스트 의 난소암 면역 항암 신약 ‘ 오레 고보 맙 ’ 에 대한 미국 FDA ( 식품 의 약국 ) 임상 3 상 이 순항 중 이 라고 14 일 밝혔 다 . 온 코 퀘스트 관계자 는 \" 2019 년 11 월 4 일 미국 FDA 에 제출 한 IND ( 임상시험 계획 ) 에 대한 지연 통보 를 받 지 않 아 , 12 월 4 일 부터 임상 3 상 이 개시 됐 다 \" 며 \" 올해 23 월 글로벌 임상시험 수탁 기관 ( CRO ) 업체 IQVIA 와 서비스 계약 을 체결 하 고 , 본격 적 인 환자 모집 을 진행 하 고 있 다 \" 고 말 했 다 . 이어 \" 현재 북미 , 남미 , 유럽 , 아시아 국가 에 139 곳 사이트 를 통해 총 602 명 의 환자 등록 을 위해 각 사이트 별 환자 모집 을 하 고 있 다 \" 며 \" 미국 부인 종양학 연구회 ( GOG Foundation ) 와 임상 3 상 관련 서비스 계약 을 체결 하 여 본격 적 인 임상 준비 중 이 다 \" 고 설명 했 다 . 온 코 퀘스트 는 현재 코로나 19 영향 으로 일부 지역 의 병원 및 임상 센터 와 의 일정 조율 중 이 다 . 오 는 7 - 8 월 1 차 환자 등록 이 완료 되 고 , 본격 적 인 임상 시험 에 들어갈 것 으로 예상 하 고 있 다 . 이 관계자 는 \" 난소암 신규 환자 대상 외 에 도 재발 환자 대상 으로 도 하반기 에 글로벌 제약사 GSK 의 난소암 치료 제 제 줄라 와 병 용 투여 치료 에 대한 임상 을 진행할 예정 \" 이 라며 \" 췌장암 에 대한 임상 또한 임상 1 / 2 상 을 미국 과 중국 환자 대상 으로 동시 에 진행 할 계획 이 다 \" 고 전했 다 . 이어 \" 두 올 산업 은 양수 한 무형 자산 파이프라인 의 임상 프로그램 이 순차 적 으로 진행 되 는 데 문제 가 없 도록 충분 한 자금 을 확보 했 다 \" 고 덧붙였 다 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 15:14:21,910 - MRR-BM25 - INFO - --------------------------------------------------------------------------\n",
      "2023-02-08 15:14:21,912 - MRR-BM25 - INFO - *BM25-MRR(mecab 적용):0.8519\n",
      "2023-02-08 15:14:21,913 - MRR-BM25 - INFO - *Ranks(500):[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0]\n",
      "2023-02-08 15:14:21,914 - MRR-BM25 - INFO - *BM25(mecab 적용) 검색실패계수: 28/500(5.60%)\n",
      "2023-02-08 15:14:21,915 - MRR-BM25 - INFO - ---------------------------------------------------------------------------\n",
      "2023-02-08 15:14:25,981 - MRR-BM25 - INFO - --------------------------------------------------------------------------\n",
      "2023-02-08 15:14:25,983 - MRR-BM25 - INFO - *BM25-MRR:0.5067\n",
      "2023-02-08 15:14:25,984 - MRR-BM25 - INFO - *Ranks(500):[1.0, 1.0, 1.0, 1.0, 0, 1.0, 0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0, 1.0, 0.3333333333333333, 0, 0.3333333333333333, 0, 0.3333333333333333]\n",
      "2023-02-08 15:14:25,985 - MRR-BM25 - INFO - *BM25 검색실패계수: 200/500(40.00%)\n",
      "2023-02-08 15:14:25,985 - MRR-BM25 - INFO - ---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------------\n",
    "# 6. BM25 계산\n",
    "# => korquad_v1.0 말뭉치를 가지고 BM25 계산하는 함수\n",
    "# => for문을 2번 돌면서 BM25 2번 계산함.\n",
    "#    - 처음에는(0) 해당 쿼리와 contexts에 대해 mecab 적용 후 BM25 스코어 계산, \n",
    "#    - 2번째는 mecab 적용하지 않고 계산\n",
    "#------------------------------------------------------------------------------------------------\n",
    "if use_bm25 == True:\n",
    "\n",
    "    import konlpy\n",
    "    from konlpy.tag import Mecab\n",
    "    from rank_bm25 import BM25Okapi\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "    def BM25tokenizer(sent):\n",
    "      return sent.split(\" \")\n",
    "\n",
    "    # 입력된 contexts를 mecab을 이용하여 형태소 추출 후 \" \" 붙여서 형태소 문장을 만듬.\n",
    "    # Mecab 선언\n",
    "    mecab = Mecab()\n",
    "\n",
    "    for count in range(2):\n",
    "        mecab_str = ''\n",
    "        # 0이면(처음엔) mecab 적용함=> tokeniaer 후 인덱싱\n",
    "        if count == 0:\n",
    "            mecab_str = \"(mecab 적용)\"\n",
    "            mecab_contexts=[]\n",
    "            for context in tqdm(contexts):\n",
    "                temp = mecab.morphs(context)   # ['세계', '배달', '피자', '리더', '도미노피자','가'..] 식으로 temp 리스트가 생성됨\n",
    "                sentence = \" \".join(temp)      # 위 temp 리스트를 공백을 넣어서 한문장으로 합침 ['세계 배달 피자 리더 도미노피자 가 ...]\n",
    "                mecab_contexts.append(sentence)\n",
    "\n",
    "            print(f'*contexts_len:{len(mecab_contexts)}')  \n",
    "            print(f'{mecab_contexts[0]}')\n",
    "\n",
    "            # tokeniaer 후 인덱싱\n",
    "            tokenized_corpus = [BM25tokenizer(doc) for doc in mecab_contexts]\n",
    "        else:\n",
    "            # 2번째는 그냥 인덱싱\n",
    "            tokenized_corpus = [BM25tokenizer(doc) for doc in contexts]\n",
    "            \n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "        #print(f'bm25.doc_len:{bm25.doc_len}')\n",
    "        #print(f'type(bm25.doc_freqs):{type(bm25.doc_freqs)}')\n",
    "        \n",
    "        bm5_predictions_list = []\n",
    "     \n",
    "        # 쿼리 후 get_scores 를 이용하여, scores를 구함.\n",
    "        for idx, query in enumerate(user_query):\n",
    "            \n",
    "            # 처음에는 mecab적용해서 query문 전처리 함.\n",
    "            if count == 0:\n",
    "                tempq = mecab.morphs(query) \n",
    "                query = \" \".join(tempq)\n",
    "                \n",
    "            # 쿼리에 따른 스코어 구함    \n",
    "            tokenized_query = BM25tokenizer(query)\n",
    "            doc_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "            # 정렬후 최대 스코어 search_k 만큼만 출력함\n",
    "            top_lists = sorted(enumerate(doc_scores), key=lambda x: x[1], reverse=True)[:search_k]\n",
    "            bm5_predictions_list.append([index + contextids[0] for index, score in top_lists])\n",
    "\n",
    "        # 정답, 여기서는 contextid를 리스트로 만듬.\n",
    "        ground_truths_list = df_questions['contextid'].values.tolist()\n",
    "\n",
    "        # MPR 계산\n",
    "        predictions_list = bm5_predictions_list  # 예측 결과 리스트\n",
    "        bm25_ranks, bm25_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "\n",
    "         # BM25-MRR 출력\n",
    "        logger.info(f'--------------------------------------------------------------------------')\n",
    "        logger.info('*BM25-MRR{}:{:.4f}'.format(mecab_str, bm25_score))\n",
    "        logger.info(f'*Ranks({len(bm25_ranks)}):{bm25_ranks[0:20]}')\n",
    "        # 검색 못한 계슈\n",
    "        #logger.info(f'---------------------------------------------------------------------------')\n",
    "        zero_count = 0\n",
    "        for item in bm25_ranks:\n",
    "            if item == 0:\n",
    "                zero_count += 1\n",
    "\n",
    "        logger.info('*BM25{} 검색실패계수: {}/{}({:.2f}%)'.format(mecab_str, zero_count, len(bm25_ranks), (zero_count/len(bm25_ranks))*100))\n",
    "        logger.info(f'---------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b162d0ab-a628-484b-93ab-5aacf826e0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
