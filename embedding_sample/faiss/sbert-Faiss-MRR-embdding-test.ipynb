{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f263c8-7ae3-454a-ac8d-c160ed0c626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "# sentence-bert와 Faiss 라이브러리를 이용하여 검색 MRR(Mean Reciprocal Rank)와 BM25 측정하는 예시임\n",
    "# => bm25 설치 : !pip install rank_bm25\n",
    "#\n",
    "# 1. 검색모델 로딩\n",
    "# 2. json QuA파일 로딩 하여, 각 항목별 리스트를 출력한후, contexts df, questions df를 만듬.\n",
    "# 3. 정답리스트에 대해 임베딩 벡터 생성 후 FAISS에 인덱싱함.\n",
    "# 4. 쿼리를 list로 만들고, 검색 후 예측된 결과를 list로 만듬\n",
    "# 5. 정답리스트와 예측리스트를 가지고 MRR을 구함\n",
    "# 6. contexts df 를 BM25 인덱싱 하고 , questions df 를 쿼리로 입력하여 BM25 스코어 구함\n",
    "#\n",
    "# 쿼리가:단어일때\n",
    "# => 문장 평균: 20%, 단어 평균: 10% \n",
    "# => BM25=Mecab 적용시: 85%, 적용안할때: 50%\n",
    "#\n",
    "#-------------------------------------------------------------------------------\n",
    "# sklenarn 으로 cosine 확인 예제\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# cosine_sim = cosine_similarity([embed_querys[0]], [embed_querys_1[0]]) # (1,768) 식에 2차원 배열입력되어야 함.\n",
    "#-------------------------------------------------------------------------------\n",
    "################################################################################################\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from os import sys\n",
    "sys.path.append('../../')\n",
    "from myutils import GPU_info, seed_everything, mlogging\n",
    "\n",
    "logger = mlogging(loggername=\"MRR-BM25\", logfilename=\"../../../log/MRR-BM25\")\n",
    "device = GPU_info()\n",
    "#device = 'cpu'  # cpu 테스트 할때\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "# 0. param 설정\n",
    "#------------------------------------------------------------------------------------\n",
    "seed = 111\n",
    "query_num = 500            # 쿼리 최대 갯수: KorQuAD_v1.0_dev.json 최대값은 5533개임, 0이면 모든 5533개 쿼리함.\n",
    "search_k = 5              # FAISS 검색시, 검색 계수(5=쿼리와 가장 근접한 5개 결과값을 반환함)\n",
    "use_cross_encoder = False   # cross_encoder 사용할지 유.무 (true=사용함, false=사용안함)\n",
    "use_bm25 = True           # BM25 출력 할지=True. 안할지=False\n",
    "embed_avg_method = 1     # 0=문장 전체를 하나의 벡터로 생성(빠름), 1 = 문장 임베딩 구할때 여러문장 벡터 평균으로 구함(느림), 2=문장에 단어(명사) 추출후 단어 벡터들의 평균 구함(더느림)\n",
    "faiss_index_method = 0   # Faiss 인덱스 생성 방식 => 0=코사인유사도(Cosine Similarity) 방식(IndexFlatIP 사용), 1= 유클리드거리(Euclidean Distance) 방식(IndexFlatL2 사용)\n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "# param 인자 범위 체크\n",
    "if faiss_index_method > 1 or faiss_index_method < 0:\n",
    "    raise ValueError(f\"faiss_index_method = {faiss_index_method} is not bad!!\")\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d37af48-ce3e-40c7-864a-52707d315490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------\n",
    "# 1.sentence bert 모델 로딩\n",
    "#-------------------------------------------------------------------------------------\n",
    "from myutils import bi_encoder\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "bi_encoder_path = \"bongsoo/kpf-sbert-v1.1\"#\"bongsoo/kpf-sbert-v1.1\" # kpf-sbert-v1.1 # klue-sbert-v1 # albert-small-kor-sbert-v1.1\n",
    "pooling_mode = 'mean' # bert면=mean, albert면 = cls\n",
    "out_dimension = 0    # 출력 임베딩 크기 지정 : 0=기본 모델 임베딩크기(768), 예:128=128 츨력임베딩 크기 \n",
    "\n",
    "word_embedding_model, bi_encoder = bi_encoder(model_path=bi_encoder_path, max_seq_len=512, do_lower_case=True, pooling_mode=pooling_mode, out_dimension=out_dimension, device=device)\n",
    "#bi_encoder.to(device)\n",
    "\n",
    "# cross-encoder 모델 로딩\n",
    "if use_cross_encoder == True:\n",
    "    cross_encoder_path = \"bongsoo/klue-cross-encoder-v1\"# klue-cross-encoder-v1 # albert-small-kor-cross-encoder-v1 # kpf-cross-encoder-v1\n",
    "    #cross_encoder_path = \"../../../data11/model/moco/cross/kpf-cross-sts4\"\n",
    "    cross_encoder = CrossEncoder(cross_encoder_path, max_length=512, num_labels=1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817b7db-b57b-4328-a521-f10fb0512295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------\n",
    "# 2. KorQuAD_v1.0_dev.json 파일 로딩 하여, 각 항목별 리스트를 출력한후, contexts df, questions df를 만듬.\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "from myutils import read_korquad_v1_json, read_aihub_qua_json\n",
    "\n",
    "# aihub QuA 파일을 불러옴.\n",
    "jsonfile = './data/VL_unanswerable.json' # VL_unanswerable.json # VL_text_entailment.json # VL_span_inference.json # KorQuAD_v1.0_dev.json\n",
    "contexts, questions, answers, contextids, qcontextids = read_aihub_qua_json(jsonfile) # read_aihub_qua_json(jsonfile)\n",
    "\n",
    "# list들을 zip 으로 묶고, dataframe 생성함\n",
    "# context, contextid를 묶어서 context df 만듬.\n",
    "df_contexts = pd.DataFrame((zip(contexts, contextids)), columns = ['context','contextid'])\n",
    "\n",
    "# question, answer, contextids를 묶어서 question df 만듬\n",
    "df_questions = pd.DataFrame((zip(questions, answers, qcontextids)), columns = ['question','answer', 'contextid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31dca2b-0527-4c98-ad4a-72a7da4ff40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contexts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e11035b-54bf-4047-97bc-1cd9c463765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contexts[0:1].context.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642f193-c571-49a4-9745-c65760e8a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49963e6-2852-4a7d-af44-8203e34e037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------\n",
    "# faiss 인덱스 생성 테스트\n",
    "#------------------------------------------------------\n",
    "from myutils import embed_text_avg, embed_vocab_bytag\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "paragraphs = df_contexts.context.to_list()\n",
    "#print(paragraphs)\n",
    "\n",
    "embeddings = [embed_text_avg(model=bi_encoder, paragraph=paragraph) for paragraph in tqdm(paragraphs)]\n",
    "\n",
    "embeddings_arr = np.array([embedding for embedding in embeddings]).astype(\"float32\")#float32 로 embeddings 타입 변경\n",
    "    \n",
    "index_test = faiss.IndexFlatIP(embeddings_arr.shape[1])\n",
    "faiss.normalize_L2(embeddings_arr)# *cosine유사도 구할때는 반드시 normalize 처리함.\n",
    "    \n",
    "# id를 매핑 시켜줌 => 이때 idtype은 반드시 int64 type이어야 함.\n",
    "index_test = faiss.IndexIDMap2(index_test)\n",
    "\n",
    "index_test.add_with_ids(embeddings_arr, df_contexts.contextid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db20fea-1fa1-4d39-b2c5-db5e33cf81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------\n",
    "# faiss 인덱스 서치 테스트\n",
    "#------------------------------------------------------\n",
    "\n",
    "from myutils import embed_text, embed_vocab_bytag\n",
    "\n",
    "query = '서울지방결창청 공안부실.'  #쿼리\n",
    "q1 = bi_encoder.encode(query)\n",
    "#q1 = embed_vocab_bytag(model=bi_encoder, paragraph=[query], show=True)\n",
    "\n",
    "vector = np.array([q1]).astype('float32')\n",
    "#print(vector.shape)\n",
    "faiss.normalize_L2(vector)   \n",
    "\n",
    "distance, idx = index_test.search(vector, k=30)\n",
    "print(f'{distance}-{idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a791f3-1714-4fca-824f-05cafc9220b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------\n",
    "# sklearn 코사인 테스트\n",
    "#------------------------------------------------------\n",
    "from myutils import embed_text_avg, embed_vocab_bytag\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cid = 372  # 검색된 contexts idx-10000 해준 값 입력.\n",
    "\n",
    "#embed1 = embed_vocab_bytag(model=bi_encoder, paragraph=[df_contexts[cid-1:cid].context.values[0]], show=True) # 단어 평균 임베딩\n",
    "embed1 = embed_text_avg(model=bi_encoder, paragraph=df_contexts[cid-1:cid].context.values[0])                  # 문장 평균 임베딩\n",
    "\n",
    "#embed2 = embed_vocab_bytag(model=bi_encoder, paragraph=[query], show=True)       # 단어 평균 쿼리\n",
    "embed2 = bi_encoder.encode(query)                                                 # 문장평균 쿼리 \n",
    "\n",
    "cosine_sim = cosine_similarity([embed1], [embed2]) # (1,768) 식에 2차원 배열입력되어야 함.\n",
    "print(f'*유사도:{cosine_sim}')\n",
    "print(df_contexts[cid-1:cid].context.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532c81d-da09-4e8c-99d0-f5cb451066e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------\n",
    "# 3. 임베딩 벡터 생성 후 FAISS에 인덱싱함.\n",
    "#---------------------------------------------------------\n",
    "from myutils import embed_text_avg, embed_vocab_bytag\n",
    "   \n",
    "#=============================================================================\n",
    "# 임베딩 벡터 생성하여 FAISS에 인덱싱하고 ID와 매핑 처리하는 함수\n",
    "# => IN : contextdf\n",
    "# => OUT : FASSI index\n",
    "#=============================================================================\n",
    "def embeddingforfaiss(df, embed_avg_method:int ):\n",
    "           \n",
    "    # embedding 생성(인코딩)\n",
    "    start = time.time()\n",
    "    paragraphs = df.context.to_list()\n",
    "    print(f'*임베딩 할 context 계수: {len(paragraphs)}') \n",
    "    \n",
    "    # paragraph_avg == True 이면 평균 문자 임베딩 벡터 구함.\n",
    "    if embed_avg_method == 1:\n",
    "        print(f'*----문장들 평균 임베딩 벡터 구하기----')\n",
    "        embeddings = [embed_text_avg(model=bi_encoder, paragraph=paragraph) for paragraph in tqdm(paragraphs)]\n",
    "    elif embed_avg_method == 2:\n",
    "        print(f'*----단어들 평균 임베딩 벡터 구하기----')\n",
    "        embeddings = [embed_vocab_bytag(model=bi_encoder, paragraph=paragraph) for paragraph in tqdm(paragraphs)]\n",
    "    else:\n",
    "        print(f'*----문단 벡터 구하기----')\n",
    "        embeddings = bi_encoder.encode(paragraphs, show_progress_bar=True, convert_to_tensor=False)\n",
    "       \n",
    "    embeddings_arr = np.array([embedding for embedding in embeddings]).astype(\"float32\")#float32 로 embeddings 타입 변경\n",
    "    #print(type(embeddings)) #print(embeddings.shape) #print(embeddings[0])    \n",
    "    \n",
    "    # instance index 생성\n",
    "    # => IndexFlatL2 : Euclidean Distance 측정함\n",
    "    # => IndexFlatIP : cosine 유사도 측정함 => faiss.normalize_L2(embeddings) 호출해줘야 함.\n",
    "    if faiss_index_method == 0:      # 0=Cosine Similarity 적용(IndexFlatIP 사용), \n",
    "        index = faiss.IndexFlatIP(embeddings_arr.shape[1])\n",
    "        faiss.normalize_L2(embeddings_arr)# *cosine유사도 구할때는 반드시 normalize 처리함.\n",
    "    elif faiss_index_method == 1:    # 1=Euclidean Distance 적용(IndexFlatL2 사용)\n",
    "        index = faiss.IndexFlatL2(embeddings_arr.shape[1])\n",
    "    \n",
    "    # id를 매핑 시켜줌 => 이때 idtype은 반드시 int64 type이어야 함.\n",
    "    index = faiss.IndexIDMap2(index)\n",
    "\n",
    "    index.add_with_ids(embeddings_arr, df.contextid.values)\n",
    "\n",
    "    print(f'*임베딩 시간 : {time.time()-start:.4f}')\n",
    "    \n",
    "    return index\n",
    "\n",
    "#df 임베딩 구하고 faiss에 추가함.\n",
    "index = embeddingforfaiss(df_contexts, embed_avg_method = embed_avg_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d66cdf-f2c3-4a49-872b-ba6be597f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------\n",
    "# 4. 쿼리를 list로 만들고, 검색 후 예측된 결과를 list로 만듬\n",
    "#----------------------------------------------------------------\n",
    "from tqdm.notebook import tqdm\n",
    "from myutils import df_sampling, embed_vocab_bytag\n",
    "\n",
    "# Query를 list로 만들고 -> query 인코딩후->검색 결과 출력\n",
    "\n",
    "if query_num == 0:   # query_num = 0 이면 모든 쿼리(5533개)\n",
    "    user_query = df_questions['question'].values.tolist()\n",
    "else:   # query_num > 0이면 해당 계수만큼 랜덤하게 샘플링하여 쿼리 목록을 만듬.\n",
    "    df_questions = df_sampling(df=df_questions, num=query_num, seed=seed)\n",
    "    user_query = df_questions['answer'].values.tolist()\n",
    "\n",
    "print(f'Query-----------------------------------------------------')\n",
    "print(user_query[0:3])\n",
    "\n",
    "# 단어 평균인 경우에는 쿼리도 평균으로 구함.\n",
    "if embed_avg_method == 2:   \n",
    "    print(f'*----단어들 평균 임베딩 벡터 구하기----')\n",
    "    vector_list = []\n",
    "    for uquery in user_query:\n",
    "        tmp = embed_vocab_bytag(model=bi_encoder, paragraph=uquery)\n",
    "        vector_list.append(tmp) \n",
    "        \n",
    "    vector = np.array(vector_list).astype('float32')\n",
    "else:\n",
    "    vector = bi_encoder.encode(user_query)\n",
    "    \n",
    "if faiss_index_method == 0:\n",
    "    faiss.normalize_L2(vector)              # *cosine유사도 구할때는 반드시 normalize 처리함.\n",
    "    \n",
    "distance, idx = index.search(np.array(vector).astype(\"float32\"), k=search_k)\n",
    "\n",
    "# 예측검색결과를 리스트로 만듬.\n",
    "bi_predictions_list = []\n",
    "\n",
    "for i, query in enumerate(tqdm(user_query)):\n",
    "    bi_predictions_list.append(idx[i].tolist())\n",
    "    \n",
    "print(f'----------------------------------------------------------')\n",
    "print(f'bi-encoder 예측:{len(bi_predictions_list)}')\n",
    "print(bi_predictions_list[0:3])\n",
    "\n",
    "# cross-encoder 사용인 경우에\n",
    "# - 한번더 검색된 결과에 {쿼리, 문장} 쌍으로 만들어서 cross-encoder로 스코어 출력함.\n",
    "if use_cross_encoder == True:\n",
    "    # {쿼리, 문장} 쌍 만듬.\n",
    "    #count = 0\n",
    "    cross_predictions_list = []\n",
    "    for i, predicts in enumerate(tqdm(bi_predictions_list)):\n",
    "        sentence_combinations = []\n",
    "        query = user_query[i]\n",
    "        #count += 1\n",
    "             \n",
    "        for predict in predicts:  \n",
    "             # {쿼리, 문장} 쌍을 만듬 (예: ['프랑스 해안에서 발견된 고래는 뭐야?, '프랑스 남부 니츠 해안에서는 지난 2022년 10월 1일 커다른 물고기 시체가 떠왔다.....']\n",
    "             sentence_combinations.append([query, df_contexts[df_contexts.contextid == predict]['context'].values.tolist()[0]])\n",
    "                     \n",
    "        # cross-enocoder 돌려서 출력된 score 추가함.\n",
    "        cross_scores = cross_encoder.predict(sentence_combinations)+1\n",
    "        #print(f'*cross_scores:{cross_scores}')\n",
    "        \n",
    "        dec_cross_idx = reversed(np.argsort(cross_scores))\n",
    "        tmp_list = []\n",
    "        for idx in dec_cross_idx:\n",
    "            #print(f'idx:{idx}-predicts:{predicts[idx]}')\n",
    "            tmp_list.append(predicts[idx])\n",
    "         \n",
    "        cross_predictions_list.append(tmp_list)   \n",
    "    \n",
    "    print(f'----------------------------------------------------------')\n",
    "    print(f'cross-encoder 예측:{len(cross_predictions_list)}')\n",
    "    print(f'{cross_predictions_list[0:3]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d524d-0666-4ba9-ac56-35a59f9af7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------\n",
    "# 5. MRR을 구함\n",
    "##--------------------------------------------------------------------------------------------------\n",
    "from myutils import mean_reciprocal_rank\n",
    "\n",
    "# 정답, 여기서는 contextid를 리스트로 만듬.\n",
    "ground_truths_list = df_questions['contextid'].values.tolist()\n",
    "#print(f'gtlen:{len(ground_truths_list)}')\n",
    "#print(ground_truths_list[0:9])\n",
    "\n",
    "logger.info(f'--------------------------------------------------------------------------')\n",
    "logger.info('json_file:{}'.format(jsonfile))\n",
    "logger.info(f'*faiss 인덱싱 방식: {faiss_index_method}(0=코사인, 1=유클리드)')\n",
    "logger.info(f'*문단 임베딩 방식: {embed_avg_method}(0=전체, 1=문장평균, 2=단어평균)')\n",
    "logger.info('*search_k:{}/query_num:{}'.format(search_k, query_num))\n",
    "\n",
    "# MRR를 구함\n",
    "if use_cross_encoder == True:\n",
    "    predictions_list = bi_predictions_list\n",
    "    bi_ranks, bi_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "\n",
    "    # BI-MRR 출력\n",
    "    logger.info(f'--------------------------------------------------------------------------')\n",
    "    logger.info('*BI-ENCODER:{}'.format(bi_encoder_path))\n",
    "    logger.info('*BI-MRR:{:.4f}'.format(bi_score))\n",
    "    logger.info(f'*Ranks({len(bi_ranks)}):{bi_ranks[0:20]}')\n",
    "    \n",
    "    predictions_list = cross_predictions_list\n",
    "    cross_ranks, cross_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "    logger.info(f'---------------------------------------------------------------------------')\n",
    "    logger.info('*CROSS-ENCODER:{}'.format(cross_encoder_path))\n",
    "    logger.info('*CROSS-MRR:{:.4f}'.format(cross_score))\n",
    "    logger.info(f'*Ranks({len(cross_ranks)}):{cross_ranks[0:20]}')\n",
    "    \n",
    "    # 검색 한 계슈\n",
    "    #logger.info(f'---------------------------------------------------------------------------')\n",
    "    search_count = 0\n",
    "    for item in cross_ranks:\n",
    "        if item != 0:\n",
    "            search_count += 1\n",
    "\n",
    "    logger.info('*검색률: {}/{}({:.2f}%)'.format(search_count, len(cross_ranks), (search_count/len(cross_ranks))*100))\n",
    "    logger.info(f'---------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "    logger.info(f'\\nBI -> CROSS---------------------------------------------------------------------------')\n",
    "    df_scores = pd.DataFrame((zip(bi_ranks, cross_ranks)), columns = ['bi-rank','cross-rank'])\n",
    "    logger.info(df_scores.head(20))\n",
    "\n",
    "else:\n",
    "    predictions_list = bi_predictions_list\n",
    "\n",
    "    bi_ranks, bi_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "\n",
    "    # BI-MRR 출력\n",
    "    logger.info(f'----------------------------------------------------------------------------')\n",
    "    logger.info('*BI-ENCODER:{}'.format(bi_encoder_path))\n",
    "    logger.info('*BI-MRR:{:.4f}'.format(bi_score))\n",
    "    logger.info(f'*Ranks({len(bi_ranks)}):{bi_ranks[0:20]}')\n",
    "    \n",
    "    # 검색 한 계슈\n",
    "    #logger.info(f'---------------------------------------------------------------------------')\n",
    "    search_count = 0\n",
    "    for item in bi_ranks:\n",
    "        if item != 0:\n",
    "            search_count += 1\n",
    "\n",
    "    logger.info('*검색률: {}/{}({:.2f}%)'.format(search_count, len(bi_ranks), (search_count/len(bi_ranks))*100))\n",
    "    logger.info(f'---------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e32738-2975-4e53-8738-da92152e387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------\n",
    "# 6. BM25 계산\n",
    "# => korquad_v1.0 말뭉치를 가지고 BM25 계산하는 함수\n",
    "# => for문을 2번 돌면서 BM25 2번 계산함.\n",
    "#    - 처음에는(0) 해당 쿼리와 contexts에 대해 mecab 적용 후 BM25 스코어 계산, \n",
    "#    - 2번째는 mecab 적용하지 않고 계산\n",
    "#------------------------------------------------------------------------------------------------\n",
    "if use_bm25 == True:\n",
    "\n",
    "    import konlpy\n",
    "    from konlpy.tag import Mecab\n",
    "    from rank_bm25 import BM25Okapi\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "    def BM25tokenizer(sent):\n",
    "      return sent.split(\" \")\n",
    "\n",
    "    # 입력된 contexts를 mecab을 이용하여 형태소 추출 후 \" \" 붙여서 형태소 문장을 만듬.\n",
    "    # Mecab 선언\n",
    "    mecab = Mecab()\n",
    "\n",
    "    for count in range(2):\n",
    "        mecab_str = ''\n",
    "        # 0이면(처음엔) mecab 적용함=> tokeniaer 후 인덱싱\n",
    "        if count == 0:\n",
    "            mecab_str = \"(mecab 적용)\"\n",
    "            mecab_contexts=[]\n",
    "            for context in tqdm(contexts):\n",
    "                temp = mecab.morphs(context)   # ['세계', '배달', '피자', '리더', '도미노피자','가'..] 식으로 temp 리스트가 생성됨\n",
    "                sentence = \" \".join(temp)      # 위 temp 리스트를 공백을 넣어서 한문장으로 합침 ['세계 배달 피자 리더 도미노피자 가 ...]\n",
    "                mecab_contexts.append(sentence)\n",
    "\n",
    "            print(f'*contexts_len:{len(mecab_contexts)}')  \n",
    "            print(f'{mecab_contexts[0]}')\n",
    "\n",
    "            # tokeniaer 후 인덱싱\n",
    "            tokenized_corpus = [BM25tokenizer(doc) for doc in mecab_contexts]\n",
    "        else:\n",
    "            # 2번째는 그냥 인덱싱\n",
    "            tokenized_corpus = [BM25tokenizer(doc) for doc in contexts]\n",
    "            \n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "        #print(f'bm25.doc_len:{bm25.doc_len}')\n",
    "        #print(f'type(bm25.doc_freqs):{type(bm25.doc_freqs)}')\n",
    "        \n",
    "        bm5_predictions_list = []\n",
    "     \n",
    "        # 쿼리 후 get_scores 를 이용하여, scores를 구함.\n",
    "        for idx, query in enumerate(user_query):\n",
    "            \n",
    "            # 처음에는 mecab적용해서 query문 전처리 함.\n",
    "            if count == 0:\n",
    "                tempq = mecab.morphs(query) \n",
    "                query = \" \".join(tempq)\n",
    "                \n",
    "            # 쿼리에 따른 스코어 구함    \n",
    "            tokenized_query = BM25tokenizer(query)\n",
    "            doc_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "            # 정렬후 최대 스코어 search_k 만큼만 출력함\n",
    "            top_lists = sorted(enumerate(doc_scores), key=lambda x: x[1], reverse=True)[:search_k]\n",
    "            bm5_predictions_list.append([index + contextids[0] for index, score in top_lists])\n",
    "\n",
    "        # 정답, 여기서는 contextid를 리스트로 만듬.\n",
    "        ground_truths_list = df_questions['contextid'].values.tolist()\n",
    "\n",
    "        # MPR 계산\n",
    "        predictions_list = bm5_predictions_list  # 예측 결과 리스트\n",
    "        bm25_ranks, bm25_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "\n",
    "         # BM25-MRR 출력\n",
    "        logger.info(f'--------------------------------------------------------------------------')\n",
    "        logger.info('*BM25-MRR{}:{:.4f}'.format(mecab_str, bm25_score))\n",
    "        logger.info(f'*Ranks({len(bm25_ranks)}):{bm25_ranks[0:20]}')\n",
    "        # 검색 한 계슈\n",
    "        #logger.info(f'---------------------------------------------------------------------------')\n",
    "        search_count = 0\n",
    "        for item in bm25_ranks:\n",
    "            if item != 0:\n",
    "                search_count += 1\n",
    "\n",
    "        logger.info('*BM25{} 검색률: {}/{}({:.2f}%)'.format(mecab_str, search_count, len(bm25_ranks), (search_count/len(bm25_ranks))*100))\n",
    "        logger.info(f'---------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d9fd8-6249-4bc1-b27f-0e97415b762c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
