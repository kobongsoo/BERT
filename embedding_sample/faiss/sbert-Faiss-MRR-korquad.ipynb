{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f263c8-7ae3-454a-ac8d-c160ed0c626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "# sentence-bert와 Faiss 라이브러리를 이용하여 검색 MRR(Mean Reciprocal Rank) 측정하는 예시임\n",
    "# => MRR 측정 말뭉치는 KorQuAD_v1.0_dev.json 말뭉치를 이용함.\n",
    "#\n",
    "# 1. 검색모델 로딩\n",
    "# 2. KorQuAD_v1.0_dev.json 파일 로딩 하여, 각 항목별 리스트를 출력한후, contexts df, questions df를 만듬.\n",
    "# 3. 정답리스트에 대해 임베딩 벡터 생성 후 FAISS에 인덱싱함.\n",
    "# 4. 쿼리를 list로 만들고, 검색 후 예측된 결과를 list로 만듬\n",
    "# 5. 정답리스트와 예측리스트를 가지고 MRR을 구함\n",
    "################################################################################################\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from os import sys\n",
    "sys.path.append('../../')\n",
    "from myutils import GPU_info, seed_everything\n",
    "\n",
    "device = GPU_info()\n",
    "seed_everything(111)\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "# 0. param 설정\n",
    "#------------------------------------------------------------------------------------\n",
    "query_num = 0            # 쿼리 최대 갯수: KorQuAD_v1.0_dev.json 최대값은 5533개임, 0이면 모든 5533개 쿼리함.\n",
    "faiss_search_k = 10         # FAISS 검색시, 검색 계수(5=쿼리와 가장 근접한 5개 결과값을 반환함)\n",
    "use_cross_encoder = True   # cross_encoder 사용할지 유.무 (true=사용함, false=사용안함)\n",
    "#-------------------------------------------------------------------------------------\n",
    "# 1.sentence bert 모델 로딩\n",
    "#-------------------------------------------------------------------------------------\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import models\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "bi_encoder_path = \"bongsoo/kpf-sbert-v1.1\"\n",
    "\n",
    "# 임베딩 벡터 폴링 모드 선택 (*아래값중 문자열로 입력함, 기본=mean)\n",
    "# mean=단어 평균, max=최대값, cls=문장, \n",
    "#['mean', 'max', 'cls', 'weightedmean', 'lasttoken']\n",
    "pooling_mode = 'mean'\n",
    "\n",
    "word_embedding_model = models.Transformer(bi_encoder_path, max_seq_length=256, do_lower_case=True, tokenizer_name_or_path=bi_encoder_path)\n",
    "#pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())  \n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode=pooling_mode)  \n",
    "bi_encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "#bi_encoder = SentenceTransformer(bi_encoder_path)\n",
    "bi_encoder.to(device)\n",
    "\n",
    "# cross-encoder 모델 로딩\n",
    "if use_cross_encoder == True:\n",
    "    cross_encoder_path = \"bongsoo/kpf-cross-encoder-v1\"\n",
    "    cross_encoder = CrossEncoder(cross_encoder_path, max_length=512, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817b7db-b57b-4328-a521-f10fb0512295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------\n",
    "# 2. KorQuAD_v1.0_dev.json 파일 로딩 하여, 각 항목별 리스트를 출력한후, contexts df, questions df를 만듬.\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "# 사용하지 않음.\n",
    "def read_json_sample(filepath):\n",
    "    titles = []\n",
    "    paragraphs = []\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        for idx, item in enumerate(data):\n",
    "            paragraphs.append([idx, item['title'], item['paragraph']])\n",
    "\n",
    "    return paragraphs\n",
    "\n",
    "jsonfile = '../../elasticsearch/data/KorQuAD_v1.0_train_convert.json'\n",
    "paragraphs = read_json(jsonfile)\n",
    "print(paragraphs[0:2])\n",
    "\n",
    "# paragraphs 리스트릴 => dataframe으로 만듬.\n",
    "df = pd.DataFrame(paragraphs, columns=['uid','title','paragraph'])\n",
    "print(df['title'][0:5].values)\n",
    "'''\n",
    "\n",
    "#==================================================================================================================\n",
    "# KorQuAD_v1.0_dev.json 파일 로딩 하여, 각 리스트들을 출력하는 함수\n",
    "# => IN : KorQuAD_v1.0_dev.json 경로\n",
    "# => OUT : contexts(문장 리스트), questions(질의리스트), answers(답변리스트), \n",
    "#          contextid(문장 id 리스트 : 10001 부터시작), pcontextid(질의와 연관된 문장 id 리스트: 10001부터 시작)\n",
    "#==================================================================================================================\n",
    "def read_json(filepath):\n",
    "    \n",
    "    context_list = []\n",
    "    question_list = []\n",
    "    qcontextid_list = []\n",
    "    answer_list = []\n",
    "    contextid_list = []\n",
    "    \n",
    "    # KorQuAD_v1.0_train.json 파일을 불러옴\n",
    "    json_data = json.load(open(filepath, \"r\", encoding=\"utf-8\"))[\"data\"]\n",
    "\n",
    "    # KorQuAD_v1.0 포멧에 맞게 파싱하여, context, question, answer 목록들을 구함.\n",
    "    context_id = 10000\n",
    "    for entry in json_data:\n",
    "            for paragraph in entry[\"paragraphs\"]:\n",
    "                context_text = paragraph[\"context\"]\n",
    "                context_id += 1\n",
    "                context_list.append(context_text)\n",
    "                contextid_list.append(context_id)\n",
    "                \n",
    "                for qa in paragraph[\"qas\"]:\n",
    "                    question_text = qa[\"question\"]\n",
    "                    \n",
    "                    for answer in qa[\"answers\"]:\n",
    "                        answer_text = answer[\"text\"]\n",
    "                        start_position_character = answer[\"answer_start\"]\n",
    "\n",
    "                        # question, context, answer, startposition 등을 설정함\n",
    "                        if question_text and answer_text and context_text and start_position_character:\n",
    "                            question_list.append(question_text)\n",
    "                            answer_list.append(answer_text)\n",
    "                            qcontextid_list.append(context_id)\n",
    "                            \n",
    "    return context_list, question_list, answer_list, contextid_list, qcontextid_list\n",
    "#==================================================================================================================\n",
    "\n",
    "# korQuad 파일을 불러옴.\n",
    "jsonfile = './data/KorQuAD_v1.0_dev.json'\n",
    "contexts, questions, answers, contextids, qcontextids = read_json(jsonfile)\n",
    "\n",
    "# list들을 zip 으로 묶고, dataframe 생성함\n",
    "# context, contextid를 묶어서 context df 만듬.\n",
    "df_contexts = pd.DataFrame((zip(contexts, contextids)), columns = ['context','contextid'])\n",
    "\n",
    "\n",
    "# question, answer, contextids를 묶어서 question df 만듬\n",
    "df_questions = pd.DataFrame((zip(questions, answers, qcontextids)), columns = ['question','answer', 'contextid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a285972-388e-4541-bff9-ad50cc556815",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contexts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a54b0b-709e-44ba-aa57-ed9723a44e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c354ccc1-2e95-4e71-8274-f5893633b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_contexts.shape)\n",
    "print(df_questions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532c81d-da09-4e8c-99d0-f5cb451066e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------\n",
    "# 3. 임베딩 벡터 생성 후 FAISS에 인덱싱함.\n",
    "#---------------------------------------------------------\n",
    "\n",
    "# 리스트 중복 제거 (순서유지 안함)\n",
    "def remove_duplicates(lst):\n",
    "    return list(set(lst))\n",
    "\n",
    "# 리스트 중복 제거 (순서유지함)\n",
    "def remove_duplicates1(lst):\n",
    "    return list(dict.fromkeys(lst))\n",
    "\n",
    "#=============================================================================\n",
    "# 임베딩 벡터 생성하여 FAISS에 인덱싱하고 ID와 매핑 처리하는 함수\n",
    "# => IN : contextdf\n",
    "# => OUT : FASSI index\n",
    "#=============================================================================\n",
    "def embeddingforfaiss(df):\n",
    "           \n",
    "    # embedding 생성(인코딩)\n",
    "    start = time.time()\n",
    "    embeddings = bi_encoder.encode(df.context.to_list(), show_progress_bar=True, convert_to_tensor=False)\n",
    "\n",
    "    #float32 로 embeddings 타입 변경\n",
    "    embeddings = np.array([embedding for embedding in embeddings]).astype(\"float32\")\n",
    "\n",
    "    # instance index 생성\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "\n",
    "    # id를 매핑 시켜줌 => 이때 idtype은 반드시 int64 type이어야 함.\n",
    "    index = faiss.IndexIDMap2(index)\n",
    "    index.add_with_ids(embeddings, df.contextid.values)\n",
    "\n",
    "    print(f'인코딩 시간 : {time.time()-start:.4f}')\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f046ff72-1dad-4bb2-8183-1ddf2f2b3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df 임베딩 구하고 faiss에 추가함.\n",
    "index = embeddingforfaiss(df_contexts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748298b5-2821-47ea-a0be-75675de11c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트로 여러문장 쿼리 해봄\n",
    "user_query = [\"파우스트_서곡\", \n",
    "             \"카카오_(기업)\",\n",
    "             \"공룡의_발견\",\n",
    "             \"미국의_정치\",\n",
    "             \"인공지능\"]\n",
    "\n",
    "vector = bi_encoder.encode(user_query)\n",
    "distance, idx = index.search(np.array(vector).astype(\"float32\"), k=3)\n",
    "\n",
    "#print(distance)\n",
    "#print(idx)\n",
    "#print([list(df[df.idx == num]['text']) for num in idx[0]])\n",
    "#print([list(df[df.idx == num]['text']) for num in idx[1]])\n",
    "\n",
    "for i, query in enumerate(user_query):\n",
    "    print(f'Q: {query}')\n",
    "    count = 0\n",
    "    for num in idx[i]:\n",
    "        context = df_contexts[df_contexts.contextid == num]['context'].values\n",
    "        print(f'{num}, {context[0]}({distance[i][count]:.3f})')\n",
    "        count += 1\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d66cdf-f2c3-4a49-872b-ba6be597f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------\n",
    "# 4. 쿼리를 list로 만들고, 검색 후 예측된 결과를 list로 만듬\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Query를 list로 만들고 -> query 인코딩후->검색 결과 출력\n",
    "\n",
    "if query_num == 0:   # query_num = 0 이면 모든 쿼리(5533개)\n",
    "    user_query = df_questions['question'].values.tolist()\n",
    "else:   # query_num > 0이면 해당 계수만큼 쿼리\n",
    "    user_query = df_questions['question'][:query_num].values.tolist()\n",
    "# => K=20으로 함.\n",
    "\n",
    "vector = bi_encoder.encode(user_query)\n",
    "distance, idx = index.search(np.array(vector).astype(\"float32\"), k=faiss_search_k)\n",
    "\n",
    "# 예측검색결과를 리스트로 만듬.\n",
    "bi_predictions_list = []\n",
    "\n",
    "for i, query in enumerate(tqdm(user_query)):\n",
    "    bi_predictions_list.append(idx[i].tolist())\n",
    "    \n",
    "print(f'----------------------------------------------------------')\n",
    "print(f'bi-encoder 예측:{len(bi_predictions_list)}')\n",
    "print(bi_predictions_list[0:3])\n",
    "\n",
    "# cross-encoder 사용인 경우에\n",
    "# - 한번더 검색된 결과에 {쿼리, 문장} 쌍으로 만들어서 cross-encoder로 스코어 출력함.\n",
    "if use_cross_encoder == True:\n",
    "    # {쿼리, 문장} 쌍 만듬.\n",
    "    #count = 0\n",
    "    cross_predictions_list = []\n",
    "    for i, predicts in enumerate(tqdm(bi_predictions_list)):\n",
    "        sentence_combinations = []\n",
    "        query = user_query[i]\n",
    "        #count += 1\n",
    "             \n",
    "        for predict in predicts:  \n",
    "             sentence_combinations.append([query, df_contexts[df_contexts.contextid == predict]['context'].values.tolist()[0]])\n",
    "                     \n",
    "        # cross-enocoder 돌려서 출력된 score 추가함.\n",
    "        cross_scores = cross_encoder.predict(sentence_combinations)+1\n",
    "        #print(f'*cross_scores:{cross_scores}')\n",
    "        \n",
    "        dec_cross_idx = reversed(np.argsort(cross_scores))\n",
    "        tmp_list = []\n",
    "        for idx in dec_cross_idx:\n",
    "            #print(f'idx:{idx}-predicts:{predicts[idx]}')\n",
    "            tmp_list.append(predicts[idx])\n",
    "         \n",
    "        cross_predictions_list.append(tmp_list)   \n",
    "    \n",
    "    print(f'----------------------------------------------------------')\n",
    "    print(f'cross-encoder 예측:{len(cross_predictions_list)}')\n",
    "    print(f'{cross_predictions_list[0:3]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76a648b-49b8-4a81-ac50-975c20cb934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색된 결과를 샘플 출력해 봄\n",
    "num = 2 #출력해볼 쿼리 번호\n",
    "\n",
    "# 쿼리\n",
    "print(f'Q: {df_questions[\"question\"][num]}')\n",
    "\n",
    "# 정답 출력\n",
    "qcontextid = df_questions[\"contextid\"][num]\n",
    "print(f'정답=========================================')\n",
    "print(f'contextid:{qcontextid}')\n",
    "print(f'{df_contexts[df_contexts.contextid == qcontextid][\"context\"].values}')\n",
    "\n",
    "print(f'예측=============================================')\n",
    "\n",
    "if use_cross_encoder == True:\n",
    "    for pcontextid in cross_predictions_list[num]:\n",
    "        print(f'contextid:{df_contexts[df_contexts.contextid == pcontextid][\"contextid\"].values}')\n",
    "        print(f'{df_contexts[df_contexts.contextid == pcontextid][\"context\"].values}')\n",
    "else:\n",
    "    for pcontextid in bi_predictions_list[num]:\n",
    "        print(f'contextid:{df_contexts[df_contexts.contextid == pcontextid][\"contextid\"].values}')\n",
    "        print(f'{df_contexts[df_contexts.contextid == pcontextid][\"context\"].values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d524d-0666-4ba9-ac56-35a59f9af7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------\n",
    "# 5. MRR을 구함\n",
    "##--------------------------------------------------------------------------------------------------\n",
    "#==================================================================================================\n",
    "# MRR(Mean Reciprocal Rank) 함수\n",
    "# => IN : ground_truths - 정답 contextid 리스트(예: [10001,10002, 10003, 10004,...])\n",
    "#         predictions - 예측값 contextid리스트(예: [[10003,10004,...],[10010, 10007,...],[],[],...]\n",
    "# => OUT : 각 쿼리에 대한 ranks 값 리스트(0~1범위), 전체 평균 쿼리 ranks 값(MRR) 리턴함\n",
    "#==================================================================================================\n",
    "def mean_reciprocal_rank(ground_truths, predictions):\n",
    "    reciprocal_ranks = []\n",
    "    \n",
    "    for gt, prediction in zip(ground_truths, predictions):\n",
    "        rank = 1\n",
    "        bsearch=False\n",
    "        for p in prediction:\n",
    "            #print(f'pred:{p}-gt:{gt}')\n",
    "            #if p in gt:\n",
    "            if p == gt:\n",
    "                reciprocal_ranks.append(1/rank)\n",
    "                bsearch=True\n",
    "                #print(f'gt:{gt}=>{1/rank}')\n",
    "                break\n",
    "            rank += 1\n",
    "            \n",
    "        if bsearch==False:\n",
    "            reciprocal_ranks.append(0)\n",
    "            #print(f'gt:{gt}=>0')\n",
    "       \n",
    "    # 각 쿼리에 대한 ranks 값(0~1범위), 전체 평균 쿼리 ranks 값(MRR) 리턴함\n",
    "    return reciprocal_ranks, sum(reciprocal_ranks) / len(reciprocal_ranks)\n",
    "#==================================================================================================\n",
    "\n",
    "# 정답, 여기서는 contextid를 리스트로 만듬.\n",
    "ground_truths_list = df_questions['contextid'].values.tolist()\n",
    "#print(f'gtlen:{len(ground_truths_list)}')\n",
    "#print(ground_truths_list[0:9])\n",
    "\n",
    "# MRR를 구함\n",
    "if use_cross_encoder == True:\n",
    "    predictions_list = bi_predictions_list\n",
    "    ranks, score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "\n",
    "    # BI-MRR 출력\n",
    "    print(f'--------------------------------------------------------------------------')\n",
    "    print('*BI-MRR:{:.4f}'.format(score))\n",
    "    print(f'*Ranks({len(ranks)}):{ranks[0:20]}')\n",
    "    \n",
    "    predictions_list = cross_predictions_list\n",
    "    ranks, score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "    print(f'---------------------------------------------------------------------------')\n",
    "    print('*CROSS-MRR:{:.4f}'.format(score))\n",
    "    print(f'*Ranks({len(ranks)}):{ranks[0:20]}')\n",
    "\n",
    "else:\n",
    "    predictions_list = bi_predictions_list\n",
    "\n",
    "    ranks, score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "\n",
    "    # BI-MRR 출력\n",
    "    print(f'----------------------------------------------------------------------------')\n",
    "    print('*BI-MRR:{:.4f}'.format(score))\n",
    "    print(f'*Ranks({len(ranks)}):{ranks[0:20]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c330d75-450c-47a2-96e4-2335ff54d956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
