{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f263c8-7ae3-454a-ac8d-c160ed0c626d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:../../../log/MRR-test_2023-02-05.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "################################################################################################\n",
    "# sentence-bert와 Faiss 라이브러리를 이용하여 검색 MRR(Mean Reciprocal Rank)와 BM25 측정하는 예시임\n",
    "# => MRR 측정 말뭉치는 KorQuAD_v1.0_dev.json 말뭉치를 이용함.\n",
    "# => bm25 설치 : !pip install rank_bm25\n",
    "#\n",
    "# 1. 검색모델 로딩\n",
    "# 2. KorQuAD_v1.0_dev.json 파일 로딩 하여, 각 항목별 리스트를 출력한후, contexts df, questions df를 만듬.\n",
    "# 3. 정답리스트에 대해 임베딩 벡터 생성 후 FAISS에 인덱싱함.\n",
    "# 4. 쿼리를 list로 만들고, 검색 후 예측된 결과를 list로 만듬\n",
    "# 5. 정답리스트와 예측리스트를 가지고 MRR을 구함\n",
    "#\n",
    "################################################################################################\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from os import sys\n",
    "sys.path.append('../../')\n",
    "from myutils import GPU_info, seed_everything, mlogging\n",
    "\n",
    "logger = mlogging(loggername=\"MRR-test\", logfilename=\"../../../log/MRR-test\")\n",
    "device = GPU_info()\n",
    "seed_everything(111)\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "# 0. param 설정\n",
    "#------------------------------------------------------------------------------------\n",
    "query_num = 500            # 쿼리 최대 갯수: KorQuAD_v1.0_dev.json 최대값은 5533개임, 0이면 모든 5533개 쿼리함.\n",
    "search_k = 10              # FAISS 검색시, 검색 계수(5=쿼리와 가장 근접한 5개 결과값을 반환함)\n",
    "use_cross_encoder = True   # cross_encoder 사용할지 유.무 (true=사용함, false=사용안함)\n",
    "use_bm25 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d37af48-ce3e-40c7-864a-52707d315490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/MOCOMSYS/anaconda3/envs/bong/lib/python3.9/site-packages/huggingface_hub/snapshot_download.py:6: FutureWarning: snapshot_download.py has been made private and will no longer be available from version 0.11. Please use `from huggingface_hub import snapshot_download` to import the only public function in this module. Other members of the file may be changed without a deprecation notice.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------\n",
    "# 1.sentence bert 모델 로딩\n",
    "#-------------------------------------------------------------------------------------\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import models\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "bi_encoder_path = \"bongsoo/klue-sbert-v1\"\n",
    "\n",
    "# 임베딩 벡터 폴링 모드 선택 (*아래값중 문자열로 입력함, 기본=mean)\n",
    "# mean=단어 평균, max=최대값, cls=문장, \n",
    "#['mean', 'max', 'cls', 'weightedmean', 'lasttoken']\n",
    "pooling_mode = 'mean'\n",
    "\n",
    "word_embedding_model = models.Transformer(bi_encoder_path, max_seq_length=256, do_lower_case=True, tokenizer_name_or_path=bi_encoder_path)\n",
    "#pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())  \n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode=pooling_mode)  \n",
    "bi_encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "#bi_encoder = SentenceTransformer(bi_encoder_path)\n",
    "bi_encoder.to(device)\n",
    "\n",
    "# cross-encoder 모델 로딩\n",
    "if use_cross_encoder == True:\n",
    "    cross_encoder_path = \"bongsoo/klue-cross-encoder-v1\"#\"bongsoo/albert-small-kor-cross-encoder-v1\"\n",
    "    cross_encoder = CrossEncoder(cross_encoder_path, max_length=512, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9817b7db-b57b-4328-a521-f10fb0512295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------\n",
    "# 2. KorQuAD_v1.0_dev.json 파일 로딩 하여, 각 항목별 리스트를 출력한후, contexts df, questions df를 만듬.\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "from myutils import read_korquad_v1_json\n",
    "\n",
    "# korQuad 파일을 불러옴.\n",
    "jsonfile = './data/KorQuAD_v1.0_dev.json'\n",
    "contexts, questions, answers, contextids, qcontextids = read_korquad_v1_json(jsonfile)\n",
    "\n",
    "# list들을 zip 으로 묶고, dataframe 생성함\n",
    "# context, contextid를 묶어서 context df 만듬.\n",
    "df_contexts = pd.DataFrame((zip(contexts, contextids)), columns = ['context','contextid'])\n",
    "\n",
    "# question, answer, contextids를 묶어서 question df 만듬\n",
    "df_questions = pd.DataFrame((zip(questions, answers, qcontextids)), columns = ['question','answer', 'contextid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a285972-388e-4541-bff9-ad50cc556815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>contextid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의...</td>\n",
       "      <td>10002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....</td>\n",
       "      <td>10003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국...</td>\n",
       "      <td>10004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논...</td>\n",
       "      <td>10005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  contextid\n",
       "0  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...      10001\n",
       "1  \"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의...      10002\n",
       "2  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr....      10003\n",
       "3  노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국...      10004\n",
       "4  헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논...      10005"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contexts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46a54b0b-709e-44ba-aa57-ed9723a44e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contextid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1989년 6월 30일 평양축전에 대표로 파견 된 인물은?</td>\n",
       "      <td>임수경</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>임종석을 검거한 장소는 경희대 내 어디인가?</td>\n",
       "      <td>학생회관 건물 계단</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>임종석이 조사를 받은 뒤 인계된 곳은 어딘가?</td>\n",
       "      <td>서울지방경찰청 공안분실</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 사람의 이름은?</td>\n",
       "      <td>임종석</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>임종석이 1989년 2월 15일에 지명수배 받은 혐의는 어떤 시위를 주도했다는 것인가?</td>\n",
       "      <td>여의도 농민 폭력 시위</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question        answer  contextid\n",
       "0                   1989년 6월 30일 평양축전에 대표로 파견 된 인물은?           임수경      10001\n",
       "1                           임종석을 검거한 장소는 경희대 내 어디인가?    학생회관 건물 계단      10001\n",
       "2                          임종석이 조사를 받은 뒤 인계된 곳은 어딘가?  서울지방경찰청 공안분실      10001\n",
       "3  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 사람의 이름은?           임종석      10001\n",
       "4   임종석이 1989년 2월 15일에 지명수배 받은 혐의는 어떤 시위를 주도했다는 것인가?  여의도 농민 폭력 시위      10001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c354ccc1-2e95-4e71-8274-f5893633b077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(964, 2)\n",
      "(5533, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_contexts.shape)\n",
    "print(df_questions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4532c81d-da09-4e8c-99d0-f5cb451066e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------\n",
    "# 3. 임베딩 벡터 생성 후 FAISS에 인덱싱함.\n",
    "#---------------------------------------------------------\n",
    "\n",
    "# 리스트 중복 제거 (순서유지 안함)\n",
    "def remove_duplicates(lst):\n",
    "    return list(set(lst))\n",
    "\n",
    "# 리스트 중복 제거 (순서유지함)\n",
    "def remove_duplicates1(lst):\n",
    "    return list(dict.fromkeys(lst))\n",
    "\n",
    "#=============================================================================\n",
    "# 임베딩 벡터 생성하여 FAISS에 인덱싱하고 ID와 매핑 처리하는 함수\n",
    "# => IN : contextdf\n",
    "# => OUT : FASSI index\n",
    "#=============================================================================\n",
    "def embeddingforfaiss(df):\n",
    "           \n",
    "    # embedding 생성(인코딩)\n",
    "    start = time.time()\n",
    "    embeddings = bi_encoder.encode(df.context.to_list(), show_progress_bar=True, convert_to_tensor=False)\n",
    "\n",
    "    #float32 로 embeddings 타입 변경\n",
    "    embeddings = np.array([embedding for embedding in embeddings]).astype(\"float32\")\n",
    "\n",
    "    # instance index 생성\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "\n",
    "    # id를 매핑 시켜줌 => 이때 idtype은 반드시 int64 type이어야 함.\n",
    "    index = faiss.IndexIDMap2(index)\n",
    "    index.add_with_ids(embeddings, df.contextid.values)\n",
    "\n",
    "    print(f'인코딩 시간 : {time.time()-start:.4f}')\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f046ff72-1dad-4bb2-8183-1ddf2f2b3a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ce9f4ab66e4624894be4c63430ba88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 시간 : 3.3827\n"
     ]
    }
   ],
   "source": [
    "#df 임베딩 구하고 faiss에 추가함.\n",
    "index = embeddingforfaiss(df_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748298b5-2821-47ea-a0be-75675de11c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 파우스트_서곡\n",
      "10039, 이 지역은 대해 때문에 세상에 알려진 지 300년 밖에 되지 않았는데, 숙종 24년(1698년) 고성 군수로 있던 남택하(南宅夏)가 찾아내고 “금강산의 얼굴빛과 같다.” 하여 해금강이라 이름 붙였다. 본래 해안 암벽, 바위섬, 자연호, 모래사장, 하천이 어우러진 경승지다. 이중 개방된 곳은 삼일포와 향로봉이며, 관동 팔경의 하나인 총석정은 개방되어 있지 않다. 삼일포는 남한의 화진포와 송지호같이 석호(潟湖)이며, 총 넓이는 0.79km에 달한다. 이 호수에는 전설에 따르면 신선 또는 화랑들이 경치가 너무 좋아 3일 동안 머물고 갔기 때문에 삼일포라 한다. 봉래대에서 삼일포 전경을 볼 수 있다. 소가 누운 모양이라고 해서 와우섬이라 이름 붙은 큰 섬을 비롯해, 3개의 작은 섬이 떠있다. 또한 삼일포 기슭에는 4명의 신선이 놀고 간 것을 기념해 세웠다는 사선정터가 있다. 향로봉은 바다의 해만물상이라 불리며, 바닷가에 육지와는 거리를 두고 홀로 솟아 있는 봉우리이다. 비바람에 씻기고 바닷물에 깎이어 독특한 모양을 지니고 있다.(51.040)\n",
      "10090, 서울 중구 중림동 149번지 성요셉 아파트는 1971년에 약현성당이 지은 아파트이다. 형태는 선형식 아파트로서 언덕길을 따라 길게 휘어져 있다. 이로 인해 각각의 위치에 따라 저층이 달랐다. 저층부 1개층은 상가로 이용되고 있으며 저층부 다음부터 최고층인 6층까지 주거 시설로 이용되고 있으며 1개 동으로 구성된 이 아파트는 전면부에 3개의 입구가 있다. 언덕 하단부에 설치된 첫번째 입구의 경우 2층 1가구와 그 외 전층을 출입할 수 있고, 중앙 입구는 2층 일부 가구만 출입이 가능하다. 이 외의 출입구는 3층 이상 출입이 가능하다. 성요셉 아파트는 초기 약현성당이 성당 성도들에게 아파트를 제공하기 위하여 시작한 사업이지만 이후 민간에 매각됐다. 서울시는 성요셉아파트의 특이한 건물형태로 인해 서울시 미래유산 아파트로 선정하였다.(51.945)\n",
      "10524, 노르드어는 6개의 파열음이 있다. 이 중 /p/는 단어 앞에 나오는 경우가 드물고, /d/와 /b/는 홑소리들 사이에서 마찰 이음으로 발음되는데, 합성어에서는 예외이다(e.g. veðrabati 베드라바티). 이런 현상은 게르만 조어에서부터 이미 나타나고 있다(e.g. 홑소리들 사이에 끼인 *b *[β] > [v]). 음소 /ɡ/는 n 또는 다른 g 뒤에서 [ɡ]로 발음되고, /s/와 /t/ 앞에서는 [k]로 발음된다. 이 음은 단어 안에서 다른 홑소리들 사이에 있을 일부 경우 유성 연구개 마찰음 [ɣ]이 되고 그 외의 경우, 유성 연구개 파열음 [ɡ]이 된다. 동노르드어의 /ʀ/ 음소는 그 발음 위치가 정확히 밝혀지지 않은 설첨음이었다가, 입천장 치찰음으로 재구축되었다. 이 음소는 게르만 조어의 음소 /z/에서 파생된 것이며 최종적으로는 음소 /r/로 진화했다. 이 과정은 서노르드어에서는 진작 이루어졌다.(52.527)\n",
      "\n",
      "\n",
      "Q: 카카오_(기업)\n",
      "10909, 일본 자객들은 치밀하게 계획을 짜고 한성으로 잠입, 명성황후의 암살을 주도하였다. 이 과정에서 조선인 병사들을 훈련하여 표면적으로 앞세웠다. 또한 명성황후의 암살 배후로 일본 공사 이노우에 가오루 등이 지목되었다. 2006년에는 최문형 한양대 명예교수가 일본 헌정자료실에서 찾아낸 야마가타 아리토모 (山縣有朋) 육군대장과 무쓰 무네미쓰 (陸奧宗光) 외상 사이의 편지를 통해 일본 정부의 개입설이 제기되기도 하였다. 명성황후의 암살 과정에서 조선인 병사들이 길안내를 했고, 일본군이 양성한 훈련대의 제1대대장 이두황, 제2대대장 우범선, 제3대대장 이진호(李軫鎬) 등이 일본 낭인에 협력했다. 그 밖에 전 군부협판 이주회 등도 포섭하였다. 이 중 우범선이 1903년 고영근에게 죽음을 당했다.(72.091)\n",
      "10130, 2010년 4월 14일 천안함 침몰 사건에 대한 성금 모금이 진행되었다. 이전까지 국민성금을 모아왔던 적은 많았으나, 불우이웃이나, 자연재해로 인한 피해 등 금전적 지원이 반드시 필요한 곳에서만 추진되어 왔다. 하지만 이번 사건에서는 개인에 대한 재산 피해도 없었기 때문에 금전적 지원이 필요한 경우라고 보기 어려웠으며, 천안함 침몰 원인이 밝혀지기는 커녕, 실종자들의 생사조차 확인되지 않은 상황에서 이러한 성금 모금은 부적절하다는 지적이 제기되었다. KBS는 이를 특집으로 생방송하여 시청자 게시판에는 항의글들이 올라왔다. 또한 이 사건의 책임이 전적으로 정부와 국방부에 있음에도 국민들에게 책임을 지우기 위한 것이 아니냐는 지적이 제기되었다. 국방부는 희생자들에 대해 훈장을 수여하고 국민성금까지 모금하여 억대의 보상금을 지급하며 '영웅' 대접을 하면서도 생존자들과 군 지휘관들에게는 징계 또는 격리수용을 하며 책임을 묻고 있다는 점이 모순으로 지적되기도 한다. 도올 김용옥은 이번 사건은 패전이라는 지적했다. 중앙일보도 칼럼을 통해 '산 사람은 죄값을 받고, 죽은 사람은 훈장을 받는다'는 의미로 \"생자유죄(生者有罪), 망자유공(亡者有功)\"이라는 격언을 언급하며 모순을 지적했다. 또 \"강릉무장공비 사건(1996), 동해 잠수정 침투 사건(1998), 북한군의 전방 사단 철책 통과 사건(2005) 등에선 지휘관을 형사입건하지 않았다.\"며 지휘관의 재량권을 인정해야 한다는 주장과 함께 최원일 함장이 58명을 구조한 공도 인정해야 한다는 견해도 있었다. 또한 천안함이 북측에 의한 어뢰 피격이든, 사고로 인한 것이든간에 근무를 제대로 하지 못했다는 것인데, 어느쪽이든간에 이들에게 영웅, 용사 등의 호칭을 사용하는것이 적절한지에 대한 논란도 있다. 정부는 이들에게 공식적으로 '용사'라는 호칭을 사용하고 있으며 사건 1주기가 되는 2011년 3월, 기업, 학교에 천안함 용사 추모 현수막과 홈페이지 배너를 달라는 내용의 공문을 보냈다.(74.188)\n",
      "10908, 한편, 명성황후의 암살은 조선 민중들의 분노를 야기하였고, 암살에 관련된 조선인 장교들과 군인들은 피신하거나 은신해 있었다. 이 때에 백범 김구(이 때의 이름은 김창수, 金昌洙)는 의병으로 만주에 있다가 1895년 초 귀국하며 일본인 상인 쓰치다 조스케(土田讓亮)를 일본 낭인으로 오인하며 치하포에서 만나 그를 죽이는 일이 발생하기도 한다. 김구는 이에 대해 뒷날 그가 일본 낭인이거나 왕비 암살에 가담한 자라고 주장하였으나, 오늘날 그는 일본인 상인으로 알려져 있다. 역사문제연구소 연구원 배경식 교수는 \"지금까지 확인 가능한 어떤 자료에도 그 일본인이 육군중위라는 기록은 없다\"며 \"일본 공사관의 보고서와 조선 관리의 보고서, 독립신문의 사건 보도는 한결같이 그를 '상인(商人)'으로 적고 있다\"고 했다. 그뿐 아니라 배 교수는 백범도 그가 육군 중위가 아니라는 걸 알았을 것이라고 주장했다. 1997년 도진순 창원대학교 교수는 일본의 자료로부터 그가 계림장업단의 상인이며 민간인이었다고 밝혔다.(74.678)\n",
      "\n",
      "\n",
      "Q: 공룡의_발견\n",
      "10218, 2000년 5월 닌텐도는 《금·은》의 북미 공식 발매일을 그해 10월 16일로 발표하였다. 닌텐도는 8월부터 게임의 예약 판매를 시작하였으며, 예약 구매한 소비자를 대상으로 미디어 브라우저가 개발한 포켓몬 테마의 웹 브라우저가 포함된 CD-ROM을 증정한다고 밝혔다. 이 웹 브라우저는 포켓몬 종류와 포켓몬 사이트 링크를 표시하는 것이 특징이다. 애플리케이션은 포켓몬 공식 웹사이트에서 다운로드할 수 있었다. 게임은 대략 600,000장이 두 달 만에 예약 판매되면서 《포켓몬스터 피카츄》가 세운 150,000장의 기록을 갱신하였다. 발매일이 다가오면서 일렉트로닉스 부티크와 같은 소매 상점이 10월 16일보다 빨리 출하된 게임을 수령하였다고 알렸으며, 예약 구매자들에게 먼저 제공한 후 나머지를 즉시 판매하기 시작하였다. 게임은 공식 발매일보다 빠른 10월 11일부터 구할 수 있었다.(53.085)\n",
      "10217, 북미 발매를 앞두었던 《금·은》은 2000년 뉴욕에서 개최한 아메리칸 인터내셔널 토이 페어에서 관람객이 직접 게임을 체험할 수 있는 자리를 마련하였다. 닌텐도는 게임의 판촉 홍보를 위해 크라이슬러 PT 크루저 다섯 대를 새로운 포켓몬 루기아와 비슷하게 개조한 후 미국 전역을 돌아다녔다. 차량에는 꼬리와 지느러미를 달았고 포켓몬 프랜차이즈의 로고와 그림이 도색되었다. 또한, 콘솔과 연결된 텔레비전을 장비하여 구경꾼들이 《포켓몬 퍼즐 리그》, 《헤이 유, 피카츄!》, 《포켓몬스터 금·은》을 플레이해볼 수 있도록 하였다. 게임을 바탕으로 제작한 텔레비전 애니메이션 시리즈 《포켓몬스터 GS》도 Kids' WB의 가을 라인업으로 예고되었다. 이 애니메이션에서 주인공 지우는 새로운 지역에서 게임에 등장했던 새로운 종류의 포켓몬들과 모험을 진행한다. 닌텐도는 새로운 포켓몬 100종류의 영문 명칭을 비공개로 유지하다 주기적으로 이름들을 공개하였다. 포켓몬의 영문 이름은 도메인명 'pokemongold.com'과 'pokemonsilver.com'을 통해서 공개되었으며, 치코리타, 루기아, 칠색조, 토게피, 부우부, 마릴 등의 영문 이름이 알려졌다.(54.470)\n",
      "10214, 크리처스 주식회사의 회장 이시하라 츠네카즈는 ABC 뉴스와의 인터뷰에서 새로운 포켓몬 종류 개발을 위한 브레인스토밍 과정에 대해서 식견을 밝혔다. \"게임 프리크 소프트웨어 개발자들의 상상에서 나온 몬스터에 대한 아이디어들은 그들이 만화를 보고 자란 어린 시절의 경험을 바탕으로 만들어진 것이다. 그들이 아이였을 때 겪은 벌레를 잡는 등의 두려운 경험에서 온 아이디어도 있었다. 어린 시절의 이러한 경험들은 포켓몬에 대한 아이디어로 만들어질 수 있었다.\" 《금·은》에서는 《적·녹》의 포켓몬 뮤와 비슷한 특징을 가진 환상의 포켓몬 세레비가 등장하였는데, 닌텐도에서 개최하는 행사를 통해서만 받을 수 있었다. 세레비를 배포한 첫 공식 행사는 2000년 일본에서 개최한 닌텐도 스페이스 월드로, 100,000명의 참가자가 포켓몬을 수령했다. 이 행사는 미리 엽서를 받아 추첨을 하는 방식으로 이루어졌으며, 100,000명에 속해있는 플레이어만이 게임보이와 《금·은》팩을 지참하여 포켓몬을 받을 수 있었다.(54.856)\n",
      "\n",
      "\n",
      "Q: 미국의_정치\n",
      "10003, 알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.(48.600)\n",
      "10856, 김영삼이 대통령 집권 후 역사바로세우기와 과거사 청산을 발표, 조선총독부를 철거하고 금융실명제로 군사정권 인사들의 차명계좌를 동결시켰으며, 신군부와 하나회를 숙청하고, 광주민주화 운동을 격상, 전두환, 노태우의 비자금 수수를 폭로하게 한 뒤, 광주학살과 12.12의 책임을 물어 사법처리시키는 등의 일련의 행위들을 보이자 보수 세력은 그의 사생활을 들먹이며 집권기간 중 공격을 가하였다. 또한 보도된 LA매일신문의 편집책임자인 극우 언론인 손충무 기자의 구속과, 석방후 미국으로의 정치망명 역시 극우세력의 김영삼에 대한 악감정을 촉발시키는 계기가 됐다. 극우세력은 그의 사생활을 비난하면서 동시에 손충무의 구속과 망명을 언론탄압으로 규정하여 공세를 가하였다.(49.602)\n",
      "10200, 현대적 의미로서의 행정학은 우드로 윌슨의 논문 〈행정의 연구〉(The Study of Administration, 1887년)를 계기로 정립되기 시작하였다는 견해가 일반적이기는 하지만 이에 대해서는 여러 비판적인 견해들을 경청할 필요가 있다. 윌슨은 당시 유럽대륙에서 진행되고 있었던 산업혁명 과정에서 대규모 조직들이 형성되고 효율적으로 관리되고 있는 현상을 주의깊게 관찰하였으며 당시 미국에서 펜들턴 법의 등장과 함께 인사 제도를 실적주의(Merit System)로 전환하는 개혁을 지켜보았다. 윌슨은 인사제도를 개혁하는 것 뿐만이 아니라 행정 시스템을 어떻게 효율적으로 바꿀 것인가를 고민하였는데 위 논문은 그 결과라고 볼 수 있다.(50.639)\n",
      "\n",
      "\n",
      "Q: 인공지능\n",
      "10765, 정치적으로 실패한 이누카이 내각을 향한 비판 여론은 정치적 폭력 행위로까지 번졌다. 비밀 결사단체인 혈맹단의 주도로 2월 9일에는 와카쓰키 내각의 전 대장대신 출신인 이노우에 준노스케가, 3월 5일에는 미쓰이 합명회사 이사장 단 다쿠마 남작이 암살당했다. 5월 15일에는 해군 청년 장교가 이누카이 총리를 총리 관저에서 살해했으며, 정우회 본부와 일본은행, 경시청, 내대신 마키노의 관저에 폭탄이 날아들었다. 혈맹단은 런던 해군 감축 조약을 완전히 폐기할 것을 요구하였다. 이 5·15 사건 다음 날 이누카이 내각의 남은 각료들은 총사직했으며, 쇼와 천황은 5월 25일에 이누카이의 후임으로 해군 출신의 사이토 마코토를 지명했다. 사이토는 9월 14일에 만주국을 승인하고 일만의정서에 조인하였다. 일만의정서의 내용에 따라 일본은 만주국의 국방을 책임지는 대신 만주에서의 모든 행동이 허용됐다. 사이토 내각의 주도로 일본은 1933년 2월에 국제 연맹을 탈퇴했다. 관동군은 1933년에 러허 성(熱河省)를 침공한데 이어 허베이 성까지 진격했다가 쇼와 천황의 제지로 한동안 산하이관에 머무르고 있었다. 그러나 5월 7일 관동군은 다시 허베이 지방으로 진격했다.(44.396)\n",
      "10109, 1943년 2월 초 에리히 폰 만슈타인 원수의 남부 집단군 소속으로 동부 전선으로 복귀했다. 사단은 파울 하우서 SS대장의 SS 기갑 군단 소속으로 이반 코네프 상장의 공세를 저지하기 위해 제3차 하리코프 공방전에 참전했다. 작전 당시 테오도어 아이케가 탑승한 피젤러 슈토르히(Fieseler Storch) 관측기가 적 전선 위를 비행하던 중 격추되었고, 그로 인해 아이케 장군이 전사했다. 분기탱천한 병사들은 적진을 돌파해 사단장의 유해를 되찾아왔다. 그 후 아이케 장군의 유해는 정식 군장을 갖춰 매장되었다. 막스 지몬 장군이 아이케의 뒤를 이어 사단장이 되었다. 얼마 후인 4월 10일 지몬 장군을 대신해 헤르만 프리스 SS준장이 사단장에 취임했다.(47.504)\n",
      "10107, 1941년이 저물 무렵 사단은 데먄스크 근방까지 진격했지만, 제2군과 더불어 소련군의 동계 역공세에 휘말려 포위망에 빠지고 말았다. 제2군은 1942년 1월부터 10월까지 거의 고립된 상황이었지만, 테오도어 아이케 SS중장과 휘하 장병들은 방어선을 유지하는 데 핵심적인 역할을 했다. 아이케 장군이 상관인 폰 브록도르프 알레펠트 백작과의 불화로 SS장관 하인리히 힘러에 의해 후방으로 전출된 후에는 선임 연대장 막스 지몬 SS준장이 사단장 대리로서 토텐코프를 지휘했다. 아이케 장군은 계속해서 자신의 사단으로 복귀하기를 희망했지만, 하인리히 힘러는 단호하게 거절했다. 지몬 장군은 계속해서 아이케 장군과 연락을 취했고, 아이케 장군은 심각한 병력 손실로 \"자신의 사단\"이 완전히 사라질지도 모른다는 걱정에 안절부절했다.(48.157)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트로 여러문장 쿼리 해봄\n",
    "user_query = [\"파우스트_서곡\", \n",
    "             \"카카오_(기업)\",\n",
    "             \"공룡의_발견\",\n",
    "             \"미국의_정치\",\n",
    "             \"인공지능\"]\n",
    "\n",
    "vector = bi_encoder.encode(user_query)\n",
    "distance, idx = index.search(np.array(vector).astype(\"float32\"), k=3)\n",
    "\n",
    "#print(distance)\n",
    "#print(idx)\n",
    "#print([list(df[df.idx == num]['text']) for num in idx[0]])\n",
    "#print([list(df[df.idx == num]['text']) for num in idx[1]])\n",
    "\n",
    "for i, query in enumerate(user_query):\n",
    "    print(f'Q: {query}')\n",
    "    count = 0\n",
    "    for num in idx[i]:\n",
    "        context = df_contexts[df_contexts.contextid == num]['context'].values\n",
    "        print(f'{num}, {context[0]}({distance[i][count]:.3f})')\n",
    "        count += 1\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41d66cdf-f2c3-4a49-872b-ba6be597f808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac3110b288d49d1a72c22925541e149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "bi-encoder 예측:500\n",
      "[[10624, 10353, 10183, 10241, 10604, 10625, 10616, 10196, 10523, 10359], [10026, 10856, 10454, 10872, 10623, 10453, 10518, 10290, 10083, 10079], [10312, 10453, 10479, 10885, 10877, 10279, 10882, 10193, 10285, 10002]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3542a55e3e64b07b9a4f80fe236aea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "cross-encoder 예측:500\n",
      "[[10523, 10353, 10359, 10241, 10616, 10196, 10604, 10625, 10624, 10183], [10026, 10454, 10856, 10453, 10872, 10518, 10623, 10079, 10290, 10083], [10312, 10882, 10877, 10453, 10193, 10885, 10279, 10285, 10479, 10002]]\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------\n",
    "# 4. 쿼리를 list로 만들고, 검색 후 예측된 결과를 list로 만듬\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Query를 list로 만들고 -> query 인코딩후->검색 결과 출력\n",
    "\n",
    "if query_num == 0:   # query_num = 0 이면 모든 쿼리(5533개)\n",
    "    user_query = df_questions['question'].values.tolist()\n",
    "else:   # query_num > 0이면 해당 계수만큼 랜덤하게 샘플링하여 쿼리 목록을 만듬.\n",
    "    df_questions = df_questions.sample(query_num)\n",
    "    df_questions = df_questions.reset_index(drop=True)  # index는 0부터 \n",
    "    user_query = df_questions['question'].values.tolist()\n",
    "\n",
    "vector = bi_encoder.encode(user_query)\n",
    "distance, idx = index.search(np.array(vector).astype(\"float32\"), k=search_k)\n",
    "\n",
    "# 예측검색결과를 리스트로 만듬.\n",
    "bi_predictions_list = []\n",
    "\n",
    "for i, query in enumerate(tqdm(user_query)):\n",
    "    bi_predictions_list.append(idx[i].tolist())\n",
    "    \n",
    "print(f'----------------------------------------------------------')\n",
    "print(f'bi-encoder 예측:{len(bi_predictions_list)}')\n",
    "print(bi_predictions_list[0:3])\n",
    "\n",
    "# cross-encoder 사용인 경우에\n",
    "# - 한번더 검색된 결과에 {쿼리, 문장} 쌍으로 만들어서 cross-encoder로 스코어 출력함.\n",
    "if use_cross_encoder == True:\n",
    "    # {쿼리, 문장} 쌍 만듬.\n",
    "    #count = 0\n",
    "    cross_predictions_list = []\n",
    "    for i, predicts in enumerate(tqdm(bi_predictions_list)):\n",
    "        sentence_combinations = []\n",
    "        query = user_query[i]\n",
    "        #count += 1\n",
    "             \n",
    "        for predict in predicts:  \n",
    "             sentence_combinations.append([query, df_contexts[df_contexts.contextid == predict]['context'].values.tolist()[0]])\n",
    "                     \n",
    "        # cross-enocoder 돌려서 출력된 score 추가함.\n",
    "        cross_scores = cross_encoder.predict(sentence_combinations)+1\n",
    "        #print(f'*cross_scores:{cross_scores}')\n",
    "        \n",
    "        dec_cross_idx = reversed(np.argsort(cross_scores))\n",
    "        tmp_list = []\n",
    "        for idx in dec_cross_idx:\n",
    "            #print(f'idx:{idx}-predicts:{predicts[idx]}')\n",
    "            tmp_list.append(predicts[idx])\n",
    "         \n",
    "        cross_predictions_list.append(tmp_list)   \n",
    "    \n",
    "    print(f'----------------------------------------------------------')\n",
    "    print(f'cross-encoder 예측:{len(cross_predictions_list)}')\n",
    "    print(f'{cross_predictions_list[0:3]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a76a648b-49b8-4a81-ac50-975c20cb934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 첫 번째 문법조약은 몇 세기에 쓰여졌나?\n",
      "정답=========================================\n",
      "contextid:10523\n",
      "['노르드어는 9개 홑소리 위치가 모두 비음화될 수 있다. 홑소리의 이음이 앞에 비음 닿소리가 위치하면서, 근처 소리에 묻히지 않을 때 홑소리의 비음화가 일어난다. 홑소리에 실린 강세 때문에 비음이 묻혀 버릴 경우, 그 홑소리의 길이가 늘어진다. 이러한 비음화는 다른 게르만 계통 언어들에서도 나타나지만, 그렇게 길게 지속되지는 않는다. 이러한 사항들은 12세기에 쓰여진 《첫 번째 문법조약》에 나와 있기에 알 수 있는 것이며, 만일 여기 보존되어 있지 않았다면 알려지지 못했을 것이다. 《첫 번째 문법조약》에서는 글자 위에 점 하나를 찍어서 비음화를 표시하도록 하고 있다. 그러나 이 표시법은 그다지 인기가 없었고 곧 무용지불이 되었다. 동노르드어에서는 11세기를 전후하여 비모음과 구모음이 대부분 융합된 것으로 생각된다. 그러나 달라르나 방언에서는 아직 구분이 이루어지고 있다. 이하 표에서는 점을 이용해 구모음과 비모음(문자 위에 틸다 부착)을 분리하고 있다.']\n",
      "예측=============================================\n",
      "contextid:[10523]\n",
      "['노르드어는 9개 홑소리 위치가 모두 비음화될 수 있다. 홑소리의 이음이 앞에 비음 닿소리가 위치하면서, 근처 소리에 묻히지 않을 때 홑소리의 비음화가 일어난다. 홑소리에 실린 강세 때문에 비음이 묻혀 버릴 경우, 그 홑소리의 길이가 늘어진다. 이러한 비음화는 다른 게르만 계통 언어들에서도 나타나지만, 그렇게 길게 지속되지는 않는다. 이러한 사항들은 12세기에 쓰여진 《첫 번째 문법조약》에 나와 있기에 알 수 있는 것이며, 만일 여기 보존되어 있지 않았다면 알려지지 못했을 것이다. 《첫 번째 문법조약》에서는 글자 위에 점 하나를 찍어서 비음화를 표시하도록 하고 있다. 그러나 이 표시법은 그다지 인기가 없었고 곧 무용지불이 되었다. 동노르드어에서는 11세기를 전후하여 비모음과 구모음이 대부분 융합된 것으로 생각된다. 그러나 달라르나 방언에서는 아직 구분이 이루어지고 있다. 이하 표에서는 점을 이용해 구모음과 비모음(문자 위에 틸다 부착)을 분리하고 있다.']\n",
      "contextid:[10353]\n",
      "['초기 전통 블루스 도입부 가사는 하나의 구절이 4번정도 반복되었던 것으로 본다. 이것은 20세기 초까지의 형태이다. 이것을 AAB 패턴이라 칭하는데, 음악의 4마디를 먼저 구성하고, 그 다음 4마디는 앞 4마디를 반복하며, 다음 4마디는 끝나는 구절로 길게 만들었다. 〈Dallas Blues〉 (1912), 〈Saint Louis Blues〉 (1914)는 12마디 형식의 AAB 가사 구조를 취하고 있다. 가사들은 보통 리듬 있게 말을 하여 패턴을 구성하고 그 위에 멜로디를 얹는 방식이었다. 초기 블루스는 대개 경험에 입각한 이야기를 풀어 자유롭게 만들었다. 아프리칸-아메리칸 싱어들은 그녀 혹은 그들의 사적인 고통 혹은 사회적 부조리함을 현실적으로 담아내었다. 그 중에선 실연, 당시 경찰관들의 잔인함, 백인들의 억압, 힘든 시기등이 있었다. 이렇듯, 가사들은 보통 아프리카-아메리칸의 사회에서의 경험, 사고 등을 이야기했는데, 다음은 블라인드 레몬 제퍼슨의 〈Rising High Water Blues〉 (1927)에서 말해주는 1927년 미시시피 대홍수이다.']\n",
      "contextid:[10359]\n",
      "[\"정의로 구분짓자면, 블루스는 음악적 형태와, 장르, 재즈는 음악적 예술 형태이다. 블루스는 코드 진행과 장르를 이 안에서 만들었다고 확신할 수 있지만, 재즈는 이것을 파악하기 매우 어렵다. 19세기의 렉타임과 모던 퓨전 음악을 전부 포함하고 있어 범위가 매우 넓기 때문이다. 블루스와 재즈는 이러한 점에서 차이점들이 있지만, 사실 공통점이 많다. 둘다 미국 남부 (Deep South)와 19세기 말에 만들어졌다. 블루스는 아프리카-아메리칸 그들의 노동요, 스피릿튜얼스, 필드 찬트 그리고 할러에서 왔다. 또한 특징인 코드 진행, 플랫, 혹은 밴드 노트, 블루 노트, 그리고 슬프고 우울한 가사가 있다. 재즈도 마찬가지로 남부 아프리카계 미국인으로부터 나왔지만, 결과적으로 아프리카와 유럽 음악이 섞였다. 재즈 초기 당시 유명한 음악으로 인정받았고, 특색으로 블루 노트, 즉흥연주, 싱코페이션(당김음, 흔히들 싱코라고 하는 이것은 어울리는 한도 안에서 박자를 수정하는 것을 말한다), 그리고 '스윙 노트'를 알렸다. 재즈는 초기 뉴올리언스 딕시랜드, 스윙 시대의 빅 밴드 음악, 비밥, 라틴 재즈, 퓨전, 에시드 재즈, 펑크, 힙합, 그리고 당연히 블루스에게도 영향을 미쳤다.\"]\n",
      "contextid:[10241]\n",
      "['우니쉬는 인공언어로 어느 단일 특정 민족어와 직결되지는 않는다. 발음과 문법체계는 피진어 체계에 기반을 두고 있으며, 어휘는 주요 15개 언어(14개 자연언어: 영어, 스페인어, 포르투갈어, 이탈리아어, 프랑스어, 독일어, 러시아어, 한국어, 중국어, 일본어, 아랍어; 1개 인공언어: 에스페란토어)에서 선정하였다. 유형론 상으로는 전치사와 형용사가 수식하는 명사 앞에 위치하는 구조이며, 어순은 “주어-동사-목적어/보어” 순서이다. 이러한 순서는 평서문뿐 아니라 의문문에서도 그대로 유지된다. 새로운 어휘는 위에 제시된 15개 언어의 어휘 중에서 ‘공통성’, ‘간결성’, ‘다양성’, ‘명료성’, 발음의 용이성’, ‘문화적 연관성’, ‘복합성’의 7가지 원칙에 의해 선정, 차용, 형성된다.']\n",
      "contextid:[10616]\n",
      "['중국에 있어서도 “법치” 또는 “의법 행정”(법에 의한 행정)이라는 말이 사용되고 있으나, 이것은 한국이나 일본에서의 “법치주의”와는 다르고, “인치(人治)”, “당치(黨治)”에 대응하는 개념에 불과하다. 중국에 있어서는 전근대적인 “관부무착”(官府無錯, 국가무책임의 법리)이라고 하는 법의식과 사회주의적인 “인민정부와 인민 간의 이익의 대립은 있을 수 없다”고 하는 발상이 행정의 법적 통제나 행정구체의 발전을 지연시키는 요인이 되고 있었다. “치안관리처벌조례”의 시행에 의해, 행정처벌에 대한 불복의 소가 급증하고, 행정사건 전반에 적용되는 통일적인 절차의 정비의 필요성이 인식되었다. 그 결과, “행정소송법”이 제정되었다. 동법은 인민법원의 사법심사의 대상을 “구체적인 행정행위”에 한정하고 있다. 이 행위의 근거규정의 상위법령의 적합성에 대하여는 원칙적으로 사법심사가 미치지 않는다. 재량행위에 있어서는 재량일탈의 유무에 대해서는 사법심사가 미치나, 당부당에 대해서는 미치지 않는다. 다만, 인민법원은 현저하게 공정을 잃은 행정처벌에 대해서는 변경의 판결을 할 수 있다. 행정소송 사건의 인용율은 일본과 비슷하게 낮다. 행정불복심판에 대해서는 “행정복의법(行政復議法)”이 규정한다. 동법 그 자체는 행정불복심사와 행정소송과의 자유선택주의를 채용하고 있으나, 개별 법령에서 행정불복심사 전치를 규정하고 있는 예가 많다. 행정불복심사에는 구체적인 행정행위에 대하여 불복심사에 부대하여, 그 행위의 근거조항에 대한 불복심사도 신청할 수 있다는 것이 특징이다. 행정작용에 수반한 손해보전은 포괄하여 “국가배상”이라고 부른다. 국가배상에는 위법한 행정작용에 기반하여 손해를 전보하는 행정보상(일본에서말하는 국가배상에 해당하나, “작업인원”의 고의과실은 요건이 되지 않는다.)과 적법한 행정작용에 기반하여 손해를 보전하는 행정보상도 규정되어 있다.']\n",
      "contextid:[10196]\n",
      "['부들의 천사관은 성서와 유다이즘과 이교도들의 관념까지 혼합된 것이지만 차츰 천사의 본성은 창조된 영체요, 자유와 지혜를 가지고 창조되었으므로 그중 일부는 타락하여 악마가 되고, 착한 천사는 하느님의 사자요, 인간의 수호자가 되었다고 사유하였다. 고대 말기의 디오니시오(Dionysius Areopagita)는 네오플라토니즘적 도식과 성서에 나오는 천사들의 이름을 이용하여 구품(九品)의 천사 계보를 꾸몄다. 즉 세라핌(熾品), 케루빔(智品), 좌품(座品), 주품(主品), 역품(力品), 능품(能品), 권품(權品), 대천사, 천사의 아홉 등급이다. 물론 이 구품천사론은 그의 신학이자 교회의 교리는 아니다. 천사론에서 가톨릭 신자가 믿어야 할 교리는 꼭 한 가지밖에 없다. 즉 하느님께서 우리 감각의 대상인 세상과 우리의 감각을 초월하는 영의 세계도 창조하셨다는 것이다. 교회는 천사의 존재를 신앙교리로 선언하였다[제4차 라테란 공의회(1215년), Denz. 428, 1차 바티칸 공의회(1870년), Denz. 1783]. 그러나 천사의 본질이 무엇인지, 역할이 무엇인지, 사람마다 수호천사를 가지고 있다느니, 여러 계급으로 구성되어 있다는 등등의 학자의 주장에 대하여 교회는 아무런 유권적 결정도 내린 일이 없다. 다만 교회는 미카엘, 가브리엘, 라파엘 천사의 이름 외에 다른 이름들을(위경에 나오는) 사용하는 것을 금하였고(745년, 라테란 공의회), 삼대(三大) 천사의 축일과(9월 29일) 수호천사의 기념일(10월 2일)을 제정하여 천사공경을 장려하고 있다. (鄭夏權)']\n",
      "contextid:[10604]\n",
      "['중국의 법률역사에서 보면 고대에는 법률영역이 구분되지 아니하고 모두 합일되어 민사와 형사를 구분하지 않았다. 근현대적 의미의 민법 편찬은 중국 청나라 말기의 법제개혁부터 시작하였다. 1910년 말, 제1차 민법전초안(大淸民律草案, 대청민률초안)을 완성하였다. 이 초안은 독일민법전의 형식을 따라 총칙, 채권, 물권, 친족, 상속 등 5편, 1569개 법조문으로 이루어져 있었다. 특히 총칙, 채권, 물권의 내용은 독일민법전과 일본민법전을 참고하였다. 그러나, 1911년 10월의 신해혁명은 청나라 200여년의 통치를 무너뜨렸고, 공화국을 건립하여, 이 민법전초안은 정식적인 법률로 자리 잡지 못 하였다. 하지만, 이 민법전초안을 통하여 대륙법계 민법, 특히 독일 민법의 편찬형식과 법률개념, 원칙, 제도와 이론을 중국으로 수입하여 현대의 중국민사 입법과 민사 이론에 큰 영향을 미쳤다. 중화민국 성립한 후에도 민법전의 편찬은 계속되었다. 청나라말 제1차 민법전 초안을 기초로 수정하여, 1925년에 중화민국민법전초안(中華民國民律草案, 중화민국민률초안)이 완성되었다. 총칙, 채권, 물권, 친족, 상속 5편을 기초로 총 1745개 법조문을 두었으며, 특히, 스위스 채권법을 참고하였다.']\n",
      "contextid:[10625]\n",
      "['4차(제3년), \"준회원2\" 이수 과정은 성직 안수준비 과정으로 4차 필기시험인 교회행정, 목회신학, 조직신학 신학필기 시험과 신구약성경 필기 시험을 본다. 신학독서보고 2회, 담임목사의 수련목 평가 2회, 영성훈련과 수련목 프로그램을 이수하고 교회행정관련 소논문이 통과되어야 하고, 연회의 3차 다면 면접의 성직심사를 마쳐야 한다. 준2과정에서 안수 받기 전 다시 신체 및 정신 건강에 대해 종합병원의 진단을 받는다. 이 과정을 마친 수련목을 위한 기본교육과 영성훈련을 거치면 안수 대상자가 된다. 소속한 연회에서는 감독이 주관하는 성직위원회의 최종 심사과정(병원 정신과 검사 포함)에서 안수 자격을 확인하고, 연회에서 감독이 모든 과정을 이수한 수련목에게 성직 안수를 한다.']\n",
      "contextid:[10624]\n",
      "['2차(제1년), \"서리\" 이수 과정은 성직 예비자 과정이다. 2차 필기시험인 성서신학과 기독교윤리, 목회신학 시험과 신구약성경 시험을 치르며, 신체 및 정신 건강에 대한 종합병원의 진단을 받는다. 전후반기 2회에 소속 교회에서 신학독서 보고서를 제출하고 담임목사는 기도, 성경독서, 교회내 활동, 성찬 및 세례 보좌 등의 목회 과정을 전후반기 2회로 목회 수련 과정을 평가한다. 교단에서 정한 영성 훈련을 참여하고 수련목 과제를 해야 한다. 소속교회 지방의 감리사 주관의 성직심사에 통과하면, 목회주제 관련 소논문을 작성해 합격해야 하고, 감독이 주관하는 연회의 1차 다면 면접형태의 성직심사를 통과하면 감리교 준회원 목회자로 받아들이고, 2차 과정은 마무리된다.']\n",
      "contextid:[10183]\n",
      "['오스트레일리아 대륙의 여러 식민지들은 대체로 인구가 적거나 죄수 유형지 또는 둘이 섞인 상태로 있었다. 그 때 당시의 행정권은 총독에 있었다. 그 이유는 대영 제국의 수도 런던과 오스트레일리아 대륙 사이의 거리가 방대하게 커서 지리적으로 불편한 여건으로 소통과 왕래가 느린게 진행되었다. 이리하여 총독은 큰 영향력을 행사할 필요가 있었다. 하지만 초기의 오스트레일리아 대륙의 식민지로 이민갔던 주민들은 영국식 웨스트민스터 체제를 이해와 동시에 참정할 기회를 늘리기 위해서 정부를 개혁할려고 노력하였다. 총독들과 대영 제국의 정부는 인구의 증가와 경제 성장의 속도어 맞추며 미국처럼 독립을 요구하는 혁명을 유발하는 일을 방지하며 여러 식믹지에 웨스트민스터 체제의 수립에 시동을 걸었다. 식민지들의 정치적인 발전은 처음에 구성원들이 완전히 임명되거나 일부만 당선된 입법기관에서 시작하였다. 그 이후로 1850년대에 웨스턴오스트레일리아 식민지와 뉴질랜드를 제외한 모든 오스트레일리아 대륙의 식민지들은 대의정체와 책임정부를 일제히 확립하였다. 웨스턴오스트레일리아 식민지도 1890년에 이와 비슷하게 확립하였다.']\n"
     ]
    }
   ],
   "source": [
    "# 검색된 결과를 샘플 출력해 봄\n",
    "num = 0 #출력해볼 쿼리 번호\n",
    "\n",
    "# 쿼리\n",
    "print(f'Q: {df_questions[\"question\"][num]}')\n",
    "\n",
    "# 정답 출력\n",
    "qcontextid = df_questions[\"contextid\"][num]\n",
    "print(f'정답=========================================')\n",
    "print(f'contextid:{qcontextid}')\n",
    "print(f'{df_contexts[df_contexts.contextid == qcontextid][\"context\"].values}')\n",
    "\n",
    "print(f'예측=============================================')\n",
    "\n",
    "if use_cross_encoder == True:\n",
    "    for pcontextid in cross_predictions_list[num]:\n",
    "        print(f'contextid:{df_contexts[df_contexts.contextid == pcontextid][\"contextid\"].values}')\n",
    "        print(f'{df_contexts[df_contexts.contextid == pcontextid][\"context\"].values}')\n",
    "else:\n",
    "    for pcontextid in bi_predictions_list[num]:\n",
    "        print(f'contextid:{df_contexts[df_contexts.contextid == pcontextid][\"contextid\"].values}')\n",
    "        print(f'{df_contexts[df_contexts.contextid == pcontextid][\"context\"].values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e9d524d-0666-4ba9-ac56-35a59f9af7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 10:10:50,631 - MRR-test - INFO - --------------------------------------------------------------------------\n",
      "2023-02-05 10:10:50,633 - MRR-test - INFO - *BI-ENCODER:bongsoo/klue-sbert-v1\n",
      "2023-02-05 10:10:50,635 - MRR-test - INFO - *BI-MRR:0.5016\n",
      "2023-02-05 10:10:50,637 - MRR-test - INFO - *Ranks(500):[0.1111111111111111, 1.0, 1.0, 1.0, 1.0, 0, 1.0, 1.0, 1.0, 0, 1.0, 0.25, 0.25, 0, 0.2, 0.5, 0, 0, 1.0, 0]\n",
      "2023-02-05 10:10:50,638 - MRR-test - INFO - ---------------------------------------------------------------------------\n",
      "2023-02-05 10:10:50,639 - MRR-test - INFO - *CROSS-ENCODER:bongsoo/klue-cross-encoder-v1\n",
      "2023-02-05 10:10:50,641 - MRR-test - INFO - *CROSS-MRR:0.6983\n",
      "2023-02-05 10:10:50,641 - MRR-test - INFO - *Ranks(500):[1.0, 1.0, 1.0, 1.0, 1.0, 0, 1.0, 1.0, 0.3333333333333333, 0, 1.0, 1.0, 1.0, 0, 1.0, 1.0, 0, 0, 1.0, 0]\n",
      "2023-02-05 10:10:50,643 - MRR-test - INFO - *검색실패계수: 137/500(27.40%)\n",
      "2023-02-05 10:10:50,644 - MRR-test - INFO - \n",
      "BI -> CROSS---------------------------------------------------------------------------\n",
      "2023-02-05 10:10:50,647 - MRR-test - INFO -      bi-rank  cross-rank\n",
      "0   0.111111    1.000000\n",
      "1   1.000000    1.000000\n",
      "2   1.000000    1.000000\n",
      "3   1.000000    1.000000\n",
      "4   1.000000    1.000000\n",
      "5   0.000000    0.000000\n",
      "6   1.000000    1.000000\n",
      "7   1.000000    1.000000\n",
      "8   1.000000    0.333333\n",
      "9   0.000000    0.000000\n",
      "10  1.000000    1.000000\n",
      "11  0.250000    1.000000\n",
      "12  0.250000    1.000000\n",
      "13  0.000000    0.000000\n",
      "14  0.200000    1.000000\n",
      "15  0.500000    1.000000\n",
      "16  0.000000    0.000000\n",
      "17  0.000000    0.000000\n",
      "18  1.000000    1.000000\n",
      "19  0.000000    0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------------------------\n",
    "# 5. MRR을 구함\n",
    "##--------------------------------------------------------------------------------------------------\n",
    "from myutils import mean_reciprocal_rank\n",
    "\n",
    "# 정답, 여기서는 contextid를 리스트로 만듬.\n",
    "ground_truths_list = df_questions['contextid'].values.tolist()\n",
    "#print(f'gtlen:{len(ground_truths_list)}')\n",
    "#print(ground_truths_list[0:9])\n",
    "\n",
    "# MRR를 구함\n",
    "if use_cross_encoder == True:\n",
    "    predictions_list = bi_predictions_list\n",
    "    bi_ranks, bi_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "\n",
    "    # BI-MRR 출력\n",
    "    logger.info(f'--------------------------------------------------------------------------')\n",
    "    logger.info('*BI-ENCODER:{}'.format(bi_encoder_path))\n",
    "    logger.info('*BI-MRR:{:.4f}'.format(bi_score))\n",
    "    logger.info(f'*Ranks({len(bi_ranks)}):{bi_ranks[0:20]}')\n",
    "    \n",
    "    predictions_list = cross_predictions_list\n",
    "    cross_ranks, cross_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "    logger.info(f'---------------------------------------------------------------------------')\n",
    "    logger.info('*CROSS-ENCODER:{}'.format(cross_encoder_path))\n",
    "    logger.info('*CROSS-MRR:{:.4f}'.format(cross_score))\n",
    "    logger.info(f'*Ranks({len(cross_ranks)}):{cross_ranks[0:20]}')\n",
    "    \n",
    "    # 검색 못한 계슈\n",
    "    print(f'---------------------------------------------------------------------------')\n",
    "    zero_count = 0\n",
    "    for item in bi_ranks:\n",
    "        if item == 0:\n",
    "            zero_count += 1\n",
    "    \n",
    "    logger.info('*검색실패계수: {}/{}({:.2f}%)'.format(zero_count, len(bi_ranks), (zero_count/len(bi_ranks))*100))\n",
    "    print(f'---------------------------------------------------------------------------')\n",
    "    \n",
    "    logger.info(f'\\nBI -> CROSS---------------------------------------------------------------------------')\n",
    "    df_scores = pd.DataFrame((zip(bi_ranks, cross_ranks)), columns = ['bi-rank','cross-rank'])\n",
    "    logger.info(df_scores.head(20))\n",
    "\n",
    "else:\n",
    "    predictions_list = bi_predictions_list\n",
    "\n",
    "    bi_ranks, bi_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "\n",
    "    # BI-MRR 출력\n",
    "    logger.info(f'----------------------------------------------------------------------------')\n",
    "    logger.info('*BI-ENCODER:{}'.format(bi_encoder_path))\n",
    "    logger.info('*BI-MRR:{:.4f}'.format(bi_score))\n",
    "    logger.info(f'*Ranks({len(bi_ranks)}):{bi_ranks[0:20]}')\n",
    "    \n",
    "    # 검색 못한 계슈\n",
    "    logger.info(f'---------------------------------------------------------------------------')\n",
    "    zero_count = 0\n",
    "    for item in bi_ranks:\n",
    "        if item == 0:\n",
    "            zero_count += 1\n",
    "    \n",
    "    logger.info('*검색실패계수: {}/{}({:.2f}%)'.format(zero_count, len(bi_ranks), (zero_count/len(bi_ranks))*100))\n",
    "    logger.info(f'---------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0e32738-2975-4e53-8738-da92152e387d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79aa28d7e77403f9964e3bcb912bfcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/964 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*contexts_len:964\n",
      "['1989 년 2 월 15 일 여의도 농민 폭력 시위 를 주도 한 혐의 ( 폭력 행위 등 처벌 에 관한 법률 위반 ) 으로 지명 수배 되 었 다 . 1989 년 3 월 12 일 서울 지방 검찰청 공 안 부 는 임종석 의 사전 구속 영장 을 발부 받 았 다 . 같 은 해 6 월 30 일 평양 축전 에 임수경 을 대표 로 파견 하 여 국가 보안법 위반 혐의 가 추가 되 었 다 . 경찰 은 12 월 18 일 ~ 20 일 사이 서울 경희대 학교 에서 임종석 이 성명 발표 를 추진 하 고 있 다는 첩보 를 입수 했 고 , 12 월 18 일 오전 7 시 40 분 경 가스총 과 전자 봉 으로 무장 한 특공 조 및 대공 과 직원 12 명 등 22 명 의 사복 경찰 을 승용차 8 대 에 나누 어 경희대 학교 에 투입 했 다 . 1989 년 12 월 18 일 오전 8 시 15 분 경 서울 청량리 경찰서 는 호위 학생 5 명 과 함께 경희대 학교 학생회관 건물 계단 을 내려오 는 임종석 을 발견 , 검거 해 구속 을 집행 했 다 . 임종석 은 청량리 경찰서 에서 약 1 시간 동안 조사 를 받 은 뒤 오전 9 시 50 분 경 서울 장안동 의 서울 지방 경찰청 공안 분실 로 인계 되 었 다 .', '\" 내각 과 장관 들 이 소외 되 고 대통령 비서실 의 권한 이 너무 크 다 \", \" 행보 가 비서 본연 의 역할 을 벗어난다 \" 는 의견 이 제기 되 었 다 . 대표 적 인 예 가 10 차 개헌안 발표 이 다 . 원로 헌법 학자 인 허영 경희대 석좌 교수 는 정부 의 헌법 개정안 준비 과정 에 대해 \" 청와대 비서실 이 아닌 국무회의 중심 으로 이뤄졌 어야 했 다 \" 고 지적 했 다 . \\' 국무 회의 의 심의 를 거쳐야 한다 \\'( 제 89 조 ) 는 헌법 규정 에 충실하 지 않 았 다는 것 이 다 . 그러 면서 \" 법무부 장관 을 제쳐 놓 고 민정 수석 이 개정안 을 설명 하 는 게 이해 가 안 된다 \" 고 지적 했 다 . 민정 수석 은 국회의원 에 대해 책임지 는 법무부 장관 도 아니 고 , 국민 에 대해 책임지 는 사람 도 아니 기 때문 에 정당 성 이 없 고 , 단지 대통령 의 신임 이 있 을 뿐 이 라는 것 이 다 . 또한 국무총리 선출 방식 에 대한 기자 의 질문 에 \" 문 대통령 도 취임 전 에 국무총리 에게 실질 적 권한 을 주 겠 다고 했 지만 그러 지 못하 고 있 다 . 대통령 비서실 장만 도 못한 권한 을 행사 하 고 있 다 . \" 고 답변 했 다 .', '알렉산더 메이 그 스 헤이 그 2 세 ( 영어 : Alexander Meigs Haig , Jr . , 1924 년 12 월 2 일 ~ 2010 년 2 월 20 일 ) 는 미국 의 국무 장관 을 지낸 미국 의 군인 , 관료 및 정치인 이 다 . 로널드 레이건 대통령 밑 에서 국무 장관 을 지냈으며 , 리처드 닉슨 과 제럴드 포드 대통령 밑 에서 백악관 비서 실장 을 지냈 다 . 또한 그 는 미국 군대 에서 2 번 째 로 높 은 직위 인 미국 육군 부 참모 총장 과 나토 및 미국 군대 의 유럽 연합군 최고 사령관 이 었 다 . 한국 전쟁 시절 더글러스 맥아더 유엔 군 사령관 의 참모 로 직접 참전 하 였으며 , 로널드 레이건 정부 출범 당시 초대 국무 장관 직 을 맡 아 1980 년 대 대한민국 과 미국 의 관계 를 조율 해 왔 다 . 저서 로 회고록 《 경고 : 현실주의 , 레이건 과 외교 정책 》( 1984 년 발간 ) 이 있 다 .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 10:10:54,289 - MRR-test - INFO - --------------------------------------------------------------------------\n",
      "2023-02-05 10:10:54,291 - MRR-test - INFO - *BM25-MRR(mecab 적용):0.9295\n",
      "2023-02-05 10:10:54,292 - MRR-test - INFO - *Ranks(500):[0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "2023-02-05 10:10:54,293 - MRR-test - INFO - ---------------------------------------------------------------------------\n",
      "2023-02-05 10:10:54,294 - MRR-test - INFO - *BM25(mecab 적용) 검색실패계수: 5/500(1.00%)\n",
      "2023-02-05 10:10:54,296 - MRR-test - INFO - ---------------------------------------------------------------------------\n",
      "2023-02-05 10:10:55,357 - MRR-test - INFO - --------------------------------------------------------------------------\n",
      "2023-02-05 10:10:55,358 - MRR-test - INFO - *BM25-MRR:0.8143\n",
      "2023-02-05 10:10:55,359 - MRR-test - INFO - *Ranks(500):[0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "2023-02-05 10:10:55,360 - MRR-test - INFO - ---------------------------------------------------------------------------\n",
      "2023-02-05 10:10:55,361 - MRR-test - INFO - *BM25 검색실패계수: 48/500(9.60%)\n",
      "2023-02-05 10:10:55,363 - MRR-test - INFO - ---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------------\n",
    "# 6. BM25 계산\n",
    "# => korquad_v1.0 말뭉치를 가지고 BM25 계산하는 함수\n",
    "# => for문을 2번 돌면서 BM25 2번 계산함.\n",
    "#    - 처음에는(0) 해당 쿼리와 contexts에 대해 mecab 적용 후 BM25 스코어 계산, \n",
    "#    - 2번째는 mecab 적용하지 않고 계산\n",
    "#------------------------------------------------------------------------------------------------\n",
    "if use_bm25 == True:\n",
    "\n",
    "    import konlpy\n",
    "    from konlpy.tag import Mecab\n",
    "    from rank_bm25 import BM25Okapi\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "    def BM25tokenizer(sent):\n",
    "      return sent.split(\" \")\n",
    "\n",
    "    # 입력된 contexts를 mecab을 이용하여 형태소 추출 후 \" \" 붙여서 형태소 문장을 만듬.\n",
    "    # Mecab 선언\n",
    "    mecab = Mecab()\n",
    "\n",
    "    for count in range(2):\n",
    "        mecab_str = ''\n",
    "        # 0이면(처음엔) mecab 적용함=> tokeniaer 후 인덱싱\n",
    "        if count == 0:\n",
    "            mecab_str = \"(mecab 적용)\"\n",
    "            mecab_contexts=[]\n",
    "            for context in tqdm(contexts):\n",
    "                temp = mecab.morphs(context)   # ['세계', '배달', '피자', '리더', '도미노피자','가'..] 식으로 temp 리스트가 생성됨\n",
    "                sentence = \" \".join(temp)      # 위 temp 리스트를 공백을 넣어서 한문장으로 합침 ['세계 배달 피자 리더 도미노피자 가 ...]\n",
    "                mecab_contexts.append(sentence)\n",
    "\n",
    "            print(f'*contexts_len:{len(mecab_contexts)}')  \n",
    "            print(f'{mecab_contexts[0:3]}')\n",
    "\n",
    "            # tokeniaer 후 인덱싱\n",
    "            tokenized_corpus = [BM25tokenizer(doc) for doc in mecab_contexts]\n",
    "        else:\n",
    "            # 2번째는 그냥 인덱싱\n",
    "            tokenized_corpus = [BM25tokenizer(doc) for doc in contexts]\n",
    "            \n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "        #print(f'bm25.doc_len:{bm25.doc_len}')\n",
    "        #print(f'type(bm25.doc_freqs):{type(bm25.doc_freqs)}')\n",
    "        \n",
    "        bm5_predictions_list = []\n",
    "     \n",
    "        # 쿼리 후 get_scores 를 이용하여, scores를 구함.\n",
    "        for idx, query in enumerate(user_query):\n",
    "            \n",
    "            # 처음에는 mecab적용해서 query문 전처리 함.\n",
    "            if count == 0:\n",
    "                tempq = mecab.morphs(query) \n",
    "                query = \" \".join(tempq)\n",
    "                \n",
    "            # 쿼리에 따른 스코어 구함    \n",
    "            tokenized_query = BM25tokenizer(query)\n",
    "            doc_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "            # 정렬후 최대 스코어 search_k 만큼만 출력함\n",
    "            top_lists = sorted(enumerate(doc_scores), key=lambda x: x[1], reverse=True)[:search_k]\n",
    "            bm5_predictions_list.append([index + contextids[0] for index, score in top_lists])\n",
    "\n",
    "        # 정답, 여기서는 contextid를 리스트로 만듬.\n",
    "        ground_truths_list = df_questions['contextid'].values.tolist()\n",
    "\n",
    "        # MPR 계산\n",
    "        predictions_list = bm5_predictions_list  # 예측 결과 리스트\n",
    "        bm25_ranks, bm25_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "\n",
    "         # BM25-MRR 출력\n",
    "        logger.info(f'--------------------------------------------------------------------------')\n",
    "        logger.info('*BM25-MRR{}:{:.4f}'.format(mecab_str, bm25_score))\n",
    "        logger.info(f'*Ranks({len(bm25_ranks)}):{bm25_ranks[0:20]}')\n",
    "        # 검색 못한 계슈\n",
    "        logger.info(f'---------------------------------------------------------------------------')\n",
    "        zero_count = 0\n",
    "        for item in bm25_ranks:\n",
    "            if item == 0:\n",
    "                zero_count += 1\n",
    "\n",
    "        logger.info('*BM25{} 검색실패계수: {}/{}({:.2f}%)'.format(mecab_str, zero_count, len(bm25_ranks), (zero_count/len(bm25_ranks))*100))\n",
    "        logger.info(f'---------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b162d0ab-a628-484b-93ab-5aacf826e0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
