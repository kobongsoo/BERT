{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f263c8-7ae3-454a-ac8d-c160ed0c626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "# sentence-bert와 Faiss 라이브러리를 이용하여 검색 MRR(Mean Reciprocal Rank)와 BM25 측정하는 예시임\n",
    "# => bm25 설치 : !pip install rank_bm25\n",
    "#\n",
    "# 1. 검색모델 로딩\n",
    "# 2. json QuA파일 로딩 하여, 각 항목별 리스트를 출력한후, contexts df, questions df를 만듬.\n",
    "# 3. 정답리스트에 대해 임베딩 벡터 생성 후 FAISS에 인덱싱함.\n",
    "# 4. 쿼리를 list로 만들고, 검색 후 예측된 결과를 list로 만듬\n",
    "# 5. 정답리스트와 예측리스트를 가지고 MRR을 구함\n",
    "# 6. contexts df 를 BM25 인덱싱 하고 , questions df 를 쿼리로 입력하여 BM25 스코어 구함\n",
    "################################################################################################\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from os import sys\n",
    "sys.path.append('../../')\n",
    "from myutils import GPU_info, seed_everything, mlogging\n",
    "\n",
    "logger = mlogging(loggername=\"MRR-BM25\", logfilename=\"../../../log/MRR-BM25\")\n",
    "device = GPU_info()\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "# 0. param 설정\n",
    "#------------------------------------------------------------------------------------\n",
    "seed = 111\n",
    "query_num = 500            # 쿼리 최대 갯수: KorQuAD_v1.0_dev.json 최대값은 5533개임, 0이면 모든 5533개 쿼리함.\n",
    "search_k = 20               # FAISS 검색시, 검색 계수(5=쿼리와 가장 근접한 5개 결과값을 반환함)\n",
    "use_cross_encoder = True   # cross_encoder 사용할지 유.무 (true=사용함, false=사용안함)\n",
    "use_bm25 = True            # BM25 출력 할지\n",
    "embedding_paragraph_avg = True # True = 문장 임베딩 구할때 여러문장 평균으로 구함(느림), Fals=문장 전체를 하나의 벡터로 생성(빠름)\n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d37af48-ce3e-40c7-864a-52707d315490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------\n",
    "# 1.sentence bert 모델 로딩\n",
    "#-------------------------------------------------------------------------------------\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import models\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "bi_encoder_path = \"bongsoo/klue-sbert-v1\" # klue-sbert-v1 # albert-small-kor-sbert-v1.1 # kpf-sbert-v1.1\n",
    "\n",
    "# 임베딩 벡터 폴링 모드 선택 (*아래값중 문자열로 입력함, 기본=mean)\n",
    "# mean=단어 평균, max=최대값, cls=문장, \n",
    "#['mean', 'max', 'cls', 'weightedmean', 'lasttoken']\n",
    "pooling_mode = 'mean' # mean # cls\n",
    "\n",
    "word_embedding_model = models.Transformer(bi_encoder_path, max_seq_length=256, do_lower_case=True, tokenizer_name_or_path=bi_encoder_path)\n",
    "#pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())  \n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode=pooling_mode)  \n",
    "bi_encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "#bi_encoder = SentenceTransformer(bi_encoder_path)\n",
    "bi_encoder.to(device)\n",
    "\n",
    "# cross-encoder 모델 로딩\n",
    "if use_cross_encoder == True:\n",
    "    cross_encoder_path = \"bongsoo/klue-cross-encoder-v1\"# klue-cross-encoder-v1 # albert-small-kor-cross-encoder-v1 # kpf_cross-encoder-v1\n",
    "    cross_encoder = CrossEncoder(cross_encoder_path, max_length=512, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817b7db-b57b-4328-a521-f10fb0512295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------\n",
    "# 2. KorQuAD_v1.0_dev.json 파일 로딩 하여, 각 항목별 리스트를 출력한후, contexts df, questions df를 만듬.\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "from myutils import read_korquad_v1_json, read_aihub_qua_json\n",
    "\n",
    "# aihub QuA 파일을 불러옴.\n",
    "jsonfile = './data/KorQuAD_v1.0_dev.json' # VL_unanswerable.json # VL_text_entailment.json # VL_span_inference.json # KorQuAD_v1.0_dev.json\n",
    "contexts, questions, answers, contextids, qcontextids = read_korquad_v1_json(jsonfile) # read_aihub_qua_json(jsonfile)\n",
    "\n",
    "# list들을 zip 으로 묶고, dataframe 생성함\n",
    "# context, contextid를 묶어서 context df 만듬.\n",
    "df_contexts = pd.DataFrame((zip(contexts, contextids)), columns = ['context','contextid'])\n",
    "\n",
    "# question, answer, contextids를 묶어서 question df 만듬\n",
    "df_questions = pd.DataFrame((zip(questions, answers, qcontextids)), columns = ['question','answer', 'contextid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31dca2b-0527-4c98-ad4a-72a7da4ff40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contexts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642f193-c571-49a4-9745-c65760e8a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532c81d-da09-4e8c-99d0-f5cb451066e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------\n",
    "# 3. 임베딩 벡터 생성 후 FAISS에 인덱싱함.\n",
    "#---------------------------------------------------------\n",
    "def embed_text(input):\n",
    "    vectors =  bi_encoder.encode(input, convert_to_tensor=False)\n",
    "    return np.array([embedding for embedding in vectors]).astype(\"float32\")#float32 로 embeddings 타입 변경\n",
    "    #return [vector.cpu().numpy().tolist() for vector in vectors]\n",
    "\n",
    "#=============================================================================\n",
    "# 문장을 .(마침표)로 여러 문장으로 나누고 한꺼번에 평균 임베딩 구하기2\n",
    "# - GPU 환경에서 속도 매우 빠름)\n",
    "#=============================================================================\n",
    "def paragraph_index2(paragraph):\n",
    "    avg_paragraph_vec = np.zeros((1,768))\n",
    "    # 2차원 문장 배열로 만든다.\n",
    "    sentences = [sentence for sentence in paragraph.split('. ') if sentence != '' and len(sentence) > 20]\n",
    "    #print(sentences)\n",
    "    \n",
    "    # 한꺼번에 문장 배열을 임베딩 처리함\n",
    "    avg_paragraph_vecs = embed_text(sentences)\n",
    "    #print(type(avg_paragraph_vecs))\n",
    "    #print(avg_paragraph_vecs.shape)\n",
    "    \n",
    "    # 배열로 만든 후 평균을 구함.\n",
    "    arr = np.array(avg_paragraph_vecs)\n",
    "    avg_paragraph_vec = arr.mean(axis=0)\n",
    "    return avg_paragraph_vec.ravel(order='C') # 1차원 배열로 변경\n",
    "\n",
    "#=============================================================================\n",
    "# 문장을 .(마침표)로 여러 문장으로 나누고 나눈문장을 1개씩 임베딩 구한후 계수만큼 나워서 평균 임베딩 구하기\n",
    "# => 속도 느림, 최대 15개만 함.(CPU 환경에서는 좋음)\n",
    "#=============================================================================\n",
    "def paragraph_index(paragraph):\n",
    "    avg_paragraph_vec = np.zeros((1,768))\n",
    "    sent_count = 0\n",
    "    \n",
    "    # ** kss로 분할할때 히브리어: מר, 기타 이상한 특수문자 있으면 에러남. \n",
    "    # 따라서 여기서는 그냥 . 기준으로 문장을 나누고 평균을 구함\n",
    "    # 하나의 문장을 읽어와서 .기준으로 나눈다.\n",
    "    sentences = [sentence for sentence in paragraph.split('. ') if sentence != '' and len(sentence) > 20]\n",
    "    \n",
    "    for sent in sentences:\n",
    "        # 문장으로 나누고, 해당 vector들의 평균을 구함.\n",
    "        avg_paragraph_vec += embed_text([sent])\n",
    "        sent_count += 1\n",
    "  \n",
    "        # 최대 15개 문장만 처리함 \n",
    "        if sent_count >= 15:\n",
    "            break\n",
    "         \n",
    "    '''\n",
    "    # kss로 분할할때 줄바꿈 있으면, 파싱하는데 에러남.따라서 \"\\n\"는 제거함\n",
    "    paragraph = paragraph.replace(\"\\n\",\"\")\n",
    "    \n",
    "    print(\"==Start paragraph_index==\")\n",
    "    print(paragraph)\n",
    "    for sent in kss.split_sentences(paragraph):\n",
    "        # 문장으로 나누고, 해당 vector들의 평균을 구함.\n",
    "        avg_paragraph_vec += embed_text([sent])\n",
    "        sent_count += 1\n",
    "        \n",
    "        # 최대 10개 문장만 처리함 \n",
    "        if sent_count >= 10:\n",
    "            break\n",
    "    '''\n",
    " \n",
    "    # 0으로 나누면 배열이 nan(not a number)가 되어 버리므로, 반드시 0>큰지 확인해야 함\n",
    "    if sent_count > 0:\n",
    "        avg_paragraph_vec /= sent_count\n",
    "    \n",
    "    return avg_paragraph_vec.ravel(order='C') # 1차원 배열로 변경\n",
    "   \n",
    "#=============================================================================\n",
    "# 임베딩 벡터 생성하여 FAISS에 인덱싱하고 ID와 매핑 처리하는 함수\n",
    "# => IN : contextdf\n",
    "# => OUT : FASSI index\n",
    "#=============================================================================\n",
    "def embeddingforfaiss(df, paragraph_avg):\n",
    "           \n",
    "    # embedding 생성(인코딩)\n",
    "    start = time.time()\n",
    "    paragraphs = df.context.to_list()\n",
    "    print(f'*임베딩 할 context 계수: {len(paragraphs)}') \n",
    "    \n",
    "    # paragraph_avg == True 이면 평균 문자 임베딩 벡터 구함.\n",
    "    if paragraph_avg == True:\n",
    "        print(f'*----평균 문장 임베딩 벡터 구하기----')\n",
    "        embeddings = [paragraph_index2(paragraph) for paragraph in tqdm(paragraphs)]\n",
    "    else:\n",
    "        embeddings = bi_encoder.encode(paragraphs, show_progress_bar=True, convert_to_tensor=False)\n",
    "       \n",
    "    embeddings = np.array([embedding for embedding in embeddings]).astype(\"float32\")#float32 로 embeddings 타입 변경\n",
    "    #print(type(embeddings)) #print(embeddings.shape) #print(embeddings[0])    \n",
    "    \n",
    "    # instance index 생성\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "   \n",
    "    # id를 매핑 시켜줌 => 이때 idtype은 반드시 int64 type이어야 함.\n",
    "    index = faiss.IndexIDMap2(index)\n",
    "    index.add_with_ids(embeddings, df.contextid.values)\n",
    "\n",
    "    print(f'*임베딩 시간 : {time.time()-start:.4f}')\n",
    "    \n",
    "    return index\n",
    "\n",
    "#df 임베딩 구하고 faiss에 추가함.\n",
    "index = embeddingforfaiss(df_contexts, paragraph_avg = embedding_paragraph_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d66cdf-f2c3-4a49-872b-ba6be597f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------\n",
    "# 4. 쿼리를 list로 만들고, 검색 후 예측된 결과를 list로 만듬\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Query를 list로 만들고 -> query 인코딩후->검색 결과 출력\n",
    "\n",
    "if query_num == 0:   # query_num = 0 이면 모든 쿼리(5533개)\n",
    "    user_query = df_questions['question'].values.tolist()\n",
    "else:   # query_num > 0이면 해당 계수만큼 랜덤하게 샘플링하여 쿼리 목록을 만듬.\n",
    "    df_questions = df_questions.sample(query_num, random_state=seed)\n",
    "    df_questions = df_questions.reset_index(drop=True)  # index는 0부터 \n",
    "    user_query = df_questions['question'].values.tolist()\n",
    "\n",
    "print(f'Query-----------------------------------------------------')\n",
    "print(user_query[0:3])\n",
    "\n",
    "vector = bi_encoder.encode(user_query)\n",
    "distance, idx = index.search(np.array(vector).astype(\"float32\"), k=search_k)\n",
    "\n",
    "# 예측검색결과를 리스트로 만듬.\n",
    "bi_predictions_list = []\n",
    "\n",
    "for i, query in enumerate(tqdm(user_query)):\n",
    "    bi_predictions_list.append(idx[i].tolist())\n",
    "    \n",
    "print(f'----------------------------------------------------------')\n",
    "print(f'bi-encoder 예측:{len(bi_predictions_list)}')\n",
    "print(bi_predictions_list[0:3])\n",
    "\n",
    "# cross-encoder 사용인 경우에\n",
    "# - 한번더 검색된 결과에 {쿼리, 문장} 쌍으로 만들어서 cross-encoder로 스코어 출력함.\n",
    "if use_cross_encoder == True:\n",
    "    # {쿼리, 문장} 쌍 만듬.\n",
    "    #count = 0\n",
    "    cross_predictions_list = []\n",
    "    for i, predicts in enumerate(tqdm(bi_predictions_list)):\n",
    "        sentence_combinations = []\n",
    "        query = user_query[i]\n",
    "        #count += 1\n",
    "             \n",
    "        for predict in predicts:  \n",
    "             sentence_combinations.append([query, df_contexts[df_contexts.contextid == predict]['context'].values.tolist()[0]])\n",
    "                     \n",
    "        # cross-enocoder 돌려서 출력된 score 추가함.\n",
    "        cross_scores = cross_encoder.predict(sentence_combinations)+1\n",
    "        #print(f'*cross_scores:{cross_scores}')\n",
    "        \n",
    "        dec_cross_idx = reversed(np.argsort(cross_scores))\n",
    "        tmp_list = []\n",
    "        for idx in dec_cross_idx:\n",
    "            #print(f'idx:{idx}-predicts:{predicts[idx]}')\n",
    "            tmp_list.append(predicts[idx])\n",
    "         \n",
    "        cross_predictions_list.append(tmp_list)   \n",
    "    \n",
    "    print(f'----------------------------------------------------------')\n",
    "    print(f'cross-encoder 예측:{len(cross_predictions_list)}')\n",
    "    print(f'{cross_predictions_list[0:3]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d524d-0666-4ba9-ac56-35a59f9af7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------\n",
    "# 5. MRR을 구함\n",
    "##--------------------------------------------------------------------------------------------------\n",
    "from myutils import mean_reciprocal_rank\n",
    "\n",
    "# 정답, 여기서는 contextid를 리스트로 만듬.\n",
    "ground_truths_list = df_questions['contextid'].values.tolist()\n",
    "#print(f'gtlen:{len(ground_truths_list)}')\n",
    "#print(ground_truths_list[0:9])\n",
    "\n",
    "logger.info(f'--------------------------------------------------------------------------')\n",
    "logger.info('json_file:{}'.format(jsonfile))\n",
    "\n",
    "# MRR를 구함\n",
    "if use_cross_encoder == True:\n",
    "    predictions_list = bi_predictions_list\n",
    "    bi_ranks, bi_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "\n",
    "    # BI-MRR 출력\n",
    "    logger.info(f'--------------------------------------------------------------------------')\n",
    "    logger.info('*BI-ENCODER:{}'.format(bi_encoder_path))\n",
    "    logger.info('*BI-MRR:{:.4f}'.format(bi_score))\n",
    "    logger.info(f'*Ranks({len(bi_ranks)}):{bi_ranks[0:20]}')\n",
    "    \n",
    "    predictions_list = cross_predictions_list\n",
    "    cross_ranks, cross_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "    logger.info(f'---------------------------------------------------------------------------')\n",
    "    logger.info('*CROSS-ENCODER:{}'.format(cross_encoder_path))\n",
    "    logger.info('*CROSS-MRR:{:.4f}'.format(cross_score))\n",
    "    logger.info(f'*Ranks({len(cross_ranks)}):{cross_ranks[0:20]}')\n",
    "    \n",
    "    # 검색 못한 계슈\n",
    "    print(f'---------------------------------------------------------------------------')\n",
    "    zero_count = 0\n",
    "    for item in bi_ranks:\n",
    "        if item == 0:\n",
    "            zero_count += 1\n",
    "    \n",
    "    logger.info('*검색실패계수: {}/{}({:.2f}%)'.format(zero_count, len(bi_ranks), (zero_count/len(bi_ranks))*100))\n",
    "    print(f'---------------------------------------------------------------------------')\n",
    "    \n",
    "    logger.info(f'\\nBI -> CROSS---------------------------------------------------------------------------')\n",
    "    df_scores = pd.DataFrame((zip(bi_ranks, cross_ranks)), columns = ['bi-rank','cross-rank'])\n",
    "    logger.info(df_scores.head(20))\n",
    "\n",
    "else:\n",
    "    predictions_list = bi_predictions_list\n",
    "\n",
    "    bi_ranks, bi_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "\n",
    "    # BI-MRR 출력\n",
    "    logger.info(f'----------------------------------------------------------------------------')\n",
    "    logger.info('*BI-ENCODER:{}'.format(bi_encoder_path))\n",
    "    logger.info('*BI-MRR:{:.4f}'.format(bi_score))\n",
    "    logger.info(f'*Ranks({len(bi_ranks)}):{bi_ranks[0:20]}')\n",
    "    \n",
    "    # 검색 못한 계슈\n",
    "    logger.info(f'---------------------------------------------------------------------------')\n",
    "    zero_count = 0\n",
    "    for item in bi_ranks:\n",
    "        if item == 0:\n",
    "            zero_count += 1\n",
    "    \n",
    "    logger.info('*검색실패계수: {}/{}({:.2f}%)'.format(zero_count, len(bi_ranks), (zero_count/len(bi_ranks))*100))\n",
    "    logger.info(f'---------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e32738-2975-4e53-8738-da92152e387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------\n",
    "# 6. BM25 계산\n",
    "# => korquad_v1.0 말뭉치를 가지고 BM25 계산하는 함수\n",
    "# => for문을 2번 돌면서 BM25 2번 계산함.\n",
    "#    - 처음에는(0) 해당 쿼리와 contexts에 대해 mecab 적용 후 BM25 스코어 계산, \n",
    "#    - 2번째는 mecab 적용하지 않고 계산\n",
    "#------------------------------------------------------------------------------------------------\n",
    "if use_bm25 == True:\n",
    "\n",
    "    import konlpy\n",
    "    from konlpy.tag import Mecab\n",
    "    from rank_bm25 import BM25Okapi\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "    def BM25tokenizer(sent):\n",
    "      return sent.split(\" \")\n",
    "\n",
    "    # 입력된 contexts를 mecab을 이용하여 형태소 추출 후 \" \" 붙여서 형태소 문장을 만듬.\n",
    "    # Mecab 선언\n",
    "    mecab = Mecab()\n",
    "\n",
    "    for count in range(2):\n",
    "        mecab_str = ''\n",
    "        # 0이면(처음엔) mecab 적용함=> tokeniaer 후 인덱싱\n",
    "        if count == 0:\n",
    "            mecab_str = \"(mecab 적용)\"\n",
    "            mecab_contexts=[]\n",
    "            for context in tqdm(contexts):\n",
    "                temp = mecab.morphs(context)   # ['세계', '배달', '피자', '리더', '도미노피자','가'..] 식으로 temp 리스트가 생성됨\n",
    "                sentence = \" \".join(temp)      # 위 temp 리스트를 공백을 넣어서 한문장으로 합침 ['세계 배달 피자 리더 도미노피자 가 ...]\n",
    "                mecab_contexts.append(sentence)\n",
    "\n",
    "            print(f'*contexts_len:{len(mecab_contexts)}')  \n",
    "            print(f'{mecab_contexts[0]}')\n",
    "\n",
    "            # tokeniaer 후 인덱싱\n",
    "            tokenized_corpus = [BM25tokenizer(doc) for doc in mecab_contexts]\n",
    "        else:\n",
    "            # 2번째는 그냥 인덱싱\n",
    "            tokenized_corpus = [BM25tokenizer(doc) for doc in contexts]\n",
    "            \n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "        #print(f'bm25.doc_len:{bm25.doc_len}')\n",
    "        #print(f'type(bm25.doc_freqs):{type(bm25.doc_freqs)}')\n",
    "        \n",
    "        bm5_predictions_list = []\n",
    "     \n",
    "        # 쿼리 후 get_scores 를 이용하여, scores를 구함.\n",
    "        for idx, query in enumerate(user_query):\n",
    "            \n",
    "            # 처음에는 mecab적용해서 query문 전처리 함.\n",
    "            if count == 0:\n",
    "                tempq = mecab.morphs(query) \n",
    "                query = \" \".join(tempq)\n",
    "                \n",
    "            # 쿼리에 따른 스코어 구함    \n",
    "            tokenized_query = BM25tokenizer(query)\n",
    "            doc_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "            # 정렬후 최대 스코어 search_k 만큼만 출력함\n",
    "            top_lists = sorted(enumerate(doc_scores), key=lambda x: x[1], reverse=True)[:search_k]\n",
    "            bm5_predictions_list.append([index + contextids[0] for index, score in top_lists])\n",
    "\n",
    "        # 정답, 여기서는 contextid를 리스트로 만듬.\n",
    "        ground_truths_list = df_questions['contextid'].values.tolist()\n",
    "\n",
    "        # MPR 계산\n",
    "        predictions_list = bm5_predictions_list  # 예측 결과 리스트\n",
    "        bm25_ranks, bm25_score = mean_reciprocal_rank(ground_truths_list, predictions_list)\n",
    "\n",
    "         # BM25-MRR 출력\n",
    "        logger.info(f'--------------------------------------------------------------------------')\n",
    "        logger.info('*BM25-MRR{}:{:.4f}'.format(mecab_str, bm25_score))\n",
    "        logger.info(f'*Ranks({len(bm25_ranks)}):{bm25_ranks[0:20]}')\n",
    "        # 검색 못한 계슈\n",
    "        logger.info(f'---------------------------------------------------------------------------')\n",
    "        zero_count = 0\n",
    "        for item in bm25_ranks:\n",
    "            if item == 0:\n",
    "                zero_count += 1\n",
    "\n",
    "        logger.info('*BM25{} 검색실패계수: {}/{}({:.2f}%)'.format(mecab_str, zero_count, len(bm25_ranks), (zero_count/len(bm25_ranks))*100))\n",
    "        logger.info(f'---------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b162d0ab-a628-484b-93ab-5aacf826e0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
