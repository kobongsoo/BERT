{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258ece4-e07f-41ce-b787-ed43f1057f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------\n",
    "# post로 search 하는 예시\n",
    "#\n",
    "# http://10.10.4.10:9000/search/?esindex=test3\n",
    "#\n",
    "# curl -X 'POST' \\\n",
    "#   'http://10.10.4.10:9000/search/?esindex=test3' \\\n",
    "#   -H 'accept: application/json' \\\n",
    "#   -H 'Content-Type: application/json' \\\n",
    "#   -d '{\n",
    "#   \"query\": \"사업계획서\",\n",
    "#   \"search_size\": 2\n",
    "# }'\n",
    "#----------------------------------------------------------------------\n",
    "import requests\n",
    "import json\n",
    "\n",
    "FASTAPI_URL = \"http://10.10.4.10:9000/search/\"\n",
    "ES_INDEX = 'test3'\n",
    "SEARCH_SIZE = 5\n",
    "\n",
    "def run_embedding_query_loop():\n",
    "    while True:\n",
    "        try:\n",
    "            handle_query_embedding()\n",
    "        except KeyboardInterrupt:\n",
    "            return\n",
    "        \n",
    "def handle_query_embedding():\n",
    "    #url\n",
    "    url = FASTAPI_URL + \"?esindex=\" + ES_INDEX\n",
    "    print(f'url:{url}')\n",
    "\n",
    "    #headers\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    #data\n",
    "    #query = \"my name is bongsoo. who are you?\"\n",
    "    #query = \"안녕하세요.지금은 curl 테스트 입니다.\"\n",
    "    query = input(\"검색 문장 입력: \")\n",
    "\n",
    "    # json 구조\n",
    "    temp = {\n",
    "        \"query\": query,\n",
    "        \"search_size\": SEARCH_SIZE,\n",
    "    }\n",
    "\n",
    "    # dict 을 json으로 변환\n",
    "    data = json.dumps(temp)\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=data)\n",
    "    except requests.exceptions.Timeout as errd:\n",
    "        print(\"Timeout Error:\", errd)\n",
    "        return\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print(\"Connection Error:\", errc)\n",
    "        return\n",
    "    except requests.exceptions.HTTPError as errb:\n",
    "        print(\"Http Error:\", errb)\n",
    "        return\n",
    "    except requests.exceptions.RequestException as erra:#Any Error except\n",
    "        print(\"AnyException Error:\", erra)\n",
    "        return\n",
    "    \n",
    "    print(type(response.text))\n",
    "    print(\"response.text: \", response.text)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "run_embedding_query_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba339714-6d6c-4fad-802c-68aa900c2344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a719571-11b9-46a4-b53a-fd267b16c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------\n",
    "# get으로 search 하는 예시\n",
    "#\n",
    "# http://10.10.4.10:9000/search/test3?query=%EC%82%AC%EC%97%85%EA%B3%84%ED%9A%8D%EC%84%9C&search_size=3\n",
    "#\n",
    "# curl -X 'GET' \\\n",
    "#   'http://10.10.4.10:9000/search/test3?query=%EC%82%AC%EC%97%85%EA%B3%84%ED%9A%8D%EC%84%9C&search_size=3' \\\n",
    "#   -H 'accept: application/json'\n",
    "#----------------------------------------------------------------------\n",
    "import requests\n",
    "import json\n",
    "\n",
    "ES_INDEX = 'test3'\n",
    "FASTAPI_URL = \"http://10.10.4.10:9000/\n",
    "SEARCH_SIZE = 5\n",
    "\n",
    "def run_embedding_query_loop():\n",
    "    while True:\n",
    "        try:\n",
    "            handle_query_embedding()\n",
    "        except KeyboardInterrupt:\n",
    "            return\n",
    "        \n",
    "def handle_query_embedding():\n",
    "    #url\n",
    " \n",
    "    #headers\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    #data\n",
    "    #query = \"my name is bongsoo. who are you?\"\n",
    "    #query = \"안녕하세요.지금은 curl 테스트 입니다.\"\n",
    "    query = input(\"검색 문장 입력: \")\n",
    "\n",
    "    url = FASTAPI_URL + \"es/\"+ES_INDEX+\"/docs?query=\" + query + \"&search_size=\" + str(SEARCH_SIZE)\n",
    "    print(f'url:{url}')\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "    except requests.exceptions.Timeout as errd:\n",
    "        print(\"Timeout Error:\", errd)\n",
    "        return\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print(\"Connection Error:\", errc)\n",
    "        return\n",
    "    except requests.exceptions.HTTPError as errb:\n",
    "        print(\"Http Error:\", errb)\n",
    "        return\n",
    "    except requests.exceptions.RequestException as erra:#Any Error except\n",
    "        print(\"AnyException Error:\", erra)\n",
    "        return\n",
    "    \n",
    "    print(type(response.text))\n",
    "    print(\"response.text: \", response.text)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "run_embedding_query_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f3ced-bef4-43ee-ac1d-6209d830381b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cd4edf-0a14-4b68-9e55-4f565eb02bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59146b05-0587-4ac7-a5f2-b0118a3331f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------\n",
    "# post로 문서 임베딩 예시\n",
    "#\n",
    "# http://10.10.4.10:9000/embed/es/?esindex=test&createindex=false\n",
    "#\n",
    "# curl -X 'POST' \\\n",
    "#   'http://10.10.4.10:9000/embed/es/?esindex=test&createindex=false' \\\n",
    "#   -H 'accept: application/json' \\\n",
    "#   -H 'Content-Type: application/json' \\\n",
    "#   -d '{\n",
    "#   \"uids\": [\n",
    "#     \"5\"\n",
    "#   ],\n",
    "#   \"titles\": [\n",
    "#     \"경찰청장 한상균 소요죄적용 입장 변함없어\"\n",
    "#   ],\n",
    "#   \"documents\": [\n",
    "#     \"강신명 경찰청장은 5일 한상균 민주노총 위원장에게 소요죄를 적용하지 않고 기소할 것으로 알려진 검찰의 방침과 관련...\"\n",
    "#   ]\n",
    "# }\n",
    "#----------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from os import sys\n",
    "sys.path.append('../')\n",
    "from myutils import remove_reverse, getListOfFiles, clean_text\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "OUT_FOLDER = '../../data11/mpower_doc/out/' # 추출된 TEXT 파일들이 있는 루트폴더\n",
    "\n",
    "# OUT_FOLDER에 모든 파일 경로를 얻어옴.\n",
    "file_paths = getListOfFiles(OUT_FOLDER)\n",
    "assert len(file_paths) > 0 # files가 0이면 assert 발생\n",
    "    \n",
    "print('*file_count: {}, file_list:{}'.format(len(file_paths), file_paths[0:5]))\n",
    "\n",
    "contexts = []\n",
    "titles = []\n",
    "contextids = []\n",
    "\n",
    "# TEXT 추출된 파일들을 읽어오면서 제목(title), 내용(contexts) 등을 저장해 둠.\n",
    "contextid = 1000\n",
    "for idx, file_path in enumerate(tqdm(file_paths)):\n",
    "    if '.ipynb_checkpoints' not in file_path:\n",
    "        sentences = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = f.read()\n",
    "            \n",
    "            #.PAGE:1 패턴을 가지는 문장은 제거함.\n",
    "            pattern = r\"\\.\\.PAGE:\\d+\\s?\"\n",
    "            data = clean_text(text=data, pattern=pattern)\n",
    "            \n",
    "            file_name = os.path.basename(file_path)  # 파일명만 뽑아냄\n",
    "            \n",
    "            #  filename = 5.보안사업부 사업계획.hwp.txt 이면 뒤에 hwp.txt는 제거하고 '5.보안사업부 사업계획' 문자열만 title로 저장함.\n",
    "            file_name = remove_reverse(file_name, '.')# 5.보안사업부 사업계획.hwp 출력됨\n",
    "            file_name = remove_reverse(file_name, '.')# 5.보안사업부 사업계획 출력됨\n",
    "            \n",
    "            contextid += 1\n",
    "            contexts.append(data)     # 파일 내용 저장 \n",
    "            titles.append(file_name)  # 파일명을 제목으로 저장(추후 쿼리할 문장이 됨)\n",
    "            contextids.append(contextid) # contextid 저장 \n",
    " \n",
    "# 데이터 프레임으로 만듬.\n",
    "df_contexts = pd.DataFrame((zip(contexts, titles, contextids)), columns = ['context','question', 'contextid'])\n",
    "\n",
    "print(f'*len(contexts): {len(contexts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b279611d-48ed-4343-bf2c-9dba866fc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_batch(url:str, headers, docs):\n",
    "    \n",
    "    uids = []\n",
    "    titles=[]\n",
    "    documents=[]\n",
    "    \n",
    "    for doc in docs:\n",
    "        uids.append(doc['uid'])\n",
    "        titles.append(doc['title'])\n",
    "        documents.append(doc['document'])\n",
    "        \n",
    "    #print(len(uids))\n",
    "    print(f'uids:{uids}')\n",
    "    \n",
    "    temp = {\n",
    "            \"uids\": uids,\n",
    "            \"titles\": titles,\n",
    "            \"documents\": documents,\n",
    "        }\n",
    "    \n",
    "    data = json.dumps(temp)\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=data)\n",
    "    except requests.exceptions.Timeout as errd:\n",
    "        print(\"Timeout Error:\", errd)\n",
    "        return\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print(\"Connection Error:\", errc)\n",
    "        return\n",
    "    except requests.exceptions.HTTPError as errb:\n",
    "        print(\"Http Error:\", errb)\n",
    "        return\n",
    "    except requests.exceptions.RequestException as erra:#Any Error except\n",
    "        print(\"AnyException Error:\", erra)\n",
    "        return\n",
    "    \n",
    "    #print(type(response.text))\n",
    "    print(\"responset: \", response)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad240edd-013e-40eb-8d0e-e8eee14f6b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "FASTAPI_URL = \"http://10.10.4.10:9000/es/mpower-kpf-128d-f16-avg/docs\"\n",
    "url = FASTAPI_URL\n",
    "print(url)\n",
    "\n",
    "#headers\n",
    "headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "uids = df_contexts['contextid'].values.tolist()\n",
    "titles = df_contexts['question'].values.tolist()\n",
    "documents = df_contexts['context'].values.tolist()\n",
    "\n",
    "docs = []\n",
    "batch_count = 0\n",
    "\n",
    "start = time.time()\n",
    "for uid, title, document in tqdm(zip(uids, titles, documents)):\n",
    "    \n",
    "    doc = {} #dict 선언\n",
    "    doc['uid'] = uid      \n",
    "    doc['title'] = title     \n",
    "    doc['document'] = document\n",
    "    docs.append(doc)\n",
    "        \n",
    "    batch_count += 1\n",
    "    \n",
    "    if batch_count % 10 == 0:\n",
    "        index_batch(url=url, headers=headers, docs=docs)\n",
    "        docs = []\n",
    "        \n",
    "if docs:\n",
    "    index_batch(url=url, headers=headers, docs=docs)\n",
    "    docs = []   \n",
    "    \n",
    "print(f'*임베딩 시간 : {time.time()-start:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8324855-817e-4970-b685-2a85201bb4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302386b1-f287-47ca-a738-1508024cba6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0313c34d-8ead-4d2f-a122-522e68327f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/MOCOMSYS/anaconda3/envs/bong/lib/python3.9/site-packages/elasticsearch/connection/base.py:200: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n",
      "/tmp/ipykernel_127407/1618931748.py:42: DeprecationWarning: The 'body' parameter is deprecated for the 'search' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  res = es.search(index=index_name, body=body)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001 : Autotools를 이용한 리눅스 응용프로그램 빌드\n",
      "1002 : Apache에서 Tomcat 사용하기\n",
      "1003 : BERT 모델 STS 성능 비교분석\n",
      "1004 : 클라우드서비스 구축 신청서\n",
      "1005 : 클라우드서비스 보안인증제 운영 변경관리서\n",
      "1006 : 회사 직원 급여관련 규정\n",
      "1007 : BERT 검색 , 분류 시스템 성능 측정\n",
      "1008 : 테이블 데이터 조회하는 방법\n",
      "1009 : 클라우드_취약점_점검_가이드(up)\n",
      "1010 : 회사 채용,승진,퇴사관련 인사규정\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------\n",
    "# FastAPI 임베딩 서버를 이용한 MPR 계산 예시\n",
    "#------------------------------------------------------------\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "import pandas as pd\n",
    "\n",
    "INDEX_NAME = 'mpower-kpf-128d-f16-variable'  # ES 인덱스 명 (*소문자로만 지정해야 함)\n",
    "\n",
    "# elastic 서버 접속 \n",
    "es = Elasticsearch(\"http://10.10.4.10:9200/\")\n",
    "es.info()\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# 쿼리 df 만듬.\n",
    "# => 인덱스내 데이터 조회 => query 이용해서 데이터 조회 후 쿼리 df 만듬\n",
    "# \n",
    "# GET /index명/_search\n",
    "#{\n",
    "#  \"_source\": [\"rfile_name\",\"rfile_text\"], \n",
    "#  \"query\": {\n",
    "#    \"match_all\": {}\n",
    "#  }\n",
    "# }\t\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "def search(index_name, data=None, source:list=None):\n",
    "    \n",
    "    if data is None: #모든 데이터 조회\n",
    "        data = {\"match_all\":{}}\n",
    "    else:\n",
    "        data = {\"match\": data}\n",
    "    \n",
    "    if source is None:\n",
    "        body = {\"query\": data}\n",
    "    else:\n",
    "        body = {\"_source\":source, \"query\": data}\n",
    "    \n",
    "    #print(body)\n",
    "    \n",
    "    res = es.search(index=index_name, body=body)\n",
    "    return res\n",
    "\n",
    "rfile_list = []\n",
    "\n",
    "'''\n",
    "# match_all로 쿼리하면 10개만 출력됨. 따라서 아래 처럼 1개씩 쿼리하면서 rfile_name과 rfile_text 불러옴.\n",
    "res = search(index_name=INDEX_NAME, source=[\"rfile_name\",\"rfile_text\"])\n",
    "\n",
    "for hits in res['hits']['hits']:\n",
    "    rfile_name = hits['_source']['rfile_name']\n",
    "    rfile_text = hits['_source']['rfile_text']\n",
    "    \n",
    "    print(f'rfile_name:{rfile_name}, rfile_text:{rfile_text}')\n",
    "    \n",
    "    if rfile_name and rfile_text:\n",
    "        docs = {}\n",
    "        docs['rfile_name'] = rfile_name\n",
    "        docs['rfile_text'] = rfile_text\n",
    "            \n",
    "    rfile_list.append(docs)\n",
    "'''    \n",
    "    \n",
    "\n",
    "# 쿼리로 rfile_name 1001 부터 1252까지 쿼리하면서 rfile_name과 rfile_text 불러옴.\n",
    "for i in range(253):\n",
    "    contextid = 1000+i\n",
    "    data = {'rfile_name': contextid}\n",
    "    res=search(index_name=INDEX_NAME, data=data, source=[\"rfile_name\",\"rfile_text\"])\n",
    "\n",
    "    for hits in res['hits']['hits']:\n",
    "        rfile_name = hits['_source']['rfile_name']\n",
    "        rfile_text = hits['_source']['rfile_text']\n",
    "        \n",
    "        if rfile_name and rfile_text:\n",
    "            docs = {}\n",
    "            docs['rfile_name'] = rfile_name\n",
    "            docs['rfile_text'] = rfile_text\n",
    "            \n",
    "        rfile_list.append(docs)\n",
    "        break\n",
    "\n",
    "\n",
    "# 리스트를 불러와서 질의 dataframe 만듬\n",
    "contextids = []\n",
    "questions = []\n",
    "\n",
    "for j, rfile in enumerate(rfile_list):\n",
    "    rfile_name = rfile['rfile_name']\n",
    "    rfile_text = rfile['rfile_text']\n",
    "    \n",
    "    contextids.append(rfile_name)\n",
    "    questions.append(rfile_text)\n",
    "    \n",
    "    if j < 10:\n",
    "        print(f'{rfile_name} : {rfile_text}')\n",
    " \n",
    "# dataframe으로 만듬\n",
    "df_questions = pd.DataFrame((zip(questions, contextids)), columns = ['question','contextid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e695ded-c5ab-4192-91a7-1131729ea815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/MOCOMSYS/anaconda3/envs/bong/lib/python3.9/site-packages/huggingface_hub/snapshot_download.py:6: FutureWarning: snapshot_download.py has been made private and will no longer be available from version 0.11. Please use `from huggingface_hub import snapshot_download` to import the only public function in this module. Other members of the file may be changed without a deprecation notice.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a69e97e00544eba0fae6d2380b8759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*len:252\n",
      "[[1001, 1083, 1087, 1121, 1250], [1002, 1059, 1250, 1220, 1048], [1064, 1075, 1043, 1024, 1007], [1186, 1180, 1122, 1004, 1103], [1005, 1234, 1233, 1186, 1151], [1006, 1163, 1164, 1136, 1010], [1233, 1237, 1228, 1158, 1041], [1207, 1209, 1189, 1021, 1233], [1250, 1185, 1228, 1009, 1175], [1010, 1132, 1136, 1187, 1006]]\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------\n",
    "# 쿼리 실행\n",
    "#user_querys = [\"독도에서 사고가 나서 실종자가 발생했다.\", \"오늘 날씨가 흐리고 비가 오겠다.\"]\n",
    "#-------------------------------------------------------------------------------------\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from os import sys\n",
    "sys.path.append('../')\n",
    "from myutils import df_sampling\n",
    "\n",
    "#--------------------------------------\n",
    "# param\n",
    "#--------------------------------------\n",
    "FASTAPI_URL = \"http://10.10.4.10:9000/\"\n",
    "SEARCH_SIZE = 5\n",
    "QMETHOD = 1 # qmethod=0 혹은 1(0=max벡터 구하기, 1=평균벡터 구하기 (default=0))\n",
    "#--------------------------------------\n",
    "\n",
    "\n",
    "user_querys = df_questions['question'].values.tolist()\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "bi_predictions_list=[]\n",
    "\n",
    "for j,user_query in enumerate(tqdm(user_querys)):\n",
    "    url = FASTAPI_URL + \"es/\"+INDEX_NAME+\"/docs?query=\" + user_query + \"&search_size=\" + str(SEARCH_SIZE) + \"&qmethod=\" + str(QMETHOD)\n",
    "    #print(f'url:{url}\\n')\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "    except requests.exceptions.Timeout as errd:\n",
    "        print(\"Timeout Error:\", errd)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print(\"Connection Error:\", errc)\n",
    "    except requests.exceptions.HTTPError as errb:\n",
    "        print(\"Http Error:\", errb)\n",
    "    except requests.exceptions.RequestException as erra:#Any Error except\n",
    "        print(\"AnyException Error:\", erra)\n",
    "    \n",
    "    # 상태 코드 성공(200) 이면 \n",
    "    status_code = response.status_code\n",
    "    if status_code == 200:\n",
    "        docs = response.json()['docs']\n",
    "        \n",
    "        rfilename = []\n",
    "        for doc in docs:\n",
    "            #print(doc)\n",
    "            rfilename.append(doc['rfile_name'])\n",
    "            \n",
    "        # MPR 계산을 위해 예측검색리스트에 검색된 데이터 입력    \n",
    "        bi_predictions_list.append(rfilename[0:SEARCH_SIZE])\n",
    "        \n",
    "    #print(response.text)\n",
    "    #print(response.headers)\n",
    "    \n",
    "    #if j > 2:\n",
    "    #    break\n",
    "\n",
    "print(f'*len:{len(bi_predictions_list)}')\n",
    "print(bi_predictions_list[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc0f0acf-6ae3-48ca-9305-a1cfd32c8e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "*BI-MRR:0.3616\n",
      "*Ranks(252):[1.0, 1.0, 0, 0.25, 1.0, 1.0, 0, 0, 0.25, 1.0]\n",
      "\n",
      "BI_RANKS 10개씩 출력\n",
      "------------------------------------------------------------------------------\n",
      "0: [1.0, 1.0, 0, 0.25, 1.0, 1.0, 0, 0, 0.25, 1.0]\n",
      "1: [1.0, 0, 0, 0.5, 1.0, 1.0, 0, 0, 1.0, 0]\n",
      "2: [0, 0.25, 0.2, 1.0, 0.25, 1.0, 0, 0, 0, 0.5]\n",
      "3: [0, 1.0, 0, 0.2, 0, 1.0, 0, 0, 0, 1.0]\n",
      "4: [0, 0.5, 1.0, 0.3333333333333333, 0, 0.25, 0, 1.0, 0, 0.5]\n",
      "5: [0, 0, 0, 0, 0, 0, 0, 0, 0.5, 0.2]\n",
      "6: [0, 0, 0.2, 0.5, 0, 0, 0, 0, 0, 1.0]\n",
      "7: [0, 1.0, 0, 0, 1.0, 0, 0, 0, 1.0, 0]\n",
      "8: [1.0, 0.3333333333333333, 0.5, 0, 0, 0.5, 0, 1.0, 1.0, 0]\n",
      "9: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "10: [0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0]\n",
      "11: [0.5, 0, 0.5, 0, 0.3333333333333333, 1.0, 0, 0.25, 0.3333333333333333, 0]\n",
      "12: [1.0, 0.5, 0, 0, 0.3333333333333333, 0.3333333333333333, 1.0, 1.0, 0, 1.0]\n",
      "13: [1.0, 0.25, 1.0, 0.25, 0.5, 1.0, 0, 1.0, 0, 0]\n",
      "14: [0, 0, 0, 0.5, 0, 0, 0, 1.0, 0.5, 0.3333333333333333]\n",
      "15: [1.0, 1.0, 0.25, 0, 1.0, 1.0, 0, 1.0, 0, 0.3333333333333333]\n",
      "16: [0.3333333333333333, 0, 0.25, 0.5, 0.3333333333333333, 1.0, 0, 1.0, 1.0, 0.5]\n",
      "17: [1.0, 1.0, 1.0, 0.5, 0, 0.5, 0, 0, 0.3333333333333333, 1.0]\n",
      "18: [0.5, 1.0, 0, 0.25, 1.0, 0.2, 1.0, 0, 1.0, 0.3333333333333333]\n",
      "19: [0, 0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0, 0]\n",
      "20: [1.0, 0.25, 0.5, 0, 1.0, 0, 0.5, 0, 0, 0]\n",
      "21: [0.25, 0, 1.0, 0, 1.0, 0.5, 1.0, 1.0, 0, 1.0]\n",
      "22: [0, 0, 0, 1.0, 0.5, 0, 1.0, 0.2, 0, 0.3333333333333333]\n",
      "23: [1.0, 0, 1.0, 0, 0, 0.5, 0, 0, 1.0, 0]\n",
      "24: [0, 0, 0, 0, 0, 0, 0, 0.5, 0.3333333333333333, 1.0]\n",
      "25: [0, 1.0]\n",
      "*검색률: 128/252(50.79%)\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "*검색실패 : 124\n",
      "[2] : BERT 모델 STS 성능 비교분석\n",
      "[6] : BERT 검색 , 분류 시스템 성능 측정\n",
      "[7] : 테이블 데이터 조회하는 방법\n",
      "[11] : 행정 전자 서명 인증 표준 API 이용을 위한 신청서 양식\n",
      "[12] : 행정전자서명인증 표준보안 개발자가이드\n",
      "[16] : BERT 기반 애플리케이션을 위한 팁과 요령\n",
      "[17] : 커맨드에서 소스 세이프 사용하는 방법\n",
      "[19] : G드라이브 운영자지침서\n",
      "[20] : Dictionary 활용\n",
      "[26] : ElasticSearch 클러스터 구성\n",
      "[27] : ESXi 서버 설정 매뉴얼\n",
      "[28] : Java 알고리즘 Provider 추가하는 방법 1\n",
      "[30] : BERT모델 이해하기\n",
      "[32] : BERT를 활용한 문서검색시스템-검토사항정리\n",
      "[34] : BERT를 사용한 주제 모델링\n",
      "[36] : Elasticsearch 를 이용한 본문검색 구축-퀵가이드(Linux)\n",
      "[37] : KeyBERT를 사용한 키워드 및 핵심 문구 추출\n",
      "[38] : MDrive 관련 개발 내용 정리 문서\n",
      "[40] : M드라이브 V9 관리자 메뉴얼\n",
      "[44] : lec20.텍스트 프로세싱-v2\n",
      "[46] : MLM 모델 훈련 시키기\n",
      "[48] : lec10.함수 인자와 매개 변수_v2\n",
      "[50] : lec13.그래픽 객체를 사용한 애니메이션-1-v4\n",
      "[51] : lec5.프로그램에서 사용하는 객체와 객체의 형태\n",
      "[52] : lec8.매개 변수와 반환값을 가진 함수\n",
      "[53] : lec4.if 와 while 을 사용한 미로 탈출 예제\n",
      "[54] : lec7.튜플을 사용한 디지털 사진 변환 예제-이미지 반전\n",
      "[55] : lec9.함수를 사용한 로봇 조종 및 디지털 사진 변환 프로그램\n",
      "[56] : lec3.if 조건문과 while 반복문\n",
      "[57] : Knowledge Distillation 구현\n",
      "[60] : onnx와 huggingface를 이용한 양자화\n",
      "[61] : SFSv10_다중 인증_V1.0\n",
      "[64] : SECUGEOIVGateway(VPN 서버) TroubleShooting\n",
      "[65] : Prompt 기반 Few-shot Learning을 이용한 한국어 자연어처리\n",
      "[66] : SentenceTransformers로 고품질 임베딩을 쉽게 얻을 수 있습니다\n",
      "[67] : Python 프로그램 작성 예제-v2\n",
      "[68] : past_key_values 사용 방법 이해\n",
      "[70] : ROBERT 모델의 증류-코드\n",
      "[72] : SentenceTransformers를 이용한 다양한 검색 방법(이미지검색포함)\n",
      "[73] : SentenceTransformers로 고품질 임베딩을 쉽게 얻을 수 있다\n",
      "[75] : Prompt 기반 Few-shot Learning을 이용한 한국어 자연어처리2\n",
      "[76] : onnx와 huggingface를 이용한 양자화2\n",
      "[77] : simpleT5-단 3줄의 코드로 T5 모델 훈련\n",
      "[79] : Tibero6 DB 포팅\n",
      "[83] : U+Box 넷드라이브 V1.0 완료보고서\n",
      "[84] : V10 사용자 매뉴얼-v1.0\n",
      "[86] : Visual Studio 설치 및 유의사항\n",
      "[89] : 15-제약 조건\n",
      "[90] : 가상 디바이스 드라이버를 초기화하고 종료하기\n",
      "[91] : 데이터베이스 개발 가이드_v1.1\n",
      "[92] : 메모리와 가상머신 관리자에 대해\n",
      "[93] : 모코엠시스-Mpower EZis-V 소개서\n",
      "[94] : 어셈블리어를 이용한 시스템프로그래밍 개발하기\n",
      "[95] : 워드 임베딩3D시각화하는 방법\n",
      "[96] : 윈도우즈 가상머신 관리할 사항\n",
      "[97] : 지능형 문서관리-인공지능 사전학습\n",
      "[98] : 청탁금지법 적용대상\n",
      "[99] : BERT 및 명사구를 사용한 핵심구 추출\n",
      "[100] : BERT로 정보 추출기 구축\n",
      "[101] : ROBERT 모델의 증류-이론\n",
      "[102] : VxD 프로그래밍 이해하기\n",
      "[103] : 네이버클라우드 S3 연동 테스트\n",
      "[104] : 델파이에 대한 개략적 소\n",
      "[105] : 데이터베이스 설계 도구\n",
      "[106] : 그룹 함수 사용 방법\n",
      "[108] : 데이터베이스 모델 검증\n",
      "[109] : 데이터 디스크 복원 연동 방법\n",
      "[111] : 데이터베이스 튜닝\n",
      "[113] : 데이터베이스 상관 모델링\n",
      "[116] : 가상디바이스 드라이버 기술과 방법\n",
      "[119] : 기계독해의 원리와 활용-TwoBlockAI\n",
      "[122] : 20.장기근속포상규정\n",
      "[123] : 2014년 MD사업부 소개 자료\n",
      "[128] : 2023년 유망 SaaS 개발·육성 지원\n",
      "[136] : 27-원격 데이터베이스 액세스\n",
      "[138] : 28-Export & Import\n",
      "[139] : 28.학자금 지원 제도\n",
      "[140] : 29-SQL Loader\n",
      "[141] : 리스트 정렬과 소수구하기\n",
      "[142] : 모코엠시스 신규입사자 입문교육\n",
      "[144] : 모코엠시스-Mpower B2B 제품소개서\n",
      "[145] : 문서중앙화 규격서\n",
      "[146] : 문서중앙화v10 통신 암호화\n",
      "[153] : 병렬 웹서버 개발 환경 구성\n",
      "[156] : 보안취약성 이슈 관련 현황 및 조치_v1.1\n",
      "[158] : 보안파일서버 사용자 기능 설명\n",
      "[161] : 3.솔루션사업부 사업계획서\n",
      "[166] : 34.주주총회 운영규정\n",
      "[174] : 5.보안사업부 사업계획\n",
      "[176] : 6.전략사업부 사업계획서\n",
      "[177] : 6.전자문서처리단계별위·변조방지방안\n",
      "[182] : 03.경조사지원규정\n",
      "[187] : 06-기본 SQL 및 SQL Plus 명령\n",
      "[190] : 07-데이터 제한 및 정렬\n",
      "[191] : 05-데이터베이스구조\n",
      "[198] : [붙임1]+미래성장유망+20대+전략분야+70개+세부전략분야\n",
      "[199] : 08-단일행함수사용\n",
      "[203] : 1_사업계획서(보안파일서버 시스템 도입) (002)_V1\n",
      "[205] : 11.외근업무 지원비 규정\n",
      "[207] : 12.원격지 근무자 비품 구매 관련 지침\n",
      "[208] : 13-테이블스페이스 관리\n",
      "[209] : 13.위임전결규정\n",
      "[211] : 14.유형자산관리지침\n",
      "[213] : 16-뷰 관리 및 활용\n",
      "[218] : 엠파워 8.0 접속기 설치 및 구성 관련 매뉴얼\n",
      "[220] : 엠파워 코퍼스 관리 방안 by pky\n",
      "[221] : 서브 Query 사용법\n",
      "[222] : 웹하드 고도화 관련 착수 보고서\n",
      "[225] : 엠파워 코퍼스 정제 방안\n",
      "[228] : 연구기자재 구입 계획서\n",
      "[231] : 엠파워V10 안드로이드 앱 소개\n",
      "[233] : 시큐어디스크 관리자 매뉴얼\n",
      "[234] : 시큐어디스크 사용자 매뉴얼\n",
      "[236] : 웹하드 디스크_백업포함_8.0 메뉴얼(접속기)\n",
      "[237] : 윈도우즈95 시스템 구조\n",
      "[239] : 이미지 프로세싱\n",
      "[240] : 이스트 소프트 인터넷 디스크 제안서\n",
      "[241] : 인공지능 모델들에서 Vocab 생성 비교 테스트\n",
      "[242] : 자료 구조 문자열과 집합\n",
      "[243] : 접속기와 M드라이브 비교\n",
      "[244] : 제로샷 러닝 학습 \n",
      "[245] : 중소기업기술개발 지원사업에 과제의 최종보고서\n",
      "[246] : 지능형 문서관리- 인공지능 사전학습_V1.0\n",
      "[250] : 출퇴근 관리 시스템 도입에 따른 근무 관련 메뉴얼\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------------------------\n",
    "# MPR 계산\n",
    "# => 정답 리스트[2,3,1,4] 과 예측검색리스트[[1,2,5,1],[3,4,2,1],[6,5,4,1], [2,3,4,1]]를 입력하여 MRR 스코어 구함\n",
    "##--------------------------------------------------------------------------------------------------\n",
    "from myutils import mean_reciprocal_rank\n",
    "\n",
    "# 정답, 여기서는 contextid를 리스트로 만듬.\n",
    "ground_truths_list = df_questions['contextid'].values.tolist()\n",
    "#print(f'gtlen:{len(ground_truths_list)}')\n",
    "#print(ground_truths_list[0:9])\n",
    "\n",
    "# MRR 계산\n",
    "bi_ranks, bi_score = mean_reciprocal_rank(ground_truths_list, bi_predictions_list)\n",
    "\n",
    "# BI-MRR 출력\n",
    "print(f'----------------------------------------------------------------------------')\n",
    "print('*BI-MRR:{:.4f}'.format(bi_score))\n",
    "print(f'*Ranks({len(bi_ranks)}):{bi_ranks[0:10]}')\n",
    "\n",
    "# 10개씩 출력해봄.\n",
    "if len(bi_ranks) > 10:\n",
    "    print()\n",
    "    print(f'BI_RANKS 10개씩 출력')\n",
    "    print('------------------------------------------------------------------------------')\n",
    "    subarrays = [bi_ranks[i:i+10] for i in range(0, len(bi_ranks), 10)]\n",
    "    # Print the resulting subarrays\n",
    "    for i, subarray in enumerate(subarrays):\n",
    "        print(f\"{i}: {subarray}\")\n",
    "    \n",
    "# 검색 한 계슈\n",
    "#logger.info(f'---------------------------------------------------------------------------')\n",
    "search_count = 0\n",
    "nosearch_count = 0\n",
    "nosearch_list = []\n",
    "for i,item in enumerate(bi_ranks):\n",
    "    if item != 0:\n",
    "        search_count += 1\n",
    "    else:\n",
    "        nosearch_count += 1\n",
    "        nosearch_list.append(i)\n",
    "    \n",
    "print('*검색률: {}/{}({:.2f}%)'.format(search_count, len(bi_ranks), (search_count/len(bi_ranks))*100))\n",
    "print(f'---------------------------------------------------------------------------')\n",
    "\n",
    "print()\n",
    "print('*검색실패 : {}'.format(nosearch_count))\n",
    "for i, nosearch in enumerate(nosearch_list):\n",
    "    print(f'[{nosearch}] : {df_questions[\"question\"][nosearch]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec1323-4f53-4cc7-ab51-1ff6e39cf0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
