{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688875d-5c9e-4ff7-af1a-cdd91b7c21b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import time\n",
    "\n",
    "openai.organization = \"org-8ee5MPlwE4fOKQYPUNGa0KO7\"\n",
    "openai.api_key = \"sk-\"\n",
    "\n",
    "# 모델 - GPT 3.5 Turbo 지정\n",
    "# => 모델 목록은 : https://platform.openai.com/docs/models/gpt-4 참조\n",
    "model = \"gpt-3.5-turbo\"#\"gpt-4\"#\"gpt-3.5-turbo\" #gpt-4-0314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca57447-a6d8-4493-a98c-1d68b9be9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 처음 역활을 부여하는 쿼리 (1번만 호출되는 쿼리임)\n",
    "def role_set_query():\n",
    "   \n",
    "    start_time = time.time()\n",
    "\n",
    "    #ROLE_PROMPT = \"쇼핑 호스트 역활을 부여합니다.질문에 대해 쇼핑 호스트 처럼 답변하고 요청 질문을 해주세요.그리고 키워드 단어들을 'key=단어,단어,...'형태로 출력해 주세요.\"\n",
    "    #ROLE_PROMPT = \"질문에 대한 답을 찾아서 한문장으로 요약해서 간단히 응답해주세요. 이때 빠르게 응답하도록 응답 내용은 30자를 넘지 말아야 합니다.\"\n",
    "\n",
    "    # 메시지 설정\n",
    "    MESSAGES = [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helful assistant.\"},\n",
    "                #{\"role\": \"system\", \"content\": \"질문에 대해 요약해줘\"},\n",
    "                #{\"role\": \"user\", \"content\" : \"How are you?\"},\n",
    "                #{\"role\": \"assistant\", \"content\" : \"I am doing well\"},\n",
    "                {\"role\": \"user\", \"content\": ROLE_PROMPT}\n",
    "            ]\n",
    "\n",
    "    # ChatGPT-API 호출하기\n",
    "    response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=MESSAGES,\n",
    "            max_tokens=500, # 토큰 수 \n",
    "            temperature=2,  # temperature 0~2 범위 : 작을수록 정형화된 답변, 클수록 유연한 답변(2는 엉뚱한 답변을 하므로, 1.5정도가 좋은것 같음=기본값은=1)\n",
    "            top_p=0.1, # 기본값은 1 (0.1이라고 하면 10% 토큰들에서 출력 토큰들을 선택한다는 의미)\n",
    "            frequency_penalty=0.5, # 일반적으로 나오지 않는 단어를 억제하는 정도\n",
    "            presence_penalty=0.5, # 동일한 단어나 구문이 반복되는 것을 억제하는 정도\n",
    "        )\n",
    "\n",
    "    print(response)\n",
    "    print()\n",
    "    answer = response['choices'][0]['message']['content']\n",
    "    print(f'A:{answer}')\n",
    "    print()    \n",
    "    \n",
    "    # 소요된 시간을 계산합니다.\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'응답시간:{elapsed_time}')\n",
    "    \n",
    "    return answer \n",
    "\n",
    "def generate_text_GPT():\n",
    "    \n",
    "    prompt = input(\"질문을 입력하세요\")\n",
    "    #print(f'\\n\\nQ:{prompt}\\n\\n')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    #print(f'len(messages):{len(messages)}') \n",
    "    #print()\n",
    "    \n",
    "    # 메시지 설정\n",
    "    MESSAGES = [\n",
    "            {\"role\": \"system\", \"content\": \"답은 간략히 한문장으로 만들어 주세요.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "\n",
    "    # ChatGPT-API 호출하기\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=MESSAGES,\n",
    "        max_tokens=512, # 토큰 수 \n",
    "        temperature=1,  # temperature 0~2 범위 : 작을수록 정형화된 답변, 클수록 유연한 답변(2는 엉뚱한 답변을 하므로, 1.5정도가 좋은것 같음=기본값은=1)\n",
    "        top_p=0.1, # 기본값은 1 (0.1이라고 하면 10% 토큰들에서 출력 토큰들을 선택한다는 의미)\n",
    "        frequency_penalty=0.5, # 일반적으로 나오지 않는 단어를 억제하는 정도\n",
    "        presence_penalty=0.5, # 동일한 단어나 구문이 반복되는 것을 억제하는 정도\n",
    "        #stop=[\"다.\",\"다!\"] # . 나오면 중단\n",
    "    )\n",
    "\n",
    "    print(response)\n",
    "    print()\n",
    "    \n",
    " \n",
    "    # 소요된 시간을 계산합니다.\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'응답시간:{elapsed_time}')\n",
    "    print()\n",
    "    #answer = response['choices'][0]['message']['content']+'다.'  # '다.'로 끝나므로, 다를 붙여줌\n",
    "    answer = response['choices'][0]['message']['content']\n",
    "    print(answer)\n",
    "    print()\n",
    "    return answer\n",
    "\n",
    "#--------------------------\n",
    "def run_query_loop():\n",
    "    \n",
    "   # answer = role_set_query()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            generate_text_GPT()\n",
    "            #answer = handle_query(answer)\n",
    "        except KeyboardInterrupt:\n",
    "            return\n",
    "#--------------------------  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3dba3-1382-4041-933e-99dedc4b257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_query_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5638c904-c8fe-435b-85a8-5f19204ad072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
