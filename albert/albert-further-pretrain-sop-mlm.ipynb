{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07847e08-52dc-49fb-bcd7-683544ee7635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:../../log/bwdataset_2022-06-08.log\n",
      "logfilepath:../../log/qnadataset_2022-06-08.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "cuda:0\n",
      "logfilepath:../../log/Albertfpt_2022-06-08.log\n"
     ]
    }
   ],
   "source": [
    "#===========================================================================================\n",
    "# ALBERT Futher-PreTraining 예시\n",
    "# => MLM(Masked Language Model) 과 SOP(Sentence Order Prediction) 로 Further Pre-Train 시키는 예시\n",
    "# => AlbertForPreTraining 사용\n",
    "# => next_sentence_label 대신에 sentence_order_label 이용\n",
    "#\n",
    "# 참고 자료 : https://huggingface.co/docs/transformers/model_doc/albert\n",
    "#===========================================================================================\n",
    "\n",
    "import torch\n",
    "from transformers import AlbertTokenizer, AlbertForPreTraining\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from os import sys\n",
    "sys.path.append('..')\n",
    "from myutils import GPU_info, seed_everything, mlogging, AccuracyForMaskedToken, SaveBERTModel\n",
    "\n",
    "device = GPU_info()\n",
    "print(device)\n",
    "\n",
    "#seed 설정\n",
    "seed_everything(222)\n",
    "\n",
    "#logging 설정\n",
    "logger =  mlogging(loggername=\"Albertfpt\", logfilename=\"../../log/Albertfpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be30ff97-d35f-4e52-a368-a17255d094dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForPreTraining were not initialized from the model checkpoint at ../../data11/model/albert/albert-base-v2-ftp-2 and are newly initialized: ['albert.pooler.bias', 'sop_classifier.classifier.weight', 'albert.pooler.weight', 'sop_classifier.classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlbertForPreTraining(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(54152, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (predictions): AlbertMLMHead(\n",
       "    (LayerNorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (decoder): Linear(in_features=128, out_features=54152, bias=True)\n",
       "  )\n",
       "  (sop_classifier): AlbertSOPHead(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 불러옴 \n",
    "vocab_path = '../../data11/model/albert/albert-base-v2-ftp-2' \n",
    "model_path = '../../data11/model/albert/albert-base-v2-ftp-2' \n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained(vocab_path)\n",
    "print(len(tokenizer))\n",
    "\n",
    "model = AlbertForPreTraining.from_pretrained(model_path)\n",
    "\n",
    "# resize_token_embeddings 으로 신규 tokenizer 사이즈로 지정 해줌.\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc9beef-e68e-4768-b255-91194d2f1836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14929418"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb381d56-ecb2-467a-b75f-107d1028db73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2, 54150,     1, 54146, 30010, 54147, 30219,     1, 54148,     1,\n",
      "         31858,     1,     9,     3,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "# text tokenizer 해봄.\n",
    "text = \"모코엠시스에서는 문서중앙화 및 보안파일서버 솔루션인 엠파워를 출시하였다.\"\n",
    "token_ids = tokenizer.encode_plus(text, max_length=128, padding=\"max_length\", return_tensors=\"pt\")\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2480a865-8328-47cb-959b-b3f50bafef17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "1\n",
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# 각 스페셜 tokenid를 구함\n",
    "CLStokenid = tokenizer.convert_tokens_to_ids('[CLS]')\n",
    "SEPtokenid = tokenizer.convert_tokens_to_ids('[SEP]')\n",
    "UNKtokenid = tokenizer.convert_tokens_to_ids('<UNK>')\n",
    "PADtokenid = tokenizer.convert_tokens_to_ids('<pad>')\n",
    "MASKtokenid = tokenizer.convert_tokens_to_ids('[MASK]')\n",
    "\n",
    "print(CLStokenid)\n",
    "print(SEPtokenid)\n",
    "print(UNKtokenid)\n",
    "print(PADtokenid)\n",
    "print(MASKtokenid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b10f29-9336-4705-8351-e512aba5a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Data 불러옴.\n",
    "# test data는 .으로 구분된 한줄 문자이 아니라. 한줄에 .로구분된 여러문장이 이어진 문장이어야 함\n",
    "# 예시:'제임스 얼 \"지미\" 카터 주니어는 민주당 출신 미국 39번째 대통령 이다.지미 카터는 조지아주 섬터 카운티 플레인스 마을에서 태어났다.\n",
    "input_corpus = '../../data/my_data/data.txt'\n",
    "\n",
    "with open(input_corpus, 'r') as fp:\n",
    "    text = fp.read().split('\\n')\n",
    "    \n",
    "print(text[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0d740db-d1bd-4b9d-bec6-6d2ebfb6b89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24171\n",
      " 1979년 백악관에서 양국 간의 평화조약으로 이끌어졌다\n"
     ]
    }
   ],
   "source": [
    "# SOP 만들기 위해, .을 기준으로 문장들을 나눈 후 길이를 얻어 둔다.\n",
    "bag = [item for sentence in text for item in sentence.split('.') if item != '']\n",
    "bag_size = len(bag)\n",
    "print(bag_size)\n",
    "print(bag[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0b1e762-b705-44ff-ab13-8d49dc527550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================================================================\n",
    "# SOP 문장 만들기 \n",
    "#\n",
    "# => SOP는 주어진 한 쌍의 문장이 positive인지 negative인지 분류하는 이진 분류 문제이다.\n",
    "# 문장 1: 그는 김치볶음밥을 요리했다.\n",
    "# 문장 2: 맛있었다.\n",
    "# =>주어진 한 쌍의 문장을 보면, 문장 2가 문장 1 다음에 온다는 것을 알 수 있다. 이때를 positive(0)라고 한다.\n",
    "\n",
    "# 문장 1: 맛있었다.\n",
    "# 문장 2: 그는 김치볶음밥을 요리했다.\n",
    "# =>위 경우는 문장 순서가 바뀐 경우 이고 negetive(1)이다.\n",
    "#=================================================================================================\n",
    "import random\n",
    "\n",
    "sentence_a = []\n",
    "sentence_b = []\n",
    "label = []\n",
    "\n",
    "for paragraph in text:\n",
    "    # 하나의 문장을 읽어와서 .기준으로 나눈다.\n",
    "    sentences = [sentence for sentence in paragraph.split('.') if sentence != '']\n",
    "    num_sentences = len(sentences)\n",
    "    \n",
    "     # . 기준으로 나눈 문장이 1이상이면..\n",
    "    if num_sentences > 1:\n",
    "        # 문장 a 시작번지는 랜덤하게, 해당 문장 이후로 지정\n",
    "        start = random.randint(0, num_sentences-2)\n",
    "        # 50/50 whether is IsNextSentence or NotNextSentence\n",
    "        # 0.5 이상 랜덤값이면, 연속적인 문장으로 만듬\n",
    "        if random.random() >= 0.5:\n",
    "            # this is IsNextSentence\n",
    "            sentence_a.append(sentences[start])\n",
    "            sentence_b.append(sentences[start+1])\n",
    "            label.append(0)  #label=0이면 연속적\n",
    "        # 0.5 이하 랜덤값이면  순서를 바꿈\n",
    "        else:\n",
    "            # this is NotNextSentence\n",
    "            sentence_a.append(sentences[start+1])\n",
    "            sentence_b.append(sentences[start])\n",
    "            label.append(1)  #label=1이면 순서가 바뀜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a62f842-e896-478d-a66e-e5ee9bf07649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      " Carter Begin, Camp David 1978\n",
      "---\n",
      "gif|섬네일|300px|캠프데이비드에서 사다트와 베긴과 함께카터는 이집트와 이스라엘을 조정하여, 캠프 데이비드에서 안와르 사다트 대통령과 메나헴 베긴 수상과 함께 중동 평화를 위한 캠프데이비드 협정을 체결했다\n",
      "\n",
      "0\n",
      " 벡터의 연구에는 산술, 대수, 기하라는 수학의 중요한 세개의 분야가 조합되어 있다\n",
      "---\n",
      " 벡터 미적분학은 여기에 해석학의 영역이 추가된다\n",
      "\n",
      "1\n",
      "13198 82487 943 비슈바나트 상수(Viswanath s constant 1 ) 수론 ? ? 13 L ≈0\n",
      "---\n",
      "76422 36535 89220 66 란다우-라마누잔 상수 수론 무리수 ( ? ) ? 30,010 K ≈ 1\n",
      "\n",
      "0\n",
      " 문예학은 음악사학, 미술사학 등과 함께 예술학의 핵심분야로서 인문학의 하위범주에 포함된다\n",
      "---\n",
      " 일반적으로 문학의 정의는 텍스트들의 집합이다\n",
      "\n",
      "0\n",
      " 스위스는 주로 나뉜 연합 국가이다\n",
      "---\n",
      " ---- – 스페인 왕국 스페인어 España – Reino de España 유엔과 유럽 연합 가입 국가로 승인 받았다\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# label = 0 이면, 연속적인 문장, 1이면 순서가 바뀐 문장\n",
    "for i in range(5):\n",
    "    print(label[i])\n",
    "    print(sentence_a[i] + '\\n---')\n",
    "    print(sentence_b[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b45822e2-93e0-41d7-a7f6-991c400b6ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "{'input_ids': tensor([[    2,  4323,  2348,  ...,     0,     0,     0],\n",
      "        [    2, 35480,     1,  ...,     0,     0,     0],\n",
      "        [    2, 36799,  3804,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2, 30001,     1,  ...,     0,     0,     0],\n",
      "        [    2, 31660, 30566,  ...,     0,     0,     0],\n",
      "        [    2, 33093,     1,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "# 위 SOP 리스트 들을 tokenizer 함\n",
    "token_max_len = 256\n",
    "# max_length = 512 하면 GPU Memory 오류 발생함\n",
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt',\n",
    "                   max_length=token_max_len, truncation=True, padding='max_length')\n",
    "\n",
    "print(inputs.keys())\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79843951-8695-4557-adfe-c1812825697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]])\n"
     ]
    }
   ],
   "source": [
    "# tokenizer 한 SOP 에 'sentence_order_label' 값(0,1) 추가함\n",
    "inputs['sentence_order_label'] = torch.LongTensor([label]).T\n",
    "\n",
    "print(inputs.sentence_order_label[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f861ced9-dc4c-4ef2-ba85-34333e42c4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'sentence_order_label', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "# MLM 만들기\n",
    "\n",
    "# labels에는 inputs_id를 복사해서 추가\n",
    "inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "\n",
    "print(inputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e7e9873-bce6-485d-b35f-9438f172c9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLSid:2, SEPid:3, UNKid:1, PADid:0, MASKid:4\n",
      "[[5, 6, 25, 27, 33], [5, 19, 25, 27]]\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'sentence_order_label', 'labels'])\n",
      "tensor([[    2,  4323,  2348,  ...,     0,     0,     0],\n",
      "        [    2, 35480,     1,  ...,     0,     0,     0],\n",
      "        [    2, 36799,  3804,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2, 30001,     1,  ...,     0,     0,     0],\n",
      "        [    2, 31660,     4,  ...,     0,     0,     0],\n",
      "        [    2, 33093,     1,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "# 각 스페셜 tokenid를 구함\n",
    "CLStokenid = tokenizer.convert_tokens_to_ids('[CLS]')\n",
    "SEPtokenid = tokenizer.convert_tokens_to_ids('[SEP]')\n",
    "UNKtokenid = tokenizer.convert_tokens_to_ids('<UNK>')\n",
    "PADtokenid = tokenizer.convert_tokens_to_ids('<pad>')\n",
    "MASKtokenid = tokenizer.convert_tokens_to_ids('[MASK]')\n",
    "print('CLSid:{}, SEPid:{}, UNKid:{}, PADid:{}, MASKid:{}'.format(CLStokenid, SEPtokenid, UNKtokenid, PADtokenid, MASKtokenid))\n",
    "\n",
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "# create mask array\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != CLStokenid) * (inputs.input_ids != SEPtokenid) * \\\n",
    "           (inputs.input_ids != UNKtokenid) * (inputs.input_ids != PADtokenid) * \\\n",
    "           (inputs.input_ids != MASKtokenid)\n",
    "\n",
    "selection = []\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )\n",
    "    \n",
    "print(selection[:2])\n",
    "\n",
    "# inputs_ids 에 [MASK] 추가시킴\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = MASKtokenid\n",
    "    \n",
    "\n",
    "print(inputs.keys())\n",
    "print(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7aad699b-ac63-43da-8d6d-bd2023397eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([    2,  4323,  2348,    15,  1232,     4,     4,   457,     3, 51181,\n",
      "            1,  6571,   306,   396,     1, 30545,     1, 45977,     1, 30672,\n",
      "            1,    13,     1, 42457,     1,     4,     1,     4, 47498, 33318,\n",
      "            1, 30359,     1,     4,     1, 37137,     1, 33309,     1, 45977,\n",
      "            1, 35695,     1, 30672, 41754, 54064,     1, 30086, 47498,     1,\n",
      "        35016,     1, 30885,     1,     3,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'sentence_order_label': tensor([0]), 'labels': tensor([    2,  4323,  2348,    15,  1232,   684, 40224,   457,     3, 51181,\n",
      "            1,  6571,   306,   396,     1, 30545,     1, 45977,     1, 30672,\n",
      "            1,    13,     1, 42457,     1, 30681,     1,    15, 47498, 33318,\n",
      "            1, 30359,     1, 30545,     1, 37137,     1, 33309,     1, 45977,\n",
      "            1, 35695,     1, 30672, 41754, 54064,     1, 30086, 47498,     1,\n",
      "        35016,     1, 30885,     1,     3,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_141384/2705128588.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "# 훈련 dataloader 만듬 \n",
    "batch_size = 32\n",
    "\n",
    "class OurDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "    \n",
    "train_dataset = OurDataset(inputs)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          #shuffle=True,\n",
    "                          sampler=RandomSampler(train_dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                          num_workers=3)\n",
    "\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d778bd2-5744-4684-ae57-dc86ca70e6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*corpus:../../data11/korpora/kowiki_20190620/wiki_eval_test.txt\n",
      "*max_sequence_len:256\n",
      "*mlm_probability:0.15\n",
      "*CLStokenid:2, SEPtokenid:3, UNKtokenid:1, PADtokeinid:0, Masktokeid:4\n",
      "*total_line: 114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a331bd63125418f9323ccc23da47df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899191a6ebda4f668e06967d25296bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([    2, 40841,   379,     1,  5325, 35600,     1, 43894,     1, 30796,\n",
      "        30238,     1, 40841,   379,     1,  5325, 35600,     1, 31869,     1,\n",
      "        43894,     1, 30796,     1, 31869,     1,   137,     1,     4,     1,\n",
      "            4,     1, 49949,     1, 31382,     1,    13,     1, 30796,     4,\n",
      "            1,     4,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([    2, 40841,   379,     1,  5325, 35600,     1, 43894,     1, 30796,\n",
      "        30238,     1, 40841,   379,     1,  5325, 35600,     1, 31869,     1,\n",
      "        43894,     1, 30796,     1, 31869,     1,   137,     1, 36199,     1,\n",
      "        30384,     1, 49949,     1, 31382,     1,    13,     1, 30796, 30238,\n",
      "            1,     9,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0])}\n"
     ]
    }
   ],
   "source": [
    "# eval data MLM 데이터 생성\n",
    "eval_corpus = '../../data11/korpora/kowiki_20190620/wiki_eval_test.txt'\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from myutils import MLMDataset\n",
    "\n",
    "#===============================================================================\n",
    "# eval dataloader 생성\n",
    "eval_dataset = MLMDataset(corpus_path = eval_corpus,\n",
    "                          tokenizer = tokenizer, \n",
    "                          CLStokeinid = CLStokenid ,   # [CLS] 토큰 id\n",
    "                          SEPtokenid = SEPtokenid ,    # [SEP] 토큰 id\n",
    "                          UNKtokenid = UNKtokenid ,    # [UNK] 토큰 id\n",
    "                          PADtokenid = PADtokenid,    # [PAD] 토큰 id\n",
    "                          Masktokenid = MASKtokenid,   # [MASK] 토큰 id\n",
    "                          max_sequence_len=token_max_len,  # max_sequence_len)\n",
    "                          mlm_probability=0.15,\n",
    "                          overwrite_cache=False\n",
    "                          )\n",
    "\n",
    "\n",
    "# eval dataloader 생성\n",
    "# => tenosor로 만듬\n",
    "eval_loader = DataLoader(eval_dataset, \n",
    "                         batch_size=batch_size, \n",
    "                         #shuffle=True, # dataset을 섞음\n",
    "                         sampler=RandomSampler(eval_dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                         num_workers=3\n",
    "                         )\n",
    "#===============================================================================\n",
    "\n",
    "print(eval_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641a532-ff41-4a44-8229-1804e2bcb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 시작\n",
    "##################################################\n",
    "epochs = 30\n",
    "learning_rate = 3e-5  # 학습률\n",
    "OUTPATH = '../../data11/model/albert/albert-base-v2-ftp-2-'\n",
    "##################################################\n",
    "\n",
    "# optimizer 적용\n",
    "optimizer = AdamW(model.parameters(), \n",
    "                 lr=learning_rate, \n",
    "                 eps=1e-8) # 0으로 나누는 것을 방지하기 위한 epsilon 값(10^-6 ~ 10^-8 사이 이값 입력합)\n",
    "\n",
    "# 총 훈련과정에서 반복할 스탭\n",
    "total_steps = len(train_loader)*epochs\n",
    "warmup_steps = int(total_steps * 0.1) #10% of train data for warm-up\n",
    "\n",
    "# 손실률 보여줄 step 수\n",
    "#p_itr = int(len(train_loader)*0.1)  \n",
    "p_itr = int(total_steps * 0.05)  \n",
    "if p_itr <= 0:\n",
    "    p_itr = 1\n",
    "    \n",
    "# step마다 모델 저장\n",
    "save_steps = int(total_steps * 0.5)\n",
    "\n",
    "logger.info('*epchos:{}, lr:{:.9f}, total_steps: {}, warmup_steps:{}, p_itr:{}, save_steps:{}'.format(epochs, learning_rate, total_steps, warmup_steps, p_itr, save_steps))\n",
    "               \n",
    "# 스캐줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=warmup_steps, \n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "itr = 1\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "total_test_correct = 0\n",
    "total_test_len = 0\n",
    "    \n",
    "list_train_loss = []\n",
    "list_train_acc = []\n",
    "list_validation_acc = []\n",
    "\n",
    "model.zero_grad()# 그래디언트 초기화\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    #loop = tqdm(train_loader, leave=True)\n",
    "    \n",
    "    #for batch in loop:\n",
    "    model.train() # 훈련모드로 변환\n",
    "    for data in tqdm(train_loader):\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        model.zero_grad()# 그래디언트 초기화\n",
    "    \n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        token_type_ids = data['token_type_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        sentence_order_label = data['sentence_order_label'].to(device)\n",
    "        labels = data['labels'].to(device)\n",
    "        \n",
    "        # process\n",
    "        outputs = model(input_ids = input_ids, \n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        sentence_order_label=sentence_order_label,\n",
    "                        labels=labels)\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.prediction_logits # torch.Size([32, 128, 157660]) => [batch_size, sequence_length, vocab_size]\n",
    "        #print(logits.shape)\n",
    "        \n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)   # 그래디언트 클리핑 (gradient vanishing이나 gradient exploding 방지하기 위한 기법)      \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # 학습률 감소\n",
    "        \n",
    "        \n",
    "        # print relevant info to progress bar\n",
    "        #loop.set_description(f'Epoch {epoch}')\n",
    "        #loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        # => torch.no_grad()는 gradient을 계산하는 autograd engine를 비활성화 하여 \n",
    "        # 필요한 메모리를 줄이고, 연산속도를 증가시키는 역활을 함\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # 손실률 계산\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            #===========================================\n",
    "            # 정확도(Accurarcy) 계산\n",
    "            correct, masked_len = AccuracyForMaskedToken(logits, labels, input_ids, MASKtokenid)           \n",
    "            total_correct += correct.sum().item() \n",
    "            total_len += masked_len \n",
    "            #=========================================\n",
    "                \n",
    "            # 주기마다 test(validataion) 데이터로 평가하여 손실류 계산함.\n",
    "            if itr % p_itr == 0:\n",
    "                \n",
    "                train_loss = total_loss/p_itr\n",
    "                train_acc = total_correct/total_len\n",
    "                       \n",
    "                ####################################################################\n",
    "                # 주기마다 eval(validataion) 데이터로 평가하여 손실류 계산함.\n",
    "                # 평가 시작\n",
    "                model.eval()\n",
    "\n",
    "                #for data in tqdm(eval_loader):\n",
    "                for data in eval_loader:\n",
    "                    # 입력 값 설정\n",
    "                    input_ids = data['input_ids'].to(device)\n",
    "                    attention_mask = data['attention_mask'].to(device)\n",
    "                    token_type_ids = data['token_type_ids'].to(device)       \n",
    "                    labels = data['labels'].to(device)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        # 모델 실행\n",
    "                        outputs = model(input_ids=input_ids, \n",
    "                                       attention_mask=attention_mask,\n",
    "                                       token_type_ids=token_type_ids,\n",
    "                                       labels=labels)\n",
    "\n",
    "                        # 출력값 loss,logits를 outputs에서 얻어옴\n",
    "                        #loss = outputs.loss\n",
    "                        logits = outputs.prediction_logits \n",
    "\n",
    "                        #===========================================\n",
    "                        # 정확도(Accurarcy) 계산\n",
    "                        correct, masked_len = AccuracyForMaskedToken(logits, labels, input_ids, MASKtokenid)           \n",
    "                        total_test_correct += correct.sum().item() \n",
    "                        total_test_len += masked_len \n",
    "                        #=========================================\n",
    "\n",
    "                val_acc = total_test_correct/total_test_len\n",
    "                    \n",
    "                logger.info('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Train Acc: {:.4f}, Val Acc:{}({}/{})'.format(epoch+1, epochs, itr, train_loss, train_acc, val_acc, total_test_correct, total_test_len))\n",
    "      \n",
    "                list_train_loss.append(train_loss)\n",
    "                list_train_acc.append(train_acc)\n",
    "                list_validation_acc.append(val_acc)\n",
    "                 \n",
    "                # 변수들 초기화    \n",
    "                total_loss = 0\n",
    "                total_len = 0\n",
    "                total_correct = 0\n",
    "                total_test_correct = 0\n",
    "                total_test_len = 0\n",
    "                ####################################################################\n",
    "\n",
    "            if itr % save_steps == 0:\n",
    "                #전체모델 저장\n",
    "                SaveBERTModel(model, tokenizer, OUTPATH, epochs, learning_rate, batch_size)\n",
    "                \n",
    "        itr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbfc6616-34d8-4df6-864d-f9f0fdc5ea53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 14:25:18,261 - bwpdataset - INFO - ==> save_model : ../../data11/model/albert/albert-base-v2-ftp-2-batch:32-ep:30-lr:0.000030000-6m8d-14:25\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "SaveBERTModel(model, tokenizer, OUTPATH, epochs, learning_rate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de6a8046-22b0-47f2-81cf-92bec91f5487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프로 loss 표기\n",
    "#!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_train_loss, label='Train Loss')\n",
    "#plt.plot(list_train_acc, label='Train Accuracy')\n",
    "#plt.plot(list_validation_acc, label='Eval Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list_train_acc, label='Train Accuracy')\n",
    "plt.plot(list_validation_acc, label='Eval Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d45e6e-cfca-4687-9bce-cd21d9925c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
