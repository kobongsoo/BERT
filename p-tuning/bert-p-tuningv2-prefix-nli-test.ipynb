{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159bc54e-0c70-4cc7-b3ff-cb2b3683cbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:bertnlitest_2022-07-13.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "#=======================================================================================\n",
    "# P-TUNING NLI(Natural Language Interference:자연어 추론) 테스트 예제\n",
    "#\n",
    "# => input_ids : [CLS]senetence1(전제)[SEP]sentence2(가설)\n",
    "# => attention_mask : 1111111111(전체,가설)0000000(그외)\n",
    "# => token_type_ids : 0000000(전제)1111111(가설)00000000(그외)\n",
    "# => laels : 참(수반:entailment), 거짓(모순:contradiction), 모름(중립:neutral)\n",
    "#\n",
    "#\n",
    "# prefix-tuning => GPT-2, T5등 LM에서 접두사 prompt를 추가하여 훈련시키는 방식\n",
    "#\n",
    "# p-tuning => P-tuning은 prefix-tuning보다 유연 합니다. \n",
    "# 시작할 때뿐만 아니라 프롬프트 중간에 학습 가능한 토큰을 삽입하기 때문입니다. \n",
    "# https://github.com/THUDM/P-tuning\n",
    "#\n",
    "# p-tuing v2 => 새로운 방식이 아니라 NLU 향상을 위해, MLM 모델에 prefix-tuning을 적용한 방식\n",
    "# https://github.com/THUDM/P-tuning-v2\n",
    "#=======================================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from os import sys\n",
    "sys.path.append('..')\n",
    "from myutils import seed_everything, GPU_info, mlogging\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "logger = mlogging(loggername=\"bertnlitest\", logfilename=\"bertnlitest\")\n",
    "device = GPU_info()\n",
    "seed_everything(111)\n",
    "\n",
    "# 모델, tokenizer 경로 지정 \n",
    "model_path = '../../data11/model/bert/bert-multilingual-cased-p-tuing-pp-nli-50'\n",
    "vocab_path = '../../data11/model/bert/bert-multilingual-cased-p-tuing-pp-nli-50'\n",
    "\n",
    "# p-tuningv2 prefixt 튜닝일때 eval 할 모델이 기존 훈련시 설정했던값과 동일하게 설정해야 함.\n",
    "pre_seq_len = 50             # prefix 계수\n",
    "prefix_projection = True     # True = two-layer MLP 사용함(Multi-layer perceptron(다중퍼셉트론))\n",
    "prefix_hidden_size = 512     # prefix hidden size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d41c55-15bb-4737-8327-deba61585b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# p-tuing v2 => 새로운 방식이 아니라 NLU 향상을 위해, MLM 모델에 prefix-tuning을 적용한 방식\n",
    "# 참고 소스 : https://github.com/THUDM/P-tuning-v2\n",
    "# \n",
    "# p-tuning-v2의 주요 기여는 원래 입력 전에 사용자 정의 길이의 레이어 프롬프트를 추가하고 \n",
    "# 다운스트림 작업에 대한 후속 교육에서 BERT 모델의 모든 매개변수를 고정하고 이러한 프롬프트만 교육하는 것임.\n",
    "# 설명 : https://zhuanlan.zhihu.com/p/459305102\n",
    "#\n",
    "# => P-tuning-v2의 구현 방식은 prefix N 시퀀스를 생성한 다음, 원래 bert 모델과 연결한다. 이때 bert의 past_key_values(*여기서는 decoding 속도 개선 목적이 아님)를 이용함\n",
    "# => bert의 past_key_values로 prefix에대한 key 와 value 를 넘겨줘서, 기존 입력 key, value와 연결시키도록 함.\n",
    "# => get_prompt() 함수 : prefix를 past_key_value 형식(batch_size, num_heads, sequence_length - 1, embed_size_per_head)으로 조정(만듬)\n",
    "# => attention_mask : 기존 attention_mask +  prefix_attention_mask \n",
    "#==============================================================================\n",
    "import copy\n",
    "import torch\n",
    "from torch._C import NoopLogger\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import CrossEntropyLoss, MSELoss, BCEWithLogitsLoss\n",
    "from transformers import BertModel, BertPreTrainedModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput, BaseModelOutput, Seq2SeqLMOutput\n",
    "\n",
    "# PrefixEncoder 클래스\n",
    "class PrefixEncoder(torch.nn.Module):\n",
    "    r'''\n",
    "    The torch.nn model to encode the prefix\n",
    "    Input shape: (batch-size, prefix-length)\n",
    "    Output shape: (batch-size, prefix-length, 2*layers*hidden)\n",
    "    '''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.prefix_projection = config.prefix_projection\n",
    "        if self.prefix_projection:\n",
    "            # Use a two-layer MLP to encode the prefix\n",
    "            self.embedding = torch.nn.Embedding(config.pre_seq_len, config.hidden_size)\n",
    "            self.trans = torch.nn.Sequential(\n",
    "                torch.nn.Linear(config.hidden_size, config.prefix_hidden_size),\n",
    "                torch.nn.Tanh(),\n",
    "                torch.nn.Linear(config.prefix_hidden_size, config.num_hidden_layers * 2 * config.hidden_size)\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = torch.nn.Embedding(config.pre_seq_len, config.num_hidden_layers * 2 * config.hidden_size)\n",
    "\n",
    "    def forward(self, prefix: torch.Tensor):\n",
    "        if self.prefix_projection:\n",
    "            prefix_tokens = self.embedding(prefix)\n",
    "            past_key_values = self.trans(prefix_tokens)\n",
    "        else:\n",
    "            past_key_values = self.embedding(prefix)\n",
    "        return past_key_values\n",
    "    \n",
    "# BertPrefixForSequenceClassification 클래스    \n",
    "class BertPrefixForSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = torch.nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        # ***bert 모델은 grad 업데이트 안함(역전파 끔)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.pre_seq_len = config.pre_seq_len\n",
    "        self.n_layer = config.num_hidden_layers  # 12\n",
    "        self.n_head = config.num_attention_heads # 12\n",
    "        self.n_embd = config.hidden_size // config.num_attention_heads  # 64 = 768 % 12\n",
    "\n",
    "        self.prefix_tokens = torch.arange(self.pre_seq_len).long()\n",
    "        self.prefix_encoder = PrefixEncoder(config)\n",
    "\n",
    "        bert_param = 0\n",
    "        for name, param in self.bert.named_parameters():\n",
    "            bert_param += param.numel()\n",
    "        all_param = 0\n",
    "        for name, param in self.named_parameters():\n",
    "            all_param += param.numel()\n",
    "        total_param = all_param - bert_param\n",
    "        print('total param is {}'.format(total_param)) # 9860105\n",
    "    \n",
    "    def get_prompt(self, batch_size):\n",
    "        # [32,20] 만듬 (32:batch_size, 20 은 self.prefix_tokens arange로 생성한 값)\n",
    "        prefix_tokens = self.prefix_tokens.unsqueeze(0).expand(batch_size, -1).to(self.bert.device)\n",
    "        #print(f'prefix_tokens=>{prefix_tokens.shape}')\n",
    "        \n",
    "        past_key_values = self.prefix_encoder(prefix_tokens)\n",
    "        #print(f'past_key_values1=>{past_key_values.shape}')\n",
    "            \n",
    "        # bsz, seqlen, _ = past_key_values.shape\n",
    "        past_key_values = past_key_values.view(\n",
    "            batch_size,\n",
    "            self.pre_seq_len,\n",
    "            self.n_layer * 2, \n",
    "            self.n_head,\n",
    "            self.n_embd\n",
    "        )\n",
    "        # batch_size:32, pre_seq_len:20, nlayer:12, nhead:12, n_emb:64\n",
    "        #print(f'*batch_size:{batch_size}, pre_seq_len:{self.pre_seq_len}, nlayer:{self.n_layer}, nhead:{self.n_head}, n_emb:{self.n_embd}') \n",
    "        \n",
    "        #print(f'past_key_values2=>{past_key_values.shape}')  # torch.Size([32, 20, 24, 12, 64])\n",
    "            \n",
    "        past_key_values = self.dropout(past_key_values)\n",
    "        #print(f'past_key_values3=>{past_key_values.shape}')  # torch.Size([32, 20, 24, 12, 64])\n",
    "            \n",
    "        past_key_values = past_key_values.permute([2, 0, 3, 1, 4]).split(2)\n",
    "        # torch.Size([2, 32, 12, 20, 64]), len\"12\n",
    "        #print(f'past_key_values4=>{past_key_values[0].shape}, len\"{len(past_key_values)}')\n",
    "        \n",
    "        return past_key_values\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        #print(f'return_dict=>{return_dict}') # True\n",
    "            \n",
    "        batch_size = input_ids.shape[0]\n",
    "        \n",
    "        # past_key_values를 지정하면, 어텐션 블록에서, 미리 계산된 키 및 값 숨겨진 상태를 포함한다.\n",
    "        # 즉 p-tuning-v2는 추가된 prefix value 와 key를 기존 입력 value와 key를 서로 연결시키는 구조이다.\n",
    "        # 따라서 prefix의 past_key_values를 구하는데 (batch_size, num_heads, sequence_length - 1, embed_size_per_head) 형태로 구하면 된다.\n",
    "        # 참고 : https://zhuanlan.zhihu.com/p/459305102\n",
    "        # => past_key_values 를 지정하지 않으면 아래와 같은 에러가 발생함.\n",
    "        # RuntimeError: The size of tensor a (128) must match the size of tensor b (148) at non-singleton dimension 3\n",
    "        past_key_values = self.get_prompt(batch_size=batch_size)\n",
    "        \n",
    "        # attention_mask : 기존 attention_mask +  prefix_attention_mask 더함.\n",
    "        # prefix_attention_mask 를 구하고, \n",
    "        prefix_attention_mask = torch.ones(batch_size, self.pre_seq_len).to(self.bert.device)\n",
    "        #print(f'prefix_attention_mask=>{prefix_attention_mask.shape}') # torch.Size([32, 20])\n",
    "        \n",
    "        # 기존 attention_mask +  prefix_attention_mask 합침.\n",
    "        attention_mask = torch.cat((prefix_attention_mask, attention_mask), dim=1) # 128(기존 attention_mask) + 20(prefix_attention_mask) = 148     \n",
    "        #print(f'*attention_mask2=>{attention_mask.shape}') # torch.Size([32, 148])\n",
    "        #print(f'*input_ids=>{input_ids.shape}')\n",
    "        #print(f'*token_type_ids=>{token_type_ids.shape}')\n",
    "        #print(f'*past_key_values=>{past_key_values[0].shape}')\n",
    "        \n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "            past_key_values=past_key_values,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab7b0330-2193-4bfb-b803-8d79ff74fe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119547\n",
      "[101, 9034, 10530, 9356, 31728, 9321, 16617, 10739, 69708, 42428, 10459, 10020, 12030, 28143, 10892, 9405, 17342, 12508, 12508, 49137, 102, 9670, 89523, 9659, 22458, 76820, 102]\n",
      "[UNK]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# tokeniaer 및 model 설정\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "tokenizer = BertTokenizer.from_pretrained(vocab_path, do_lower_case=False)\n",
    "# strip_accents=False : True로 하면, 가자 => ㄱ ㅏ ㅈ ㅏ 식으로 토큰화 되어 버림(*따라서 한국어에서는 반드시 False)\n",
    "# do_lower_case=False : # 소문자 입력 사용 안함(한국어에서는 반드시 False)\n",
    "#tokenizer = BertTokenizer(vocab_file=vocab_path, strip_accents=False, do_lower_case=False) \n",
    "\n",
    "\n",
    "# tokenier 테스트\n",
    "print(len(tokenizer))\n",
    "print(tokenizer.encode(\"눈에 보이는 반전이었지만 영화의 흡인력은 사라지지 않았다\", \"정말 재미있다\"))\n",
    "print(tokenizer.convert_ids_to_tokens(131027))\n",
    "print(tokenizer.convert_tokens_to_ids('정말'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7b1989-04a7-4962-b389-0eb2a539d1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features from dataset file at ../../data11/korpora/klue-nli/klue-nli-v1.1_dev.json\n",
      "loading data... LOOKING AT ../../data11/korpora/klue-nli/klue-nli-v1.1_dev.json\n",
      "tokenize sentences, it could take a lot of time...\n",
      "tokenize sentences [took %.3f s] 0.9729437828063965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4182ca06ae4366b6f835c9d1d25ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Example ***\n",
      "sentence A, B: 흡연자분들은 발코니가 있는 방이면 발코니에서 흡연이 가능합니다. + 어떤 방에서도 흡연은 금지됩니다.\n",
      "tokens: [CLS] 흡 ##연 ##자 ##분 ##들은 발 ##코 ##니 ##가 있는 방 ##이 ##면 발 ##코 ##니 ##에서 흡 ##연 ##이 가 ##능 ##합 ##니다 . [SEP] 어떤 방 ##에서 ##도 흡 ##연 ##은 [UNK] . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "label: contradiction\n",
      "features: ClassificationFeatures(input_ids=[101, 10020, 25486, 13764, 37712, 22879, 9323, 25517, 25503, 11287, 13767, 9328, 10739, 14867, 9323, 25517, 25503, 11489, 10020, 25486, 10739, 8843, 74986, 33188, 48345, 119, 102, 55910, 9328, 11489, 12092, 10020, 25486, 10892, 100, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "*** Example ***\n",
      "sentence A, B: 10명이 함께 사용하기 불편함없이 만족했다. + 10명이 함께 사용하기 불편함이 많았다.\n",
      "tokens: [CLS] 10 ##명이 함께 사 ##용 ##하기 불 ##편 ##함 ##없 ##이 만 ##족 ##했다 . [SEP] 10 ##명이 함께 사 ##용 ##하기 불 ##편 ##함 ##이 많 ##았다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "label: contradiction\n",
      "features: ClassificationFeatures(input_ids=[101, 10150, 66923, 19653, 9405, 24974, 22440, 9368, 50450, 48533, 119136, 10739, 9248, 52560, 12490, 119, 102, 10150, 66923, 19653, 9405, 24974, 22440, 9368, 50450, 48533, 10739, 9249, 27303, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "Saving features into cached file, it could take a lot of time...\n",
      "Saving features into cached file %s [took %.3f s] ../../data11/korpora/klue-nli/cached_BertTokenizer_128_klue-nli-v1.1_dev.json 0.21775102615356445\n",
      "eval_loader_len: 94\n"
     ]
    }
   ],
   "source": [
    "# 평가 data loader 생성\n",
    "from os import sys\n",
    "sys.path.append('..')\n",
    "from myutils import ClassificationDataset, KlueNLICorpus, data_collator\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "#############################################################################\n",
    "# 변수 설정\n",
    "#############################################################################\n",
    "max_seq_len = 128   # 글자 최대 토큰 길이 해당 토큰 길이 이상은 잘린다.\n",
    "batch_size = 32        # 배치 사이즈(64면 GUP Memory 오류 나므로, 32 이하로 설정할것=>max_seq_length 를 줄이면, 64도 가능함)\n",
    "cache = True   # 캐쉬파일 생성할거면 True로 (True이면 loding할때 캐쉬파일있어도 이용안함)\n",
    "#############################################################################\n",
    "\n",
    "# corpus 파일 설정\n",
    "corpus = KlueNLICorpus()\n",
    "\n",
    "# 평가 dataset 생성\n",
    "file_fpath = '../../data11/korpora/klue-nli/klue-nli-v1.1_dev.json'\n",
    "dataset = ClassificationDataset(file_fpath=file_fpath, max_seq_length=max_seq_len, tokenizer=tokenizer, corpus=corpus, overwrite_cache=cache)\n",
    "\n",
    "# 평가 dataloader 생성\n",
    "eval_loader = DataLoader(dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          #shuffle=True, # dataset을 섞음\n",
    "                          sampler=RandomSampler(dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                          collate_fn=data_collator, # dataset을 tensor로 변환(예시 {'input_ids':tensor[0,1,2,3,1,], 'token_type_id:tensor[0,0,0,0,0], 'attention_mask:tensor[1,1,1,1,1], 'labels':tensor[5]}\n",
    "                          num_workers=4)\n",
    "\n",
    "print('eval_loader_len: {}'.format(len(eval_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dedc0545-a28c-4ed0-ab63-5aeda326649b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id : {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
      "id2label : {0: 'entailment', 1: 'contradiction', 2: 'neutral'}\n",
      "12\n",
      "12\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "corpus_labels = corpus.get_labels()\n",
    "\n",
    "label2id = {l: i for i, l in enumerate(corpus_labels)}\n",
    "id2label = {id: label for label, id in label2id.items()}\n",
    "print(f\"label2id : {label2id}\")\n",
    "print(f\"id2label : {id2label}\")\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=3,  #nli이므로 3으로 함\n",
    "    #label2id=dataset.label2id,\n",
    "    #id2label=dataset.id2label,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    finetuning_task=\"rte\",\n",
    "    revision=\"main\"\n",
    ")\n",
    "\n",
    "#========================================================================\n",
    "# 훈련 모델에 따라 아래값들을 바꿔줘야 함.\n",
    "#========================================================================\n",
    "\n",
    "#get_model 에서 --prefix인경우 config 인자 설정해 주고 있음.\n",
    "config.hidden_dropout_prob = 0.1\n",
    "config.pre_seq_len = pre_seq_len             # prefix 계수\n",
    "config.prefix_projection = prefix_projection    # True = two-layer MLP 사용함(Multi-layer perceptron(다중퍼셉트론))\n",
    "config.prefix_hidden_size = prefix_hidden_size     # prefix hidden size\n",
    "#========================================================================\n",
    "\n",
    "print(config.num_hidden_layers)\n",
    "print(config.num_attention_heads)\n",
    "print(config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ae6e867-84c9-4313-b7ae-9f2d07d7cf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total param is 9890051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertPrefixForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (prefix_encoder): PrefixEncoder(\n",
       "    (embedding): Embedding(50, 768)\n",
       "    (trans): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=512, out_features=18432, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################################\n",
    "# 변수들 설정\n",
    "# - model_path : from_pretrained() 로 호출하는 경우에는 모델파일이 있는 폴더 경로나 \n",
    "#          huggingface에 등록된 모델명(예:'bert-base-multilingual-cased')\n",
    "#          torch.load(model)로 로딩하는 경우에는 모델 파일 풀 경로\n",
    "#\n",
    "# - vocab_path : from_pretrained() 호출하는 경우에는 모델파일이 있는 폴더 경로나\n",
    "#          huggingface에 등록된 모델명(예:'bert-base-multilingual-cased')   \n",
    "#          BertTokenizer() 로 호출하는 경우에는 vocab.txt 파일 풀 경로,\n",
    "#############################################################################################\n",
    "     \n",
    "# p-tuning 모델인 경우\n",
    "model = BertPrefixForSequenceClassification.from_pretrained(model_path, config=config, revision=\"main\")\n",
    "\n",
    "# 레벨을 1개만 선택하는 경우\n",
    "#model = BertForSequenceClassification.from_pretrained(model_path, num_labels=3)\n",
    "#model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=6)\n",
    "\n",
    "# 레벨을 멀티로 선택해야 하는 경우\n",
    "#model = BertForSequenceClassification.from_pretrained(model_path, problem_type=\"multi_label_classification\",num_labels=6)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c6fdf52-538a-4a3c-a3f7-bde3fab418b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 12:50:02,102 - bertnlitest - INFO - === model: ../../data11/model/bert/bert-multilingual-cased-p-tuing-pp-nli-50 ===\n",
      "2022-07-13 12:50:02,105 - bertnlitest - INFO - num_parameters: 187743491\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"=== model: {model_path} ===\")\n",
    "logger.info(f\"num_parameters: {model.num_parameters()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2068553-5650-47a4-bdd6-c9e79e1580cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 12:50:02,162 - bertnlitest - INFO - ---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fcbae4efd9444b8474c10f728ccb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 12:50:07,422 - bertnlitest - INFO - eval-accuracy: 0.6893333333333334\n",
      "2022-07-13 12:50:07,424 - bertnlitest - INFO - ---------------------------------------------------------\n",
      "2022-07-13 12:50:07,425 - bertnlitest - INFO - === 처리시간: 5.263 초 ===\n",
      "2022-07-13 12:50:07,426 - bertnlitest - INFO - -END-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 평가 시작\n",
    "model.eval()\n",
    "\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "start = time.time()\n",
    "logger.info(f'---------------------------------------------------------')\n",
    "\n",
    "for data in tqdm(eval_loader):\n",
    "     # 입력 값 설정\n",
    "    input_ids = data['input_ids'].to(device)\n",
    "    attention_mask = data['attention_mask'].to(device)\n",
    "    token_type_ids = data['token_type_ids'].to(device)       \n",
    "    labels = data['labels'].to(device)\n",
    " \n",
    "    # 손실률 계산하는 부분은 no_grade 시켜서, 계산량을 줄임.\n",
    "    # => torch.no_grad()는 gradient을 계산하는 autograd engine를 비활성화 하여 \n",
    "    # 필요한 메모리를 줄이고, 연산속도를 증가시키는 역활을 함\n",
    "    with torch.no_grad():\n",
    "        # 모델 실행\n",
    "        outputs = model(input_ids=input_ids, \n",
    "                       attention_mask=attention_mask,\n",
    "                       token_type_ids=token_type_ids,\n",
    "                       labels=labels)\n",
    "    \n",
    "        # 출력값 loss,logits를 outputs에서 얻어옴\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        #print(F.softmax(logits))\n",
    "        #pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        #print(logits)\n",
    "        correct = pred.eq(labels)\n",
    "        total_correct += correct.sum().item()\n",
    "        total_len += len(labels)\n",
    "\n",
    "logger.info(f\"eval-accuracy: {total_correct / total_len}\")\n",
    "logger.info(f'---------------------------------------------------------')\n",
    "logger.info(f'=== 처리시간: {time.time() - start:.3f} 초 ===')\n",
    "logger.info(f'-END-\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
