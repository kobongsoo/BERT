{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "252f1e4a-09f6-4253-b1ae-4cc9193711f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참고 사이트 \n",
    "# 참고소스1 : transformers huggingface mlm 사전 학습 예제\n",
    "#   - https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
    "#\n",
    "# 참고소스2  : bert를 가지고 중국어 corpus로 추가학습시킨 예제\n",
    "#    - https://github.com/zhusleep/pytorch_chinese_lm_pretrain 에 run_language_model_bert.py \n",
    "#      https://www.fatalerrors.org/a/further-pre-training-of-chinese-language-model-bert-roberta.html\n",
    "\n",
    "import transformers\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import os\n",
    "from os import sys\n",
    "sys.path.append('..')\n",
    "from myutils import seed_everything, TextDatasetForNextSentencePrediction, GPU_info, mlogging, MyTextDataset\n",
    "from transformers import BertTokenizer, BertModel, BertTokenizerFast, BertConfig, AutoModelWithLMHead, BertForMaskedLM\n",
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0267fd3e-7443-43a2-83ae-ff3ccbb9dece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "cuda:0\n",
      "logfilepath:bertperplexityeval_2022-09-13.log\n"
     ]
    }
   ],
   "source": [
    "# wand 비활성화 \n",
    "# => trainer 로 훈련시키면 기본이 wandb 활성화이므로, 비활성화 시킴\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "device = GPU_info()\n",
    "print(device)\n",
    "\n",
    "#seed 설정\n",
    "seed_everything(111)\n",
    "\n",
    "#logging 설정\n",
    "logger=mlogging(loggername=\"bertperplexityeval\", logfilename=\"bertperplexityeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7a70767-9737-4081-8664-c8291f0289cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수들 설정\n",
    "#input_corpus = \"Korpora/kowikitext/kowikitext_20200920.test\"\n",
    "input_corpus = \"../../data11/my_corpus/bong_eval.txt\"\n",
    "\n",
    "\n",
    "input_model_path = \"../../data11/model/bert/mbertV2.0\"\n",
    "vocab_file=\"../../data11/model/bert/mbertV2.0/vocab.txt\"\n",
    "ouput_model_dir = \"../../data11/model/bert/mbertV2.0-1\"\n",
    "\n",
    "'''\n",
    "input_model_path = \"model/bert-multilingual-cased\"\n",
    "vocab_file=\"model/bert-multilingual-cased/vocab/vocab.txt\"\n",
    "ouput_model_dir = \"model/bert-multilingual-cased\"\n",
    "'''\n",
    "'''\n",
    "input_model_path = \"model/bert-multilingual-cased_furter_pt_model_0216\"\n",
    "vocab_file=\"model/bert-multilingual-cased_furter_pt_model_0216/vocab/vocab.txt\"\n",
    "ouput_model_dir = \"model/bert-multilingual-cased_furter_pt_model_0216\"\n",
    "'''\n",
    "# 토큰활 할때 최대 길이 \n",
    "token_max_len = 128\n",
    "\n",
    "# 훈련용 변수\n",
    "batch_size = 32   # 128로 하면, GPU Out of memory 발생함(=>**따라서 32로 진행)\n",
    " # embedding size 최대 몇 token까지 input으로 사용할 것인지 지정(기본:512) 512, 1024, 2048 식으로 지정함, 엄청난 장문을 다룰경우 10124까지\n",
    "max_position_embeddings = 128 \n",
    "logging_steps = 1  # 훈련시, 로깅할 step 수 (크면 10000번 정도하고, 작으면 100번정도)\n",
    "save_steps = 1     # 10000 step마다 모델 저장\n",
    "save_total_limit = 1 # 마지막 3개 모델 빼고 과거 모델은 삭제(100000번째마다 모델 저장하는데, 마지감 3개 빼고 나머지는 삭제)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1417fe82-bcd5-4431-a7fd-2c7691008a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data11/model/bert/mbertV2.0/vocab.txt is_fast:True\n",
      "special_token_size: 5, tokenizer.vocab_size: 152537\n",
      "vocab_size: 152538\n",
      "tokenizer_len: 152537\n"
     ]
    }
   ],
   "source": [
    "# tokenizer 생성\n",
    "# => BertTokenizer, BertTokenizerFast 둘중 사용하면됨\n",
    "'''\n",
    "tokenizer = BertTokenizer(vocab_file=vocab_file, \n",
    "                          max_len=token_max_len, \n",
    "                          do_lower_case=False)\n",
    "'''\n",
    "\n",
    "#tokenizer = BertTokenizerFast(vocab_speical_path)\n",
    "tokenizer = BertTokenizerFast(\n",
    "    vocab_file=vocab_file,\n",
    "    max_len=token_max_len,\n",
    "    do_lower_case=False,\n",
    "    )\n",
    "    \n",
    "# fast 토크너나이즈인지 확인\n",
    "print(f'{vocab_file} is_fast:{tokenizer.is_fast}')\n",
    "\n",
    "# speical 토큰 계수 + vocab 계수 - 이미 vocab에 포함된 speical 토큰 계수(5)\n",
    "vocab_size = len(tokenizer.all_special_tokens) + tokenizer.vocab_size - 5 + 1\n",
    "#vocab_size = len(tokenizer.all_special_tokens) + tokenizer.vocab_size - 5\n",
    "print('special_token_size: {}, tokenizer.vocab_size: {}'.format(len(tokenizer.all_special_tokens), tokenizer.vocab_size))\n",
    "print('vocab_size: {}'.format(vocab_size))\n",
    "print('tokenizer_len: {}'.format(len(tokenizer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab8dc487-a740-4188-9525-2676e4078a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(152538, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=152538, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output_hidden_states = False # 기본은 False=>output 2개 출력됨, True로 지정하면 output이 3개 출력됨\n",
    "#return_dict = True   #False로 지정하는 경우 일반적인 tuple을 리턴, True인 경우는 transformers.file_utils.ModelOutput(ouput.logisc) 으로 리턴\n",
    "#model = BertModel.from_pretrained(input_model_path, output_hidden_states = output_hidden_states, return_dict = return_dict)\n",
    "\n",
    "\n",
    "# AutoModelForMaskedLM, BertForMaskedLM \n",
    "# further pre-training 인 경우 (기존 거에 추가적으로 하는 경우)\n",
    "config = BertConfig.from_pretrained(input_model_path)\n",
    "model = BertForMaskedLM.from_pretrained(input_model_path, from_tf=bool(\".ckpt\" in input_model_path), config=config)\n",
    "\n",
    "# 모델 embedding 사이즈를 tokenizer +1 크기 만큼 재 설정함.\n",
    "# => 원래 크기를 tokenizer 사이즈 만큼만 설정하면되는데, kobert는 8002로 평가하면, 오류발생하므로 +1 정도 크게 설정함\n",
    "model.resize_token_embeddings(len(tokenizer) + 1)\n",
    "model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73bf3af8-5592-44f4-8a3a-cc2700587606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203344602"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6321b2d-2517-4820-8c12-79ba7e2a0a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-91bccccf01bee1c6\n",
      "Reusing dataset text (/MOCOMSYS/.cache/huggingface/datasets/text/default-91bccccf01bee1c6/0.0.0/08f6fb1dd2dab0a18ea441c359e1d63794ea8cb53e7863e6edf8fc5655e47ec4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_dataset========================================\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 1500\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#==================================================================================================\n",
    "# load_dataset을 이용하여, 훈련/평가 dataset 로딩.\n",
    "#\n",
    "# [로컬 데이터 파일 로딩]\n",
    "# => dataset = load_dataset(\"text\", data_files='로컬.txt')       # text 로컬 파일 로딩\n",
    "# => dataset = load_dataset(\"csv\", data_files='로컬.csv')        # csv 로컬 파일 로딩\n",
    "# => dataset = load_dataset(\"csv\", data_files='로컬.tsv', delimiter=\"\\t\")  # tsv 로컬 파일 로딩\n",
    "# => dataset = load_dataset(\"json\", data_files='로컬.json')      # json 로컬 파일 로딩\n",
    "# => dataset = load_dataset(\"pandas\", data_files='로컬.pkl')     # pickled dataframe 로컬 파일 로딩\n",
    "#\n",
    "# [원격 데이터 파일 로딩]\n",
    "# url = \"https://github.com/crux82/squad-it/raw/master/\"\n",
    "# data_files = {\n",
    "#    \"train\": url + \"SQuAD_it-train.json.gz\",\n",
    "#    \"test\": url + \"SQuAD_it-test.json.gz\",\n",
    "# }\n",
    "# squad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")\n",
    "#\n",
    "# 출처 : https://wikidocs.net/166816\n",
    "#==================================================================================================\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 평가 말뭉치 로딩\n",
    "#train_dataset = load_dataset(input_corpus)\n",
    "eval_dataset = load_dataset(\"text\", data_files=input_corpus, split=\"train\") # text 로컬 파일 로딩\n",
    "\n",
    "# eval_dataset 출력해봄\n",
    "print(f\"eval_dataset========================================\")\n",
    "print(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e719b1d8-20eb-4c50-b8eb-7dd326bbd352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_dataset========================================\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 1500\n",
      "})\n",
      "['공공지원 민간임대주택은 주변 시세의 95  이하의 저렴한 임대료 혜택 외에도 품질좋은 주택에서 8년간 안심하고 살 수 있는 장점이 있다 ', '위기아동 발생을 미리 예방할 수 있는 지원활동이나 인프라 구축보다는 피해아동이 발생했을 때 그때그때 대처하는 방식에서 벗어나지 못하고 있다는 것이다 ', '여야가 각종 현안마다 정치적 타협을 모색하는 대신 검찰과 법원을 찾아 상대를 처벌해 달라고 독촉하는  정치의 사법화 가 극심해지고 있다는 지적이다 ']\n"
     ]
    }
   ],
   "source": [
    "# eval_dataset 출력해봄\n",
    "print(f\"eval_dataset========================================\")\n",
    "print(eval_dataset)\n",
    "print(eval_dataset['text'][0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5f7abda-249d-4210-b14a-679827ea2326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /MOCOMSYS/.cache/huggingface/datasets/text/default-91bccccf01bee1c6/0.0.0/08f6fb1dd2dab0a18ea441c359e1d63794ea8cb53e7863e6edf8fc5655e47ec4/cache-d6811f5a8acb686f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.2 ms, sys: 6.36 ms, total: 54.6 ms\n",
      "Wall time: 52.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n%time tokenized_dataset = text_dataset.map(tokenizer_function, batched=False)\\nprint(tokenized_dataset_fast['train']['text'][0:2])\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer 처리\n",
    "def tokenizer_function(examples):\n",
    "    result =  tokenizer(examples['text'], truncation=True, max_length=token_max_len, return_overflowing_tokens=True)\n",
    "    \n",
    "    # 신규 인덱스와 이전 인덱스와의 매핑 추출\n",
    "    sample_map = result.pop(\"overflow_to_sample_mapping\")\n",
    "    for key, values in examples.items():\n",
    "        result[key] = [values[i] for i in sample_map]\n",
    "    return result\n",
    "\n",
    "\n",
    "# batched=True 하면 빠른 tokenizer 이용(Rust)\n",
    "%time eval_dataset_fast = eval_dataset.map(tokenizer_function, batched=True)\n",
    "\n",
    "'''\n",
    "%time tokenized_dataset = text_dataset.map(tokenizer_function, batched=False)\n",
    "print(tokenized_dataset_fast['train']['text'][0:2])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cf08241-8bed-442b-9e5a-d4756331f7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_dataset_fast=======================================\n",
      "Dataset({\n",
      "    features: ['text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 1500\n",
      "})\n",
      "*fast_len:1500, len:1500\n",
      "{'text': ['공공지원 민간임대주택은 주변 시세의 95  이하의 저렴한 임대료 혜택 외에도 품질좋은 주택에서 8년간 안심하고 살 수 있는 장점이 있다 ', '위기아동 발생을 미리 예방할 수 있는 지원활동이나 인프라 구축보다는 피해아동이 발생했을 때 그때그때 대처하는 방식에서 벗어나지 못하고 있다는 것이다 '], 'input_ids': [[101, 120673, 120141, 121218, 151323, 125141, 10892, 120118, 136752, 10459, 11978, 121775, 10459, 125634, 11102, 142626, 125037, 9597, 35979, 120363, 119214, 10892, 122174, 11489, 129, 10954, 18784, 132432, 12453, 9408, 9460, 13767, 121850, 10739, 11506, 102], [101, 120839, 134836, 119574, 10622, 121162, 121857, 14843, 9460, 13767, 119577, 120530, 43739, 121103, 119647, 80001, 11018, 120125, 134836, 10739, 119574, 119424, 10622, 9137, 121927, 142642, 122805, 12178, 119640, 11489, 121768, 12508, 9290, 12453, 77324, 24190, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(f\"eval_dataset_fast=======================================\")\n",
    "print(eval_dataset_fast)\n",
    "print(f'*fast_len:{len(eval_dataset_fast)}, len:{len(eval_dataset)}')  # fast_dataset과 dataset 길이를 비교함\n",
    "print(eval_dataset_fast[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0716b5dd-7a0d-4830-b7b5-25af92fdf78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_dataset_fast(MLM)=======================================\n",
      "tensor([   101, 120673, 120141, 121218, 151323, 125141,  10892,    103,    103,\n",
      "         10459,  11978, 121775,  10459, 125634,  11102, 142626, 125037,   9597,\n",
      "         35979, 120363, 119214,  10892,    103,  11489,    129,  10954,    103,\n",
      "        132432,  12453,   9408,   9460,  13767, 121850,  10739,  11506,    102,\n",
      "             0])\n",
      "{'text': '공공지원 민간임대주택은 주변 시세의 95  이하의 저렴한 임대료 혜택 외에도 품질좋은 주택에서 8년간 안심하고 살 수 있는 장점이 있다 ', 'input_ids': [101, 120673, 120141, 121218, 151323, 125141, 10892, 120118, 136752, 10459, 11978, 121775, 10459, 125634, 11102, 142626, 125037, 9597, 35979, 120363, 119214, 10892, 122174, 11489, 129, 10954, 18784, 132432, 12453, 9408, 9460, 13767, 121850, 10739, 11506, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# MLM을 위한 DataCollatorForLangunageModeling 호출\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# input_ids에 대해 MLM 만들기\n",
    "data_collator = DataCollatorForLanguageModeling(    # [MASK] 를 씌우는 것은 저희가 구현하지 않아도 됩니다! :-)\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "# input_ids MLM 만들고 출력 해봄\n",
    "mlm_eval_sample = data_collator(eval_dataset_fast['input_ids'][0:2])\n",
    "\n",
    "print(f\"eval_dataset_fast(MLM)=======================================\")\n",
    "print(mlm_eval_sample['input_ids'][0])\n",
    "print(eval_dataset_fast[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f1a41e3-1a73-4b51-9d01-e37dad9ada32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_metric 사용을 위해서는 datasets, sklearn 패키지 설치해야함\n",
    "#!pip install datasets\n",
    "#!pip install sklearn\n",
    "\n",
    "# 참고 소스 : https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "def preprocess_logits_for_metrics1(logits, labels):\n",
    "    return logits.argmax(dim=-1)\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # preds have the same shape as the labels, after the argmax(-1) has been calculated\n",
    "    # by preprocess_logits_for_metrics\n",
    "    labels = labels.reshape(-1)\n",
    "    preds = preds.reshape(-1)\n",
    "    mask = labels != -100\n",
    "    labels = labels[mask]\n",
    "    preds = preds[mask]\n",
    "    return metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "184731d1-196f-4c01-a2f8-213263d7bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*no_cuda: False\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# cpu 사용이면 'no_cuda = True' 설정함.\n",
    "no_cuda = False\n",
    "if device == 'cpu':\n",
    "    no_cuda = True\n",
    "print(f'*no_cuda: {no_cuda}')\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    no_cuda = no_cuda,                      # GPU 사용  안함\n",
    "    output_dir=ouput_model_dir,\n",
    "    per_device_eval_batch_size=batch_size\n",
    "    #per_gpu_eval_batch_size=batch_size\n",
    ")\n",
    "\n",
    "\n",
    "eval_dataset_fast_input_ids = eval_dataset_fast['input_ids']\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,  #data\n",
    "    eval_dataset=eval_dataset_fast_input_ids,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c3acac3-01de-48c2-9176-43a4d54b8ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1500\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################################################################\n",
    "# 펄플렉서티(Perplexity, PPL) 로 성능 평가함 \n",
    "# => PPL은 선택할 수 있는 가능한 경우의 수를 의미하는 분기계수(branching factor)입니다. \n",
    "#   PPL은 이 언어 모델이 특정 시점에서 평균적으로 몇 개의 선택지를 가지고 고민하고 있는지를 의미합니다. \n",
    "#  가령, 언어 모델에 어떤 테스트 데이터을 주고 측정했더니 PPL이 10이 나왔다고 해봅시다. \n",
    "#  그렇다면 해당 언어 모델은 테스트 데이터에 대해서 다음 단어를 예측하는 모든 시점(time step)마다 \n",
    "#  평균 10개의 단어를 가지고 어떤 것이 정답인지 고민하고 있다고 볼 수 있습니다. \n",
    "#  같은 테스트 데이터에 대해서 두 언어 모델의 PPL을 각각 계산 후에 PPL의 값을 비교하면, \n",
    "#  두 언어 모델 중 PPL이 더 낮은 언어 모델의 성능이 더 좋다고 볼 수 있습니다.\n",
    "###################################################################\n",
    "eval_output = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb86528d-8350-4328-acdb-2158d259ab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 13:30:22,357 - bertperplexityeval - INFO - ***** Eval results *****\n",
      "2022-09-13 13:30:22,359 - bertperplexityeval - INFO - ../../data11/model/bert/mbertV2.0:  perplexity = 19.781589884565754\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "# Evaluation\n",
    "results = {}\n",
    "\n",
    "perplexity = math.exp(eval_output[\"eval_loss\"])\n",
    "result = {\"perplexity\": perplexity}\n",
    "\n",
    "output_eval_file = os.path.join(ouput_model_dir, \"eval_results_lm.txt\")\n",
    "with open(output_eval_file, \"w\") as writer:\n",
    "    logger.info(\"***** Eval results *****\")\n",
    "    for key in sorted(result.keys()):\n",
    "        logger.info(\"%s:  %s = %s\", input_model_path, key, str(result[key]))\n",
    "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "results.update(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2278c226-29d2-42b8-afa0-d192f1e296fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 13 13:30:22 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A30          Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    44W / 165W |  14071MiB / 24258MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    169804      C   ...nda3/envs/bong/bin/python     7573MiB |\n",
      "|    0   N/A  N/A    172797      C   ...nda3/envs/bong/bin/python     6495MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# OUT OF MEMORY 에러면 GPU 사용량 체크\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2960bfc-b612-4466-8180-fffef5e5e1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
