{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f1e4a-09f6-4253-b1ae-4cc9193711f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참고 사이트 \n",
    "# 참고소스1 : transformers huggingface mlm 사전 학습 예제\n",
    "#   - https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
    "#\n",
    "# 참고소스2  : bert를 가지고 중국어 corpus로 추가학습시킨 예제\n",
    "#    - https://github.com/zhusleep/pytorch_chinese_lm_pretrain 에 run_language_model_bert.py \n",
    "#      https://www.fatalerrors.org/a/further-pre-training-of-chinese-language-model-bert-roberta.html\n",
    "\n",
    "import transformers\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from myutils import seed_everything, TextDatasetForNextSentencePrediction, GPU_info, mlogging, MyTextDataset\n",
    "from transformers import BertTokenizer, BertModel, BertTokenizerFast, BertConfig, AutoModelWithLMHead, BertForMaskedLM\n",
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0267fd3e-7443-43a2-83ae-ff3ccbb9dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = GPU_info()\n",
    "print(device)\n",
    "\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "#seed 설정\n",
    "seed_everything(111)\n",
    "\n",
    "#logging 설정\n",
    "logger=mlogging(loggername=\"bertperplexityeval\", logfilname=\"bertperplexityeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a70767-9737-4081-8664-c8291f0289cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수들 설정\n",
    "#input_corpus = \"Korpora/kowikitext/kowikitext_20200920.test\"\n",
    "input_corpus = \"Korpora/nsmc/ratings_test.txt\"\n",
    "\n",
    "\n",
    "input_model_path = \"model/kobertmodel\"\n",
    "vocab_file=\"model/kobertmodel/vocab/vocab.txt\"\n",
    "ouput_model_dir = \"model/kobertmodel\"\n",
    "\n",
    "'''\n",
    "input_model_path = \"model/bert-multilingual-cased\"\n",
    "vocab_file=\"model/bert-multilingual-cased/vocab/vocab.txt\"\n",
    "ouput_model_dir = \"model/bert-multilingual-cased\"\n",
    "'''\n",
    "'''\n",
    "input_model_path = \"model/bert-multilingual-cased_furter_pt_model_0216\"\n",
    "vocab_file=\"model/bert-multilingual-cased_furter_pt_model_0216/vocab/vocab.txt\"\n",
    "ouput_model_dir = \"model/bert-multilingual-cased_furter_pt_model_0216\"\n",
    "'''\n",
    "# 토큰활 할때 최대 길이 \n",
    "token_max_len = 126\n",
    "\n",
    "# 훈련용 변수\n",
    "batch_size = 8   # 128로 하면, GPU Out of memory 발생함(=>**따라서 64로 진행)\n",
    "train_epochs = 10\n",
    " # embedding size 최대 몇 token까지 input으로 사용할 것인지 지정(기본:512) 512, 1024, 2048 식으로 지정함, 엄청난 장문을 다룰경우 10124까지\n",
    "max_position_embeddings = 256 \n",
    "logging_steps = 1  # 훈련시, 로깅할 step 수 (크면 10000번 정도하고, 작으면 100번정도)\n",
    "save_steps = 1     # 10000 step마다 모델 저장\n",
    "save_total_limit = 1 # 마지막 3개 모델 빼고 과거 모델은 삭제(100000번째마다 모델 저장하는데, 마지감 3개 빼고 나머지는 삭제)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1417fe82-bcd5-4431-a7fd-2c7691008a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer 생성\n",
    "# => BertTokenizer, BertTokenizerFast 둘중 사용하면됨\n",
    "tokenizer = BertTokenizer(vocab_file=vocab_file, \n",
    "                          max_len=token_max_len, \n",
    "                          do_lower_case=False)\n",
    "\n",
    "'''\n",
    "#tokenizer = BertTokenizerFast(vocab_speical_path)\n",
    "tokenizer = BertTokenizerFast(\n",
    "    vocab_file=vocab_file,\n",
    "    max_len=token_max_len,\n",
    "    do_lower_case=False,\n",
    "    )\n",
    "'''    \n",
    "\n",
    "# speical 토큰 계수 + vocab 계수 - 이미 vocab에 포함된 speical 토큰 계수(5)\n",
    "vocab_size = len(tokenizer.all_special_tokens) + tokenizer.vocab_size - 5 + 1\n",
    "#vocab_size = len(tokenizer.all_special_tokens) + tokenizer.vocab_size - 5\n",
    "print('special_token_size: {}, tokenizer.vocab_size: {}'.format(len(tokenizer.all_special_tokens), tokenizer.vocab_size))\n",
    "print('vocab_size: {}'.format(vocab_size))\n",
    "print('tokenizer_len: {}'.format(len(tokenizer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8dc487-a740-4188-9525-2676e4078a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_hidden_states = False # 기본은 False=>output 2개 출력됨, True로 지정하면 output이 3개 출력됨\n",
    "#return_dict = True   #False로 지정하는 경우 일반적인 tuple을 리턴, True인 경우는 transformers.file_utils.ModelOutput(ouput.logisc) 으로 리턴\n",
    "#model = BertModel.from_pretrained(input_model_path, output_hidden_states = output_hidden_states, return_dict = return_dict)\n",
    "\n",
    "\n",
    "# AutoModelForMaskedLM, BertForMaskedLM \n",
    "# further pre-training 인 경우 (기존 거에 추가적으로 하는 경우)\n",
    "config = BertConfig.from_pretrained(input_model_path)\n",
    "model = BertForMaskedLM.from_pretrained(input_model_path, from_tf=bool(\".ckpt\" in input_model_path), config=config)\n",
    "\n",
    "# 모델 embedding 사이즈를 tokenizer +1 크기 만큼 재 설정함.\n",
    "# => 원래 크기를 tokenizer 사이즈 만큼만 설정하면되는데, kobert는 8002로 평가하면, 오류발생하므로 +1 정도 크게 설정함\n",
    "model.resize_token_embeddings(len(tokenizer) + 1)\n",
    "model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf3af8-5592-44f4-8a3a-cc2700587606",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6321b2d-2517-4820-8c12-79ba7e2a0a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = MyTextDataset(tokenizer=tokenizer, \n",
    "                            file_path=input_corpus, \n",
    "                            block_size=token_max_len, \n",
    "                            overwrite_cache=False,\n",
    "                            show_num=3)\n",
    "\n",
    "#혹은\n",
    "#eval_dataset = MyLineByLineTextDataset(tokenizer=tokenizer, file_path=input_corpus, block_size=token_max_len, show_format_dict=False,show_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0716b5dd-7a0d-4830-b7b5-25af92fdf78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLM 만들기\n",
    "data_collator = DataCollatorForLanguageModeling(    # [MASK] 를 씌우는 것은 저희가 구현하지 않아도 됩니다! :-)\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "# MLM 출력 해보기\n",
    "print(data_collator(eval_dataset.examples[0:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a41e3-1a73-4b51-9d01-e37dad9ada32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_metric 사용을 위해서는 datasets, sklearn 패키지 설치해야함\n",
    "#!pip install datasets\n",
    "#!pip install sklearn\n",
    "\n",
    "# 참고 소스 : https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "def preprocess_logits_for_metrics1(logits, labels):\n",
    "    return logits.argmax(dim=-1)\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # preds have the same shape as the labels, after the argmax(-1) has been calculated\n",
    "    # by preprocess_logits_for_metrics\n",
    "    labels = labels.reshape(-1)\n",
    "    preds = preds.reshape(-1)\n",
    "    mask = labels != -100\n",
    "    labels = labels[mask]\n",
    "    preds = preds[mask]\n",
    "    return metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184731d1-196f-4c01-a2f8-213263d7bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=ouput_model_dir,\n",
    "    per_device_eval_batch_size=batch_size\n",
    "    #per_gpu_eval_batch_size=batch_size\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,  #data\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    "    #preprocess_logits_for_metrics=preprocess_logits_for_metrics1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3acac3-01de-48c2-9176-43a4d54b8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# 펄플렉서티(Perplexity, PPL) 로 성능 평가함 \n",
    "# => PPL은 선택할 수 있는 가능한 경우의 수를 의미하는 분기계수(branching factor)입니다. \n",
    "#   PPL은 이 언어 모델이 특정 시점에서 평균적으로 몇 개의 선택지를 가지고 고민하고 있는지를 의미합니다. \n",
    "#  가령, 언어 모델에 어떤 테스트 데이터을 주고 측정했더니 PPL이 10이 나왔다고 해봅시다. \n",
    "#  그렇다면 해당 언어 모델은 테스트 데이터에 대해서 다음 단어를 예측하는 모든 시점(time step)마다 \n",
    "#  평균 10개의 단어를 가지고 어떤 것이 정답인지 고민하고 있다고 볼 수 있습니다. \n",
    "#  같은 테스트 데이터에 대해서 두 언어 모델의 PPL을 각각 계산 후에 PPL의 값을 비교하면, \n",
    "#  두 언어 모델 중 PPL이 더 낮은 언어 모델의 성능이 더 좋다고 볼 수 있습니다.\n",
    "###################################################################\n",
    "eval_output = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb86528d-8350-4328-acdb-2158d259ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "# Evaluation\n",
    "results = {}\n",
    "\n",
    "perplexity = math.exp(eval_output[\"eval_loss\"])\n",
    "result = {\"perplexity\": perplexity}\n",
    "\n",
    "output_eval_file = os.path.join(ouput_model_dir, \"eval_results_lm.txt\")\n",
    "with open(output_eval_file, \"w\") as writer:\n",
    "    logger.info(\"***** Eval results *****\")\n",
    "    for key in sorted(result.keys()):\n",
    "        logger.info(\"%s:  %s = %s\", input_model_path, key, str(result[key]))\n",
    "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "results.update(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2278c226-29d2-42b8-afa0-d192f1e296fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 17 17:59:59 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A30          Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    29W / 165W |      0MiB / 24258MiB |     14%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# OUT OF MEMORY 에러면 GPU 사용량 체크\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2960bfc-b612-4466-8180-fffef5e5e1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
