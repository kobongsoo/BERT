{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "159bc54e-0c70-4cc7-b3ff-cb2b3683cbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:bertftmultitrain_2022-03-28.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "# NLI(Natural Language Interference:자연어 추론) 훈련 예제\n",
    "#\n",
    "# => input_ids : [CLS]senetence1(전제)[SEP]sentence2(가설)\n",
    "# => attention_mask : 1111111111(전체,가설)0000000(그외)\n",
    "# => token_type_ids : 0000000(전제)1111111(가설)00000000(그외)\n",
    "# => laels : 참(수반:entailment), 거짓(모순:contradiction), 모름(중립:neutral)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "import torch.nn.functional as F\n",
    "from os import sys\n",
    "sys.path.append('..')\n",
    "from myutils import seed_everything, GPU_info, mlogging\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "logger = mlogging(loggername=\"bertfttrain\", logfilename=\"bertftmultitrain\")\n",
    "device = GPU_info()\n",
    "seed_everything(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "731f6745-a2f4-4b2d-9a19-1fa2efa6f3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at model/bert/bmc-fpt-wiki_20190620_mecab_false_0311-nouns-0327/ were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at model/bert/bmc-fpt-wiki_20190620_mecab_false_0311-nouns-0327/ and are newly initialized: ['classifier.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(167550, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################################\n",
    "# 변수들 설정\n",
    "# - model_path : from_pretrained() 로 호출하는 경우에는 모델파일이 있는 폴더 경로나 \n",
    "#          huggingface에 등록된 모델명(예:'bert-base-multilingual-cased')\n",
    "#          torch.load(model)로 로딩하는 경우에는 모델 파일 풀 경로\n",
    "#\n",
    "# - vocab_path : from_pretrained() 호출하는 경우에는 모델파일이 있는 폴더 경로나\n",
    "#          huggingface에 등록된 모델명(예:'bert-base-multilingual-cased')   \n",
    "#          BertTokenizer() 로 호출하는 경우에는 vocab.txt 파일 풀 경로,\n",
    "#\n",
    "# - OUTPATH : 출력 모델, vocab 저장할 폴더 경로\n",
    "#############################################################################################\n",
    "\n",
    "model_path = 'model/bert/bmc-fpt-wiki_20190620_mecab_false_0311-nouns-0327/'\n",
    "vocab_path = 'model/bert/bmc-fpt-wiki_20190620_mecab_false_0311-nouns-0327/'\n",
    "OUTPATH = 'model/classification/bmc-fpt-wiki_20190620_mecab_false_0311-nouns-0327-ft-nli-0328/'\n",
    "\n",
    "# tokeniaer 및 model 설정\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# strip_accents=False : True로 하면, 가자 => ㄱ ㅏ ㅈ ㅏ 식으로 토큰화 되어 버림(*따라서 한국어에서는 반드시 False)\n",
    "# do_lower_case=False : # 소문자 입력 사용 안함(한국어에서는 반드시 False)\n",
    "#tokenizer = BertTokenizer(vocab_file=vocab_path, strip_accents=False, do_lower_case=False) \n",
    "tokenizer = BertTokenizer.from_pretrained(vocab_path, do_lower_case=False)\n",
    "\n",
    "# NLI 모델에서 레벨은 3개지(참,거짓,모름) 이므로, num_labels=3을 입력함\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=3)\n",
    "#model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=6)\n",
    "\n",
    "# 레벨을 멀티로 선택해야 하는 경우\n",
    "#model = BertForSequenceClassification.from_pretrained(model_path, problem_type=\"multi_label_classification\",num_labels=6)\n",
    "                   \n",
    "#기존 모델 파일을 로딩하는 경우    \n",
    "#model = torch.load(model_path) \n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "918a05d8-aee5-42df-9a1c-1dc2443f655d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214722051"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65d611fe-b906-45ee-afc2-dcbfcd760751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 15:58:32,911 - bwpdataset - INFO - Creating features from dataset file at korpora/klue-nli/klue-nli-v1.1_train.json\n",
      "2022-03-28 15:58:32,913 - bwpdataset - INFO - loading data... LOOKING AT korpora/klue-nli/klue-nli-v1.1_train.json\n",
      "2022-03-28 15:58:33,305 - bwpdataset - INFO - tokenize sentences, it could take a lot of time...\n",
      "2022-03-28 15:58:40,609 - bwpdataset - INFO - tokenize sentences [took 7.303 s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c696f832e1844f1ba221ad9bc091ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 15:58:40,674 - bwpdataset - INFO - *** Example ***\n",
      "2022-03-28 15:58:40,676 - bwpdataset - INFO - sentence A, B: 힛걸 진심 최고다 그 어떤 히어로보다 멋지다 + 힛걸 진심 최고로 멋지다.\n",
      "2022-03-28 15:58:40,676 - bwpdataset - INFO - tokens: [CLS] [UNK] 진심 최고 ##다 그 어떤 히어로 ##보다 멋 ##지 ##다 [SEP] [UNK] 진심 최고 ##로 멋 ##지 ##다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "2022-03-28 15:58:40,677 - bwpdataset - INFO - label: entailment\n",
      "2022-03-28 15:58:40,678 - bwpdataset - INFO - features: ClassificationFeatures(input_ids=[101, 100, 128087, 83491, 11903, 8924, 55910, 126825, 80001, 9270, 12508, 11903, 102, 100, 128087, 83491, 11261, 9270, 12508, 11903, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
      "2022-03-28 15:58:40,678 - bwpdataset - INFO - *** Example ***\n",
      "2022-03-28 15:58:40,679 - bwpdataset - INFO - sentence A, B: 100분간 잘껄 그래도 소닉붐땜에 2점준다 + 100분간 잤다.\n",
      "2022-03-28 15:58:40,679 - bwpdataset - INFO - tokens: [CLS] 100 ##분 ##간 [UNK] 그 ##래 ##도 [UNK] 2 ##점 ##준 ##다 [SEP] 100 ##분 ##간 [UNK] . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "2022-03-28 15:58:40,680 - bwpdataset - INFO - label: contradiction\n",
      "2022-03-28 15:58:40,681 - bwpdataset - INFO - features: ClassificationFeatures(input_ids=[101, 10407, 37712, 18784, 100, 8924, 37388, 12092, 100, 123, 34907, 54867, 11903, 102, 10407, 37712, 18784, 100, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "2022-03-28 15:58:40,682 - bwpdataset - INFO - Saving features into cached file, it could take a lot of time...\n",
      "2022-03-28 15:58:42,353 - bwpdataset - INFO - Saving features into cached file korpora/klue-nli/cached_BertTokenizer_128_klue-nli-v1.1_train.json [took 1.671 s]\n",
      "2022-03-28 15:58:42,442 - bwpdataset - INFO - Creating features from dataset file at korpora/klue-nli/klue-nli-v1.1_dev.json\n",
      "2022-03-28 15:58:42,444 - bwpdataset - INFO - loading data... LOOKING AT korpora/klue-nli/klue-nli-v1.1_dev.json\n",
      "2022-03-28 15:58:42,491 - bwpdataset - INFO - tokenize sentences, it could take a lot of time...\n",
      "2022-03-28 15:58:43,406 - bwpdataset - INFO - tokenize sentences [took 0.914 s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b809d8e2f4ef4c4cbb7ba6b95a887914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 15:58:43,432 - bwpdataset - INFO - *** Example ***\n",
      "2022-03-28 15:58:43,433 - bwpdataset - INFO - sentence A, B: 흡연자분들은 발코니가 있는 방이면 발코니에서 흡연이 가능합니다. + 어떤 방에서도 흡연은 금지됩니다.\n",
      "2022-03-28 15:58:43,434 - bwpdataset - INFO - tokens: [CLS] 흡연자 ##분 ##들은 발코니 ##가 있는 방이 ##면 발코니 ##에서 흡연 ##이 가능 ##합 ##니다 . [SEP] 어떤 방 ##에서 ##도 흡연 ##은 [UNK] . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "2022-03-28 15:58:43,435 - bwpdataset - INFO - label: contradiction\n",
      "2022-03-28 15:58:43,435 - bwpdataset - INFO - features: ClassificationFeatures(input_ids=[101, 163750, 37712, 22879, 145028, 11287, 13767, 134085, 14867, 145028, 11489, 128650, 10739, 119558, 33188, 48345, 119, 102, 55910, 9328, 11489, 12092, 128650, 10892, 100, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "2022-03-28 15:58:43,436 - bwpdataset - INFO - *** Example ***\n",
      "2022-03-28 15:58:43,437 - bwpdataset - INFO - sentence A, B: 10명이 함께 사용하기 불편함없이 만족했다. + 10명이 함께 사용하기 불편함이 많았다.\n",
      "2022-03-28 15:58:43,437 - bwpdataset - INFO - tokens: [CLS] 10 ##명이 함께 사용 ##하기 불편 ##함 ##없 ##이 만족 ##했다 . [SEP] 10 ##명이 함께 사용 ##하기 불편 ##함 ##이 많 ##았다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "2022-03-28 15:58:43,438 - bwpdataset - INFO - label: contradiction\n",
      "2022-03-28 15:58:43,438 - bwpdataset - INFO - features: ClassificationFeatures(input_ids=[101, 10150, 66923, 19653, 119547, 22440, 122667, 48533, 119136, 10739, 120231, 12490, 119, 102, 10150, 66923, 19653, 119547, 22440, 122667, 48533, 10739, 9249, 27303, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "2022-03-28 15:58:43,439 - bwpdataset - INFO - Saving features into cached file, it could take a lot of time...\n",
      "2022-03-28 15:58:43,649 - bwpdataset - INFO - Saving features into cached file korpora/klue-nli/cached_BertTokenizer_128_klue-nli-v1.1_dev.json [took 0.210 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader_len: 1563, eval_loader_len: 188\n"
     ]
    }
   ],
   "source": [
    "# 학습 data loader 생성\n",
    "sys.path.append('..')\n",
    "from myutils import ClassificationDataset, KlueNLICorpus, data_collator\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "#############################################################################\n",
    "# 변수 설정\n",
    "#############################################################################\n",
    "max_seq_len = 128   # 글자 최대 토큰 길이 해당 토큰 길이 이상은 잘린다.\n",
    "batch_size = 16        # 배치 사이즈(64면 GUP Memory 오류 나므로, 32 이하로 설정할것=>max_seq_length 를 줄이면, 64도 가능함)\n",
    "\n",
    "# 훈련할 csv 파일\n",
    "file_fpath = 'korpora/klue-nli/klue-nli-v1.1_train.json'\n",
    "#file_fpath = 'Korpora/nsmc/ratings_train.txt'\n",
    "cache = True   # 캐쉬파일 생성할거면 True로 (True이면 loding할때 캐쉬파일있어도 이용안함)\n",
    "#############################################################################\n",
    "\n",
    "# corpus 파일 설정\n",
    "corpus = KlueNLICorpus()\n",
    "\n",
    "# 학습 dataset 생성\n",
    "dataset = ClassificationDataset(file_fpath=file_fpath,max_seq_length=max_seq_len, tokenizer=tokenizer, corpus=corpus, overwrite_cache=cache)\n",
    "\n",
    "\n",
    "# 학습 dataloader 생성\n",
    "train_loader = DataLoader(dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          #shuffle=True, # dataset을 섞음\n",
    "                          sampler=RandomSampler(dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                          collate_fn=data_collator, # dataset을 tensor로 변환(예시 {'input_ids':tensor[0,1,2,3,1,], 'token_type_id:tensor[0,0,0,0,0], 'attention_mask:tensor[1,1,1,1,1], 'labels':tensor[5]}\n",
    "                          num_workers=4)\n",
    "\n",
    "# 평가 dataset 생성\n",
    "file_fpath = 'korpora/klue-nli/klue-nli-v1.1_dev.json'\n",
    "dataset = ClassificationDataset(file_fpath=file_fpath, max_seq_length=max_seq_len, tokenizer=tokenizer, corpus=corpus, overwrite_cache=cache)\n",
    "\n",
    "# 평가 dataloader 생성\n",
    "eval_loader = DataLoader(dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          #shuffle=True, # dataset을 섞음\n",
    "                          sampler=RandomSampler(dataset, replacement=False), #dataset을 랜덤하게 샘플링함\n",
    "                          collate_fn=data_collator, # dataset을 tensor로 변환(예시 {'input_ids':tensor[0,1,2,3,1,], 'token_type_id:tensor[0,0,0,0,0], 'attention_mask:tensor[1,1,1,1,1], 'labels':tensor[5]}\n",
    "                          num_workers=4)\n",
    "\n",
    "print('train_loader_len: {}, eval_loader_len: {}'.format(len(train_loader), len(eval_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fec919e-d8b7-4b20-a20b-28cf66a49a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167550\n",
      "[101, 9034, 10530, 124997, 11018, 125215, 10739, 69708, 42428, 10459, 10020, 129937, 10892, 132489, 12508, 49137, 102, 9670, 89523, 125551, 76820, 102]\n",
      "최치원\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# tokenier 테스트\n",
    "print(len(tokenizer))\n",
    "print(tokenizer.encode(\"눈에 보이는 반전이었지만 영화의 흡인력은 사라지지 않았다\", \"정말 재미있다\"))\n",
    "print(tokenizer.convert_ids_to_tokens(131027))\n",
    "print(tokenizer.convert_tokens_to_ids('정말'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2068553-5650-47a4-bdd6-c9e79e1580cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:01:24,330 - bertfttrain - INFO - === model: model/bert/bmc-fpt-wiki_20190620_mecab_false_0311-nouns-0327/ ===\n",
      "2022-03-28 16:01:24,335 - bertfttrain - INFO - num_parameters: 214722051\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f9bc16229341fab2050764d476b4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba4454f9b5d48ceb0385ce840896547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23523/2764082033.py:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred = torch.argmax(F.softmax(logits), dim=1)\n",
      "2022-03-28 16:01:48,194 - bertfttrain - INFO - [Epoch 1/10] Iteration 200 -> Train Loss: 1.1005, Train Accuracy: 0.349\n",
      "2022-03-28 16:02:10,433 - bertfttrain - INFO - [Epoch 1/10] Iteration 400 -> Train Loss: 1.0979, Train Accuracy: 0.357\n",
      "2022-03-28 16:02:34,086 - bertfttrain - INFO - [Epoch 1/10] Iteration 600 -> Train Loss: 0.9981, Train Accuracy: 0.505\n",
      "2022-03-28 16:02:59,270 - bertfttrain - INFO - [Epoch 1/10] Iteration 800 -> Train Loss: 0.8528, Train Accuracy: 0.628\n",
      "2022-03-28 16:03:22,605 - bertfttrain - INFO - [Epoch 1/10] Iteration 1000 -> Train Loss: 0.8359, Train Accuracy: 0.639\n",
      "2022-03-28 16:03:45,135 - bertfttrain - INFO - [Epoch 1/10] Iteration 1200 -> Train Loss: 0.8074, Train Accuracy: 0.653\n",
      "2022-03-28 16:04:07,575 - bertfttrain - INFO - [Epoch 1/10] Iteration 1400 -> Train Loss: 0.7564, Train Accuracy: 0.687\n",
      "2022-03-28 16:04:26,416 - bertfttrain - INFO - ---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5f58aba29f46a7bb96d726af114c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23523/2764082033.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred = torch.argmax(F.softmax(logits), dim=1)\n",
      "2022-03-28 16:04:30,701 - bertfttrain - INFO - [Epoch 1/10] Validatation Accuracy:0.6316666666666667\n",
      "2022-03-28 16:04:30,703 - bertfttrain - INFO - ---------------------------------------------------------\n",
      "2022-03-28 16:04:30,703 - bertfttrain - INFO - === 처리시간: 4.287 초 ===\n",
      "2022-03-28 16:04:30,704 - bertfttrain - INFO - -END-\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7fb35510136489a936d086bb8fa4dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:04:35,555 - bertfttrain - INFO - [Epoch 2/10] Iteration 1600 -> Train Loss: 0.7385, Train Accuracy: 0.691\n",
      "2022-03-28 16:05:01,881 - bertfttrain - INFO - [Epoch 2/10] Iteration 1800 -> Train Loss: 0.6702, Train Accuracy: 0.723\n",
      "2022-03-28 16:05:24,411 - bertfttrain - INFO - [Epoch 2/10] Iteration 2000 -> Train Loss: 0.6418, Train Accuracy: 0.743\n",
      "2022-03-28 16:05:46,931 - bertfttrain - INFO - [Epoch 2/10] Iteration 2200 -> Train Loss: 0.6477, Train Accuracy: 0.734\n",
      "2022-03-28 16:06:09,506 - bertfttrain - INFO - [Epoch 2/10] Iteration 2400 -> Train Loss: 0.6134, Train Accuracy: 0.758\n",
      "2022-03-28 16:06:31,939 - bertfttrain - INFO - [Epoch 2/10] Iteration 2600 -> Train Loss: 0.6222, Train Accuracy: 0.746\n",
      "2022-03-28 16:06:54,490 - bertfttrain - INFO - [Epoch 2/10] Iteration 2800 -> Train Loss: 0.6210, Train Accuracy: 0.753\n",
      "2022-03-28 16:07:17,030 - bertfttrain - INFO - [Epoch 2/10] Iteration 3000 -> Train Loss: 0.5949, Train Accuracy: 0.764\n",
      "2022-03-28 16:07:31,420 - bertfttrain - INFO - ---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88dc648d7247494381d03ec044779804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:07:35,588 - bertfttrain - INFO - [Epoch 2/10] Validatation Accuracy:0.6923333333333334\n",
      "2022-03-28 16:07:35,590 - bertfttrain - INFO - ---------------------------------------------------------\n",
      "2022-03-28 16:07:35,591 - bertfttrain - INFO - === 처리시간: 4.171 초 ===\n",
      "2022-03-28 16:07:35,592 - bertfttrain - INFO - -END-\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd9879977dc4657bb2a26fd4563b90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:07:44,313 - bertfttrain - INFO - [Epoch 3/10] Iteration 3200 -> Train Loss: 0.5570, Train Accuracy: 0.782\n",
      "2022-03-28 16:08:06,851 - bertfttrain - INFO - [Epoch 3/10] Iteration 3400 -> Train Loss: 0.4135, Train Accuracy: 0.844\n",
      "2022-03-28 16:08:29,270 - bertfttrain - INFO - [Epoch 3/10] Iteration 3600 -> Train Loss: 0.4531, Train Accuracy: 0.826\n",
      "2022-03-28 16:08:51,773 - bertfttrain - INFO - [Epoch 3/10] Iteration 3800 -> Train Loss: 0.4362, Train Accuracy: 0.840\n",
      "2022-03-28 16:09:16,939 - bertfttrain - INFO - [Epoch 3/10] Iteration 4000 -> Train Loss: 0.4425, Train Accuracy: 0.835\n",
      "2022-03-28 16:09:39,405 - bertfttrain - INFO - [Epoch 3/10] Iteration 4200 -> Train Loss: 0.4075, Train Accuracy: 0.851\n",
      "2022-03-28 16:10:01,961 - bertfttrain - INFO - [Epoch 3/10] Iteration 4400 -> Train Loss: 0.4313, Train Accuracy: 0.842\n",
      "2022-03-28 16:10:24,534 - bertfttrain - INFO - [Epoch 3/10] Iteration 4600 -> Train Loss: 0.4210, Train Accuracy: 0.837\n",
      "2022-03-28 16:10:34,778 - bertfttrain - INFO - ---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6736d3025fa84439a945d08ec662bd0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:10:38,975 - bertfttrain - INFO - [Epoch 3/10] Validatation Accuracy:0.6986666666666667\n",
      "2022-03-28 16:10:38,977 - bertfttrain - INFO - ---------------------------------------------------------\n",
      "2022-03-28 16:10:38,978 - bertfttrain - INFO - === 처리시간: 4.200 초 ===\n",
      "2022-03-28 16:10:38,979 - bertfttrain - INFO - -END-\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166bbacfd2034f0a85d966c803a6f9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:10:54,131 - bertfttrain - INFO - [Epoch 4/10] Iteration 4800 -> Train Loss: 0.3373, Train Accuracy: 0.879\n",
      "2022-03-28 16:11:17,772 - bertfttrain - INFO - [Epoch 4/10] Iteration 5000 -> Train Loss: 0.2693, Train Accuracy: 0.908\n",
      "2022-03-28 16:11:40,521 - bertfttrain - INFO - [Epoch 4/10] Iteration 5200 -> Train Loss: 0.2858, Train Accuracy: 0.898\n",
      "2022-03-28 16:12:03,052 - bertfttrain - INFO - [Epoch 4/10] Iteration 5400 -> Train Loss: 0.2988, Train Accuracy: 0.897\n",
      "2022-03-28 16:12:25,766 - bertfttrain - INFO - [Epoch 4/10] Iteration 5600 -> Train Loss: 0.3125, Train Accuracy: 0.893\n",
      "2022-03-28 16:12:52,218 - bertfttrain - INFO - [Epoch 4/10] Iteration 5800 -> Train Loss: 0.2747, Train Accuracy: 0.899\n",
      "2022-03-28 16:13:15,525 - bertfttrain - INFO - [Epoch 4/10] Iteration 6000 -> Train Loss: 0.2981, Train Accuracy: 0.897\n",
      "2022-03-28 16:13:38,206 - bertfttrain - INFO - [Epoch 4/10] Iteration 6200 -> Train Loss: 0.2908, Train Accuracy: 0.899\n",
      "2022-03-28 16:13:44,208 - bertfttrain - INFO - ---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d13172759f24266893c99616c52b93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:13:48,392 - bertfttrain - INFO - [Epoch 4/10] Validatation Accuracy:0.7106666666666667\n",
      "2022-03-28 16:13:48,393 - bertfttrain - INFO - ---------------------------------------------------------\n",
      "2022-03-28 16:13:48,394 - bertfttrain - INFO - === 처리시간: 4.186 초 ===\n",
      "2022-03-28 16:13:48,394 - bertfttrain - INFO - -END-\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7f61da71d64140a8b47e453b3fba6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:14:05,305 - bertfttrain - INFO - [Epoch 5/10] Iteration 6400 -> Train Loss: 0.2554, Train Accuracy: 0.913\n",
      "2022-03-28 16:14:29,623 - bertfttrain - INFO - [Epoch 5/10] Iteration 6600 -> Train Loss: 0.1911, Train Accuracy: 0.938\n",
      "2022-03-28 16:14:53,040 - bertfttrain - INFO - [Epoch 5/10] Iteration 6800 -> Train Loss: 0.2026, Train Accuracy: 0.941\n",
      "2022-03-28 16:15:15,479 - bertfttrain - INFO - [Epoch 5/10] Iteration 7000 -> Train Loss: 0.1990, Train Accuracy: 0.934\n",
      "2022-03-28 16:15:37,297 - bertfttrain - INFO - [Epoch 5/10] Iteration 7200 -> Train Loss: 0.2066, Train Accuracy: 0.938\n",
      "2022-03-28 16:16:02,904 - bertfttrain - INFO - [Epoch 5/10] Iteration 7400 -> Train Loss: 0.2090, Train Accuracy: 0.936\n",
      "2022-03-28 16:16:24,833 - bertfttrain - INFO - [Epoch 5/10] Iteration 7600 -> Train Loss: 0.2235, Train Accuracy: 0.927\n",
      "2022-03-28 16:16:47,534 - bertfttrain - INFO - [Epoch 5/10] Iteration 7800 -> Train Loss: 0.2150, Train Accuracy: 0.930\n",
      "2022-03-28 16:16:49,703 - bertfttrain - INFO - ---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40c70ab9cc944708c122a0f7ab85ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:16:53,896 - bertfttrain - INFO - [Epoch 5/10] Validatation Accuracy:0.7106666666666667\n",
      "2022-03-28 16:16:53,898 - bertfttrain - INFO - ---------------------------------------------------------\n",
      "2022-03-28 16:16:53,900 - bertfttrain - INFO - === 처리시간: 4.197 초 ===\n",
      "2022-03-28 16:16:53,901 - bertfttrain - INFO - -END-\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd10651ea0c4df0b05e6f32ad47818c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:17:16,055 - bertfttrain - INFO - [Epoch 6/10] Iteration 8000 -> Train Loss: 0.1311, Train Accuracy: 0.961\n",
      "2022-03-28 16:17:42,107 - bertfttrain - INFO - [Epoch 6/10] Iteration 8200 -> Train Loss: 0.1598, Train Accuracy: 0.958\n",
      "2022-03-28 16:18:06,305 - bertfttrain - INFO - [Epoch 6/10] Iteration 8400 -> Train Loss: 0.1363, Train Accuracy: 0.963\n",
      "2022-03-28 16:18:29,075 - bertfttrain - INFO - [Epoch 6/10] Iteration 8600 -> Train Loss: 0.1800, Train Accuracy: 0.954\n",
      "2022-03-28 16:18:51,306 - bertfttrain - INFO - [Epoch 6/10] Iteration 8800 -> Train Loss: 0.1913, Train Accuracy: 0.952\n",
      "2022-03-28 16:19:14,139 - bertfttrain - INFO - [Epoch 6/10] Iteration 9000 -> Train Loss: 0.1783, Train Accuracy: 0.953\n",
      "2022-03-28 16:19:37,234 - bertfttrain - INFO - [Epoch 6/10] Iteration 9200 -> Train Loss: 0.1612, Train Accuracy: 0.959\n",
      "2022-03-28 16:19:58,931 - bertfttrain - INFO - ---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a30042e70444609997b126fcb3b6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:20:03,141 - bertfttrain - INFO - [Epoch 6/10] Validatation Accuracy:0.7043333333333334\n",
      "2022-03-28 16:20:03,144 - bertfttrain - INFO - ---------------------------------------------------------\n",
      "2022-03-28 16:20:03,145 - bertfttrain - INFO - === 처리시간: 4.214 초 ===\n",
      "2022-03-28 16:20:03,146 - bertfttrain - INFO - -END-\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048cfed9a6d74606a4e27aab3ec02dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:20:05,972 - bertfttrain - INFO - [Epoch 7/10] Iteration 9400 -> Train Loss: 0.1784, Train Accuracy: 0.954\n",
      "2022-03-28 16:20:27,648 - bertfttrain - INFO - [Epoch 7/10] Iteration 9600 -> Train Loss: 0.1155, Train Accuracy: 0.972\n",
      "2022-03-28 16:20:50,147 - bertfttrain - INFO - [Epoch 7/10] Iteration 9800 -> Train Loss: 0.1282, Train Accuracy: 0.969\n",
      "2022-03-28 16:21:13,934 - bertfttrain - INFO - [Epoch 7/10] Iteration 10000 -> Train Loss: 0.0947, Train Accuracy: 0.974\n",
      "2022-03-28 16:21:33,994 - bertfttrain - INFO - [Epoch 7/10] Iteration 10200 -> Train Loss: 0.1371, Train Accuracy: 0.966\n",
      "2022-03-28 16:21:56,239 - bertfttrain - INFO - [Epoch 7/10] Iteration 10400 -> Train Loss: 0.1162, Train Accuracy: 0.971\n",
      "2022-03-28 16:22:18,440 - bertfttrain - INFO - [Epoch 7/10] Iteration 10600 -> Train Loss: 0.0887, Train Accuracy: 0.979\n",
      "2022-03-28 16:22:40,742 - bertfttrain - INFO - [Epoch 7/10] Iteration 10800 -> Train Loss: 0.1142, Train Accuracy: 0.972\n",
      "2022-03-28 16:22:56,610 - bertfttrain - INFO - ---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844635d007b84fbc8b82dc1bf677cb72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:23:00,882 - bertfttrain - INFO - [Epoch 7/10] Validatation Accuracy:0.7186666666666667\n",
      "2022-03-28 16:23:00,884 - bertfttrain - INFO - ---------------------------------------------------------\n",
      "2022-03-28 16:23:00,885 - bertfttrain - INFO - === 처리시간: 4.275 초 ===\n",
      "2022-03-28 16:23:00,885 - bertfttrain - INFO - -END-\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459e4f0c58d44c9eb922ec16ee1943e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:23:07,958 - bertfttrain - INFO - [Epoch 8/10] Iteration 11000 -> Train Loss: 0.1107, Train Accuracy: 0.971\n",
      "2022-03-28 16:23:30,722 - bertfttrain - INFO - [Epoch 8/10] Iteration 11200 -> Train Loss: 0.0693, Train Accuracy: 0.983\n",
      "2022-03-28 16:23:53,346 - bertfttrain - INFO - [Epoch 8/10] Iteration 11400 -> Train Loss: 0.0803, Train Accuracy: 0.981\n",
      "2022-03-28 16:24:16,490 - bertfttrain - INFO - [Epoch 8/10] Iteration 11600 -> Train Loss: 0.0876, Train Accuracy: 0.981\n",
      "2022-03-28 16:24:41,181 - bertfttrain - INFO - [Epoch 8/10] Iteration 11800 -> Train Loss: 0.0798, Train Accuracy: 0.981\n",
      "2022-03-28 16:25:04,095 - bertfttrain - INFO - [Epoch 8/10] Iteration 12000 -> Train Loss: 0.0874, Train Accuracy: 0.981\n",
      "2022-03-28 16:25:26,667 - bertfttrain - INFO - [Epoch 8/10] Iteration 12200 -> Train Loss: 0.0819, Train Accuracy: 0.982\n",
      "2022-03-28 16:25:49,354 - bertfttrain - INFO - [Epoch 8/10] Iteration 12400 -> Train Loss: 0.0929, Train Accuracy: 0.983\n",
      "2022-03-28 16:26:01,312 - bertfttrain - INFO - ---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e57c825b9d4c00aadf6e6d2226cd84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:26:05,583 - bertfttrain - INFO - [Epoch 8/10] Validatation Accuracy:0.715\n",
      "2022-03-28 16:26:05,585 - bertfttrain - INFO - ---------------------------------------------------------\n",
      "2022-03-28 16:26:05,586 - bertfttrain - INFO - === 처리시간: 4.274 초 ===\n",
      "2022-03-28 16:26:05,587 - bertfttrain - INFO - -END-\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fad482c5b24554b8677b88c4b90afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:26:16,866 - bertfttrain - INFO - [Epoch 9/10] Iteration 12600 -> Train Loss: 0.0647, Train Accuracy: 0.985\n",
      "2022-03-28 16:26:39,392 - bertfttrain - INFO - [Epoch 9/10] Iteration 12800 -> Train Loss: 0.0472, Train Accuracy: 0.989\n",
      "2022-03-28 16:27:01,734 - bertfttrain - INFO - [Epoch 9/10] Iteration 13000 -> Train Loss: 0.0613, Train Accuracy: 0.987\n",
      "2022-03-28 16:27:24,000 - bertfttrain - INFO - [Epoch 9/10] Iteration 13200 -> Train Loss: 0.0471, Train Accuracy: 0.989\n",
      "2022-03-28 16:27:46,413 - bertfttrain - INFO - [Epoch 9/10] Iteration 13400 -> Train Loss: 0.0736, Train Accuracy: 0.985\n",
      "2022-03-28 16:28:08,655 - bertfttrain - INFO - [Epoch 9/10] Iteration 13600 -> Train Loss: 0.0673, Train Accuracy: 0.985\n",
      "2022-03-28 16:28:31,024 - bertfttrain - INFO - [Epoch 9/10] Iteration 13800 -> Train Loss: 0.0821, Train Accuracy: 0.984\n",
      "2022-03-28 16:28:53,216 - bertfttrain - INFO - [Epoch 9/10] Iteration 14000 -> Train Loss: 0.0444, Train Accuracy: 0.989\n",
      "2022-03-28 16:29:00,883 - bertfttrain - INFO - ---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75b5bf3cfa044bfb5aa54a025c5e82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:29:05,157 - bertfttrain - INFO - [Epoch 9/10] Validatation Accuracy:0.7143333333333334\n",
      "2022-03-28 16:29:05,158 - bertfttrain - INFO - ---------------------------------------------------------\n",
      "2022-03-28 16:29:05,159 - bertfttrain - INFO - === 처리시간: 4.276 초 ===\n",
      "2022-03-28 16:29:05,165 - bertfttrain - INFO - -END-\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278dd912fc724fe2a3b6262bbe206974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:29:20,698 - bertfttrain - INFO - [Epoch 10/10] Iteration 14200 -> Train Loss: 0.0321, Train Accuracy: 0.993\n",
      "2022-03-28 16:29:43,226 - bertfttrain - INFO - [Epoch 10/10] Iteration 14400 -> Train Loss: 0.0398, Train Accuracy: 0.990\n",
      "2022-03-28 16:30:05,757 - bertfttrain - INFO - [Epoch 10/10] Iteration 14600 -> Train Loss: 0.0332, Train Accuracy: 0.990\n",
      "2022-03-28 16:30:28,278 - bertfttrain - INFO - [Epoch 10/10] Iteration 14800 -> Train Loss: 0.0376, Train Accuracy: 0.991\n",
      "2022-03-28 16:30:49,599 - bertfttrain - INFO - [Epoch 10/10] Iteration 15000 -> Train Loss: 0.0509, Train Accuracy: 0.989\n",
      "2022-03-28 16:31:12,066 - bertfttrain - INFO - [Epoch 10/10] Iteration 15200 -> Train Loss: 0.0430, Train Accuracy: 0.990\n",
      "2022-03-28 16:31:34,595 - bertfttrain - INFO - [Epoch 10/10] Iteration 15400 -> Train Loss: 0.0427, Train Accuracy: 0.990\n",
      "2022-03-28 16:31:56,973 - bertfttrain - INFO - [Epoch 10/10] Iteration 15600 -> Train Loss: 0.0213, Train Accuracy: 0.994\n",
      "2022-03-28 16:32:00,485 - bertfttrain - INFO - ---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8bd804dc2042b19dd79f7ecf28eb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:32:04,657 - bertfttrain - INFO - [Epoch 10/10] Validatation Accuracy:0.7206666666666667\n",
      "2022-03-28 16:32:04,659 - bertfttrain - INFO - ---------------------------------------------------------\n",
      "2022-03-28 16:32:04,660 - bertfttrain - INFO - === 처리시간: 4.176 초 ===\n",
      "2022-03-28 16:32:04,661 - bertfttrain - INFO - -END-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "import time\n",
    "\n",
    "logger.info(f\"=== model: {model_path} ===\")\n",
    "logger.info(f\"num_parameters: {model.num_parameters()}\")\n",
    "\n",
    "##################################################\n",
    "# 변수 설정\n",
    "##################################################\n",
    "epochs = 10            # epochs\n",
    "learning_rate = 2e-5  # 학습률\n",
    "p_itr = 200           # 손실률 보여줄 step 수\n",
    "##################################################\n",
    "\n",
    "# optimizer 적용\n",
    "optimizer = AdamW(model.parameters(), \n",
    "                 lr=learning_rate, \n",
    "                 eps=1e-8) # 0으로 나누는 것을 방지하기 위한 epsilon 값(10^-6 ~ 10^-8 사이 이값 입력합)\n",
    "\n",
    "# 총 훈련과정에서 반복할 스탭\n",
    "total_steps = len(train_loader)*epochs\n",
    "\n",
    "num_warmup_steps = total_steps * 0.1\n",
    "\n",
    "# 스캐줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=num_warmup_steps, \n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "itr = 1\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "list_training_loss = []\n",
    "list_acc_loss = []\n",
    "list_validation_acc_loss = []\n",
    "\n",
    "model.zero_grad()# 그래디언트 초기화\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    model.train() # 훈련모드로 변환\n",
    "    for data in tqdm(train_loader):\n",
    "    \n",
    "        #optimizer.zero_grad()\n",
    "        model.zero_grad()# 그래디언트 초기화\n",
    "        \n",
    "        # 입력 값 설정\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        token_type_ids = data['token_type_ids'].to(device)       \n",
    "        labels = data['labels'].to(device)\n",
    "        #print('Labels:{}'.format(labels))\n",
    "        \n",
    "        # 모델 실행\n",
    "        outputs = model(input_ids=input_ids, \n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        labels=labels)\n",
    "        \n",
    "        # 출력값 loss,logits를 outputs에서 얻어옴\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        #print('Loss:{}, logits:{}'.format(loss, logits))\n",
    "        \n",
    "        # optimizer 과 scheduler 업데이트 시킴\n",
    "        loss.backward()   # backward 구함\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)   # 그래디언트 클리핑 (gradient vanishing이나 gradient exploding 방지하기 위한 기법)\n",
    "        optimizer.step()  # 가중치 파라미터 업데이트(optimizer 이동)\n",
    "        scheduler.step()  # 학습률 감소\n",
    "        \n",
    "        # 정확도와 손실률 계산하는 부분은 no_grade 시켜서, 계산량을 줄임.\n",
    "        # => torch.no_grad()는 gradient을 계산하는 autograd engine를 비활성화 하여 \n",
    "        # 필요한 메모리를 줄이고, 연산속도를 증가시키는 역활을 함\n",
    "        with torch.no_grad():\n",
    "            # 정확도와 총 손실률 계산\n",
    "            pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "            correct = pred.eq(labels)\n",
    "            total_correct += correct.sum().item()\n",
    "            total_len += len(labels)    \n",
    "            total_loss += loss.item()\n",
    "            #print('pred:{}, correct:{}'.format(pred, correct))\n",
    "\n",
    "            # 주기마다 test(validataion) 데이터로 평가하여 손실류 계산함.\n",
    "            if itr % p_itr == 0:\n",
    "\n",
    "                logger.info('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Train Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
    "\n",
    "                list_training_loss.append(total_loss/p_itr)\n",
    "                list_acc_loss.append(total_correct/total_len)\n",
    "\n",
    "                total_loss = 0\n",
    "                total_len = 0\n",
    "                total_correct = 0\n",
    "\n",
    "        itr+=1\n",
    "        \n",
    "        #if itr > 5:\n",
    "        #    break\n",
    "   \n",
    "    ####################################################################\n",
    "    # 1epochs 마다 실제 test(validattion)데이터로 평가 해봄\n",
    "    start = time.time()\n",
    "    logger.info(f'---------------------------------------------------------')\n",
    "\n",
    "    # 평가 시작\n",
    "    model.eval()\n",
    "    \n",
    "    total_test_correct = 0\n",
    "    total_test_len = 0\n",
    "    \n",
    "    for data in tqdm(eval_loader):\n",
    "        # 입력 값 설정\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        token_type_ids = data['token_type_ids'].to(device)       \n",
    "        labels = data['labels'].to(device)\n",
    " \n",
    "        # 손실률 계산하는 부분은 no_grade 시켜서, 계산량을 줄임.\n",
    "        # => torch.no_grad()는 gradient을 계산하는 autograd engine를 비활성화 하여 \n",
    "        # 필요한 메모리를 줄이고, 연산속도를 증가시키는 역활을 함\n",
    "        with torch.no_grad():\n",
    "            # 모델 실행\n",
    "            outputs = model(input_ids=input_ids, \n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids,\n",
    "                            labels=labels)\n",
    "    \n",
    "            # 출력값 loss,logits를 outputs에서 얻어옴\n",
    "            #loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "    \n",
    "            # 총 손실류 구함\n",
    "            pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "            correct = pred.eq(labels)\n",
    "            total_test_correct += correct.sum().item()\n",
    "            total_test_len += len(labels)\n",
    "    \n",
    "    list_validation_acc_loss.append(total_test_correct/total_test_len)\n",
    "    logger.info(\"[Epoch {}/{}] Validatation Accuracy:{}\".format(epoch+1, epochs, total_test_correct / total_test_len))\n",
    "    logger.info(f'---------------------------------------------------------')\n",
    "    logger.info(f'=== 처리시간: {time.time() - start:.3f} 초 ===')\n",
    "    logger.info(f'-END-\\n')\n",
    "    ####################################################################\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e56cc12-2914-4fea-a6c9-15bec647112f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD4CAYAAAD4k815AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA9WElEQVR4nO3deVzU1f7H8deZYV8EWVQQkEXcRVC0REvNSrOyLDPLStu7Zbbdui23ftWtW93bbb2tt7K01NLS3DWXstxxF3dxARdWUVCRZc7vj+9gKCgDDswwfp6PBw+Y73y/M59hec/hfM/3HKW1RgghhOswOboAIYQQ9iXBLoQQLkaCXQghXIwEuxBCuBgJdiGEcDFujnrikJAQHR0d7ainF0KIRmnNmjW5WuvQ8+3jsGCPjo4mNTXVUU8vhBCNklJqX037SFeMEEK4GAl2IYRwMRLsQgjhYiTYhRDCxUiwCyGEi5FgF0IIFyPBLoQQLsZh49jrKnVvPkt35dGyqTcRTb1pGehNWIAXbmZ5jxJCCGiEwb5m3xHeXbDjjG0RTb359a99JdyFEIJGGOwP9oljZEo0BwtOcqDgJAu3ZvP1sr3syCqiQ3gTR5cnhBAO1yibuF7uZmJD/bgsPpRRKdEArM8ocGhNQgjhLBplsFfWKtiHpj7urM844uhShBDCKTT6YFdKkRgZyLr9BY4uRQghnEKjD3aAxMim7MoporC41NGlCCGEw7lGsEcFojVszDzq6FKEEMLhXCPYIwIBWLdf+tmFEMIlgj3Ax53YUF8ZGSOEELhIsAMkRTZlfUYBWmtHlyKEEA7lMsGeGBVIblEJmUdOOroUIYRwKJcJ9qTIQADWSXeMEOIi5zLB3raFP17uJjmBKoS46LlMsLubTXRuGSAnUIUQFz2XCXaApKimpB08xqmyckeXIoQQDlNjsCulvlJKZSulNp/jfqWU+kAptUsptVEp1dX+ZdomMTKQkjILWw8VOqoEIYRwOFta7F8DA89z/zVAvPXjAeCTCy+rbhKtJ1DXSz+7EOIiVmOwa62XAPnn2eUGYJw2rAAClVJh9iqwNsICvGjexFP62YUQFzV79LG3BDIq3c60bmtwp2d6lGAXQjirshIoLa7Xp2jQFZSUUg9gdNcQFRVVL8/RMTyAeWlZnCwpx9vDXC/PIYSoR2UlUJQFfs3BzePM+7SGk0egvMS4X6naP/6pQshKg5ztkLsDcneCLofAVtC0lfHZ0x+0BSxlYCk3nq/sFJQVG1+7eYFPEHg3NT5Mbn/uayk78/ks5ZCzDQ6uMz6yNsP170Pi7XX/HtXAHsF+AIisdDvCuq0KrfXnwOcAycnJ9XLtf0yILwB7847TPkyWyhPCaZWXwfEcKDoMR/ZCZipkroaD66H8FKDArxkERICHHxQegqOZUHrCON47CFp0hrAEaBoNqlIHhNnDGrpBRgAXZcGeJZD+GxxYYwQ5GAEdHA8mk/H8xQX193o9m0BYF7jkIWjWvv6eB/sE+3RgtFJqEnAJcFRrfcgOj1snFcG+J1eCXYjTjh00WqGe/uffz1IOm6bA8g+h9KQRRl5NjM+ms+LC7GG0qM2e4OZZqYVbBuWlRsv4VCGcOganisBSam3Rlhst3xO5xjGnH88TwhOhx/0QHAdF2UaQH800Hie0HbS+0gh6k5vR8j20EVZ+bn0jqIEyQ8uu0PtxiLwEQttCQCSYKv1nX3wUjuwz3jxMbsabhcn852t08zS+LjsJJ/LhZL7xWVuM/U1u1ser9J+EUhAUB0GxxhtIA6gx2JVSE4G+QIhSKhP4P8AdQGv9KTAbGATsAk4Ad9dXsbaoHOxCuKTSYqPV6dXEaLGeS+FhSJsKmyYb+5s9jWDseCO0GWgcX0Fr2D4bFr0G2VugeSfjsYuPGcFceNgI5D8PsHZPlBihWlZiBJrJbASo2d1oZVe8Kfi3MN4IlNkIP7O70ZXi3xz8Whhh3axD1a4XW5SXwom8M7eVFRtdNiePGMHr6Q9RPc98zdXxCjD+A7BFQETta20gNQa71vq2Gu7XwCN2q+gC+Xq60byJJ+k5EuyikTp5BH56EDJWQHBrCGkLoW2g5DjsXQoHUo1QBWiRAF3vgs63gIevEeDpv0H6r8bx2mIEdP+XoCgHtvwM22cZIevXAsxuYHI3grBgn9GyHPoVdBjSYK3LC2Z2N944ztY0usFLcRbKUdPcJicn69TU1Hp57Ns+X8GpsnJ+erhXvTy+uMiVl8GhDXAs02gBe/ja77Fzd8KEW6FgPyQMg6MZkLPD6IdWZqOPtlUKtOoFxw7Amm8gaxO4eRvdBqXHAWXs12YAdBpqvClUsFiMfuxtM+B4rtHaregiib8aEkcYYS+cllJqjdY6+Xz7uORPMCbUlzmbHNbNL1zBwXUw+2nj5FqTcOPDzRsyVhofJUXGfp4BkDQCut9n9AvXRGvI2wV7/zD6Z8O6QHhX4wTfroUw+W6jBTpqJkRd+udxxUeN4D67j7z7fXBoPayfYDx2zOUQ3dt4vOqYTBB1ifEhXJZLBntsiC9HTpRy5HgJTX3r0GcnLm4lx2HKvUbfcnBr2L8cjh0yWrah7aHLcKPF7BMM68bDqv/Bio8hKgVCWhsn5Jq0BO9AOFlg7evNh/x0oyvleHbV52wabbTSQ9vDbRONYXeVeQVUX6tSEJ5kfAhh5ZLBfvoEat5xCXZRe/NeMEJ45AyIuczYZrEYIyHO7naJ7QNXvw5rv4Htc2D73OqDW5mNVn9sX4juBa16g1+oMbTv4Fqjbzy2L1z9Ws0jV4SogWsHe85xukY1dXA1wu60NkZBFB4yWrr2DMLtc2HNWEh59M9QB6ML41x96f7Noc8zxgcYo1YKDxqtde+mRreIh3/1JyNj+xgfQtiRSwZ7ZJAPZpOSIY+upLQYZj0J+1cYJw3LrJdkmz2MfuW210Drq4zuk8ObjI+cbUboV3SNBEYZ+55ryFtRDkwfbQz1u+LFutfq7mWMWRbCQVwy2N3NJqKCfCTYXYXFAtMeMsZkt7/eCPGASKMr48BaY/z1rKfOPMbN2xgNUpABO+Yb3SgV2zsMNi7njr7caEVXXMI++6/GuO27phsXogjRSLlksIPRHZMuwe4aFvyfEepXvQq9Hjvzvk43G/3SuTshfbFxQrNFgjFCpeKKQq2Ni1RytxsX62z6ETZ+D76hxjjvyhe3DPgnNO/QcK9NiHrg0sG+fHceFovGZKrDREHCOaz6Hyz7wBjWlzKm+n2UMlrnlcdrn32/bzD4phhjwAf802jlb59r9Jv7hxkXuATHGaNdhGjkXDrYT5aWk1VYTFiAt6PLEXWxbTbMeQbaXAMD36rbTH7Vcfc2WvqdbrbP4wnhZBrJNcO1FytzxthfabExnru+lZfC4n/C93cYF/AM/VKuhhSiFlw22GNCJdjtylIOE26Bd9rDpBGwb7nRd21v2Vvhi/7w21vQeSjcOc2+l+wLcRFw2WZQc38vvN3N7JHJwOzj1zeN+aw7DoHdi2HbTGjZDToPM0anVMx77R9u3K5MayOw0xcb85NUzPjnFWC8YZyqNIPgmm/A0w+GjTdGrwghas1lg91kUkSH+EqL3R52LYAl/4bEO+DGj4xL7tdPMC6jn/u3qvv7hhoLCTTraAT27kXGxURgXIGpy6seA8aY9LbXwKD/VH1zEELYzGWDHYx+9q2Hjjm6jMbt6AH46QEjqAf929jm4WsshpB8r3H5fMWc1yfzjXHj2WlGC33tOGN+7dh+EHeF8dEk3FjE4FShMWZcmf5swbt7Ofa1CuEiXDrYY0J8mZd2mNJyC+5mlz2dUH/KS2HKPcZaj8PGgYfPmfebTMYwwermwgbjwiKlqo5m8fC1DjM8x3FCiAvi0mkXE+JLmUWTeeSko0tpnP5411is4fr3ISS+9sebTPYboiiEsJlrB/vpkTFFDq6kETqRD0s/MC7h7zzU0dUIIWrBpYO9Yiy7LJNXB8v/aywm0fd5R1cihKgllw72QB8Pmvq4y8iY2jqeBys+hU43ybwpQjRCLh3sYPSzS7DX0tL3jNkQ+zzr6EqEEHXg8sEe38yfdfsLWLy9mlVtLiZaQ+pX8M1gWP0llJyofr+ibGPirc63nHtSLSGEU3P5YB9zZTwxIb7c8/Vq3luwA4ulHi6DbyjlpUYoF+XU7riTBTB5JMx8wlh8YtaT8G5HWPS6EeSV/fEelJdAn2ouPBJCNApK18d8HzZITk7WqampDfJcJ0vK+fu0zfy4NpN+bUN599ZEAn0a4VqoG76HqQ8Yi0zcNhFadD7z/p0LYN04Y7m4igWOj+fClLvh2EHo/xL0fNRYnHn5f401OgFC20LLZAhLgF9eMmY9vPHjBn95QoiaKaXWaK2Tz7vPxRDsAFprvlu5n1dmpNEq2Jdpj/TCz7ORXZ/13S1waINxWX7xUbjpM2M4YuFhmPussRiFT4hxn6X0z+MComDoVxDZ/czHy90FaT9BZipkrjauHDW5w+jVEBTTsK9NCGETCfZq/LEzl7u+Wsn1XcJ579ZEVGO5gOZEPrwdDz0fgUsfhkm3GyvbJww3Fo0oOwWXPw29rItRZG+Bg+uM1YG632csqnw+WkN+utHd06xd/b8eIUSd2BLsjazJeuF6x4fw5FVteHv+DnrEBDHiklaOLsk2W6aBpQw6DTUuxR81G2aMgY2TIKYPXPeusQJQhYquGFspdebxQohG66ILdoCH+7Zm1d4jvDJ9C10iAunUMsDRJdVs0xQIafNnv7q7Fwz5zGilB7eWS/eFEKfZNCpGKTVQKbVdKbVLKVVlcLNSKkoptVgptU4ptVEpNcj+pdqPyaR479ZEgnw9ePi7tRwrLq35IEc6egD2LTNa65UDXCljDhcJdSFEJTUGu1LKDHwEXAN0AG5TSp19OeLfgR+01knAcMDph1QE+Xrw39uTOFBwkpembXZ0OeeX9hOgZc4WIYRNbGmx9wB2aa3TtdYlwCTghrP20UAT69cBwEH7lVh/kqODuO+yGKZvOEhG/jku2HEGm6YY/eXSBy6EsIEtwd4SyKh0O9O6rbKXgTuUUpnAbODR6h5IKfWAUipVKZWak1PLi2zqycie0Sil+HblPkeXUr283XBovdENI4QQNrDXlae3AV9rrSOAQcB4pVSVx9Zaf661TtZaJ4eGOsfSZ+GB3lzdoTnfr86guPQcS7Y50qYpgDIm5BJCCBvYEuwHgMhKtyOs2yq7F/gBQGu9HPACQuxRYEO4q2c0BSdKmb7ByXqQtIZNk6FVL2NJOSGEsIEtwb4aiFdKxSilPDBOjk4/a5/9QH8ApVR7jGB3jr4WG1waG0Tb5v58s2wvjrpgqwqLBRa/Dnk7IeEWR1cjhGhEagx2rXUZMBqYB2zFGP2SppR6VSk12LrbU8D9SqkNwERglHaahKyZUoq7UlqRdvAYa/cfcXQ5UHLcmLRryb8h6U5IHOHoioQQjYhNFyhprWdjnBStvO2lSl9vAXrZt7SGdWNiS96cs41vlu2jW6sgxxVy7CBMHA6HNsLVrxtTCMg4dSFELbj8tL228vV0Y1hyJLM3HSL7WHHDF1B2ClZ/AZ/1MUbC3DYJUkZLqAshak2CvZI7L21FmUUzfoWdhj4WH4UJt8K8F4w50atTehJWfgbvJ8Ksp4wpd++dD20H2qcGIcRF56KcK+ZcokN8GdixBf9dvAsfDzce6hNb99kfy0rg+ztg71LYMQ/WT4C+z0Hy3aBMxhQBaVNhy89wIheiUmDIJ8aEXtJKF0JcAAn2s7x7ayJPT9nAW3O3sSOrkDdu6oyXu/ncB1gsRhBXDmOLBX5+BPYsMSbqat4R5j0Pc56GFR8bJ0ePZ4ObN7S5GrrfDzGX1f+LE0JcFCTYz+LtYebD25Jo29yf//yygz25x/n8rm408/equnPebvj2JjB7GHOed7kNvJrAwldg0w/GikVdhhv73jUddsyFP94F/zDoeCPEXw0evg36+oQQru+iW2ijNuZuPsQT32+gR0wQ39zT48w7D200Ql1bILAVHFwL7r4Q3Rt2zoPke+Dad6RbRQhhV7LQxgUa2CmMDZlH+d+SdI6eKCXAx924Y98y46SoZxO4cyqEtjFWM1r1BWz+EdpdB4PellAXQjiEjIqpwYCOLSizaBZuyzI27JgP44eAX3O4Z64R6gAtuxknP/+2B4aNB9N5+uWFEKIeSbDXIKFlAC2aeDEv7TDk74HJoyC0rRHqgZFVD/DwBZN8W4UQjiNdMTUwmRRXd2zO5NR9lJe8iNlkhuETwLfRzHEmhLjISLDb4OoOLXBb9SnmjGVww0cQEOHokoQQ4pwk2G1wSZM8kt0nkebXk44yIZcQwslJZ3BNLOW4z3gEi8mLMUV3U2ppNJNWCiEuUhLs53LyCKT/CjOfgMzV7Ex+md3Ffqzak+/oyoQQ4rykK+ZsKz+DFZ/AkT1/bku6gzb9R+G1/BfmpR2mV2s5cSqEcF4S7JVlrIY5f4PIHtD1TghPgrBE8AnCG7g8PpT5aVm8fH1HTCa5+EgI4Zwk2CuUlcD0R421RUdMMeZ8OcuAji2YvyWLjQeOkhgZ2PA1CiGEDaSPvcIf70DOVrju3WpDHaB/+2aYTYpZG51s0WshhKhEgh0geysseRs6DYU2A865W6CPB4M6hzF26V7nWBtVCCGqIcFuKTe6YDz94Zq3atz9tRs60SLAi9HfreXI8ZIGKFAIIWrn4g52iwV++xdkroaBb9o0TUCAjzsfj+hKblEJT/ywHouMaxdCOJmLN9jzdsO4wfDbm9BxCCQMs/nQhIhAXryuPb9uz+GT33YDUFJmYWV6Hu8v2MnGzIJ6KloIIWp28Y2KsZQby9Mteh3M7nD9B9D1rlrPnX7Hpa1YtfcI/5m/nVV78kndm8/xknIAJq/JYP4Tl+PjcfF9e4UQjnfxJI/FAttmwq9vQPYWaDsIrv2PMbyxDpRSvHFTZ3ZlF5GeW8SNSS25LD4UDzfFPV+n8v6CnTw3qL2dX4QQQtTM9YNda9g+Gxa/AVmbIDgebvkGOtxwwSsc+Xm6MeexqotQ35ocyRd/7GFwYjgdwwMu6DmEEKK2XL+P/ff/wKTbofQ4DPkcHllpLCRdj8vWPTeoHU193Hn+p02Uy8lVIUQDc/0W++7FENYF7lsE5oZ5uYE+Hrx4XQcem7Se8cv3MqpXDHlFp/ghNZOf1mZyqsyCv5cbfp5uBPl68Ei/1nRqKS17IYR9uHawaw3ZaUa3SwOFeoXBXcKZsiaTf8/bzpr9BczbfJiScgs9YoIID/CisLiMwuIyVqTnsWbfEaaP7k2LAK8GrVEI4ZpsSjul1EDgfcAMfKG1frOafYYBLwMa2KC1vt2OddZN4WFj+t1mHRv8qZVSvH5jZwa+v4Rft2dz+yVR3HFpFK2b+Z+x3/bDhdz08VIeGJ/K9w/0xNtDFsEWQlyYGoNdKWUGPgKuAjKB1Uqp6VrrLZX2iQeeA3pprY8opZrVV8G1km0tsZljRqdEBfvw61/74u/lfs7AbtvCn/eGJ/HA+FSe+XEjHwxPRNVj/78QwvXZcvK0B7BLa52utS4BJgE3nLXP/cBHWusjAFrrbPuWWUcVwd684VvsFZo18aqxFX5Vh+Y8M6AdMzYc5KPFuxqoMiGEq7Il2FsCGZVuZ1q3VdYGaKOUWqqUWmHtuqlCKfWAUipVKZWak5NTt4prI2sL+LUAn6D6f64L9FCfWIYkteTt+TtYsqMBvjdCCJdlr+GObkA80Be4DfifUirw7J201p9rrZO11smhoaF2eurzyE6D5h3q/3nsoOKCp9gQX16ekUZpucXRJQkhGilbgv0AEFnpdoR1W2WZwHStdanWeg+wAyPoHcdSDjnboVnjCHYAL3czL1zbnvSc43y7Yp+jyxFCNFK2BPtqIF4pFaOU8gCGA9PP2mcaRmsdpVQIRtdMuv3KrIP8PVBW3KiCHeCKds24LD6E9xbslGmBhRB1UmOwa63LgNHAPGAr8IPWOk0p9apSarB1t3lAnlJqC7AYeFprnVdfRdskO8343Ei6Yioopfj7tR0oLC7l/YU7HV2OEKIRsmkcu9Z6NjD7rG0vVfpaA09aP5xD1hZAQWg7R1dSa21b+HP7JVGMX7Gv2rHvQghxPq47V0x2GgTFgru3oyupkyeubIOPh5nXZm11dClCiEbGhYN9a6Prhqks2M+Tx/rH8+v2HFbtyXd0OUKIRsQ1g730JOSnO2QqAXsa2i0CgA0ZBY4tRAjRqLhmsOdsA21p1C12MGaJDPL1ID23yNGlCCEaEdcM9qyKOWIad4sdICbEl/Sc444uQwjRiLhmsGdvATcvCIpxdCUXLDbEl/RcCXYhhO1cN9hD24Kp8U+BGxPqS07hKQqLSx1dihCikXDNYM/a4hLdMACxIX4A7JFWuxDCRq4X7Cfyoehwoz9xWiE21BeQYBdC2M71gj3LOpWAgxbXsLdWwT4oBbvlBKoQwkauF+zZ1is1XaQrxtPNTERTb2mxCyFs5nrBnrMVvALAv4WjK7Gb2BA/0nNkLLsQwjauF+x5uyE4Hlxo3dCYEF/25B7HmGtNCCHOz/WCPT8dguMcXYVdxYX6cqKknKxjpxxdihCiEXCtYC89CUczIMi1gj3GOuRRphYQQtjCtYI9f4/x2cVa7BVDHmVqASGELVws2Hcbn4NiHVuHnbVo4oWXu0lGxgghbOJawZ5nDXYXa7GbTIoYGRkjhLCRawV7/m7wDTWGO7qYWOvIGCGEqIlrBXvebpc7cVohNtSXjCMnKSmzOLoUIYSTc71gd7FumAoxIb6UWzT780+c3rb10DEGvreEGRsOOrAyIYSzcZ1gP1VkTP7lYidOK8SGWoc8WvvZtdb8Y+YWth0u5NGJ6/jHzC2UlktrXggBbo4uwG7y043Pwa0dW0c9iQk5c5bH33bksGx3Hs8PasfBgmK+/GMPmzKP8t/bkzhyopTF27NZvC2bjPwTTLj/UqKtxwshXJ8LBbtrjoipEODtToifB+k5xym3aN6cs42oIB9GpcTg4WYiKSqQZ3/cRM83F1FuMaYeaNfCn6MnS3nx582Mu6cHyoWmWRBCnJvrBHveLuOzi3bFwJ9zxkxbd4Bthwv58LYkPNyM3rQbElvStoU/E1bup0NYE/q0DSUswJuvl+7h5RlbmLnxENd3CT/j8cav2MfYP/Zw+yVR3NYjCl9P1/l1EOJi5jp97Hnp4B8GHq7b5RAb4sfO7EL+M387CREBXNs57Iz727Vowqs3dGJ4jyjCArwBuLNnNJ1bBvCPmVs4Vml5vekbDvLSz5s5XlLGa7O20vutRXywcCdHT8gSfEI0dq4T7PmuO9SxQkyoL0dOlHLwaDHPXtMOk6nmrhWzSfH6kE7kFJ3infk7APhjZy5P/bCe7q2C+O3pfvz4lxS6tWrKO7/sYNAHv8uQSiEaOZuCXSk1UCm1XSm1Syn17Hn2u1kppZVSyfYr0UYuPNSxQqz1BGi/tqGkxIXYfFxCRCB3XdqKccv3MnHVfh4cn0psiB//uysZL3cz3Vo15YuR3fnPLV04UHCSjZkF9fQKhBANocZgV0qZgY+Aa4AOwG1KqSoLiiql/IHHgJX2LrJGJwvgRK7LB3v36CAubxPK36+r/XquTw1oS7CfJ8/9tIlAHw++uacHAT7uZ+zTv30zlIJlu/PsVbIQwgFsabH3AHZprdO11iXAJOCGavb7B/AWUGzH+mxzevIv1w72pr4ejLunB3HWMe210cTLnTeGdKZDWBO+uacHLQK8quwT6ONBx/AmLNuda49yhRAOYkuwtwQyKt3OtG47TSnVFYjUWs+yY222y6sYw+7awX6hruzQnNmPXUbrZud+Y0iJC2HtvgKKS8sbsDIhhD1d8MlTpZQJeAd4yoZ9H1BKpSqlUnNyci70qf+UvxtQ0DTGfo95keoZF0xJuYXUvUccXYoQoo5sCfYDQGSl2xHWbRX8gU7Ar0qpvcClwPTqTqBqrT/XWidrrZNDQ0PrXvXZ8nZDQCS4V+1eELXTPToIN5OS7hghGjFbgn01EK+UilFKeQDDgekVd2qtj2qtQ7TW0VrraGAFMFhrnVovFVcnfzcEu+6FSQ3Jz9ONLpGBcgJViEasxmDXWpcBo4F5wFbgB611mlLqVaXU4PousEZaG1eduviJ04aUEhfMxsyCMy5oEkI0Hjb1sWutZ2ut22it47TWr1u3vaS1nl7Nvn0btLV+Ih+Kj8qJUzvqGReMRcPqPfmOLkUIUQeN/8rTi2SoY0PqGtUUDzeTdMcI0Ug1/mCvmPzLRafrdQQvdzPJrZpKsAvRSDXOYC85AZt/gkkjYMZj4OYFgVGOrsqlpMQFs/XQMfKPlzi6FCFELTW+eVpTv4L5L0JJEfi1gO73QeLt4Obh6MpcSs+4EGAHK9LzGHTWLJJCCOfW+II9KBY63Qydh0KrXmAyO7oil5QQEYCvh5llu3Ml2IVoZBpfsMf2NT5EvXI3m+gRE8SyXdLPLkRj0zj72EWDuCw+lPTc46fXWRVCNA4S7OKcrurQHIB5aYcdXIkQojYk2MU5RQb50KllEwl2IRoZCXZxXgM6tGDd/gKyjtV+mv2TJeUcP1VWD1UJIc5Hgl2c14BOLQCYvyXL5mO01kxbd4Beby1i6KfLKSuXNVSFaEgS7OK84pv5ERviy7zNtnXHZOSfYOTY1Tz+/XoCvN3ZeugYE1dn1HygEMJuJNjFeSmluLpjC1ak53H0xLlneywtt/DZb7u5+t0lrNmbzyuDO7LgyT5cGhvEO/O3c/Rk1WPnbj7ED6kZFJyQq1uFsCcJdlGjAR2bU2bRLNxWfXfMst25DHr/d96Ys41erYP55ck+jEyJxmxSvHhdBwpOlvLhwp1nHDNlTSYPfbuWZ6ZsJPm1BYwau4rJqRmcLJEl+YS4UBLsokZdIgJp3sSzyuiY7MJixkxcx+3/W0lxWTlf3JXMFyO7Ex7ofXqfjuEB3JocydfL9pKeUwTAL1uy+NuPG+nVOpifHk7h3t4x7Mwq4ukpG3nw2zVorRv09QnhaiTYRY1MJsWAji34bUfO6Rb10l1GK31u2mHG9I/nlyf6cKV13PvZnrq6LV7uZv45exsr0vN4ZMJaOoU34bM7k+ka1ZTnBrXnj7/147lr2rFkRw6zN8nwSiEuhAS7sMmAji0oLrXw245sPly4kzu/XEmgjwezHu3Nk1e1wcv93HP2hPp7MvqK1izYmsWosauICvJh7N098PP8c0YLpRT3XRZLx/AmvDozjSIZJilEnUmwC5v0iAkiwNudJ3/YwH9+2cH1XcL5+ZFexDf3t+n4u3tFEx3sQ7CvJ+Pv7UGQb9XZOM0mxWs3diK78BTv/bLD3i9BiItG45sETDiEu9nEoM5h/Lgmk9du7MSIS6JQStl8vKebmWmP9MJsUvh7uZ9zv6SopgzvHsXYZXsZmhxBuxZN7FG+EBcV5agTVcnJyTo1teGWRhUXrri0nGPFpTTz96rX5zlyvIT+7/xGbIgvPzzYE5PJ9jcQIVydUmqN1jr5fPtIV4ywmZe7ud5DHaCprwfPXtOO1H1HmLruQL0/nxCuRoJdOKWhXSNo29yfCav2O7oUIRodCXbhlEwmxeDEcNbsO8LBgpOOLkeIRkWCXTita61L8s3edMjBlQjRuEiwC6cVHeJLp5ZNmLlRgl2I2pBgF07t2s7hrM8oICP/hKNLEaLRkGAXTq2iO2bOZvu22mdvOsSQj5fy6owt7MwqtOtjC+FoEuzCqUUF+5AQEcAsO3XHHDlewugJa3n4u7XkFp1i/Iq9XPXuEoZ+soyf18vQSuEabAp2pdRApdR2pdQupdSz1dz/pFJqi1Jqo1JqoVKqlf1LFRerazuHsSHzaJ27YywWTXZhMbM2HuKqd5cwL+0wT13VhkVP9WX5c/157pp25B8v4bFJ6/l9Z46dqxei4dU4pYBSygx8BFwFZAKrlVLTtdZbKu22DkjWWp9QSv0F+Bdwa30ULC4+gzqH8cacbczadIiH+sSd3m6xaJSiytQGOYWnmL3pEPPSDrMv7wRZx4opsxhXWLcPa8K4e3rQIdyYqiDEz5MH+8QxMiWahJfns2RHDpfFhzbcixOiHtgyV0wPYJfWOh1AKTUJuAE4Hexa68WV9l8B3GHPIsXFLTLIhy6RgczaaAR70akyvvx9D1/8no7JpIhv5kd8cz8imvqwIj2PpbtysWho09yPHjFBtAjwIizAi5aB3lwWH4qHW9V/VL3czSRFBbI8Pc8Br1AI+7Il2FsClRetzAQuOc/+9wJzqrtDKfUA8ABAVFSUjSUKAdd1DuP12Vt5Z/52vlu5n7zjJVzVoTnN/D3ZmVXEnM2HKThRSmSQN3/pG8fgLi1p28K2mScrpMSF8N7CHRScKCHQp+rsk0I0Fnad3VEpdQeQDPSp7n6t9efA52BMAmbP5xau7ZrOLXh99lY+WLSLS2OD+GJgO5Kimp6+X2vNseIymni51WrWycpSWgfz7gJYkZ7PwE4t6lzrjqxC3pm/gx3ZhTx6RWtuTGxZ55qEqAtbgv0AEFnpdoR12xmUUlcCLwB9tNan7FOeEIaIpj68e2sXQvw86d06pEpQKqUI8D73dMC26BIRiLe7meW7c+sU7PvzTvDegh1MXX8AXw83Ipp688T3G5i4MoNXb+woUxCLBmNLsK8G4pVSMRiBPhy4vfIOSqkk4DNgoNY62+5VCgEMSYqo18f3cDPRPSaIZbtr388+P+0wD3+3FrNJ8cBlsTzUJ44Ab3e+T83grbnbuPaDP7i3dwx/vbpttX38C7Zkcay4lJu61u9rFBeHGoNda12mlBoNzAPMwFda6zSl1KtAqtZ6OvBvwA+YbG1J7ddaD67HuoWoFylxwbw5ZxvZhcU2T1FcbtG8OWcbsaG+jL/3Epo3+fO423pEMbBjC96au43Pl6Szdt8RPh7RlWbWfcotmn/N28Znv6Xjblb0b9ecAJ8L+89DCJv62LXWs4HZZ217qdLXV9qjmNLSUjIzMykuLrbHw4l65uXlRUREBO7urhNEKXHBgNHPPrhLuE3HzNx4kPTc43w8ousZoV6hqa8Hb96cQErrEP42ZSPXffgHn9zRjbhQXx6duI7fd+ZyRbtmLNqWzby0wwzrHlnNswhhO6daGi8zMxN/f3+io6PlZJOT01qTl5dHZmYmMTExji7HbjqGB+Dv5cby3blnBLvWmpyiU1Va8eUWzYeLdtGmuR8DO56/X35wl3Dim/nx4Pg1DP98OSF+nuQVlfDmTZ25tXskff79KzM2HpRgFxfMqaYUKC4uJjg4WEK9EVBKERwc7HL/XZlNiktigqv0s7+3YCc9Xl/I96vPXPhjzuZD7Mou4tEr4m1awq99WBOmj+5F79YhAEx68FKG9zDWj72+SxjLdueRWyRjD8SFcapgh6pXEQrn5ao/q5S4YPblnSDziDGFwR87c/lg0U6aeLnx3E+bmLv5MGBc+frBwp3EhfoyyDpZmS0CfTwYe3cPlv7tCrpWGrJ5fZdwyi2aOdbHF6KunC7YhXC0lNZGP/vy3XlkHyvm8e/X0TrUj0V/7UuXyEDGTFrH8t15zEs7zI6sIsb0j8dchwW3z27ht23uT+tmfszYcNAur0NcvCTYK8nLyyMxMZHExERatGhBy5YtT98uKSk577GpqamMGTOmVs8XHR1Nbm7uhZQs6kGbZv4E+3qwdFcuYyat4/ipcj4e0ZUQP0/GjupOqyAf7h+XyptztxEb4st1CbadZK2JUorrE8JZvTefw0dr18WltVzvJ/4kwV5JcHAw69evZ/369Tz00EM88cQTp297eHhQVlZ2zmOTk5P54IMPGrBaUV9MJsWlccFMW3+QFen5/OPGTsQ3N6YnCPTxYNy9PQjwdmdf3gke6de6Tq31c7muSxhaw6xaLAeotWb45yu488uVFJ069++ouHg41aiYyl6ZkcaWg8fs+pgdwpvwf9d3rNUxo0aNwsvLi3Xr1tGrVy+GDx/OY489RnFxMd7e3owdO5a2bdvy66+/8vbbbzNz5kxefvll9u/fT3p6Ovv37+fxxx+3uTW/d+9e7rnnHnJzcwkNDWXs2LFERUUxefJkXnnlFcxmMwEBASxZsoS0tDTuvvtuSkpKsFgs/Pjjj8THx9flWyPOkhIXzKyNhxjaLYKh3c68aCgswJsJ91/C/LQsbki0T2u9QlyoHx3DmzBjw0Hu7f3naKNNmUdxMyvah1W9enVeWhYr9+QDcNeXK/n6nh408XKdIaii9pw22J1JZmYmy5Ytw2w2c+zYMX7//Xfc3NxYsGABzz//PD/++GOVY7Zt28bixYspLCykbdu2/OUvf7FpvPejjz7KyJEjGTlyJF999RVjxoxh2rRpvPrqq8ybN4+WLVtSUFAAwKeffspjjz3GiBEjKCkpoby83N4v/aI1uEs4x06WMTKl+qUFWgX7cv/lsfXy3NclhPPW3G1k5J/Aw83Em3O2MXXdAQK83VnwZB9C/T1P72uxaN79ZQexIb48dXVbHv9+HXd8sZJx9/SQicwuYk4b7LVtWdenW265BbPZDMDRo0cZOXIkO3fuRClFaWlptcdce+21eHp64unpSbNmzcjKyiIioubLxZcvX85PP/0EwJ133skzzzwDQK9evRg1ahTDhg3jpptuAqBnz568/vrrZGZmctNNN0lr3Y78vdz5S9+4mnesB9clhPHW3G08M2UjGzMLKC3XjEqJZsLK/bw8PY2PRnQ9ve/szYfYnlXI+8MTuTYhDC93E3/5di23/W8l397bg2A/z/M8k3BV0sduA19f39Nfv/jii/Tr14/NmzczY8aMc47j9vT88w/KbDaft3/eFp9++imvvfYaGRkZdOvWjby8PG6//XamT5+Ot7c3gwYNYtGiRRf0HMI5RAb5nJ4bvmdcCL88eTkvD+7ImP6tmbXpEPPTjOGQ5RbNewt20rqZ3+kTuP3bN+eLkcmk5xRxzzepnCqr+l/c8VNl/OXbNQz7bDkvTN3E2KV7WLorl3KLnIB1FRLstXT06FFatmwJwNdff233x09JSWHSpEkAfPfdd1x22WUA7N69m0suuYRXX32V0NBQMjIySE9PJzY2ljFjxnDDDTewceNGu9cjHOP9W5OY8lBPvhiZTKtgo2HxYJ842rXw58WfN3OsuJSZGw+yK7uIx688c7jl5W1CeX94IhsyCnhlxpYzHrfconls0jrmpR2mpMzCjA0HeWXGFkZ8sZJ/zt7aoK9R1B8J9lp65plneO6550hKSrrgVjhAQkICERERRERE8OSTT/Lhhx8yduxYEhISGD9+PO+//z4ATz/9NJ07d6ZTp06kpKTQpUsXfvjhBzp16kRiYiKbN2/mrrvuuuB6hHOICvYhOTrojG3uZhP/GppATuEpXp+5lfcX7KRdC38Gdap6cdTATmE81CeOCSv380Pqn+vkvDF7Kwu2ZvPy4I5Me6QXG/7vala90J8bE8MZv3wfBwpO1vtrE/VPOWr8a3Jysk5NTT1j29atW2nfvr1D6hF1Iz+zhvf6rC387/c9AHx6R7dzzh1fVm5h5NhVrN57hB8fSmHTgaM8P3UTo1KieXnwmeewDhacpO+/f2VIUkveGppQ769B1J1Sao3WOvl8+0iLXYhG5omr2hAd7EOXiAAGdGx+zv3czCY+GJ5EiK8H93yzmhd/3kzftqH8/dqqb8Thgd6MuDSKKWszSc8pqrfaDx8t5qWfN9Pv7V/ZkVVYb89zsXPaUTFCiOr5eLgxa4xx7qWm+XqC/Tz55I5u3PLpclqH+vHhbUm4matvzz3ctzXfr87g3QU7+fC2pCr3F5eW89uOHGZuPMTSXbl0iQjgxqSWXN2hBd4eZkrLLfyxK5cZ6w+yIj2P+Ob+9IwL5tLYYJo38eSz39KZsGo/FovG293MQ9+uYfro3vh5SgzZm3xHhWiEfGsRhl0iA5nz+GWE+Hnif54Ll0L9Pbm7VzQfLd7NX/rE0SHcuBhqV3Yhn/6WzrzNhyk8VUaQrwe9WoewZm8+j01aj6+HmZ5xwazdX0D+8RL8vdzoFRfCrpwi3pyz7fTjm02KoV0jGH1FazKPnGTEFyt49seNfHhbUr1NKHew4CTPT92EAr4c2d2mGThdgQS7EBeBuFA/m/Z74LI4xi/fxzu/bOf5Qe35YOFOft5wEG93M9clhHFdQjgpccG4mU1YLJqVe/KZui6TpbvySIkLZnCXcPq0DcXTzbjuI7uwmJXp+ezJPc7gLuFEhxgjfCKDfPjrgLb8a+52ukcHMTIlus6vLfPICTZkHCUlLpimvsZFWVprflp7gJenp3GytJwyi+bnDQfqfXlFZyHBLoQ4LcDHnQf7xPHvedtZtC0bTzczD1wey4OXxxHke+aVrCaTomdcMD2tq05Vp5m/F9efYyWqhy6PY83eI7w2awsJEQEkVZrC2FYFJ0oY8cVK9uWdwKQgKaop/dqGsunAUealZdE9uin/HtqFMZPW8dac7Qzo2AIfD9ePPTl5KoQ4w6iUaHq1DubuXjEseaYfz13Tvkqo24PJpPjPsC40b+LFI9+tPedJ23KLJv941dlVy8otjJ6wjkMFxbwzrAujr4inpMzC2/N3sHhbDs9d045JD/QkOsSXl67rwOFjxXz2W7rdX4czcv23rlrIy8ujf//+ABw+fBiz2UxoaCgAq1atwsPj3L/cqampjBs3rtYzPK5fv56kpCTmzJnDwIED6168EHbi6+nGd/dd2iDPFejjwad3dOPOL1dyw0dL+fC2JPq2bXb6/m2Hj/H05I1sPXSMh/vGMfqKeDzcjPboG3O28ceuXP51cwI3dTW6WJ68qg3ZhcbV4JWXMUyODuK6hDA+W7KbW7tHEh7o3SCvz1GkxV6JI6btnThxIr1792bixIkXUnqNZIIw4aw6tQxg+ujetAz05p6vV/PZb7spKbPw3oIdXP/hHxw6epL+7ZvxwaJdXP/hH2zMLGDKmky+/GMPo1Kiq6wR28zfq8ratADPXtMOreGtuduq3HchMvJPcKSa/ygcyXlb7HOehcOb7PuYLTrDNW/W6pD6nLZXa83kyZP55ZdfuOyyyyguLsbLy/iFfOutt/j2228xmUxcc801vPnmm+zatYuHHnqInJwczGYzkydPJiMj4/TzAowePZrk5GRGjRpFdHQ0t956K7/88gvPPPMMhYWFfP7555SUlNC6dWvGjx+Pj48PWVlZPPTQQ6SnG/+mfvLJJ8ydO5egoCAef/xxAF544QWaNWvGY489dgE/ACGqFxnkw08Pp/D05I28MWcbny9JJ+94CTcmhvPS9R0J8vVg4dYsnp+6iSEfL8OkjKmVX6hmTP65RDT14YHLY/lw0S7u6hlNt1a179Ov7OiJUt6at42Jq/bjZlL0a9uMm7q2pF+7ZqdPHjuK8wa7E6mvaXuXLVtGTEwMcXFx9O3bl1mzZnHzzTczZ84cfv75Z1auXImPjw/5+cZc2yNGjODZZ59lyJAhFBcXY7FYyMjIqPLclQUHB7N27VrA6Gq6//77Afj73//Ol19+yaOPPsqYMWPo06cPU6dOpby8nKKiIsLDw7npppt4/PHHsVgsTJo0iVWrVtnj2ylEtXw83Pjv7Ul0+LUJP68/wFs3J3Blhz8vwOrfvjnzo4N4c85Wth4q5KPbu+J+jjH55/JQnzi+X53B6AlreW5Qe65PCKsy1DLrWDEmpc6YHrkyrTVT1x3g9VlbKThZyqiUaNzNJqauO8D8LVkEeLsT0dQbN5PCZFJ4upl4sE8c/Sp1MdU35w32Wras61N9Tds7ceJEhg8fDsDw4cMZN24cN998MwsWLODuu+/Gx8cHgKCgIAoLCzlw4ABDhgwBON2yr8mtt956+uvNmzfz97//nYKCAoqKihgwYAAAixYtYty4cQCnF/IICAggODiYdevWkZWVRVJSEsHB5x79IIQ9KKV4pF9rHunXutr7A7zdeeOmuk954Ovpxv/uSua5nzYxZuI6vl66hxev60B0sC+zNh1i+vqDrNprNKQSIwO5sn0z+rdvjrtZsSHjKJsOHGXlnny2HjpGYmQg44Z0omN4AADPDGjL0t15zNxwkCMnSiizaMotmn15J3hgXCofj+jGVR3OfaWwPTlvsDuR6qbtnTp1Knv37qVv377VHlPTtL3l5eX8+OOP/Pzzz7z++utorcnLy6OwsHaXWbu5uWGxWE7fPnsa4cq1jxo1imnTptGlSxe+/vprfv311/M+9n333cfXX3/N4cOHueeee2pVlxDOqktkIDMe7c2UNRn8e94Ohny8DDeTosyiad3Mj6euagPAgm3ZvD1/B2/P33H6WB8PM53CA/jnkM4M7x55xgVPbmYTfdqE0qdN6BnPd/RkKXd9tYqHv1vDf2/vyoCO1c/tY08S7LVkr2l7Fy5cSEJCAvPmzTu9beTIkUydOpWrrrqKV199lREjRpzuigkKCiIiIoJp06Zx4403curUKcrLy2nVqhVbtmzh1KlTnDx5koULF9K7d+9qn7OwsJCwsDBKS0v57rvvTr+O/v3788knn/D444+f7ooJCAhgyJAhvPTSS5SWljJhwoQ6v1YhnI3ZpLi1exTXJoTz9dI9FJ0q5/ouYXQIa3K6a+bR/vFkHyvm1x05mJSiS0QAsaF+tV7jNsDbnfH39uCuL1fxyHdr+e/tXc85cZu9yKiYWrLXtL0TJ0483a1S4eabb2bixIkMHDiQwYMHk5ycTGJiIm+//TYA48eP54MPPiAhIYGUlBQOHz5MZGQkw4YNo1OnTgwbNoykpKpzfFT4xz/+wSWXXEKvXr1o167d6e3vv/8+ixcvpnPnznTr1o0tW4w5vD08POjXrx/Dhg073RUlhCvx83Rj9BXxPHtNOzqGB1Tpb2/WxIthyZEM7RZBfHP/Oi9c3sTLCPeEiABGT1jL3M2H7VH+Ocm0veKcLBYLXbt2ZfLkyedcdk9+ZkLYrrC4lMcmrefxK+NJiAis02PYbdpepdRApdR2pdQupdSz1dzvqZT63nr/SqVUdJ0qFk5jy5YttG7dmv79+8taqkLYib+XO1+N6l7nULdVjX3sSikz8BFwFZAJrFZKTddaV15z617giNa6tVJqOPAWcGvVRxONRYcOHU6PaxdCNC62tNh7ALu01ula6xJgEnDDWfvcAHxj/XoK0F/VcR5OR3UNidqTn5UQzsmWYG8JVL4KJtO6rdp9tNZlwFGgyqBnpdQDSqlUpVRqTk5OlSfy8vIiLy9PAqMRqBieaet4eiFEw2nQ4Y5a68+Bz8E4eXr2/REREWRmZlJd6Avn4+XlVeWiKyGE49kS7AeAyrPsRFi3VbdPplLKDQgA8mpbjLu7OzExMbU9TAghRCW2dMWsBuKVUjFKKQ9gODD9rH2mAyOtXw8FFmnpTxFCCIeoscWutS5TSo0G5gFm4CutdZpS6lUgVWs9HfgSGK+U2gXkY4S/EEIIB7Cpj11rPRuYfda2lyp9XQzcYt/ShBBC1IXDrjxVSuUA++p4eAiQa8dy7M2Z63Pm2sC563Pm2sC563Pm2qBx1ddKax16vp0dFuwXQimVWtMltY7kzPU5c23g3PU5c23g3PU5c23gevXJJGBCCOFiJNiFEMLFNNZg/9zRBdTAmetz5trAuetz5trAuetz5trAxeprlH3sQgghzq2xttiFEEKcgwS7EEK4mEYX7DUt+uGAer5SSmUrpTZX2haklPpFKbXT+rmpg2qLVEotVkptUUqlKaUec5b6lFJeSqlVSqkN1tpesW6PsS7Wssu6eItHQ9d2Vp1mpdQ6pdRMZ6pPKbVXKbVJKbVeKZVq3ebwn2ul+gKVUlOUUtuUUluVUj2doT6lVFvr96zi45hS6nFnqK1SjU9Y/yY2K6UmWv9WavV716iCvdKiH9cAHYDblFIdHFsVXwMDz9r2LLBQax0PLLTedoQy4CmtdQfgUuAR6/fLGeo7BVyhte4CJAIDlVKXYizS8q7WujVwBGMRF0d6DNha6bYz1ddPa51YaXyzM/xcK7wPzNVatwO6YHwPHV6f1nq79XuWCHQDTgBTnaE2AKVUS2AMkKy17oQxjUvF4kW2/95prRvNB9ATmFfp9nPAc05QVzSwudLt7UCY9eswYLuja7TW8jPGSlhOVR/gA6wFLsG4us6tup+3A+qKwPgjvwKYCShnqQ/YC4Sctc0pfq4Ys7vuwTo4w9nqq1TP1cBSZ6qNP9e2CMKY8mUmMKC2v3eNqsWObYt+OIPmWutD1q8PA80dWQyAdR3aJGAlTlKftZtjPZAN/ALsBgq0sVgLOP7n+x7wDGCx3g7GeerTwHyl1Bql1APWbU7xcwVigBxgrLUb6wullK8T1VdhODDR+rVT1Ka1PgC8DewHDmEsWrSGWv7eNbZgb3S08Rbr0DGlSik/4Efgca31scr3ObI+rXW5Nv4ljsBYgrGdI+qojlLqOiBba73G0bWcQ2+tdVeMbslHlFKXV77Twb93bkBX4BOtdRJwnLO6Nhz9d2Htox4MTD77PkfWZu3bvwHjzTEc8KVqV2+NGluw27LohzPIUkqFAVg/ZzuqEKWUO0aof6e1/snZ6gPQWhcAizH+xQy0LtYCjv359gIGK6X2YqzzewVGv7FT1Gdt2aG1zsboI+6B8/xcM4FMrfVK6+0pGEHvLPWB8Ya4VmudZb3tLLVdCezRWudorUuBnzB+F2v1e9fYgt2WRT+cQeWFR0Zi9G03OKWUwpgrf6vW+p1Kdzm8PqVUqFIq0Pq1N0bf/1aMgB/qyNoAtNbPaa0jtNbRGL9ni7TWI5yhPqWUr1LKv+JrjL7izTjBzxVAa30YyFBKtbVu6g9swUnqs7qNP7thwHlq2w9cqpTysf79Vnzvavd758iTF3U8uTAI2IHRH/uCE9QzEaMvrBSjpXIvRl/sQmAnsAAIclBtvTH+pdwIrLd+DHKG+oAEYJ21ts3AS9btscAqYBfGv8meTvAz7gvMdJb6rDVssH6kVfwdOMPPtVKNiUCq9ec7DWjqLPVhdG/kAQGVtjlFbdZaXgG2Wf8uxgOetf29kykFhBDCxTS2rhghhBA1kGAXQggXI8EuhBAuRoJdCCFcjAS7EEK4GAl2IYRwMRLsQgjhYv4fDp4IY3FxhCMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프로 loss 표기\n",
    "#!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_training_loss, label='Train Loss')\n",
    "plt.plot(list_acc_loss, label='Train Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86681fcb-84e3-428c-82ea-fb08f5ea4a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train loss와 Validatiaon acc 출력\n",
    "plt.plot(list_training_loss, label='Train Loss')\n",
    "plt.plot(list_validation_acc_loss, label='Validatiaon Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "986e2215-3eda-471e-be76-bace043b0770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model/classification/bmc-fpt-wiki_20190620_mecab_false_0311-nouns-0327-ft-nli-0328/tokenizer_config.json',\n",
       " 'model/classification/bmc-fpt-wiki_20190620_mecab_false_0311-nouns-0327-ft-nli-0328/special_tokens_map.json',\n",
       " 'model/classification/bmc-fpt-wiki_20190620_mecab_false_0311-nouns-0327-ft-nli-0328/vocab.txt',\n",
       " 'model/classification/bmc-fpt-wiki_20190620_mecab_false_0311-nouns-0327-ft-nli-0328/added_tokens.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 전체모델 저장\n",
    "os.makedirs(OUTPATH, exist_ok=True)\n",
    "#torch.save(model, OUTPATH + 'pytorch_model.bin') \n",
    "model.save_pretrained(OUTPATH)  # save_pretrained 로 저장하면 config.json, pytorch_model.bin 2개의 파일이 생성됨\n",
    "\n",
    "# tokeinizer 파일 저장(vocab)\n",
    "VOCAB_PATH = OUTPATH\n",
    "os.makedirs(VOCAB_PATH,exist_ok=True)\n",
    "tokenizer.save_pretrained(VOCAB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c3933a-a9f5-4dab-80ae-2869ef5aadd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
